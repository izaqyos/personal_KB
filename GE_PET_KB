.........................................Table Of Contents...............................................................
1. introduction <URL:#tn=1. introduction>
		1.2 Terminology <URL:#tn=		1.2 Terminology>
                    1.2.1 radiation related <URL:#tn=                    1.2.1 radiation related>
                    1.2.2 product related <URL:#tn=                    1.2.2 product related>
                    1.2.3  <URL:#tn=                    1.2.3 >
		1.3  New hire doc <URL:#tn=		1.3  New hire doc>
            1.3   <URL:#tn=            1.3  >
2. Coding workflow <URL:#tn=2. Coding workflow>
    2.1 introduction <URL:#tn=    2.1 introduction>
        2.1.1 branches <URL:#tn=        2.1.1 branches>
        2.1.2 create view and branch <URL:#tn=        2.1.2 create view and branch>
            2.1.2.1 My way <URL:#tn=            2.1.2.1 My way>
        2.1.3 commit, Submit change process, code review, collaborator <URL:#tn=        2.1.3 commit, Submit change process, code review, collaborator>
            2.1.3.010 My new step by step procedure <URL:#tn=            2.1.3.010 My new step by step procedure>
            2.1.3.010 My old step by step procedure <URL:#tn=            2.1.3.010 My old step by step procedure>
            2.1.3.1 First time only operations.  <URL:#tn=            2.1.3.1 First time only operations. >
            2.1.3.2 wiki data on how to submit CR via collaborator  <URL:#tn=            2.1.3.2 wiki data on how to submit CR via collaborator >
            2.1.3.3 post diffs <URL:#tn=            2.1.3.3 post diffs>
            2.1.3.4 printCR_Data.py  my tool to get this data <URL:#tn=            2.1.3.4 printCR_Data.py  my tool to get this data>
            2.1.3.5 How To get clearcase data on an element <URL:#tn=            2.1.3.5 How To get clearcase data on an element>
            2.1.3.6 To get list of checked out files: <URL:#tn=            2.1.3.6 To get list of checked out files:>
            2.1.3.7 Kevin's script  <URL:#tn=            2.1.3.7 Kevin's script >
            2.1.3.8 Create new review ID <URL:#tn=            2.1.3.8 Create new review ID>
            2.1.3.9 Shay's ccolab stuff <URL:#tn=            2.1.3.9 Shay's ccolab stuff>
            2.1.3.10 Post changes to an existing review <URL:#tn=            2.1.3.10 Post changes to an existing review>
            2.1.3.11 <URL:#tn=            2.1.3.11>
        2.1.4 merge, diff  <URL:#tn=        2.1.4 merge, diff >
            2.1.4.1 findmerge,  <URL:#tn=            2.1.4.1 findmerge, >
                2.1.4.1.1 merge branches using findmerge <URL:#tn=                2.1.4.1.1 merge branches using findmerge>
                2.1.4.1.1 findmerge <URL:#tn=                2.1.4.1.1 findmerge>
                    2.1.4.1.1.1 merge views using findmerge <URL:#tn=                    2.1.4.1.1.1 merge views using findmerge>
                    2.1.4.1.1.2 findmerge specific files <URL:#tn=                    2.1.4.1.1.2 findmerge specific files>
                    2.1.4.1.1.3 findmerge by branch <URL:#tn=                    2.1.4.1.1.3 findmerge by branch>
                    2.1.4.1.1.4 findmerge aliases <URL:#tn=                    2.1.4.1.1.4 findmerge aliases>
                    2.1.4.1.1.5 findmerge specific file <URL:#tn=                    2.1.4.1.1.5 findmerge specific file>
            2.1.4.2 ct merge  <URL:#tn=            2.1.4.2 ct merge >
            2.1.4.3 Diff specific version <URL:#tn=            2.1.4.3 Diff specific version>
            2.1.4.4 Diff files from two different views (regardless of their checkin state) <URL:#tn=            2.1.4.4 Diff files from two different views (regardless of their checkin state)>
            2.1.4.5 <URL:#tn=            2.1.4.5>
        2.1.4  Roman's cleartool clearcase doc <URL:#tn=        2.1.4  Roman's cleartool clearcase doc>
        2.1.5 My example <URL:#tn=        2.1.5 My example>
            2.1.5.1 a. ct setview pac_col_ddg.4_dev <URL:#tn=            2.1.5.1 a. ct setview pac_col_ddg.4_dev>
            2.1.5.2 create new view <URL:#tn=            2.1.5.2 create new view>
            2.1.5.3 d. edit config-spec <URL:#tn=            2.1.5.3 d. edit config-spec>
                2.1.5.3.1 My first view example <URL:#tn=                2.1.5.3.1 My first view example>
                2.1.5.3.2 My haifa view example <URL:#tn=                2.1.5.3.2 My haifa view example>
                2.1.5.3.3 <URL:#tn=                2.1.5.3.3>
            2.1.5.4 e. create the new branch <URL:#tn=            2.1.5.4 e. create the new branch>
        2.1.6 Checkout checking best practices <URL:#tn=        2.1.6 Checkout checking best practices>
        2.1.7 Static Analysis <URL:#tn=        2.1.7 Static Analysis>
            2.1.7.1 Coverity <URL:#tn=            2.1.7.1 Coverity>
                2.1.7.1.1 Register  <URL:#tn=                2.1.7.1.1 Register >
                2.1.7.1.2 Running Coverity (the simple way) <URL:#tn=                2.1.7.1.2 Running Coverity (the simple way)>
                2.1.7.1.3 <URL:#tn=                2.1.7.1.3>
            2.1.7.2 <URL:#tn=            2.1.7.2>
        2.1.8 Someone else commit made my view not compile.  <URL:#tn=        2.1.8 Someone else commit made my view not compile. >
            2.1.8.1 how to fix  <URL:#tn=            2.1.8.1 how to fix >
            2.1.8.2 <URL:#tn=            2.1.8.2>
        2.1.9 <URL:#tn=        2.1.9>
    2.2	 Build source code <URL:#tn=    2.2	 Build source code>
        2.2.1	 preliminary steps <URL:#tn=        2.2.1	 preliminary steps>
        2.2.2 Build FAQs <URL:#tn=        2.2.2 Build FAQs>
            2.2.2.1 Building pet_raw gives error XrmMergeDatabases <URL:#tn=            2.2.2.1 Building pet_raw gives error XrmMergeDatabases>
        2.2.3 Build haifa view <URL:#tn=        2.2.3 Build haifa view>
            2.2.3.1 Shy tar script -  Copy derived objects <URL:#tn=            2.2.3.1 Shy tar script -  Copy derived objects>
        2.2.4 Build 32bit <URL:#tn=        2.2.4 Build 32bit>
            2.2.4.1  ~/work/scripts/deployAcqBinaries_64.sh  <URL:#tn=            2.2.4.1  ~/work/scripts/deployAcqBinaries_64.sh >
            2.2.4.2 Deploy esoteric binaries <URL:#tn=            2.2.4.2 Deploy esoteric binaries>
            2.2.4.3 Build command line <URL:#tn=            2.2.4.3 Build command line>
            2.2.4.4 Known issues <URL:#tn=            2.2.4.4 Known issues>
                2.2.4.4.1 pet_cal build fails <URL:#tn=                2.2.4.4.1 pet_cal build fails>
                    2.2.4.4.1.1 missing platSerialize lib <URL:#tn=                    2.2.4.4.1.1 missing platSerialize lib>
                    2.2.4.4.1.2 <URL:#tn=                    2.2.4.4.1.2>
                2.2.4.4.2 <URL:#tn=                2.2.4.4.2>
            2.2.4.5 <URL:#tn=            2.2.4.5>
        2.2.5 Build 64bit <URL:#tn=        2.2.5 Build 64bit>
    2.3 Run unit tests <URL:#tn=    2.3 Run unit tests>
        2.3.1 gtest <URL:#tn=        2.3.1 gtest>
            2.3.1.1 set paths <URL:#tn=            2.3.1.1 set paths>
            2.3.1.2 build and run <URL:#tn=            2.3.1.2 build and run>
            2.3.1.3 gtest <URL:#tn=            2.3.1.3 gtest>
                2.3.1.3.1 Common issues <URL:#tn=                2.3.1.3.1 Common issues>
                    2.3.1.3.1.1 error: void value not ignored as it ought to be <URL:#tn=                    2.3.1.3.1.1 error: void value not ignored as it ought to be>
                2.3.1.3.2 <URL:#tn=                2.3.1.3.2>
            2.3.1.4 SubjectMaking Google Unit Tests Into Friend Classes <URL:#tn=            2.3.1.4 SubjectMaking Google Unit Tests Into Friend Classes>
            2.3.1.5 <URL:#tn=            2.3.1.5>
        2.3.2 <URL:#tn=        2.3.2>
    2.4 codeing workflow related aliases <URL:#tn=    2.4 codeing workflow related aliases>
    2.5 <URL:#tn=    2.5>
3. Source code <URL:#tn=3. Source code>
    3.1 Architecture <URL:#tn=    3.1 Architecture>
        3.1.1 petRDFS <URL:#tn=        3.1.1 petRDFS>
        3.1.2 High level diagram <URL:#tn=        3.1.2 High level diagram>
    3.2 RDF <URL:#tn=    3.2 RDF>
        3.2.1  /vobs/pet_platform/source/libH5Wrap/H5Wrap.cpp <URL:#tn=        3.2.1  /vobs/pet_platform/source/libH5Wrap/H5Wrap.cpp>
        3.2.2 /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp <URL:#tn=        3.2.2 /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp>
        3.2.3 <URL:#tn=        3.2.3>
    3.3 RDF Data <URL:#tn=    3.3 RDF Data>
        3.3.1 general <URL:#tn=        3.3.1 general>
        3.3.2 Versions <URL:#tn=        3.3.2 Versions>
            3.3.2.1 RDFv10.0 <URL:#tn=            3.3.2.1 RDFv10.0>
            3.3.2.2 A summary of the more significant RDFv9.0 API and RDF content changes were: <URL:#tn=            3.3.2.2 A summary of the more significant RDFv9.0 API and RDF content changes were:>
        3.3.3 Backward Compatibility Strategy <URL:#tn=        3.3.3 Backward Compatibility Strategy>
        3.3.4 PET Raw File Systems <URL:#tn=        3.3.4 PET Raw File Systems>
        3.3.5 HDF5 <URL:#tn=        3.3.5 HDF5>
        3.3.6 Error Handling and Recovery <URL:#tn=        3.3.6 Error Handling and Recovery>
        3.3.7 PET RDF Contents and File Format <URL:#tn=        3.3.7 PET RDF Contents and File Format>
            3.3.7.1 Header Data <URL:#tn=            3.3.7.1 Header Data>
            3.3.7.2 Bulk Data <URL:#tn=            3.3.7.2 Bulk Data>
                3.3.7.2.1 Histograms <URL:#tn=                3.3.7.2.1 Histograms>
                3.3.7.2.2 Coincidence Event List <URL:#tn=                3.3.7.2.2 Coincidence Event List>
            3.3.7.3 Ancillary Data <URL:#tn=            3.3.7.3 Ancillary Data>
                3.3.7.3.1 Singles Data <URL:#tn=                3.3.7.3.1 Singles Data>
                3.3.7.3.2 Deadtime Data <URL:#tn=                3.3.7.3.2 Deadtime Data>
                3.3.7.3.3 Block Busy Deadtime <URL:#tn=                3.3.7.3.3 Block Busy Deadtime>
                3.3.7.3.4 Block Event Mux Losses <URL:#tn=                3.3.7.3.4 Block Event Mux Losses>
                3.3.7.3.5 RDF code <URL:#tn=                3.3.7.3.5 RDF code>
                3.3.7.3.6 DDG groups and datasets <URL:#tn=                3.3.7.3.6 DDG groups and datasets>
                3.3.7.3.7 <URL:#tn=                3.3.7.3.7>
        3.3.8 RDF tools <URL:#tn=        3.3.8 RDF tools>
            3.3.8.1 rdfTell <URL:#tn=            3.3.8.1 rdfTell>
                3.3.8.1.1 Description <URL:#tn=                3.3.8.1.1 Description>
                3.3.8.1.2 Source code <URL:#tn=                3.3.8.1.2 Source code>
                3.3.8.1.3 <URL:#tn=                3.3.8.1.3>
            3.3.8.2 ListDecode <URL:#tn=            3.3.8.2 ListDecode>
            3.3.8.3 ListTool <URL:#tn=            3.3.8.3 ListTool>
            3.3.8.4 RDF Import Raw List <URL:#tn=            3.3.8.4 RDF Import Raw List>
            3.3.8.5 RDF Reducer <URL:#tn=            3.3.8.5 RDF Reducer>
            3.3.8.6 rdfImportRawList  <URL:#tn=            3.3.8.6 rdfImportRawList >
            3.3.8.7 SyntheticListData , generate Synthetic List Data, rdfImportRawList and addMotion  <URL:#tn=            3.3.8.7 SyntheticListData , generate Synthetic List Data, rdfImportRawList and addMotion >
                3.3.8.7.1 how to run <URL:#tn=                3.3.8.7.1 how to run>
                3.3.8.7.2 code <URL:#tn=                3.3.8.7.2 code>
                3.3.8.7.3 generateListData binary code <URL:#tn=                3.3.8.7.3 generateListData binary code>
                    3.3.8.7.3.1 generateListData ClearCase location <URL:#tn=                    3.3.8.7.3.1 generateListData ClearCase location>
                    3.3.8.7.3.2 Code <URL:#tn=                    3.3.8.7.3.2 Code>
                    3.3.8.7.3.3 Functionality breakdown <URL:#tn=                    3.3.8.7.3.3 Functionality breakdown>
                    3.3.8.7.3.4 <URL:#tn=                    3.3.8.7.3.4>
                3.3.8.7.4 <URL:#tn=                3.3.8.7.4>
        3.3.9 Source files RDF <URL:#tn=        3.3.9 Source files RDF>
        3.3.10 RDF accept, rdfAccept <URL:#tn=        3.3.10 RDF accept, rdfAccept>
            3.3.10.1 RDF Accept breakdown <URL:#tn=            3.3.10.1 RDF Accept breakdown>
            3.3.10.2 rdfAccept configuration - /usr/PET/systemConfig/rdfAccept.cfg   <URL:#tn=            3.3.10.2 rdfAccept configuration - /usr/PET/systemConfig/rdfAccept.cfg  >
                3.3.10.2.1 Michael mail <URL:#tn=                3.3.10.2.1 Michael mail>
                3.3.10.2.2 Fix error ConversionPipeline.Warn  ConversionPipeline.cc(137) in readGeometry(): There is no handler registered for this RDF version. <URL:#tn=                3.3.10.2.2 Fix error ConversionPipeline.Warn  ConversionPipeline.cc(137) in readGeometry(): There is no handler registered for this RDF version.>
                3.3.10.2.3 Error - [rdfAccept.cc] Failed product compatibility check. <URL:#tn=                3.3.10.2.3 Error - [rdfAccept.cc] Failed product compatibility check.>
                    3.3.10.2.3.1 code <URL:#tn=                    3.3.10.2.3.1 code>
                3.3.10.2.4 Another mail re. product compatibility check <URL:#tn=                3.3.10.2.4 Another mail re. product compatibility check>
                3.3.10.2.5 <URL:#tn=                3.3.10.2.5>
            3.3.10.3 <URL:#tn=            3.3.10.3>
        3.3.11 logging <URL:#tn=        3.3.11 logging>
            3.3.11.1 instructions for using logging infrastructure in PET. <URL:#tn=            3.3.11.1 instructions for using logging infrastructure in PET.>
            3.3.11.2 LOG_MSG_ERROR , LOG_MSG_DEBUG macros <URL:#tn=            3.3.11.2 LOG_MSG_ERROR , LOG_MSG_DEBUG macros>
            3.3.11.3 <URL:#tn=            3.3.11.3>
        3.3.12 <URL:#tn=        3.3.12>
    3.4 Acquisition flow <URL:#tn=    3.4 Acquisition flow>
        3.4.1 high level description <URL:#tn=        3.4.1 high level description>
        3.4.2 Source code pointer <URL:#tn=        3.4.2 Source code pointer>
            3.4.2.1 Pre mice  <URL:#tn=            3.4.2.1 Pre mice >
                3.4.2.1.1 useful greps <URL:#tn=                3.4.2.1.1 useful greps>
                3.4.2.1.2 Allocates memory <URL:#tn=                3.4.2.1.2 Allocates memory>
                3.4.2.1.3 libcldevices main receive loop <URL:#tn=                3.4.2.1.3 libcldevices main receive loop>
                    3.4.2.1.3.1 Some linked list Q references <URL:#tn=                    3.4.2.1.3.1 Some linked list Q references>
                    3.4.2.1.3.2 <URL:#tn=                    3.4.2.1.3.2>
                3.4.2.1.4 Main processing, /vobs/pet_acq/source/libsortMain/SorterMain.cpp <URL:#tn=                3.4.2.1.4 Main processing, /vobs/pet_acq/source/libsortMain/SorterMain.cpp>
                    3.4.2.1.4.1 class CSorterMain  <URL:#tn=                    3.4.2.1.4.1 class CSorterMain >
                    3.4.2.1.4.2 void CSorterMain::StartScan( CE_SORT_TYPE sortType ) <URL:#tn=                    3.4.2.1.4.2 void CSorterMain::StartScan( CE_SORT_TYPE sortType )>
                    3.4.2.1.4.3 void CSorterMain::RunCyclic() -> ProcessCoinEvents() <URL:#tn=                    3.4.2.1.4.3 void CSorterMain::RunCyclic() -> ProcessCoinEvents()>
                    3.4.2.1.4.4 get events <URL:#tn=                    3.4.2.1.4.4 get events>
                3.4.2.1.5 Control thread     pet_acq/libacqCtrl/acqmain.cpp <URL:#tn=                3.4.2.1.5 Control thread     pet_acq/libacqCtrl/acqmain.cpp>
            3.4.2.2 post mice <URL:#tn=            3.4.2.2 post mice>
            3.4.2.3 <URL:#tn=            3.4.2.3>
        3.4.3 <URL:#tn=        3.4.3>
    3.5 infrastructure <URL:#tn=    3.5 infrastructure>
        3.5.1  libgebase2 <URL:#tn=        3.5.1  libgebase2>
            3.5.1.1  /vobs/pet_raw/source/rdfAPI/libRawPrimitives/MemDataBuf.h <URL:#tn=            3.5.1.1  /vobs/pet_raw/source/rdfAPI/libRawPrimitives/MemDataBuf.h>
        3.5.2 <URL:#tn=        3.5.2>
    3.6 MICE events format <URL:#tn=    3.6 MICE events format>
        3.6.1 convert Galileo To Mice  <URL:#tn=        3.6.1 convert Galileo To Mice >
        3.6.2 <URL:#tn=        3.6.2>
    3.7 <URL:#tn=    3.7>
4.  Machines <URL:#tn=4.  Machines>
    4.1  Dev <URL:#tn=    4.1  Dev>
    4.2 Set X-11 display to laptop <URL:#tn=    4.2 Set X-11 display to laptop>
    4.3 Reserve, Register time to work on test machine <URL:#tn=    4.3 Reserve, Register time to work on test machine>
    4.4 test Machines <URL:#tn=    4.4 test Machines>
        4.4.1  List of test machines <URL:#tn=        4.4.1  List of test machines>
        4.4.2 Test machines Wiki guides <URL:#tn=        4.4.2 Test machines Wiki guides>
            4.4.2.1 Working with PET machines  <URL:#tn=            4.4.2.1 Working with PET machines >
                4.4.2.1.1 Connecting <URL:#tn=                4.4.2.1.1 Connecting>
                4.4.2.1.2 Config files <URL:#tn=                4.4.2.1.2 Config files>
                4.4.2.1.3 UI actions <URL:#tn=                4.4.2.1.3 UI actions>
                4.4.2.1.4 Shell commands <URL:#tn=                4.4.2.1.4 Shell commands>
                4.4.2.1.5 Applications <URL:#tn=                4.4.2.1.5 Applications>
                4.4.2.1.6 App management: <URL:#tn=                4.4.2.1.6 App management:>
                4.4.2.1.7 Env variables <URL:#tn=                4.4.2.1.7 Env variables>
                4.4.2.1.8 <URL:#tn=                4.4.2.1.8>
            4.4.2.2 PAARTF  wiki <URL:#tn=            4.4.2.2 PAARTF  wiki>
                4.4.2.2.1 Installing PAARTF on a console <URL:#tn=                4.4.2.2.1 Installing PAARTF on a console>
                4.4.2.2.2 Connecting with VNC to a console <URL:#tn=                4.4.2.2.2 Connecting with VNC to a console>
                4.4.2.2.3 Intalling PAARTF on console: <URL:#tn=                4.4.2.2.3 Intalling PAARTF on console:>
                4.4.2.2.4 Running PAARTF on a console <URL:#tn=                4.4.2.2.4 Running PAARTF on a console>
                4.4.2.2.5 Extending PAARTF (PAARTF behind the scenes) <URL:#tn=                4.4.2.2.5 Extending PAARTF (PAARTF behind the scenes)>
                4.4.2.2.6 <URL:#tn=                4.4.2.2.6>
        4.4.3 <URL:#tn=        4.4.3>
    4.5 My local dev machine yosiidev  <URL:#tn=    4.5 My local dev machine yosiidev >
        4.5.1  passwords <URL:#tn=        4.5.1  passwords>
        4.5.2 login <URL:#tn=        4.5.2 login>
        4.5.3 configure DHCP <URL:#tn=        4.5.3 configure DHCP>
    4.6 Host machines <URL:#tn=    4.6 Host machines>
        4.6.1 :/home/de680136//work/scripts/ <URL:#tn=        4.6.1 :/home/de680136//work/scripts/>
    4.7 <URL:#tn=    4.7>
5. Test enviroment <URL:#tn=5. Test enviroment>
    5.1 PAARTF petack test  <URL:#tn=    5.1 PAARTF petack test >
        5.1.1 Workflow for tests <URL:#tn=        5.1.1 Workflow for tests>
        5.1.2  PAARTF documents <URL:#tn=        5.1.2  PAARTF documents>
            5.1.2.1  PET Acquisition Auto Regression Test Facility <URL:#tn=            5.1.2.1  PET Acquisition Auto Regression Test Facility>
                5.1.2.1.1  Installing PAARTF on a console <URL:#tn=                5.1.2.1.1  Installing PAARTF on a console>
                5.1.2.1.2 Connecting with VNC to a console <URL:#tn=                5.1.2.1.2 Connecting with VNC to a console>
                5.1.2.1.3 Intalling PAARTF on console <URL:#tn=                5.1.2.1.3 Intalling PAARTF on console>
                5.1.2.1.4 Running PAARTF on a console <URL:#tn=                5.1.2.1.4 Running PAARTF on a console>
            5.1.2.2 Test and gold qualification <URL:#tn=            5.1.2.2 Test and gold qualification>
            5.1.2.3 myworkshop docs. search paartf <URL:#tn=            5.1.2.3 myworkshop docs. search paartf>
                5.1.2.3.1 PAARTF SDD <URL:#tn=                5.1.2.3.1 PAARTF SDD>
                    5.1.2.3.1.1 High level <URL:#tn=                    5.1.2.3.1.1 High level>
                    5.1.2.3.1.2 ClearCase tree <URL:#tn=                    5.1.2.3.1.2 ClearCase tree>
                        5.1.2.3.1.2.1 Detailed tree <URL:#tn=                        5.1.2.3.1.2.1 Detailed tree>
                    5.1.2.3.1.3 Install <URL:#tn=                    5.1.2.3.1.3 Install>
                    5.1.2.3.1.4 Running PAARTF  <URL:#tn=                    5.1.2.3.1.4 Running PAARTF >
                    5.1.2.3.1.5 Configuration  <URL:#tn=                    5.1.2.3.1.5 Configuration >
                    5.1.2.3.1.6 PAARTF Database files <URL:#tn=                    5.1.2.3.1.6 PAARTF Database files>
                    5.1.2.3.1.7 PAARTF Sequence Files <URL:#tn=                    5.1.2.3.1.7 PAARTF Sequence Files>
                    5.1.2.3.1.8 PAARTF Sequence Scripts <URL:#tn=                    5.1.2.3.1.8 PAARTF Sequence Scripts>
                    5.1.2.3.1.9 PAARTF Supporting Files <URL:#tn=                    5.1.2.3.1.9 PAARTF Supporting Files>
                    5.1.2.3.1.10 PetAcqMgr <URL:#tn=                    5.1.2.3.1.10 PetAcqMgr>
                    5.1.2.3.1.11 Calibration Processing Libraries  <URL:#tn=                    5.1.2.3.1.11 Calibration Processing Libraries >
                    5.1.2.3.1.12 DetCalServer  <URL:#tn=                    5.1.2.3.1.12 DetCalServer >
                    5.1.2.3.1.13 Calibration Tools <URL:#tn=                    5.1.2.3.1.13 Calibration Tools>
                    5.1.2.3.1.14 DetPerfTool <URL:#tn=                    5.1.2.3.1.14 DetPerfTool>
                    5.1.2.3.1.15 rtsClient <URL:#tn=                    5.1.2.3.1.15 rtsClient>
                    5.1.2.3.1.16 CmdLineServer <URL:#tn=                    5.1.2.3.1.16 CmdLineServer>
                    5.1.2.3.1.17 Processing scripts (startRTSClient, saveRTSData, endRTSClient, logMemUsage) <URL:#tn=                    5.1.2.3.1.17 Processing scripts (startRTSClient, saveRTSData, endRTSClient, logMemUsage)>
                    5.1.2.3.1.18 rdfTell, rdfSnoop and objEvRdfSnoop <URL:#tn=                    5.1.2.3.1.18 rdfTell, rdfSnoop and objEvRdfSnoop>
                        5.1.2.3.1.18.1 /vobs/pet_acq_test/source/acqAutoTest/common/bin/ScanRunnerScripts/rdfSnoop <URL:#tn=                        5.1.2.3.1.18.1 /vobs/pet_acq_test/source/acqAutoTest/common/bin/ScanRunnerScripts/rdfSnoop>
                    5.1.2.3.1.19 objEvDbQuery, dbQuery, petQueryTool and dbFilter <URL:#tn=                    5.1.2.3.1.19 objEvDbQuery, dbQuery, petQueryTool and dbFilter>
                    5.1.2.3.1.20 calTell, calSnoop <URL:#tn=                    5.1.2.3.1.20 calTell, calSnoop>
                    5.1.2.3.1.21 dcsSnoop, cleanDCSLog, saveDCSLOG <URL:#tn=                    5.1.2.3.1.21 dcsSnoop, cleanDCSLog, saveDCSLOG>
                    5.1.2.3.1.22 System <URL:#tn=                    5.1.2.3.1.22 System>
                    5.1.2.3.1.23 <URL:#tn=                    5.1.2.3.1.23>
                5.1.2.3.2 <URL:#tn=                5.1.2.3.2>
            5.1.2.4 Add PAARTF test <URL:#tn=            5.1.2.4 Add PAARTF test>
                5.1.2.4.1 Example CR <URL:#tn=                5.1.2.4.1 Example CR>
                5.1.2.4.2 Sravan's explanation <URL:#tn=                5.1.2.4.2 Sravan's explanation>
                5.1.2.4.3 <URL:#tn=                5.1.2.4.3>
            5.1.2.5 Source code <URL:#tn=            5.1.2.5 Source code>
                5.1.2.5.1 GUI <URL:#tn=                5.1.2.5.1 GUI>
                5.1.2.5.2 scanRunner <URL:#tn=                5.1.2.5.2 scanRunner>
                5.1.2.5.3 <URL:#tn=                5.1.2.5.3>
            5.1.2.6 Mike's email <URL:#tn=            5.1.2.6 Mike's email>
            5.1.2.7 <URL:#tn=            5.1.2.7>
        5.1.3 <URL:#tn=        5.1.3>
    5.2 Manual test RDF tools <URL:#tn=    5.2 Manual test RDF tools>
        5.2.1  Test RDF Accept <URL:#tn=        5.2.1  Test RDF Accept>
            5.2.1.0  my manual test procedure <URL:#tn=            5.2.1.0  my manual test procedure>
            5.2.1.1  Test without changes <URL:#tn=            5.2.1.1  Test without changes>
        5.2.2 Test modified rdfAccept code <URL:#tn=        5.2.2 Test modified rdfAccept code>
            5.2.2.1 a. modify code, build  <URL:#tn=            5.2.2.1 a. modify code, build >
            5.2.2.2 b. deploy to test machine <URL:#tn=            5.2.2.2 b. deploy to test machine>
                5.2.2.2.1 deployRDFBinaries <URL:#tn=                5.2.2.2.1 deployRDFBinaries>
                5.2.2.2.2 <URL:#tn=                5.2.2.2.2>
            5.2.2.3 c. Apply changed so <URL:#tn=            5.2.2.3 c. Apply changed so>
            5.2.2.4 d. patch/unpatch/display scripts <URL:#tn=            5.2.2.4 d. patch/unpatch/display scripts>
            5.2.2.5 Test in sandbox <URL:#tn=            5.2.2.5 Test in sandbox>
            5.2.2.6  My 9.0 to 9.8 rdfAccept tester <URL:#tn=            5.2.2.6  My 9.0 to 9.8 rdfAccept tester>
            5.2.2.7 <URL:#tn=            5.2.2.7>
        5.2.3 Where are RDF files? <URL:#tn=        5.2.3 Where are RDF files?>
            5.2.3.1 RDF files <URL:#tn=            5.2.3.1 RDF files>
            5.2.3.2 List files <URL:#tn=            5.2.3.2 List files>
            5.2.3.3 Norm Corrections files <URL:#tn=            5.2.3.3 Norm Corrections files>
            5.2.3.4 <URL:#tn=            5.2.3.4>
        5.2.4 <URL:#tn=        5.2.4>
    5.3 Test using real host GUI <URL:#tn=    5.3 Test using real host GUI>
        5.3.1 Connect to GUI <URL:#tn=        5.3.1 Connect to GUI>
        5.3.2 Pull out specific image files using GUI <URL:#tn=        5.3.2 Pull out specific image files using GUI>
            5.3.2.1  Pull out norm Corrections  image files using GUI <URL:#tn=            5.3.2.1  Pull out norm Corrections  image files using GUI>
                5.3.2.1.1   <URL:#tn=                5.3.2.1.1  >
                5.3.2.1.2 <URL:#tn=                5.3.2.1.2>
            5.3.2.2 <URL:#tn=            5.3.2.2>
        5.3.3 <URL:#tn=        5.3.3>
    5.4 customize test env <URL:#tn=    5.4 customize test env>
        5.4.1 Deploy My environment  <URL:#tn=        5.4.1 Deploy My environment >
        5.4.2 <URL:#tn=        5.4.2>
    5.5 binaries locations <URL:#tn=    5.5 binaries locations>
        5.5.1 PAR (PET Acquisition and Reconstruction inner host) <URL:#tn=        5.5.1 PAR (PET Acquisition and Reconstruction inner host)>
            5.5.1.1 pet_acq - main Acquisition Executable  <URL:#tn=            5.5.1.1 pet_acq - main Acquisition Executable >
        5.5.2 Host machine <URL:#tn=        5.5.2 Host machine>
        5.5.3 <URL:#tn=        5.5.3>
    5.6 Manage machine <URL:#tn=    5.6 Manage machine>
        5.6.1  List services <URL:#tn=        5.6.1  List services>
        5.6.2 stop all services <URL:#tn=        5.6.2 stop all services>
        5.6.3 restart machine <URL:#tn=        5.6.3 restart machine>
        5.6.4 patch machine <URL:#tn=        5.6.4 patch machine>
        5.6.5 Get machine version <URL:#tn=        5.6.5 Get machine version>
            5.6.5.1 swhwinfo  <URL:#tn=            5.6.5.1 swhwinfo >
            5.6.5.2  petbayinfo  <URL:#tn=            5.6.5.2  petbayinfo >
            5.6.5.3 <URL:#tn=            5.6.5.3>
        5.6.6 <URL:#tn=        5.6.6>
    5.7 <URL:#tn=    5.7>
6. Development <URL:#tn=6. Development>
    6.1 rdfAccept <URL:#tn=    6.1 rdfAccept>
        6.1.1 9.7 UserBlock support <URL:#tn=        6.1.1 9.7 UserBlock support>
        6.1.2 MICE support <URL:#tn=        6.1.2 MICE support>
            6.1.2.1 MICE code <URL:#tn=            6.1.2.1 MICE code>
            6.1.2.2 rdfAccept Conversion <URL:#tn=            6.1.2.2 rdfAccept Conversion>
            6.1.2.3 CRdfList code list file  <URL:#tn=            6.1.2.3 CRdfList code list file >
                6.1.2.3.1 CRdfList create list command line <URL:#tn=                6.1.2.3.1 CRdfList create list command line>
                6.1.2.3.2 rdfImportRawList CLI <URL:#tn=                6.1.2.3.2 rdfImportRawList CLI>
                6.1.2.3.3 rdfAccept convert list file <URL:#tn=                6.1.2.3.3 rdfAccept convert list file>
                6.1.2.3.4 list dataset references <URL:#tn=                6.1.2.3.4 list dataset references>
                6.1.2.3.5 <URL:#tn=                6.1.2.3.5>
            6.1.2.4 Integration points <URL:#tn=            6.1.2.4 Integration points>
                6.1.2.4.1 DSS, DDWave <URL:#tn=                6.1.2.4.1 DSS, DDWave>
                    6.1.2.4.1.1 email: Hello Roman and Yosi, <URL:#tn=                    6.1.2.4.1.1 email: Hello Roman and Yosi,>
                6.1.2.4.2 My details <URL:#tn=                6.1.2.4.2 My details>
                6.1.2.4.3 <URL:#tn=                6.1.2.4.3>
            6.1.2.5 l2mice makeDynData <URL:#tn=            6.1.2.5 l2mice makeDynData>
            6.1.2.6 Guidance on periodic GalileoCoincEvtDefs::PET_LINK_EVT_COINC_COUNT <URL:#tn=            6.1.2.6 Guidance on periodic GalileoCoincEvtDefs::PET_LINK_EVT_COINC_COUNT>
                6.1.2.6.1 Mike's email  <URL:#tn=                6.1.2.6.1 Mike's email >
                6.1.2.6.2 <URL:#tn=                6.1.2.6.2>
            6.1.2.7 <URL:#tn=            6.1.2.7>
        6.1.3 Last dev cycle <URL:#tn=        6.1.3 Last dev cycle>
            6.1.3.1 Clearcase details <URL:#tn=            6.1.3.1 Clearcase details>
                6.1.3.1.1  branch yosi4_pac_col_ddgv, view yosi1_haifa_pac_col_ddg <URL:#tn=                6.1.3.1.1  branch yosi4_pac_col_ddgv, view yosi1_haifa_pac_col_ddg>
                6.1.3.1.2 <URL:#tn=                6.1.3.1.2>
        6.1.4 rdfAccept MICE test strategy <URL:#tn=        6.1.4 rdfAccept MICE test strategy>
            6.1.4.1  use ListDecode <URL:#tn=            6.1.4.1  use ListDecode>
            6.1.4.2 Actuall tests <URL:#tn=            6.1.4.2 Actuall tests>
                6.1.4.2.1 tests history file  <URL:#tn=                6.1.4.2.1 tests history file >
                6.1.4.2.2 mail 2 mike <URL:#tn=                6.1.4.2.2 mail 2 mike>
                6.1.4.2.3 <URL:#tn=                6.1.4.2.3>
            6.1.4.3 <URL:#tn=            6.1.4.3>
        6.1.5 <URL:#tn=        6.1.5>
    6.2 PAARTF Development <URL:#tn=    6.2 PAARTF Development>
        6.2.1 Important locations <URL:#tn=        6.2.1 Important locations>
            6.2.1.1 List files used for PAARTF <URL:#tn=            6.2.1.1 List files used for PAARTF>
            6.2.1.2 <URL:#tn=            6.2.1.2>
        6.2.2 <URL:#tn=        6.2.2>
    6.3 <URL:#tn=    6.3>
7. CRs, Code reviews <URL:#tn=7. CRs, Code reviews>
    7.1 Offer <URL:#tn=    7.1 Offer>
        7.1.1 SinoMath, https://collaborator.engops.health.ge.com/ui#review:id=182826 <URL:#tn=        7.1.1 SinoMath, https://collaborator.engops.health.ge.com/ui#review:id=182826>
        7.1.2 <URL:#tn=        7.1.2>
    7.2 Yony <URL:#tn=    7.2 Yony>
        7.2.1 You are a Required reviewer for new Review #183224: "Mice1". <URL:#tn=        7.2.1 You are a Required reviewer for new Review #183224: "Mice1".>
    7.3 Roman <URL:#tn=    7.3 Roman>
    7.4 Michael Cook <URL:#tn=    7.4 Michael Cook>
        7.4.1 Subject: rdfAccept fix for making 'valid' Deadtime & Block Temperature datasets <URL:#tn=        7.4.1 Subject: rdfAccept fix for making 'valid' Deadtime & Block Temperature datasets>
        7.4.2 <URL:#tn=        7.4.2>
    7.5 <URL:#tn=    7.5>
8.  passwords <URL:#tn=8.  passwords>
    8.1  PET Host machines (e.g. jaws4) <URL:#tn=    8.1  PET Host machines (e.g. jaws4)>
    8.2 <URL:#tn=    8.2>
9. Tools <URL:#tn=9. Tools>
    9.1 valgrind  <URL:#tn=    9.1 valgrind >
    9.2 <URL:#tn=    9.2>
10. <URL:#tn=10.>
.................................................END TOC..............................................


















1. introduction

		1.2 Terminology
                    1.2.1 radiation related
PET - positron emission tomography
CT - computerized tomography

Curie Ci 3.7X10^10
MilliCurie Ci 3.7X10^7
MicroCurie Ci 3.7X10^4
Becquerel Bq , 1 decay per sec, 2.7X10^-11Ci
MegaBecquerel MBq , 10^6 decay per sec, 370Mbq=10mCi
LoR - Line of response 
PMT - Photo multiplier Tube
TOF- Time of flight (TOF) is a property of an object, particle or acoustic, electromagnetic or other wave. It is the time that such an object needs to travel a distance through a medium. The measurement of this time (i.e. the time of flight) can be used for a time standard (such as an atomic fountain), as a way to measure velocity or path length through a given medium, or as a way to learn about the particle or medium (such as composition or flow rate). 

FBP - Filtered Backprojection

                    1.2.2 product related
CSE - separate project, DB layer 
PET - Photon emissions tomography
SPECT -  different product
nuke - SPECT
DMI - Discovery MI 
TGP - Table Gantry processing board 
DAS - Date acquisition 
ORP - Detector Tube
DMOD - Detector Modulator
PROP - coincidence Detector
PARC - PET  acquisition and Reconstruction 
Xeleris - work station
VolC - technician access to PET
PET SOC - PET System operation control
PAC - PET Acquisition 
scout - short preliminary CT scan
CT - computerized tomography
ISS - Detector team, PROP + DMOD 
DQA - Daily QA
SRM - System readinesses monitor
IOW - Inside Out Watch , data stream outside for analysis



                    1.2.3 


		1.3  New hire doc
Basic needs
Entrance/Exit front door time keeper
Entrance	Exit	
| 1.	F1
| 2.	92
| 3.	F4
| 4.	Wave your badge	1.	F2
| 2.	92
| 3.	F4
| 4.	Wave your badge	F1 for entrance, F2 for exit
92 is PET project
F4 is OK
Make sure your badge is caught

Hilanet
Link	https://ge.net.hilan.co.il/login
Login	SSO
Password	You will get mail with initial password and instructions

Cibus
Link	http://cibus.co.il/new_default.aspx 
Username	SSO
Password	1234
Company name	GE-MI

Transportation
Talk to your team lead if you need transportation
Link	http://3.213.42.129/HaifaTransportation/Account/Login.aspx 
Username	SSO
Password	elgems

GE IT ServiceNow helpdesk
Open IT related tickets
https://ge.service-now.com/Helpdesk/

GE web mail
https://budurbpa06.e2k.ad.ge.com/owa/?modurl=0 

NM Haifa portal - many useful links and information
Your starting point to many GE resources
http://supportcentral.ge.com/products/sup_products.asp?prod_id=187578 

My Workshop
Repository for documents, search for any DOCxxxxxxx
http://data.supportcentral.ge.com/data/sup_document.asp?id=3498716&type=doc 

GE Learning
https://geportal.sumtotalsystems.com/sites/100054/SitePages/GE_Learning.aspx

Development needs
MyTech  when you need to install software tools
https://ge.service-now.com/mytech/home.do
 
Rally
https://rally1.rallydev.com/#/69743579912d/dashboard

Code collaborator https://collaborator.engops.health.ge.com/ui 
Haifa PAC confluence
https://devcloud.swcoe.ge.com/devspace/display/UMCOA/PET+Haifa+-+temp 




PAC confluence
https://devcloud.swcoe.ge.com/devspace/pages/viewpage.action?spaceKey=WMKDA&title=PET+Software+Home 
	
Haifa Box


Coverity











ClearQuest

ClearCase
Step 1
Complete the following online courses from GE Learning. Use Internet Explorer for doing them and make sure to save a screenshot of completion certificate.
ClearCase WI-MI-Haifa	GEHC-TECH-QMS35474988
NM ClearCase Fundamentals	GEHC-TECH-HCS34739016
ClearQuest Defect Management - Base User	GEHC-TECH-CM30609390_CURR

Step 2

Step 3














Step 4

Step 5  remember to change highlighted to your new Unix login

Step 6  remember to change highlighted to your Unix login

Step 7

Step 8
Connect via SSH (preferably using MobaXterm) to the servers:
1) ctds64-1        3.87.209.39
2) ctds64-2        3.87.209.40
3) ctds32-1        3.87.209.35
4) ctds32-2        3.87.209.36        


















            1.3  


2. Coding workflow

    2.1 introduction

        2.1.1 branches
main program branch:                pet_columbia  , NPI branch
PAC branch (build 103 of above):    pac_col_ddg   , informal PAC branch. TBD .4 and .4_dev
my branches need to derive from pac_col_ddg , e.g. yosi_pac_col_ddg

Build view: pac_col_ddg.4
Dev view: pac_col_ddg.4_dev
Label: PAC_COL_DDG.4

For  main program branch there would be two views. N and N-1 dev. The motivation is develop on N-1 until ready. Then use N view for product.
Ex:
N:
[de680136@ctds64-1:2018-04-03 10:46:35:~:]3097$ ct lsview | grep columb | grep 133
* pet_columbia.133     /view_store/ctbld_vws/ctbuild/pet_columbia.133.vws

N-1 dev
[de680136@ctds64-1:2018-04-03 10:49:54:~:]3099$ ct lsview | grep columb | grep 132 | grep dev
  pet_columbia.132_dev /view_store/ctbld_vws/ctbuild/pet_columbia.132_dev.vws

id=__GE_ClearCase_Usage__
        2.1.2 create view and branch

            2.1.2.1 My way


a. run ctcreateview script:
[de680136@nmpetdev64:2018-04-04 09:54:53:~:]5117$ ctcreateview yosi1_haifa_col133
creating view yosi1_haifa_col133. running: cleartool mkview -tag yosi1_haifa_col133 /view_store/ctbld_vws/yosi1_haifa_col133  
Created view.
Host-local path: ilhaimiviews:/view_store/ctbld_vws/yosi1_haifa_col133
Global path:     /view_store/ctbld_vws/yosi1_haifa_col133
It has the following rights:
User : de680136 : rwx
Group: hmi_sw   : r-x
Other:          : r-x
reminder. set config spec (ctedcs, branch yosi1_haifa_col133_br ) and create branches for favourite vobs. Example:
ct mkbrtype -pbr -nc  branch_name@/vobs/pet_acq
ct mkbrtype -pbr -nc  branch_name@/vobs/pet_raw
ct mkbrtype -pbr -nc  branch_name@/vobs/pet_platform
Script can create branch with name yosi1_haifa_col133_br for vobs: /vobs/pet_platform /vobs/pet_ddwave/ /vobs/pet_cal /vobs/pet_acq /vobs/pet_acq_test /vobs/pet_raw 
Do you want to create branches? y/ny
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_platform 
Created branch type "yosi1_haifa_col133_br".
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_ddwave/ 
Created branch type "yosi1_haifa_col133_br".
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_cal 
Created branch type "yosi1_haifa_col133_br".
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_acq 
Created branch type "yosi1_haifa_col133_br".
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_acq_test 
Created branch type "yosi1_haifa_col133_br".
Creating branch with name yosi1_haifa_col133_br for vob /vobs/pet_raw 
Created branch type "yosi1_haifa_col133_br".
branches created

b. enter view
[de680136@nmpetdev64:2018-04-04 09:55:10:~:]5118$ ct setview yosi1_haifa_col133
cleartool: Warning: Unable to get current directory: Invalid argument.
cleartool: Warning: Setting current working directory to "/".
Loading yizaq BASHRC for GE  Linux environment
LOADING de680136 aliases for GE Linux environment

c. edit config-spec 

$ctedcs 
:%d
:r/copyofSourceViewConfigSpec
:wq!

d. Add to svs alias


a. setview pac_col_ddg 
b.  (/vobs/util/scripts/)newview yosi_pac_col_ddg
    for haifa 
        ct setview shy_hfa_pac_col_ddg.4
        /vobs/util/scripts/newview yosi_haifa_pac_col_ddg
        If newview fails use
                ct mkview -tag yosi_haifa_pac_col_ddg /view_store/ctbld_vws/yosi_haifa_pac_col_ddg  
                 
        /vobs/util/scripts/newview yony_haifa_pac_col_ddg
        If newview fails use
                ct mkview -tag yony_haifa_pac_col_ddg /view_store/ctbld_vws/yony_haifa_pac_col_ddg  
        ct catcs > ~/yosi_cs

c. exit view and set to new view
e.g.
ct setview yosi_haifa_pac_col_ddg
ct setview yony_haifa_pac_col_ddg

d. edit config spec
ct edcs
use branch name e.g. yosi_pac_col_ddg

e.  <URL:#r=__cli_make_new_branch__>

using script:
newbranch create above refenced branch

checkout checkin

        2.1.3 commit, Submit change process, code review, collaborator

id=__GE_my_steps_prepare_CR__
            2.1.3.010 My new step by step procedure

prep list of changes using branch name:
[de680136@nmpetdev64:2018-03-14 10:32:38:/vobs/pet_raw/source/rdfAPI/libMice:]5320$ prepareReviewChanges.sh  yosi4_pac_col_ddgv > ~/mice_changes

<URL:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/DevHomeDir/de680136/work/scripts/prepareReviewChanges.sh>

review chances:
[de680136@nmpetdev64:2018-03-14 10:27:18:/vobs/pet_raw/source/rdfAPI/libMice:]5157$ prepareReviewChanges.py ~/mice_changes  vd i
<URL:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/DevHomeDir/de680136/work/scripts/prepareReviewChanges.py>

            2.1.3.010 My old step by step procedure
-> list Cos
ctlsco > ~/cofiles

e.g. 
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ cleartool lscheckout -cview -me -avobs
w/ alias...
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ctlsco
--12-06T01:43  de680136   checkout version "ConversionPipeline.cc" from /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/0 (reserved)
  "Support RDF 9.9 user block for RDF accept."
--12-20T00:58  de680136   checkout version "rdfConvertUtils9.0to10.0.cc" from /main/pac_col_ddg/yosi1_pac_col_ddg/1 (reserved)
--12-07T02:48  de680136   checkout version "rdfConvertUtils9.0to10.0.h" from /main/pac_col_ddg/yosi1_pac_col_ddg/0 (reserved)
  "RDF Accept v9.x to 10. add user block support."

cleartool lscheckout -cview -me -avobs

-> checkin
$ for l in $(ctlsco ) ; do echo "checking in $l"; ct ci $l ;done 
or 
$ ctciall
or
$ for file in $(cat ~/cofiles ); do ct ci $file; done


-> Create change list file
files:
ConversionPipeline.cc
rdfConvertUtils9.0to10.0.cc
rdfConvertUtils9.0to10.0.h

find each one. e.g.
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$ find -name 'ConversionPipeline.cc'
./librdfAccept/rdfAcceptLib/ConversionPipeline.cc

use printCR_Data.py 
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$ printCR_Data.py ./librdfAccept/rdfAcceptLib/ConversionPipeline.cc > ~/changes
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$ printCR_Data.py ./librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc >> ~/changes
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$ printCR_Data.py ./librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.h >> ~/changes

or in loop...
[de680136@ctds64-1:2018-01-10 03:12:38:~:]2051$ for file in $(ctlsco ); do ~/work/scripts/printCR_Data.py  $file >> ~/changes2; done
[de680136@ctds64-1:2018-01-10 03:14:56:~:]2052$ cat ~/changes2 
/vobs/pet_raw/source/rdfAPI/librdfCpp/RdfFile.cpp /main/pet_columbia/pac_col_ddg/yosi2_pac_col_ddg/CHECKEDOUT /main/pet_columbia/pac_col_ddg/yosi2_pac_col_ddg/0
/vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp /main/pet_columbia/pac_col_ddg/yosi2_pac_col_ddg/CHECKEDOUT /main/pet_columbia/pac_col_ddg/yosi2_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc /main/pac_col_ddg/yosi2_pac_col_ddg/CHECKEDOUT /main/pac_col_ddg/yosi2_pac_col_ddg/0

better way is to loop over all files that have my branch. e.g.
[de680136@nmpetdev64:2018-03-12 14:08:01:/vobs/pet_raw/source:]5219$ cat !!:0
cat ~de680136/work/scripts/prepareReviewChanges.sh
#!/usr/bin/bash

if [[ $# -ne 1 ]]; then
        echo "plz provide branch name"
        exit 0
fi

brname="$1"

cleartool find -a -version "version(.../${brname}/LATEST)" -print | tr "@" " " | sed 's/\( .*\)/\1 \1/' | sed 's/[0-9]\+$/0/'


[de680136@nmpetdev64:2018-03-12 14:08:04:/vobs/pet_raw/source:]5220$ ~de680136/work/scripts/prepareReviewChanges.sh yosi4_pac_col_ddg

Older way, using my python script
-> review changes
a. produce CR report
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$  printCR_Data.py ./librdfAccept/rdfAcceptLib/ConversionPipeline.cc > ~/changes && printCR_Data.py ./librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc >> ~/changes &&  printCR_Data.py ./librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.h >> ~/changes

cat ~/changes 
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/ConversionPipeline.cc /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/1 /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc /main/pac_col_ddg/yosi1_pac_col_ddg/2 /main/pac_col_ddg/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.h /main/pac_col_ddg/yosi1_pac_col_ddg/1 /main/pac_col_ddg/yosi1_pac_col_ddg/0

b. launch diff using my script, default vimdiff (vd)
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$  prepareReviewChanges.py  ~/changes

For cleartool diff, textual or graphical 
[de680136@ctds64-1:2018-01-10 03:49:26:~:]2068$ prepareReviewChanges.py  ~/changes2 ctdt > ~/full_diffs
[de680136@ctds64-1:2018-01-10 03:49:45:~:]2069$ prepareReviewChanges.py  ~/changes2 ctdg

[de680136@nmpetdev64:2018-03-14 09:52:40:/vobs/pet_raw/source/rdfAPI/libMice:]5155$ prepareReviewChanges.py ~/changed_PCRD  vd i
Chosen diff method is vd
Got interactive flag set to vd
Interactive mode set to True
processing line: cleartool ci -nc   "/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc" 

Would you like to fire diff cleartool ci -nc   "/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc" 
? [y - yes, q - quit, anything else skip to next diff 
q
Quitting diff session



-> Create new review 
use ccollab web page, https://collaborator.engops.health.ge.com/ui  
    --> home->create new review
    --> choose PET Code review template
    --> fill SA data

<URL:#r=__pet_static_analysis__>

    --> Note. Michael's CR todo list
Now, from this point on, all developers should use the ‘Pet Template’ Code Review for new Code Reviews. 
Agreed?

And the Code Review author designates 1-3 ‘Required’ Reviewers, and as many ‘Optional’ as desired.
And the Code Review author fills in all ‘required’ sections of the PET Template Code Review (eg. Static Analysis Performed, What level of testing, How to verify, etc….)

Agreed?

Mjc

| p.s. The author of the Code Review should also notify the PAC ‘point man’ for the pac_col_ddg.4 sw build after the following criteria has been met:
| 1.	Successfully merged the appropriate files to pac_col_ddg.N_dev view
| 2.	Can 64-bit compile without warnings/error (and 32-bit compile when applicable) the impacted libs/executable in the pac_col_ddg.N_dev view
| 3.	Can execute successfully all applicable (potentially impacted) google tests from the  pac_col_ddg.N_dev view
| 4.	A list of applicable clearcase files (including directories) constituting the ‘submittal’ has been generated
| 5.	Our Box site has been updated to reflect a completed Code Review
        To do this edit excel doc at https://ge.ent.box.com/file/242821842185

    -->
-> upload to ccollab
  cat ~/changes | ccollab addversions --upload-comment "Add rdfAccept support for user block" 176704

  cat ~/changes2 | ccollab addversions --upload-comment "Fix rdfAccept: User Block residual issue and inccorect multi-dim order case" 178694


            2.1.3.1 First time only operations. 
            VNC. ccollabgui. File-> Preferences -> server URL ( https://collaborator.engops.health.ge.com ), user name (SSO)

            2.1.3.2 wiki data on how to submit CR via collaborator 
            http://wiki.health.ge.com/gehcwiki/index.php/Code_Collaborator_Quick-Start_Page_(PET) 

            2.1.3.3 post diffs
     --> my example
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ printCR_Data.py RdfUserBlockTest.cpp  > ~/temp/changes
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ printCR_Data.py Makefile  >> ~/temp/changes
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ printCR_Data.py .  >> ~/temp/changes
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ cat !$
cat ~/temp/changes
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfUserBlockTest.cpp /main/yosi1_pac_col_ddg/1 /main/0
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/Makefile /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1 /main/0
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/1 /main/0

  cat ~/temp/changes | ccollab addversions --upload-comment "UT for RDF 9.9 user block feature" 172386
Connecting to Collaborator Server https://collaborator.engops.health.ge.com
Connected as: Izaq, Yosi (212680136)
Loading review ID 172386.
Attaching Named Versions to Review
Auto-detecting SCM System for '/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfUserBlockTest.cpp'.
Detected ClearCase.
Adding versions /main/yosi1_pac_col_ddg/1 and /main/0.
Adding versions /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1 and /main/0..
Sending local data to Collaborator server
Uploading Changelist to Collaborator server.
/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfUserBlockTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/Makefile
/pet_raw/source/rdfAPI/librdfCpp/gtest/SinogramDatasetTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/SinglesDatasetTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/DeadTimeDatasetTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfFileTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/CorrectionsDatasetTest.cpp
/pet_raw/source/rdfAPI/librdfCpp/gtest/Makefile
/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfUserBlockTest.cpp.
Associating changes with review 172386
Changes successfully attached to Review #172386: "RDFv9.9 User Block implementation"

general explanation re. ccollab post diffs to code collaborator
required input: list of changed files versions

From your clearcase view on ctds<32,64>-<1,2,3,4>:

  cat uploads.txt | ccollab addversions --upload-comment "Changes for feature x" <review-number>

where uploads.txt is something like:

     /vobs/gre/pet/lib_common/libEvtList/RdfList.cpp /main/kh_m3/kh_xar/pet_velocity/jcd_vipreplay/8 /PET_VELOCITY.51.ALL_FILES
     /vobs/gre/pet/lib_common/libEvtList/GleplDecCtrl.cpp /main/jcd_vipreplay/LATEST /main/0
     /vobs/gre/pet/lib_common/libEvtList/GleplDecCtrl.h /main/jcd_vipreplay/LATEST /main/0



            2.1.3.4 printCR_Data.py  my tool to get this data
        --> run
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ printCR_Data.py  .
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/1 /main/0
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ printCR_Data.py Makefile 
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/Makefile /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1 /main/0

        --> code
[212680136@G9VK2GH2E:Tue Dec 05:~:]$ lt $MY_WORK_PATH/Work/scripts/python/ | grep print
-rwxr-xr-x+ 1 212680136 Domain Users 1.5K Dec  5 11:04 printCR_Data.py*
[212680136@G9VK2GH2E:Tue Dec 05:~:]$ cat $MY_WORK_PATH/Work/scripts/python/printCR_Data.py 
#!/usr/bin/python

"""
Author yosi.izaq@ge.com
small util. 
input: clearcase file
output: fullpath new_version old_version
"""

import os,sys,re
from subprocess import PIPE, Popen



def main():
    #print 'producing data for file {0}'.format(sys.argv[1])
    file = sys.argv[1]
    file_fpath = os.path.abspath(file)
    #print 'full path: {0}'.format(file_fpath)
#only works in python > 2.7
#    cc_desc = subprocess.check_output(['cleartool', 'desc', file])
    proc = Popen(['cleartool', 'desc', file], stdout=PIPE)
    
    #get as list
    ##print proc.communicate()[0].split()
    #get as string
    ##print proc.communicate()[0]
    cc_desc_lst = proc.communicate()[0].split()

    cur_ver=cc_desc_lst[cc_desc_lst.index('version')+1]
    pred_ver = '/main/0' 
    #pred_ver=cc_desc_lst[-1] #Note, this will return the predecessor. most times better return /main/0 ...

    #print "file CC desc: {0}".format(cc_desc_lst)
    #print "current ver: {0}".format(cur_ver)
    #print "pred ver: {0}".format(pred_ver)

    #cur_match_pat = r"\w+"
    #cur_match_pat = r"\w+@@(.*)"+'"'
    cur_match_pat = r".+@@(.*)"+'"'
    cur_match = re.search(cur_match_pat, cur_ver)
    if cur_match is not None:
        #print "matched {0}".format(cur_match.groups())
        cur_file = cur_match.group(1)
        #print "cur file: {0}".format(cur_file)
        print "{0} {1} {2}".format(file_fpath, cur_file, pred_ver ) 

if __name__=="__main__":
    main()


        -->

            2.1.3.5 How To get clearcase data on an element
-> [de680136@ctds64-1:Mon Dec 04:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ct ls Makefile 
Makefile@@/main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1          Rule: .../yosi1_pac_col_ddg/LATEST
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ct desc Makefile 
version "Makefile@@/main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1"
  created 2017-12-04T09:44:25-06:00 by Yosi Izaq  - 212680136 (de680136.unity@ctds64-1)
  "Add RDF user block tests."
  Element Protection:
    User : lg181686 : r--
    Group: unity    : r--
    Other:          : r--
  element type: text_file
  predecessor version: /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/0

-> [de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ct desc RdfUserBlockTest.cpp 
version "RdfUserBlockTest.cpp@@/main/yosi1_pac_col_ddg/1"
  created 2017-12-04T09:43:43-06:00 by Yosi Izaq  - 212680136 (de680136.unity@ctds64-1)
  "RDF file user block related UT."
  Element Protection:
    User : de680136 : r--
    Group: unity    : r--
    Other:          : r--
  element type: text_file
  predecessor version: /main/yosi1_pac_col_ddg/0

-> [de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ct lsvtree RdfUserBlockTest.cpp 
RdfUserBlockTest.cpp@@/main
RdfUserBlockTest.cpp@@/main/0
RdfUserBlockTest.cpp@@/main/yosi1_pac_col_ddg
RdfUserBlockTest.cpp@@/main/yosi1_pac_col_ddg/1


            2.1.3.6 To get list of checked out files:
cleartool lscheckout -cview -me -avobs
e.x.
[de680136@ctds64-1:Tue Dec 05:/vobs/pet_raw/source/rdfAPI/librdfCpp:]$ cleartool lscheckout -cview -me -avobs
--11-15T03:11  de680136   checkout version "/vobs/pet_acq/source/libcldevices/clUnlist.cpp" from /main/pet_columbia/pac_col_ddg/1 (reserved)
  "Add debug prints for repeat count >0 issue in tests  LT17_05_1 and LT22_LR_MFOV"

            2.1.3.7 Kevin's script 
            dumpreport <CR ID>
copy output to SPR

            2.1.3.8 Create new review ID
use ccollab web page, https://collaborator.engops.health.ge.com/ui  
home->create new review

            2.1.3.9 Shay's ccolab stuff
  /opt/collaborator/default/ccollab addchanges <review number or NEW> <files list with full paths>

  /vobs/util/scripts/ccollab-addvers -v -r <new/number> -l <base label> -f zero <files/folders>
  /vobs/util/scripts/ccollab-addvers -v -r <new/number> -p <files/folders> 

  ex:
generate full paths file
[de680136@ctds64-1:Thu Dec 21:/vobs/pet_raw/source:]$ cat ~/changes | awk '{print $1}' > ~/changes_files 
  /opt/collaborator/default/ccollab addchanges new ~/changes_files
  note. not working...

            2.1.3.10 Post changes to an existing review
a. Change files. Then checkin. Update version in changes file.

b. rerun ccolab command
e.g.  
$ cat ~/changes1 | ccollab addversions --upload-comment "Add rdfAccept support for user block" 176704

            2.1.3.11
        2.1.4 merge, diff 

            2.1.4.1 findmerge, 

                2.1.4.1.1 merge branches using findmerge
c. ct setview <merge target view>

    -> perform merge
d1.

ct findmerge [scope: -a,directory,-avobs]  -fver .../<branch named>/latest -print (or -merge)

example:
    - check what merges are required 
 3102  ct findm .  -fver .../yony_pac_col_ddg/latest -print

    - perform merge
 3102  ct findm .  -fver .../yony_pac_col_ddg/latest -merge

    - check what's checked out
 3104  ct lsco -a -cview

    - checkin all
 3107  ct ci -nc $(ct lsco -a -cview -s)

                2.1.4.1.1 findmerge

                    2.1.4.1.1.1 merge views using findmerge
 source view to current view
    -- check whether merge  is required 
[de680136@ctds64-1:2017-12-31 04:08:50:/vobs/pet_raw/source:]1509$ ct findmerge -all -ftag pac_col_ddg.4_dev  -print

merge all:
ct findmerge -all -ftag pac_col_ddg.4_dev  -gmerge

d2. another way to perform merge 
ct findmerge ...\LATEST 
options: 
    -print , just print diffs
    -merge , merge automatically if no conflicting diffs
    -gmerge , requires graphical terminal (like cygwin xwin + export DISPLAY="<windos IP>:0.0"

e. checkin all merged files
save their full paths, e.g. file@.../LATEST

d. Make local build
cd /vob/<vob name: e.g. pet_raw>/source
clearmake -CGNU
check kevins 'cm' alias in his .bashrc (his user is de064881)

                    2.1.4.1.1.2 findmerge specific files
[de680136@nmpetdev64:2018-04-25 13:20:59:/vobs/pet_raw/source/rdfAPI/libMice:]6407$ ct findmerge /vobs/pet_raw/source/rdfUtils/addMotion/addMotion.cpp -fver /main/pac_col_ddg/leonid_paartf_lt24/2  -gmerge

                    2.1.4.1.1.3 findmerge by branch
example:
    - check what merges are required 
 ct findm .  -fver .../yony_pac_col_ddg/latest -print

    - perform merge
 ct findm .  -fver .../yony_pac_col_ddg/latest -merge

                    2.1.4.1.1.4 findmerge aliases
alias ctmergFromView="__merge_from_view"
alias ctmergFromBranch="__merge_from_branch"
alias ctmergFromViewPrint="__merge_from_view_print"
alias ctmergFromBranchPrint="__merge_from_branch_print"

                    2.1.4.1.1.5 findmerge specific file
[de680136@nmpetdev64:2018-04-25 13:20:33:/vobs/pet_raw/source/rdfAPI/libMice:]6406$ ct merge -to /vobs/pet_raw/source/rdfUtils/addMotion/addMotion.cpp -ver /main/pac_col_ddg/leonid_paartf_lt24/2  

            2.1.4.2 ct merge 
            - Specific files merge

- regular merge
Get source version. Usually from CR. e.g. /main/pac_col_ddg/pac_col_ddg.4_vikas_9.7/10 
otherwise go to source view and ct lsvtree file 
from list choose desired source ver. format example: file@@/main/root_branch/parent_branch/child_branch/2
take the /main suffix

[de680136@ctds64-1:Wed Dec 20:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ct merge -to rdfConvertUtils9.0to10.0.cc -ver /main/pac_col_ddg/pac_col_ddg.4_vikas_9.7/10 

note that file must be checked out first or ct merge will return error. ex:
[de680136@nmpetdev64:2018-04-25 13:19:52:/vobs/pet_raw/source/rdfAPI/libMice:]6404$ ct merge -to /vobs/pet_raw/source/rdfUtils/addMotion/addMotion.cpp -ver /main/pac_col_ddg/leonid_paartf_lt24/2  
Redirecting output of merger to a private file because the specified target "/vobs/pet_raw/source/rdfUtils/addMotion/addMotion.cpp" is not a checked out version.
cleartool: Error: Unable to create a merge arrow because the result of the merger is not a VOB version object.
cleartool: Error: Unable to merge to target "/vobs/pet_raw/source/rdfUtils/addMotion/addMotion.cpp".

- findmerge 
	ct findmerge [file_name] -ftag [source_view] -merge -nc


all flags. Note, -qntrivial question on non trivial conflicts
[de680136@ctds64-1:Wed Dec 20:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ct merge
cleartool: Error: Pathname required.
Usage: merge {-out output-pname | -to contrib-and-result-pname}
             { -graphical [-tiny] |
               [-tiny | -window] [-serial_format | -diff_format | -columns n]}
             [-base pname | -insert | -delete] [-ndata | -narrows] [-replace]
             [-query | -abort | -qall | -qntrivial]
             [-c comment | -cfile pname | -cq | -cqe | -nc]
             [-options pass-through-options]
             {-version contrib-version-selector ... | contrib-pname ...}


- graphical merge
a. ssh -Y (X11 gui forwarding)
[212680136@G9VK2GH2E:2018-03-04 09:38:22:~:]2001$ alias sshdsloc64_1 
alias sshdsloc64_1='ssh -Y de680136@3.213.176.186'
[212680136@G9VK2GH2E:2018-03-04 09:38:26:~:]2002$ sshdsloc64_1 
Last login: Sun Mar  4 09:38:10 2018 from g9vk2gh2e.clients.em.health.ge.com
Loading yizaq BASHRC for GE  Linux environment
LOADING de680136 aliases for GE Linux environment

b. set view and print report of files requiring merge
[de680136@nmpetdev64:2018-03-04 09:38:30:~:]4018$ smy2ndview 
Loading yizaq BASHRC for GE  Linux environment
LOADING de680136 aliases for GE Linux environment
[de680136@nmpetdev64:2018-03-04 09:38:59:~:]4018$ cdrdfaccept 
[de680136@nmpetdev64:2018-03-04 09:39:07:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]4019$  cleartool findm .  -ftag elenav_mice_dev -print
cleartool: Warning: Element "./rdfAccept.cc" is checked out in view "elenav_mice_dev".
Needs Merge "./rdfAccept.cc" [to /main/pet_columbia/pac_col_ddg/yosi4_pac_col_ddgv/CHECKEDOUT from /main/pet_columbia/elenav_mice_dev/CHECKEDOUT base /main/pet_columbia/9]
cleartool: Warning: Element "./rdfConvertUtils9.0to10.0.cc" is checked out in view "elenav_mice_dev".
Needs Merge "./rdfConvertUtils9.0to10.0.cc" [to /main/pac_col_ddg/yosi4_pac_col_ddgv/CHECKEDOUT from /main/pac_col_ddg/elenav_mice_dev/CHECKEDOUT base /main/pac_col_ddg/10]
cleartool: Warning: Element "./rdfConvertUtils9.0to10.0.h" is checked out in view "elenav_mice_dev".
Needs Merge "./rdfConvertUtils9.0to10.0.h" [to /main/pac_col_ddg/yosi4_pac_col_ddgv/CHECKEDOUT from /main/pac_col_ddg/elenav_mice_dev/CHECKEDOUT base /main/pac_col_ddg/5]
cleartool: Warning: Element "./RdfVersion.cc" is checked out in view "elenav_mice_dev".
Needs Merge "./RdfVersion.cc" [(automatic) to /main/pet_columbia/pac_col_ddg/3 from /main/pet_columbia/pac_col_ddg/elenav_mice_dev/CHECKEDOUT (base also /main/pet_columbia/pac_col_ddg/3)]
Log has been written to "findmerge.log.2018-03-04T09:39:25+02:00".

c. gmerge
[de680136@nmpetdev64:2018-03-04 09:40:41:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]4020$  cleartool findm ./rdfAccept.cc  -ftag elenav_mice_dev -gmerge
-
            2.1.4.3 Diff specific version
a. Get file:
[de680136@ctds64-1:Wed Dec 20:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ct get -to ~/temp/rdfConvertUtils9.0to10.0.cc  rdfConvertUtils9.0to10.0.cc@@/main/pac_col_ddg/yosi1_pac_col_ddg/1

b. diff
[de680136@ctds64-1:Wed Dec 20:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ vimdiff ~/temp/rdfConvertUtils9.0to10.0.cc rdfConvertUtils9.0to10.0.cc

or
[de680136@ctds64-1:Wed Dec 20:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ct diff  -diff rdfConvertUtils9.0to10.0.cc  rdfConvertUtils9.0to10.0.cc@@/main/pac_col_ddg/pac_col_ddg.4_vikas_9.7/10 


            2.1.4.4 Diff files from two different views (regardless of their checkin state)
setview to view1 and diff to /view/view2/path. e.g.
[de680136@ctds64-1:2018-01-16 01:35:30:/vobs/pet_acq_test/source:]2167$ vimdiff /vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc /view/cook_pac_col_ddg.5//vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc

            2.1.4.5
        2.1.4  Roman's cleartool clearcase doc
http://www.yolinux.com/TUTORIALS/ClearcaseCommands.html 


*** make sure your home directory contains a file .rhosts wich contains one line [username] 600 
	(don't ask me why)

ct instead of cleartool:
	alias ct="/usr/atria/bin/cleartool"	0

Views:
	ct lsview  			- list of views  
	ct setview [view]	- sets [view]
	ct pwv				- echo current view 	
	ct edcs 			- edit the config spec
	ct catcs 			- print config spec

	/vobs/utils/scripts/newview [view_name] 	- creates new view
    
    use the newly and modified newview script (/vobs/helios/util/scripts/newview) from revo_flowdown_test.1
    
	/vobs/com_util/tools/scripts/bootTools -c -p helios -t /vobs/helios		// once per view
	
Create new branch:	
	/vobs/rhap/util/scripts/newbranch [branch_name] 	- creats new branch for most of the vobs
	ct mkbrtype -pbr -nc  [branch]@[vob] 				- creats [branch] for [vob]

Remove branch:
	ct rmbranch [path]@@/main/.../branch_to_remove	- remove branch together with all its subversions from version tree of specific file

File management:	
	ct -nc co [file]   			- checkout [file]
	ct unco [file]				- undo checkout [file]
	ct -c "Comment" ci [file]		- checkin [file]
	ct ci -c "Comment" `ct lsco -me -cview -short  -r`	- recursively checkin all files checked out by me in the current view
	ct mkelem -nc [file]			- add new element (git stage)    
	ct lsco -rec -cview     		- list of checked out files in current view current path
	ct lsco -avobs -cview			- list of checked out files in current view all vobs
	ct desc [file] 				- [file] history
	ct lsvtree [file]			- [file] tree 
	ct descr [file_name]			- [file] currently viewed version
	-nc					- no comment
	-c "This is a comment"			- providing comment

Compare:
	ct diff -pred [file_name]	// preview version
	vim -d [file1] [file2]    	// use lstree or desc to extract files paths	

Merge:
	ct setview [target view] 
	cd [file_entry]  
	ct findmerge [file_name] -ftag [source_view] -merge -nc
	ct merge -to [target_file] -version [source_tree_without_file_name_@@]
	
Find:
	ct find -avobs -version "lbtype(Label.3) && ! lbtype(Label.0)" -print		\\ all files with Label.3 but not Label.0
	ct find /vobs/pet_platform/ -version 'version(.../my_branch/LATEST)' -print	\\ all latest files in pet_platform on my_branch
	
flags:
	-nc 	no comment	
    
    
    
    
    
    ============================================================
    
ct help <command>                       Usage statement for command
ct man <command>                        Manual page for command

ct lsvob                                List VOBs
ct mount <vob-tag>                      Mount VOB
ct umount <vob-tag>                     Unmount VOB

ct lsview                               List views
ct startview <view-tag>                 Start view
ct setview <view-tag>                   Set view (UNIX)
ct endview <view-tag>                   Stop view
ct endview -server <view-tag>           Stop view and kill view server process
net use <drive:> \\view\<view-tag>      Map drive to view
net use <drive:> /d                     Disconnect drive from view

ct lsvtree <pname>                      Version tree browser
ct lsvtree -gra <pname>                 Version tree browser (graphical)

ct pwd                                  Print working directory
ct pwv                                  Print working view
ct ls                                   List contents of directory with ClearCase info
ct ls -view                             List only private files in directory
ct ls -vob                              List only vob elements in directory

ct lsprivate                            List private files in the view
ct lsco [-all] [-cview] [-s]            Find checkouts

ct mkview -tag <view-tag> <stg-dir>                     Create view
ct mkview -tag <view-tag> -stream <stream> <stg-dir>    Create view (UCM)
ct rmview -tag <view-tag>                               Remove view

ct mkstream <stream>                    Create stream (UCM)

ct lsact                                List activities at current stream (UCM)
ct setact <act-id> | [-none]            Set activities (UCM)
ct mkact -headline <headline>           Create activity (UCM)
ct rmact <act-id>                       Remove activity (UCM)

ct co [-unres] <pname>                  Checkout
ct ci <pname>                           Checkin
ct unco <pname>                         Uncheckout
ct reserve <pname>                      Change unreserved to reserved checkout
ct unreserve <pname>                    Change reserved to unreserved checkout

ct mkelem <pname>                       Make new file element
ct mkdir <pname>                        Make new directory element

ct mv <src-pname> <dest-pname>          Move an element
ct rmname <pname>                       Logical delete of element
ct ln [-s]                              Create link

------------------------------------------------------------------------------------------

<cmd> <pname>                           Operate on version selected by view
<cmd> <pname@@\version-id>              Operate on version given the version-id

ct diff [-gra] [-pred] <pname>          Diff tool
ct merge [-gra]                         Merge
ct findmerge                            Batch merge

ct mklbtype <label-type-name>           Create label type
ct mklabel <label-type-name> <file>    Attach label
ct mklabel -replace -r MICE_DELIVERABLE1.0 libMice/        create or update label and replace older versions
[de680136@ctds64-1:2018-01-25 06:45:35:/vobs/pet_raw/source/rdfAPI:]2484$ ct mklabel -replace -r MICE_DELIVERABLE1.0 libMice/
ct lock lbtype:<label-type-name>        Lock label

ct mkbl [-incremental | -full] <baseline-root-name>                Make baseline (UCM)
ct chbl [-level <promotion-level>]                                 Promote baseline (UCM)
ct chstream [-recommended <baseline-selector>] <stream-selector>   Recommend baseline (UCM)

ct rebase -gmerge -recommended          Rebase stream (UCM)
ct rebase -complete                     Complete rebase (UCM)

ct deliver                              Deliver activities (UCM)
ct deliver -complete                    Complete deliver (UCM)
ct deliver -activites <act-selectors>   Deliver specific activities (UCM)

ct setcs -stream                        Synchronize view

ct catcs                                View config spec
ct edcs                                 Edit config spec
ct setcs                                Set config spec

ct find                                 Search/Reporting utility

------------------------------------------------------------------------------------------

ct lsstgloc                             List all storage locations
ct mkstgloc                             Create storage location
ct rmstgloc                             Remove a storage location

ct mkvob -tag <vob-tag> <stg-dir>       Create VOB
ct rmvob <stg-dir>                      Remove VOB
ct describe vob:<vob-tag>               Display owner and group of VOB
ct protectvob                           Change owner and group of VOB

clearfsimport <src-path> <target>       Import files and directory structures
clearexport_*                           Export versioned files from another tool
clearimport                             Import versioned files

ct rmver                                Physically remove a version from VOB
ct rmbranch                             Physically remove an entire branch from VOB
ct rmelem                               Physically remove an entire element from VOB

ct relocate                             Relocate elements from one VOB to another

ct protect [-chown] [-chgrp] [-chmod]   Change element permission, owner, group
ct describe <element-path@@>            Display element permission, owner, group

mvfsstorage                             Display location of data container
ct dump                                 Display location of source and cleartext container

ct getlog                               Display error logs

ct mktrtype                             Create trigger type
ct mktrigger                            Attach/apply trigger
ct rmtrigger                            Remove a single instance of trigger
ct rmtype [-rmall] trtype:<trig-type>   Remove trigger type

ct mkattype <type-name>                 Create attribute type
ct mkattr <attype> <value> <pname>      Attach/apply attribute
ct rmattr                               Remove a single instance of attribute
ct rmtype [-rmall] attype:<att-type>    Remove attribute type

------------------------------------------------------------------------------------------

site_prep                               Prepare the ClearCase release area
setup / install_release                 Install ClearCase on client or server
clearlicense [-hostid]                  Display license information
rgy_passwd                              Set the registry password
ct hostinfo -l                          Display host ClearCase information

net stop albd                           Stop ClearCase services (Windows)
net start albd                          Start ClearCase services (Windows)
/etc/init.d/clearcase stop              Stop ClearCase services (UNIX)
/etc/init.d/clearcase start             Start ClearCase services (UNIX)

ct lsregion                             Display ClearCase regions
ct mkregion -tag <name>                 Create ClearCase region
ct rmregion [-rmall] -tag <name>        Remove ClearCase region

ct register (-vob|-view) <stg-path>     Register a VOB or view
ct unregister (-vob|-view) <stg-path>   Unregister a VOB or view
ct mktag (-vob|-view) -tag <tag> <stg>  Create a VOB or view tag
ct rmtag (-vob|-view) <tag>             Remote a VOB or view tag

rgy_check [-vobs] [-views] [-storage]   Verify registry integrity

ct lock vob:<vob-tag>                   Lock VOB
ct unlock vob:<vob-tag>                 Unlock VOB

ct recoverview -syn -tag <view-tag>     Recover stranded view private files

fix_prot                                Fix protection problems
dbcheck -a -k <vob_db>                  Scan RAIMA db for corruption
ct checkvob [-fix] -pool <vob-stg-dir>  Scan db/storage pools for consistency
	
	
	
	
id=__my_example_create_new_view_and_branch__	

        2.1.5 My example
	
            2.1.5.1 a. ct setview pac_col_ddg.4_dev

    a1. optional, get config spec of parent view
[de680136@ctds64-1:Mon Nov 13:~:]$ ct catcs > temp/pacddg4_cs
element * CHECKEDOUT
element /vobs/util/... UTIL1.71 -nocheckout
element /vobs/product-soup/... PRODUCT-SOUP1.31 -nocheckout
element /vobs/coreload/...  CSER_3_1_14_RFV1_V1_20170227 -nocheckout
element /vobs/commondisplay/... CT_DISPLAY_20160209 -nocheckout
element /vobs/com_platform/mak/environment.mk COM_MAKEFILES.4.4 -nocheckout
element /vobs/com_platform/mak/... COM_MAKEFILES.1 -nocheckout
element /vobs/3p/sysos/... SLES_11_5415620_REV3 -nocheckout
element /vobs/pet/3p/hdf5/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/hdf-java/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/spectraeigen/... SPECTRA_EIGEN.SOUPRS_GROUP_A.1 -nocheckout
element /vobs/pet/3p/... PET_3P_KH -nocheckout
element /vobs/pet_detector/... PET_DET_GALILEO.53 -nocheckout
element /vobs/pet_detector/... PET_DET_ECOS_PLATFORM.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17_PET_CHAOS.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17A -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/fw_tools/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/ACE_wrappers/... ACE_WRAPPERS_20120525 -nocheckout
element /vobs/iungo/... IUNGO_CJ3.5 -nocheckout
element /vobs/3p/boost/... BOOST2.7 -nocheckout
element /vobs/3p/QuadProg++/... QUADPROG2.0 -nocheckout
element /vobs/3p/hwloc/... HW_TOOLS2.0 -nocheckout
element /vobs/3p/intel/... INTEL2.8 -nocheckout
element /vobs/hdf5/... HDF51.2 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_PET1.17 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_CJ3.21 -nocheckout
element /vobs/3p/qpid/... QPID4.2 -nocheckout
element /vobs/obelus/... OBELUS_COMM_REVO_M3_1.8 -nocheckout
element /vobs/gbl_fw/... SH_FW_UTIL.1 -nocheckout
element /vobs/wind_sh/... SH_FW_UTIL.1 -nocheckout
element /vobs/com_util/bin/... SUN_UTILITIES.1 -nocheckout
element * .../pac_col_ddg/LATEST
element * PAC_COL_DDG.4 -mkbranch pac_col_ddg
element * PET_COLUMBIA.122 -mkbranch pac_col_ddg
element /vobs/pet_acq_test/... PET_ACQ_TEST.COM.3 -mkbranch pac_col_ddg
element /vobs/pet_recon_test/... PET_RECON_TEST.COM.1 -nocheckout
element * PET_CORELOAD.71 -mkbranch pac_col_ddg
element * PET_MICT_PLUS.48 -mkbranch pac_col_ddg
element * CJ_KL.89 -mkbranch pac_col_ddg
element * CORELOAD.118 -mkbranch pac_col_ddg
element * GSI_MICT_PLUS.145 -mkbranch pac_col_ddg
element * VISM3.6 -mkbranch pac_col_ddg
element * KH_XAR.30 -mkbranch pac_col_ddg
element * /main/0 -mkbranch pac_col_ddg

            2.1.5.2 create new view
de676967@ctds64-4:/home/de676967> ksh /vobs/util/scripts/newview yosi1_pac_col_ddg_4dev                                                                 
View yosi_pac_col_ddg_4dev created.                                                                                                                                                          
To remove this dynamic view use the command: 'cleartool rmview -tag yosi_pac_col_ddg_4dev' 

c. setview to new view
de676967@ctds64-4:/home/de676967> ct setview yosi_pac_col_ddg_4dev
ct setview yosi1_pac_col_ddg_4dev

id=__my_example_create_new_view_and_branch__	

            2.1.5.3 d. edit config-spec
ct edcs
Put branch line first after nocheckout section

                2.1.5.3.1 My first view example


de676967@ctds64-4:/home/de676967> ct catcs                                                                                                                                                  
element * CHECKEDOUT
element /vobs/util/... UTIL1.71 -nocheckout                                                                                                                                                  
element /vobs/product-soup/... PRODUCT-SOUP1.31 -nocheckout
element /vobs/coreload/...  CSER_3_1_14_RFV1_V1_20170227 -nocheckout
element /vobs/commondisplay/... CT_DISPLAY_20160209 -nocheckout
element /vobs/com_platform/mak/environment.mk COM_MAKEFILES.4.4 -nocheckout
element /vobs/com_platform/mak/... COM_MAKEFILES.1 -nocheckout
element /vobs/3p/sysos/... SLES_11_5415620_REV3 -nocheckout
element /vobs/pet/3p/hdf5/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/hdf-java/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/spectraeigen/... SPECTRA_EIGEN.SOUPRS_GROUP_A.1 -nocheckout
element /vobs/pet/3p/... PET_3P_KH -nocheckout
element /vobs/pet_detector/... PET_DET_GALILEO.53 -nocheckout
element /vobs/pet_detector/... PET_DET_ECOS_PLATFORM.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17_PET_CHAOS.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17A -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/fw_tools/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/ACE_wrappers/... ACE_WRAPPERS_20120525 -nocheckout
element /vobs/iungo/... IUNGO_CJ3.5 -nocheckout
element /vobs/3p/boost/... BOOST2.7 -nocheckout
element /vobs/3p/QuadProg++/... QUADPROG2.0 -nocheckout
element /vobs/3p/hwloc/... HW_TOOLS2.0 -nocheckout
element /vobs/3p/intel/... INTEL2.8 -nocheckout
element /vobs/hdf5/... HDF51.2 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_PET1.17 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_CJ3.21 -nocheckout
element /vobs/3p/qpid/... QPID4.2 -nocheckout
element /vobs/obelus/... OBELUS_COMM_REVO_M3_1.8 -nocheckout
element /vobs/gbl_fw/... SH_FW_UTIL.1 -nocheckout
element /vobs/wind_sh/... SH_FW_UTIL.1 -nocheckout
element /vobs/com_util/bin/... SUN_UTILITIES.1 -nocheckout
//Take files from my branch 1st rule
element * .../yosi_pac_col_ddg_4dev/LATEST
//from other branches make my branch on Checkout  
element * .../pac_col_ddg/LATEST -mkbranch yosi_pac_col_ddg_4dev
element * PAC_COL_DDG.4 -mkbranch yosi_pac_col_ddg_4dev
element * PET_COLUMBIA.122 -mkbranch yosi_pac_col_ddg_4dev
element /vobs/pet_acq_test/... PET_ACQ_TEST.COM.3 -mkbranch yosi_pac_col_ddg_4dev
element /vobs/pet_recon_test/... PET_RECON_TEST.COM.1 -nocheckout
element * PET_CORELOAD.71 -mkbranch yosi_pac_col_ddg_4dev
element * PET_MICT_PLUS.48 -mkbranch yosi_pac_col_ddg_4dev
element * CJ_KL.89 -mkbranch yosi_pac_col_ddg_4dev
element * CORELOAD.118 -mkbranch yosi_pac_col_ddg_4dev
element * GSI_MICT_PLUS.145 -mkbranch yosi_pac_col_ddg_4dev
element * VISM3.6 -mkbranch yosi_pac_col_ddg_4dev
element * KH_XAR.30 -mkbranch yosi_pac_col_ddg_4dev
element * /main/0 -mkbranch yosi_pac_col_ddg_4dev

                2.1.5.3.2 My haifa view example

Loading yizaq BASHRC for GE  Linux environment
LOADING de680136 aliases for GE Linux environment
element * CHECKEDOUT
element /vobs/util/... UTIL1.71 -nocheckout
element /vobs/product-soup/... PRODUCT-SOUP1.31 -nocheckout
element /vobs/coreload/...  CSER_3_1_14_RFV1_V1_20170227 -nocheckout
element /vobs/commondisplay/... CT_DISPLAY_20160209 -nocheckout
element /vobs/com_platform/mak/environment.mk COM_MAKEFILES.4.4 -nocheckout
element /vobs/com_platform/mak/... COM_MAKEFILES.1 -nocheckout
element /vobs/3p/sysos/... SLES_11_5415620_REV3 -nocheckout
element /vobs/pet/3p/hdf5/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/hdf-java/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/spectraeigen/... SPECTRA_EIGEN.SOUPRS_GROUP_A.1 -nocheckout
element /vobs/pet/3p/... PET_3P_KH -nocheckout
element /vobs/pet_detector/... PET_DET_GALILEO.53 -nocheckout
element /vobs/pet_detector/... PET_DET_ECOS_PLATFORM.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17_PET_CHAOS.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17A -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/fw_tools/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/ACE_wrappers/... ACE_WRAPPERS_20120525 -nocheckout
element /vobs/iungo/... IUNGO_CJ3.5 -nocheckout
element /vobs/3p/boost/... BOOST2.7 -nocheckout
element /vobs/3p/QuadProg++/... QUADPROG2.0 -nocheckout
element /vobs/3p/hwloc/... HW_TOOLS2.0 -nocheckout
element /vobs/3p/intel/... INTEL2.8 -nocheckout
element /vobs/hdf5/... HDF51.2 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_PET1.17 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_CJ3.21 -nocheckout
element /vobs/3p/qpid/... QPID4.2 -nocheckout
element /vobs/obelus/... OBELUS_COMM_REVO_M3_1.8 -nocheckout
element /vobs/gbl_fw/... SH_FW_UTIL.1 -nocheckout
element /vobs/wind_sh/... SH_FW_UTIL.1 -nocheckout
element /vobs/com_util/bin/... SUN_UTILITIES.1 -nocheckout

# My config spec
element * .../yosi3_pac_col_ddg/LATEST

# MICE_DELIVERABLE label. This allows my view to see files that have this label 
element * MICE_DELIVERABLE -mkbranch yosi3_pac_col_ddg

#Toggle following rule for seeing/not seeing parent branch (pac_col_ddg) changed files 
#element * .../pac_col_ddg/LATEST -mkbranch yosi3_pac_col_ddg
element * PAC_COL_DDG.4 -mkbranch yosi3_pac_col_ddg
element * PET_COLUMBIA.122 -mkbranch pac_col_ddg
element /vobs/pet_acq_test/... PET_ACQ_TEST.COM.3 -mkbranch yosi3_pac_col_ddg
element /vobs/pet_recon_test/... PET_RECON_TEST.COM.1 -nocheckout


#This will create my branch directly for these labeled files
element * PET_CORELOAD.71 -mkbranch yosi3_pac_col_ddg
element * PET_MICT_PLUS.48 -mkbranch yosi3_pac_col_ddg
element * CJ_KL.89 -mkbranch yosi3_pac_col_ddg
element * CORELOAD.118 -mkbranch yosi3_pac_col_ddg
element * GSI_MICT_PLUS.145 -mkbranch yosi3_pac_col_ddg
element * VISM3.6 -mkbranch yosi3_pac_col_ddg
element * KH_XAR.30 -mkbranch yosi3_pac_col_ddg

##don't create my branch. Allow to see code but not co
#element * PET_CORELOAD.71 
#element * PET_MICT_PLUS.48 
#element * CJ_KL.89 
#element * CORELOAD.118 
#element * GSI_MICT_PLUS.145 
#element * VISM3.6 
#element * KH_XAR.30 

# create pac_col_ddg parent branch if it wasn't existing for this file
#element * /main/0 -mkbranch pac_col_ddg

# create my branch if it wasn't existing for this file
element * /main/0 -mkbranch yosi3_pac_col_ddg

                2.1.5.3.3
            2.1.5.4 e. create the new branch
id=__cli_make_new_branch__
    e2. create manually per vob
	ct mkbrtype -pbr -nc  [branch]@[vob] 				- creats [branch] for [vob]
ct mkbrtype -pbr -nc  yosi_pac_col_ddg_4dev@/vobs/pet_acq
ct mkbrtype -pbr -nc  yosi_pac_col_ddg_4dev@/vobs/pet_raw
ct mkbrtype -pbr -nc  yosi_pac_col_ddg_4dev@/vobs/pet_platform

ct mkbrtype -pbr -nc  yony_haifa_pac_col_ddg@/vobs/pet_acq
ct mkbrtype -pbr -nc  yony_haifa_pac_col_ddg@/vobs/pet_raw
ct mkbrtype -pbr -nc  yony_haifa_pac_col_ddg@/vobs/pet_platform
ex:

    e1. create for most vobs. not working (path issue)
/vobs/rhap/util/scripts/newbranch  yosi_pac_col_ddg_4dev
f. access code

deploy DO (pre compiled binaries)
e.g. [de680136@nmpetdev64:2018-03-26 10:43:58:/home/de683594/PET_PROJ_INFO/BUILD_TARS:]5290$ /home/de683594/scripts/pet_scripts/extract_pet_dos_from_buils.sh pac_col_ddg.7


        2.1.6 Checkout checking best practices

a. CR requires predecessor versions. Make sure to log it before checkout
e.g.
:!cleartool desc rdfAPI/librdfCpp/gtest/RdfFileTest.cpp > ~/work/changelogs/rdfUserBlockChange
!cleartool desc rdfAPI/librdfCpp/gtest/Makefile > ~/work/changelogs/rdfUserBlockChange 

b. co
[de680136@ctds64-1:Wed Nov 22:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ct co Makefile 
Checkout comments for "Makefile":
UT for user block RDF
.
Created branch "yosi1_pac_col_ddg" from "Makefile" version "/main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/0".
Checked out "Makefile" from version "/main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/0".
c. ci
log checked in version

        2.1.7 Static Analysis

            2.1.7.1 Coverity


                2.1.7.1.1 Register 
       https://devcloud.swcoe.ge.com/devspace/display/UMCOA/PET+Coverity 
Requesting access:
Go to https://oneidm.ge.com/
Click 'Request Access'
Request access for 'Unix-Internal-Server - Healthcare' for yourself
In 'Role Category', select 'CT-PET'.
In Role, select 'APP Coverity CTWAU Developer'.
Add to Request and submit.
(note - you may have to complete GE learning online course:  Basic Coverity training for CT software developers (Code : GEHC-HCS-MICT-422475)

id=__pet_static_analysis__
                2.1.7.1.2 Running Coverity (the simple way)
If you just wish to run coverity for your own code, complete the following:
(recommended: add /vobs/util/tools/coverity/scripts to your $PATH)
If you don't have Java in your PATH, run this command: export PATH="${PATH}:/usr/java/jdk1.6.0_24/bin"
Be sure, COVERITY_HOME is set correctly. You can run 'source /etc/profile.d/coverity.csh' (or coverity.sh, depends on shell you're using) to set COVERITY_HOME to the right version of coverity based on a OS version.
Go to your code source directory (for example: /vobs/pet_platform/source) and run the following commands:
make clean
coverity.py --clean
coverity.py -H ctwau-coverity-stg.am.health.ge.com --inter-dir <temp directory> clearmake -C gnu <your clearmake parameters if neccessary>
for example:
       /vobs/pet_raw/source
       make clean
       coverity.py --clean
       coverity.py -H ctwau-coverity-stg.am.health.ge.com --inter-dir /tmp/pac_cov_analysis/lg772415 clearmake -C gnu includes libraries
 
my example:
[de680136@ctds64-1:2018-01-10 06:02:13:/vobs/pet_raw/source/rdfAPI/librdfCpp:]2001$ make clean && coverity.py --clean && coverity.py -H ctwau-coverity-stg.am.health.ge.com --inter-dir /tmp  clearmake -C gnu
Analysis summary report:
------------------------
Files analyzed                 : 73
Total LoC input to cov-analyze : 69399
Functions analyzed             : 517
Classes/structs analyzed       : 191
Paths analyzed                 : 8205
Time taken by analysis         : 00:00:48
Defect occurrences found       : 6 Total
                                 2 CHECKED_RETURN
                                 1 DEADCODE
                                 1 STACK_USE
                                 2 UNINIT

New snapshot ID 11162 added.
Elapsed time: 00:00:15
INFO: coverity build log: /tmp/yosi1_pac_col_ddg_4dev/pet_raw/x86_64/build-log.txt
INFO: coverity.py debug log: /tmp/yosi1_pac_col_ddg_4dev/pet_raw/x86_64/debug-log.txt
INFO: results successfully committed to https://ctwau-coverity-stg.am.health.ge.com:443
INFO: coverity project is named "de680136 yosi1_pac_col_ddg_4dev"
The process could take a few long minutes, depending on the number of files you have in your source directory.
If the coverity fails, it is only because the code did not compile. Could be winking or make problem. Try to compile again with the correct parameters.
When coverity is finished and passed, a short summary is displayed and the final results can be found in 2 places - in your temp directory mentioned in the command line and in Coverity web page.
 
Running Coverity (PET program)
There is a script that runs coverity on all PAC programs. The best practice is to run it whenever an important milestone is about to release. Can be found in :
/home/lg772415/pac_cov_analysis.sh
The script includes a very good information about how to run it.
 
Analyzing Results
Sign in to Coverity web page and select your view (under projects).
In Issues menu, you will see your defects from the last run listed with defect type, ID, severity, impact, as well as the file and function the defect detected. To configure your display, go to Configuration menu. Example:

If you fix the defects and run coverity again, the defect should be gone from the list (no need to check in your elements).
Additinal Information:
These were just the basics about coverity. There is a folder in our PET box called 'Coverity' with more information, including setting up, running and analyzing results in the web page.	


                2.1.7.1.3
            2.1.7.2

        2.1.8 Someone else commit made my view not compile. 

            2.1.8.1 how to fix 
a. list my changed files
[de680136@ctds64-1:Sun Dec 31:/vobs/pet_platform/source:]$ cat ~/changes 
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/ConversionPipeline.cc /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/3 /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc /main/pac_col_ddg/yosi1_pac_col_ddg/4 /main/pac_col_ddg/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.h /main/pac_col_ddg/yosi1_pac_col_ddg/1 /main/pac_col_ddg/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/RdfVersion.h /main/pet_columbia/yosi1_pac_col_ddg/1 /main/pet_columbia/yosi1_pac_col_ddg/0
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/RdfVersion.cc /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/1 /main/pet_columbia/pac_col_ddg/yosi1_pac_col_ddg/0

b. check whether merge  is required 
[de680136@ctds64-1:2017-12-31 04:08:50:/vobs/pet_raw/source:]1509$ ct findmerge -all -ftag pac_col_ddg.4_dev  -print
Needs Merge "/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc" [to /main/pac_col_ddg/yosi1_pac_col_ddg/4 from /main/pac_col_ddg/6 base /main/pac_col_ddg/5]
Needs Merge "/vobs/pet_raw/source/rdfAPI/libRawPrimitives/gtest/MultiDimArrayFileTest.cpp" [(automatic) to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/0 from /main/pet_columbia/pac_col_ddg/3 (base also /main/pet_columbia/pac_col_ddg/2)]
Needs Merge "/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/Makefile" [to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/yosi1_pac_col_ddg/1 from /main/pet_columbia/pac_col_ddg/4 base /main/pet_columbia/pac_col_ddg/3]
Needs Merge "/vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp" [to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/4 from /main/pet_columbia/pac_col_ddg/9 base /main/pet_columbia/pac_col_ddg/8]
Needs Merge "/vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.h" [to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/3 from /main/pet_columbia/pac_col_ddg/8 base /main/pet_columbia/pac_col_ddg/7]
Needs Merge "/vobs/pet_raw/source/rdfAPI/librdfCpp/RdfFile.cpp" [to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/3 from /main/pet_columbia/pac_col_ddg/7 base /main/pet_columbia/pac_col_ddg/6]
Needs Merge "/vobs/pet_raw/source/rdfAPI/librdfCpp/SinglesDataset.cpp" [(automatic) to /main/pet_columbia/pac_col_ddg/omri_pac_col_ddg.3/0 from /main/pet_columbia/pac_col_ddg/3 (base also /main/pet_columbia/pac_col_ddg/2)]
Log has been written to "findmerge.log.2017-12-31T04:08:56-06:00".



Full diff 
[de680136@ctds64-1:2017-12-31 04:08:07:/vobs/pet_raw/source:]1508$  diff -r . /view/pac_col_ddg.4_dev/vobs/pet_raw/source/

c. perform merge
[de680136@ctds64-1:2017-12-31 05:43:40:/vobs/pet_raw/source:]1569$ ct findmerge -all -ftag pac_col_ddg.4_dev  -gmerge

            2.1.8.2

        2.1.9
	
    2.2	 Build source code
	
        2.2.1	 preliminary steps
a.  Get binaries
de680136@ctds64-1:/vobs/pet_cal/source/dcal_ermes> cdpetack                                                                                                                                                                                 
de680136@ctds64-1:/vobs/pet_acq/source> 
cdpetacq                                                                                                                                                                                  && /vobs/util/scripts/winkrecursive --view pac_col_ddg.4 /vobs/pet_acq/source/pet_acq/sles11\-x86_64/pet_acq 

b. gremake
de680136@ctds64-1:/vobs/pet_acq/source> alias cmake             
cmake='clearmake -C gnu '

cd /vobs/pet_platform/source/libgebase2 && cmake

de680136@ctds64-1:/vobs/pet_acq/source> alias gremake
gremake='clearmake -C gnu -I /vobs/gre/platform/mak'
de680136@ctds64-1:/vobs/pet_acq/source> gremake   

c. cmake includes 
cd /vobs/pet_platform && cmake includes && cd /vobs/pet_raw && cmake includes && cd /vobs/pet_cal && cmake includes && cd /vobs/pet_acq && cmake includes

d. more binaries
de010814@ctds64-4:/vobs/pet_cal/source> cd /vobs/pet_cal/source/dcal_ermes && /vobs/util/scripts/winkrecursive --view pac_col_ddg.4 dcal_ermes.in

generic command:  winkrecursive --view <current stable view>(pet_columbia.113) /vobs/ pet_acq/source/pet_acq/sles11\-x86_64/pet_acq
/vobs/util/scripts/winkrecursive --view pac_col_ddg.4_dev  /vobs/pet_raw/lib-sles11-x86_64

e. build pet_acq 

f.  note, LD_LIBRARY_PATH required to run...
run /home/de680136/work/scripts/set_env
de680136@ctds64-1:/vobs/pet_acq/source> cat /home/de680136/work/scripts/set_env
#!/bin/ksh
                                                                                      
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/vobs/pet/3p/hdf5/1.8.19/sles11-x86_64/lib/:/vobs/pet_platform/source/libH5Wrap/sles11-x86_64:/vobs/pet_platform/source/libgebase2/sles11-x86_64:/vobs/pet_platform/source/libpetbase/sles11-x86_64:/vobs/pet_platform/source/libErr/sles11-x86_64:/vobs/pet_platform/source/libpetlwc/sles11-x86_64:/vobs/pet_platform/source/libpethwcfg/sles11-x86_64:/vobs/pet_platform/source/libconfigMgr/sles11-x86_64:/vobs/pet_raw/source/rdfAPI/librdfCpp/sles11-x86_64:/vobs/pet_raw/source/rdfCompression/librivn/sles11-x86_64:/vobs/pet_raw/source/rdfAPI/libRawPrimitives/sles11-x86_64:/vobs/pet_raw/source/rdfCompression/libobrivn/sles11-x86_64:/vobs/pet_raw/source/rdfAPI/libEvtList/sles11-x86_64:/vobs/pet_raw/source/rdfAPI/librdf/sles11-x86_64


export HDF5_PLUGIN_PATH=/vobs/pet_raw/lib-sles11-x86_64

f. Manually copy missing links
    f1. for pet_acq
/vobs/pet_acq/source/libacqCtrl/acqmain.cpp:43:23: error: message_N.h: No such file or directory

[de680136@ctds64-1:Thu Nov 16:/vobs/pet_acq/source:]$ cd ../../pet_platform/include-legacy/
[de680136@ctds64-1:Thu Nov 16:/vobs/pet_platform/include-legacy:]$ ls
idbConstants.h@  message.h@  message_N.h@  PetIdentityEnums.h@  sharcAcqExternal.h@
[de680136@ctds64-1:Thu Nov 16:/vobs/pet_platform/include-legacy:]$ ll
total 4.0K
drwxrwxr-x  2 de069356 unity 170 2017-05-09 15:09 ./
drwxrwxr-x 14 vobdog   unity 532 2017-11-15 07:21 ../
lrwxrwxrwx  1    29030 unity  40 2012-11-08 15:27 idbConstants.h -> /vobs/pet/dragon/db/dbinc/idbConstants.h*
lrwxrwxrwx  1    29030 unity  39 2012-11-08 15:26 message.h -> /vobs/pet/dragon/legacy/legacy_ermes.in
lrwxrwxrwx  1    29030 unity  39 2012-11-08 15:27 message_N.h -> /vobs/pet/dragon/legacy/legacy_ermes.nu
lrwxrwxrwx  1 de064881 unity  49 2016-04-19 16:32 PetIdentityEnums.h -> /vobs/platform/Identity/source/PetIdentityEnums.h
lrwxrwxrwx  1 de069356 unity  47 2013-04-02 15:45 sharcAcqExternal.h -> /vobs/pet_acq/source/pet_acq/sharcAcqExternal.h*

use my aliases to list missing link targets
      ls -l $1 | awk '{system ("ls -l "$NF)}'                                                                                                                                                                                                
     }                                                                                                                                                                                                                                       
     alias lslink="__lsSymLinkTrg"                                                                                                                                                                                                           
                                                                                                                                                                                                                                             
     __lsAllSymLinkTrgInDirectory()                                                                                                                                                                                                          
     {                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                             
     for file in $(ls -l | awk '{print $8}'); do lslink $file; done                                                                                                                                                                          
     }                                                                                                                                                                                                                                       
     alias lslinks="__lsAllSymLinkTrgInDirectory" 

[de680136@ctds64-1:Thu Nov 16:/vobs/pet_platform/include-legacy:]$ cp /view/pac_col_ddg.4_dev/vobs/pet/dragon/legacy/legacy_ermes.nu   /vobs/pet/dragon/legacy/legacy_ermes.nu
cp /view/pac_col_ddg.4_dev//vobs/pet/legacy_subsystems/ermes/sharcacquisition_ermes.in /vobs/pet/legacy_subsystems/ermes/sharcacquisition_ermes.in
cp /view/pac_col_ddg.4_dev/vobs/gre/pet/pacq_ermes/pacq_pr_ermes.in /vobs/gre/pet/pacq_ermes/pacq_pr_ermes.in


    f2. for pet_raw 
[de680136@ctds64-1:Wed Nov 29:/vobs/pet_raw:]$ find -type l | grep 'db_ermes.in' 
./include-legacy/db_ermes.in
[de680136@ctds64-1:Wed Nov 29:/vobs/pet_raw:]$ find -type l | grep 'db_ermes.in' 
./include-legacy/db_ermes.in
[de680136@ctds64-1:Wed Nov 29:/vobs/pet_raw:]$ ls -l ./include-legacy/db_ermes.in 
lrwxrwxrwx 1 212058754 unity 31 2012-11-16 16:48 ./include-legacy/db_ermes.in -> /vobs/pet/dragon/db/db_ermes.in
[de680136@ctds64-1:Wed Nov 29:/vobs/pet_raw:]$ cp /view/pac_col_ddg.4/vobs/pet/dragon/db/db_ermes.in  /vobs/pet/dragon/db/db_ermes.in 
cp /view/pac_col_ddg.4/vobs/pet/dragon/db/db_ermes.nu /vobs/pet/dragon/db/db_ermes.nu


        2.2.2 Build FAQs

            2.2.2.1 Building pet_raw gives error XrmMergeDatabases
[de680136@ctds64-1:Wed Dec 13:/vobs/pet_raw/source:]$ cmake
...
        g++ -o rdfAccept rdfAccept.o rdfAcceptIdent.o -rdynamic -Wl,--hash-style=sysv  -m64  -L /vobs/pet_platform/lib-sles11-x86_64 -lconfigMgr -lpetlwc -lH5Wrap -lgebase2 -lpetbase -lpetcfg -lpethwcfg2 -lErr -L /vobs/pet_raw/lib-sles11-x86_64 -lrdf -lrdfCpp -lrivn -lRawPrimitives -lobrivn -lH5Wrap -lEvtList -L /vobs/com_platform/lib64 -lreadcfg -lmsghand -lcup -lcupipc -ldebug -leventmgr -lplatform_misc -L/vobs/pet/3p/hdf5/HDF5.SOUPRS_GROUP_C/sles11-x86_64/lib -lhdf5 -lhdf5_hl  -lpthread -lrdfv7.0 -lrdfv7.1 -lrdfv8.0 -lrdfv9.0 -lrdfAccept  
/vobs/pet_platform/lib-sles11-x86_64/libcfg.so: undefined reference to `XrmGetFileDatabase'
/vobs/pet_platform/lib-sles11-x86_64/libcfg.so: undefined reference to `XrmGetResource'
/vobs/pet_platform/lib-sles11-x86_64/libcfg.so: undefined reference to `XrmDestroyDatabase'
/vobs/pet_platform/lib-sles11-x86_64/libcfg.so: undefined reference to `XrmMergeDatabases'
/vobs/pet_platform/lib-sles11-x86_64/libcfg.so: undefined reference to `XrmPutResource'

reason, these symbols are from libX11 and only linked on 32bit platform
step one for fix, build on 32 bit platform
[de680136@ctds64-1:Wed Dec 13:/vobs/pet_raw/source:]$ uname -a
Linux ctds64-1 2.6.32.12-0.7-default #1 SMP 2010-05-20 11:14:20 +0200 x86_64 x86_64 x86_64 GNU/Linux
[de680136@ctds32-2:Thu Dec 14:~:]$ uname -a
Linux ctds32-2 2.6.32.12-0.7-pae #1 SMP 2010-05-20 11:14:20 +0200 i686 i686 i386 GNU/Linux

Then, one of two options:
a. unset LD_LIBRARY_PATH 
[de680136@ctds32-3:Thu Dec 14:/vobs/pet_raw/source/rdfUtils/rdfAccept:]$ echo $LD_LIBRARY_PATH 
/usr/lib:/lib:/vobs/com_platform/lib:/vobs/gre/pet/platform/lib:/vobs/pet/lib/linux2:/usr/lib:/usr/X11R6/lib:/vobs/3p/boost/1.39.0/lib:/vobs/3p/boost/1.39.0/lib64:/vobs/pet/3p/hdf5/HDF5.SOUPRS_GROUP_C/sles11-i686/lib:/vobs/pet_platform/lib-sles11-i686:/vobs/pet_raw/lib-sles11-i686:/vobs/pet_cal/lib-sles11-i686:/vobs/gre/pet/lib_common/lib64:/vobs/gre/pet/platform/lib:/vobs/helios/lib:/vobs/helios/com_platform/lib
[de680136@ctds32-3:Thu Dec 14:/vobs/pet_raw/source/rdfUtils/rdfAccept:]$ unset LD_LIBRARY_PATH

b. modify Makefile
add to LIBRARIES line:
    $(LIB_XT)

Now rebuild
[de680136@ctds32-3:Thu Dec 14:/vobs/pet_raw/source/rdfUtils/rdfAccept:]$ cmake
        mkdir -p -m 0777 /vobs/pet_raw/include /vobs/pet_raw/lib-sles11-i686 /vobs/pet_raw/bin-sles11-i686 /vobs/pet_raw/packages

        for d in sles11-i686 ; do if [ ! -d $d ]; then  mkdir -p -m 0777 $d ; fi; done

        clearmake --directory=sles11-i686 -C gnu  SRC_DIR=/vobs/pet_raw/source/rdfUtils/rdfAccept TARGETTYPE=x86 -f /vobs/pet_raw/source/rdfUtils/rdfAccept/Makefile rdfAcceptIdent
clearmake[1]: Entering directory `/vobs/pet_raw/source/rdfUtils/rdfAccept/sles11-i686'
        /vobs/util/tools/makeIdent -f rdfAcceptIdent -c rdfAccept

clearmake[1]: Leaving directory `/vobs/pet_raw/source/rdfUtils/rdfAccept/sles11-i686'
        clearmake --directory=sles11-i686 -C gnu  SRC_DIR=/vobs/pet_raw/source/rdfUtils/rdfAccept TARGETTYPE=x86 -f /vobs/pet_raw/source/rdfUtils/rdfAccept/Makefile rdfAccept
clearmake[1]: Entering directory `/vobs/pet_raw/source/rdfUtils/rdfAccept/sles11-i686'
        gcc    -c rdfAcceptIdent.c -o rdfAcceptIdent.o

        g++ -o rdfAccept rdfAccept.o rdfAcceptIdent.o -rdynamic  -m32  -L /vobs/pet_platform/lib-sles11-i686 -lconfigMgr -lpetlwc -lH5Wrap -lgebase2 -lpetbase -lpetcfg -lpethwcfg2 -lErr -L /vobs/pet_raw/lib-sles11-i686 -lrdf -lrdfCpp -lrivn -lRawPrimitives -lobrivn -lH5Wrap -lEvtList -L /vobs/com_platform/lib -lreadcfg -lmsghand -lcup -lcupipc -ldebug -leventmgr -lplatform_misc -L/vobs/pet/3p/hdf5/HDF5.SOUPRS_GROUP_C/sles11-i686/lib -lhdf5 -lhdf5_hl  -lpthread -lrdfv7.0 -lrdfv7.1 -lrdfv8.0 -lrdfv9.0 -lrdfAccept  
/usr/lib/gcc/i586-suse-linux/4.3/../../../../i586-suse-linux/bin/ld: warning: libfile.so, needed by /vobs/pet_raw/lib-sles11-i686/librdfv9.0.so, not found (try using -rpath or -rpath-link)
/usr/lib/gcc/i586-suse-linux/4.3/../../../../i586-suse-linux/bin/ld: warning: libcfg.so, needed by /vobs/pet_raw/lib-sles11-i686/librdfv9.0.so, not found (try using -rpath or -rpath-link)
        ln -s -f /vobs/pet_raw/source/rdfUtils/rdfAccept/sles11-i686/rdfAccept /vobs/pet_raw/bin-sles11-i686

clearmake[1]: Leaving directory `/vobs/pet_raw/source/rdfUtils/rdfAccept/sles11-i686'





        2.2.3 Build haifa view

            2.2.3.1 Shy tar script -  Copy derived objects
my alias:
[de680136@nmpetdev64:2018-03-29 14:34:06:/vobs/pet_platform/source:]5393$ ctDlDOs 7

Details:
[de680136@nmpetdev64:2018-01-18 14:24:27:/vobs/pet_platform/source:]2324$ cd /home/de683594/PET_PROJ_INFO/BUILD_TARS
[de680136@nmpetdev64:2018-01-18 14:40:49:/home/de683594/PET_PROJ_INFO:]2325$ ct pwv
Working directory view: ** NONE **
Set view: yosi_haifa_pac_col_ddg
[de680136@nmpetdev64:2018-01-18 14:41:08:/home/de683594/PET_PROJ_INFO:]2326$ /home/de683594/scripts/pet_scripts/extract_pet_dos_from_buils.sh pac_col_ddg.7

Example:
[de680136@nmpetdev64:2018-02-25 15:21:20:/vobs/pet_platform/include-legacy:]3772$ cd ~de683594/PET_PROJ_INFO/BUILD_TARS/

[de680136@nmpetdev64:2018-02-25 15:22:18:/home/de683594/PET_PROJ_INFO/BUILD_TARS:]3773$ ~de683594/scripts/pet_scripts/extract_pet_dos_from_buils.sh
what is the source view?
usage: /home/de683594/scripts/pet_scripts/extract_pet_dos_from_buils.sh view_name

[de680136@nmpetdev64:2018-02-25 15:22:33:/home/de683594/PET_PROJ_INFO/BUILD_TARS:]3774$ ct pwv
Working directory view: ** NONE **
Set view: yosi1_haifa_pac_col_ddg

[de680136@nmpetdev64:2018-02-25 15:22:45:/home/de683594/PET_PROJ_INFO/BUILD_TARS:]3775$ ~de683594/scripts/pet_scripts/extract_pet_dos_from_buils.sh pac_col_ddg.6

        2.2.4 Build 32bit

            2.2.4.1  ~/work/scripts/deployAcqBinaries_64.sh 
Builds and deploys.
Can edit script to disable deploy

            2.2.4.2 Deploy esoteric binaries
 source ~de683594/scripts/pet_scripts/setup_32


            2.2.4.3 Build command line
 alias cmakedc32="cmake clean && clearmake -C gnu debug=2 arch=32"

            2.2.4.4 Known issues

                2.2.4.4.1 pet_cal build fails

                    2.2.4.4.1.1 missing platSerialize lib
need to build vob: platSerialize, path: /vobs/platform/plat_serialize_pkt

                    2.2.4.4.1.2


                2.2.4.4.2


            2.2.4.5
        2.2.5 Build 64bit



    2.3 Run unit tests

        2.3.1 gtest

            2.3.1.1 set paths


export HDF5_PLUGIN_PATH=/vobs/pet_raw/lib-${HOST_DIST}-${HOST_ARCH}
in my .kshrc

Or you just set -
HDF5_PLUGIN_PATH = /vobs/pet_raw/lib-sles11-x86_64

- .kshrc
#linkage related
##################### Do not edit the following lines ##############

default_dir="/usr/3p/admin"
set -A MACHINE_INFO $(uname -a)

#echo "i pitty da fool on ${MACHINE_INFO[1]}!"

if [ -r "$default_dir/CSHRC" ]; then
        source $default_dir/CSHRC
else
	if [ "${MACHINE_INFO[0]}" == "Linux" ]; then
		set sysTYPE=linux2
		set system=linux2
	    	if [ "${MACHINE_INFO[1]}" == "petrecon1" ]; then
                
                    export LIB_EXT=64
                    #set it to something common first
                    export LD_LIBRARY_PATH=/usr/lib${LIB_EXT}:/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib64/linux2:/usr/lib64:/usr/X11R6/lib
                elif [ ${MACHINE_INFO[9]} == "x86_64" ]; then
                    export LIB_EXT=64
                    #set it to something common first
			export LD_LIBRARY_PATH=/usr/lib${LIB_EXT}:/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib64/linux2:/usr/lib64:/usr/X11R6/lib
       		else
                    export LD_LIBRARY_PATH=/usr/lib:/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib/linux2:/usr/lib:/usr/X11R6/lib
		fi
	else
		set sysTYPE=sun5
		set system=sun5
    		export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/lib
		# source PET .project file if it exists
		if ( -f $HOME/.project.cshrc ) then
    			source $HOME/.project.cshrc
		fi
	fi
fi

export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/3p/boost/1.39.0/lib
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/3p/boost/1.39.0/lib64
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/3p/hdf5/HDF5.SOUPRS_GROUP_C/${HOST_DIST}-${HOST_ARCH}/lib
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_platform/lib-${HOST_DIST}-${HOST_ARCH}
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_raw/lib-${HOST_DIST}-${HOST_ARCH}
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_cal/lib-${HOST_DIST}-${HOST_ARCH}

#
# libgebase load lib paths
#
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/lib_common/lib64

#
# HDF5 load library paths
#
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib:/vobs/helios/lib:/vobs/helios/com_platform/lib
#setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/home/ctnetap1/de058754/b64static/lib
#setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/home/ctnetap1/de058754/szip-2.1/lib


- .bashrc

#For evn var HDF5 lib
##
## Linking with libraries in new component vobs
##
if [ -f "/etc/redhat-release" ]; then
    export HOST_DIST=rhel5
fi

if [ -f "/etc/SuSE-release" ]; then
    export HOST_DIST=sles11
fi

export HOST_ARCH=$(/bin/arch)
export HDF5_PLUGIN_PATH=/vobs/pet_raw/lib-${HOST_DIST}-${HOST_ARCH}
##################### Do not edit the following lines ##############

default_dir="/usr/3p/admin"
MACHINE_INFO=( $(uname -a) )

#echo "i pitty da fool on ${MACHINE_INFO[1]}!"

if [ -r "$default_dir/CSHRC" ]; then
        source $default_dir/CSHRC
else
	if [ "${MACHINE_INFO[0]}" == "Linux" ]; then
		set sysTYPE=linux2
		set system=linux2
	    	if [ "${MACHINE_INFO[1]}" == "petrecon1" ]; then
                
                    export LIB_EXT=64
                    #set it to something common first
                    export LD_LIBRARY_PATH=/usr/lib${LIB_EXT}:/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib${LIB_EXT}
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib64/linux2:/usr/lib64:/usr/X11R6/lib
                elif [ ${MACHINE_INFO[9]} == "x86_64" ]; then
                    export LIB_EXT=64
                    #set it to something common first
			export LD_LIBRARY_PATH=/usr/lib${LIB_EXT}:/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib${LIB_EXT}
			export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib64/linux2:/usr/lib64:/usr/X11R6/lib
       		else
                    export LD_LIBRARY_PATH=/usr/lib:/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/com_platform/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib
                    export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/lib/linux2:/usr/lib:/usr/X11R6/lib
		fi
	else
		set sysTYPE=sun5
		set system=sun5
    		export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/lib
		# source PET .project file if it exists
		if ( -f $HOME/.project.cshrc ) then
    			source $HOME/.project.cshrc
		fi
	fi
fi

export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/3p/boost/1.39.0/lib
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/3p/boost/1.39.0/lib64
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet/3p/hdf5/HDF5.SOUPRS_GROUP_C/${HOST_DIST}-${HOST_ARCH}/lib
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_platform/lib-${HOST_DIST}-${HOST_ARCH}
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_raw/lib-${HOST_DIST}-${HOST_ARCH}
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/pet_cal/lib-${HOST_DIST}-${HOST_ARCH}

#
# libgebase load lib paths
#
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/lib_common/lib64

#
# HDF5 load library paths
#
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/vobs/gre/pet/platform/lib:/vobs/helios/lib:/vobs/helios/com_platform/lib
#setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/home/ctnetap1/de058754/b64static/lib
#setenv LD_LIBRARY_PATH ${LD_LIBRARY_PATH}:/home/ctnetap1/de058754/szip-2.1/lib


#source ~/.aliases
. ~/.aliases

-
            2.3.1.2 build and run
[de680136@ctds64-1:Wed Nov 22:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ 
cmake test
./sles11-x86_64/gtestRdfCpp 
[de680136@ctds64-1:Wed Nov 22:/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest:]$ ./sles11-x86_64/gtestRdfCpp 
Running main() from gtest_main.cc
[==========] Running 11 tests from 3 test cases.
[----------] Global test environment set-up.
[----------] 2 tests from DeadTimeDatasetTest
[ RUN      ] DeadTimeDatasetTest.ReadAndPushSamples
[       OK ] DeadTimeDatasetTest.ReadAndPushSamples (725 ms)
[ RUN      ] DeadTimeDatasetTest.ReadWriteFile
[       OK ] DeadTimeDatasetTest.ReadWriteFile (264 ms)
[----------] 2 tests from DeadTimeDatasetTest (989 ms total)

[----------] 7 tests from SinogramDatasetTest
[ RUN      ] SinogramDatasetTest.ReadWriteSinogramFile
Keeping temporary file: /tmp/Sinogram_obj_test_gzl4bo (369152 bytes)
[       OK ] SinogramDatasetTest.ReadWriteSinogramFile (13 ms)
[ RUN      ] SinogramDatasetTest.WriteAndRead3dTofFile
Keeping temporary file: /tmp/Sinogram_obj_test_vaOYd9 (1405812 bytes)
[       OK ] SinogramDatasetTest.WriteAndRead3dTofFile (700 ms)
[ RUN      ] SinogramDatasetTest.CalcStats
 Expand Sino Stack and Calc Stats Time: 0.472s Uncompress Partial CalcStats Time: 0.241s
Keeping temporary file:  (7286680 bytes)
[       OK ] SinogramDatasetTest.CalcStats (941 ms)
[ RUN      ] SinogramDatasetTest.GetTofCollapsed
Keeping temporary file: /tmp/Sinogram_obj_test_oQsO9X (2564300 bytes)
[       OK ] SinogramDatasetTest.GetTofCollapsed (1017 ms)
[ RUN      ] SinogramDatasetTest.PushTofCollapsed3dSino
Keeping temporary file: /tmp/Sinogram_obj_test_DjpW3P (1985748 bytes)
[       OK ] SinogramDatasetTest.PushTofCollapsed3dSino (880 ms)
[ RUN      ] SinogramDatasetTest.AddByteTofSinoLists
Keeping temporary file: /tmp/Sinogram_obj_test_kP8p9K (2708608 bytes)
[       OK ] SinogramDatasetTest.AddByteTofSinoLists (1407 ms)
[ RUN      ] SinogramDatasetTest.CheckSlice
Keeping temporary file:  (140737140006352 bytes)
[       OK ] SinogramDatasetTest.CheckSlice (1801 ms)
[----------] 7 tests from SinogramDatasetTest (6759 ms total)

[----------] 2 tests from SinglesDatasetTest
[ RUN      ] SinglesDatasetTest.ReadWriteSinglesFile
08:17:17.710 Error /vobs/pet_raw/source/rdfAPI/librdfCpp/SinglesDataset.cpp(272) in bool CSinglesRDFPrivate::Read(uint32_t, uint32_t, CSinglesList**): [Wed Nov 22 08:17:17 2017]Trying to read invalid number of samples to singles dataset
08:17:17.711 Error 

CRawDataAccessError dump for error log...logged from ~CRawDataAccessError
[TID:140422425315072][/vobs/pet_raw/source/rdfAPI/librdfCpp/SinglesDataset.cpp(272) in bool CSinglesRDFPrivate::Read(uint32_t, uint32_t, CSinglesList**): [Wed Nov 22 08:17:17 2017]Trying to read invalid number of samples to singles dataset]

Keeping temporary file: /tmp/Singles_obj_test_3p7ijO (181096 bytes)
[       OK ] SinglesDatasetTest.ReadWriteSinglesFile (7 ms)
[ RUN      ] SinglesDatasetTest.PushSinglesList
Keeping temporary file:  (140737140006352 bytes)
[       OK ] SinglesDatasetTest.PushSinglesList (7 ms)
[----------] 2 tests from SinglesDatasetTest (14 ms total)

[----------] Global test environment tear-down
[==========] 11 tests from 3 test cases ran. (7762 ms total)
[  PASSED  ] 11 tests.
	
            2.3.1.3 gtest

                2.3.1.3.1 Common issues

                    2.3.1.3.1.1 error: void value not ignored as it ought to be
                    
/vobs/pet_raw/source/rdfAPI/librdfCpp/gtest/RdfUserBlockTest.cpp:205: error: void value not ignored as it ought to be

Short fix, ASSERT_TRUE must be place in void returning function

long answer, https://stackoverflow.com/questions/34696483/assert-throw-error-void-value-not-ignored-as-it-ought-to-be
Short version

You write test in the wrong way, to write test you should put assertion inside test (macro TEST) or test fixtures (macro TEST_F).

Long version

a . What's really happens?

To find out the real problem is not easy because the Google Testing Framework use macros which hide real code. To see code after macro substitution is required to perform preprocessing, something like this:

g++ -E main.cpp -o main.p
The result of preprocessing when using ASSERT_THROW will be looks like this (after formatting):

class my_exp {};

int main(int argc, char *argv[])
{
    switch (0)
        case 0:
        default:
        if (::testing::internal::ConstCharPtr gtest_msg = "") {
            bool gtest_caught_expected = false;
            try {
                if (::testing::internal::AlwaysTrue () ) {
                    throw my_exp ();
                };
            } catch (my_exp const &) {
                gtest_caught_expected = true;
            } catch (...) {
                gtest_msg.value = "Expected: throw my_exp() throws an exception of type my_exp.\n Actual: it throws a different type.";
                goto gtest_label_testthrow_7;
            } if (!gtest_caught_expected) {
                gtest_msg.value = "Expected: throw my_exp() throws an exception of type my_exp.\n  Actual: it throws nothing.";
                goto gtest_label_testthrow_7;
            }
        }
        else
            gtest_label_testthrow_7:
            return ::testing::internal::AssertHelper (::testing::TestPartResult::kFatalFailure, "main.cpp", 7, gtest_msg.value) = ::testing::Message ();

    return 0;
}
For EXPECT_THROW result will be the same except some difference:

    else
        gtest_label_testthrow_7:
        ::testing::internal::AssertHelper (::testing::TestPartResult::kNonFatalFailure, "main.cpp", 7, gtest_msg.value) = ::testing::Message ();
b . OK, the reason of different behaviour is found, let's continue.

In the file src/gtest.cc can be found AssertHelper class declaration including assignment operator which return void:

void AssertHelper::operator=(const Message& message) const
So now reason of the compiler complain is clarified.

c . But why this problem is caused is not clear. Try realise why for ASSERT_THROW and EXPECT_THROW different code was generated. The answer is the macro from file include/gtest/internal/gtest-internal.h

#define GTEST_FATAL_FAILURE_(message) \
  return GTEST_MESSAGE_(message, ::testing::TestPartResult::kFatalFailure)

#define GTEST_NONFATAL_FAILURE_(message) \
  GTEST_MESSAGE_(message, ::testing::TestPartResult::kNonFatalFailure)
which contain return for fatal case.

d . But now is question why this assertions usually works well?

To answer of this question try investigate code snipped which written in correct way when assertion is placed inside test:

#include <gtest/gtest.h>

class my_exp {};

TEST (MyExp, ThrowMyExp)
{
    ASSERT_THROW (throw my_exp (), my_exp);
}
To exclude pollution of the answer I just notice that in such case the return statement for ASSERT_THROW also exist, but it is placed inside method:

void MyExp_ThrowMyExp_Test::TestBody ()
which return void! But in your example assertions are placed inside main function which return int. Looks like this is source of problem!

Try prove this point with simple snippet:

void f1 () {};
void f2 () {return f1();};
//int  f2 () {return f1();}; // error here!

int main (int argc, char * argv [])
{
    f2;
    return 0;
}
e. So the final answer is: the ASSERT_THROW macro contain return statement for expression which evaluates to void and when such expression is placed into function which return non void value the gcc complain about error.

P.S. But anyway I have no idea why for one case return is used but for other case is not.

Update: I've asked this question on GitHub and got the following answer:

ASSERT_XXX is used as a poor man's exception to allow it to work in environments where exceptions are disabled. It does a return; instead. It is meant to be used from within the TEST() methods, which return void.
Update: I've just realised that this question described in the official documentation:

By placing it in a non-void function you'll get a confusing compile error > like "error: void value not ignored as it ought to be".



                2.3.1.3.2
            2.3.1.4 SubjectMaking Google Unit Tests Into Friend Classes

Mike was asking for some details today on how to use class friends for google unit testing protected or private methods. Here's how to do it and an example if you need to look at the code.

If you declare a google unit test like the following:

class SomeVeryDescriptiveClassName : public ::testing::Test
{
    protected:
        virtual void SetUp() { }
        virtual void TearDown() {}
};

TEST_F(SomeVeryDescriptiveClassName, MySimpleTestFunc)

The Google Test macro TEST_F() actually creates the following function when compiling your test code:

SomeVeryDescriptiveClassName_MySimpleTestFunc_Test

You would then need to add the following to the library or application class:

friend class SomeVeryDescriptiveClassName_MySimpleTestFunc_Test; // for unit testing

For an example, see:

/vobs/pet_raw/source/rdfAPI/libRawPrimitives/MultiDimArrayList.h
/vobs/pet_raw/source/rdfAPI/libRawPrimitives/gtest/MultiDimArrayListTest.cpp

            2.3.1.5

        2.3.2
    2.4 codeing workflow related aliases

alias ctxt='_open_current_context'
#alias ctxt_piano='_open_current_context_piano'
alias ct='cleartool'
alias ctlscoR="_list_checkoutsR"
alias ctlscoVerb="_list_checkouts__verbose"
alias ctlsco="_list_checkouts"
alias ctciall="_ci_all"
alias ctmergFromView="__merge_from_view"
alias ctmergFromBranch="__merge_from_branch"
alias ctmergFromViewPrint="__merge_from_view_print"
alias ctmergFromBranchPrint="__merge_from_branch_print"


    2.5
	
	
	
	
	
	
	
	
	






3. Source code

    3.1 Architecture

        3.1.1 petRDFS
Raw Data Format - save the scan images

grep in code:

pet_acq/source/libacqCtrl/acqmain.cpp|6492| * under /petRDFS that indicates the directory of the most recently produced sinogram RDFs.
    called from static void FrameSaved( struct GEMessage *p1 )

pet_acq/source/libdetectorIF/SDTlistFrame.h|18| #define RDF_PATH_SDT_LIST "/petRDFS/SDTtemp"
pet_acq/source/libframeSaver/FrameSaver.cpp|261| #define TEMP_SINO_LINK_DIR "/petRDFS/workInProgress"
pet_acq/source/libframeSaver/FrameSaver.cpp|263| #define TEMP_SINO_TEST_FILE "/petRDFS/workInProgress/testfile"
pet_acq/source/libframeSaver/FrameSaver.cpp|279| if (strncmp(root, "petRDFS", 7) == 0)
pet_acq/source/libzch/ZchControl.cpp|39| /*static*/const string CZchControl::m_zchTempDirPath = "/petRDFS/zchTemp/";
pet_acq/source/libzch/ZchControl.cpp|41| /*static*/const string CZchControl::m_reserveFilePath = "/petRDFS/zchTemp/reserve"; 
pet_acq/source/libzch/ZchControl.cpp|79| ErrLog(__DATE__, __func__, S_ACQ_FILE_SPACE_EM, "/petRDFS");
pet_acq/source/system_test/coinLossCk|39| These are typically stored in /petRDFS/.../SINOxxxx.
pet_acq/source/system_test/showSinoCounts|16| These are typically stored in /petRDFS/.../SINOxxxx.
pet_raw/source/librdfAccept/rdf7.0lib/rdfExternal7_0.h|152| #define  RDF_FILESYSTEM_ROOT_DEFAULT         "/petRDFS"
pet_raw/source/librdfAccept/rdf7.1lib/rdfExternal7_1.h|153| #define  RDF_FILESYSTEM_ROOT_DEFAULT         "/petRDFS"
pet_raw/source/librdfAccept/rdf8.0lib/rdfExternal8_0.h|177| #define  RDF_FILESYSTEM_ROOT_DEFAULT         "/petRDFS"
pet_raw/source/rdfAPI/librdf/rdfExternal.h|195| #define  RDF_FILESYSTEM_ROOT_DEFAULT         "/petRDFS"
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|488| //   sino file path: "/petRDFS/ABC/DEF/SINO0001"
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|8190| // <top-level-dir>     - root filesystem directory (e.g. /petLists or /petRDFS) or alternate top-level directory (e.g. /petRDFS/SDTtemp)
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|8205| // - CRdfFile::Create() - to create SINOxxxx files in the /petRDFS filesystem
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|8209| // - Top level (/petRDFS or /petLists depending on the dataOrientation parameter)
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|8219| // - no guarantee is made that the intermediate directories for the same scan will be the same on both the /petLists and /petRDFS filesystems
pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp|8233| examDirPath = pCreateParams->alternateRDFS;                 // pet_acq creates corresponding SDT data in /petRDFS/SDTtemp
pet_raw/source/rdfAPI/librdfCpp/testScanDir/testScanDir.cpp|77| strcpy(createParams.alternateRDFS, "/petRDFS/SDTtemp");
pet_raw/source/rdfAPI/librdfCpp/testScanDir/testScanDir.cpp|100| strcpy(createParams.alternateRDFS, "/petRDFS/SDTtemp");
pet_raw/source/rdfAPI/librdfCpp/testScanDir/testScanDir.cpp|234| cout << "Enter Base File path name (Format /petRDFS/PPPPPPP/EEEEEEEE/SSSSSSSS/FileName)" <<endl;
tags|17045| CZchControl::m_reserveFilePath	pet_acq/source/libzch/ZchControl.cpp	/^\/*static*\/const string CZchControl::m_reserveFilePath = "\/petRDFS\/zchTemp\/reserve"; $/;"	m	class:CZchControl	file:
tags|17048| CZchControl::m_zchTempDirPath	pet_acq/source/libzch/ZchControl.cpp	/^\/*static*\/const string CZchControl::m_zchTempDirPath = "\/petRDFS\/zchTemp\/";$/;"	m	class:CZchControl	file:
tags|198228| m_reserveFilePath	pet_acq/source/libzch/ZchControl.cpp	/^\/*static*\/const string CZchControl::m_reserveFilePath = "\/petRDFS\/zchTemp\/reserve"; $/;"	m	class:CZchControl	file:
tags|198773| m_zchTempDirPath	pet_acq/source/libzch/ZchControl.cpp	/^\/*static*\/const string CZchControl::m_zchTempDirPath = "\/petRDFS\/zchTemp\/";$/;"	m	class:CZchControl	file:

        3.1.2 High level diagram
https://devcloud.swcoe.ge.com/devspace/display/UMCOA/PET+acq+schematics


    3.2 RDF

RDF files use HDF library.
Structure: groups (folders), datasets (has metadata, attributes, dimensions etc), filters (like compression)

There are different types of files. 

list RDF: contains singles, deadtimes, coincidences and medical records

BLF - Base List File

HDFView - viewer

OBRIVN - propietary GE compression algorithm 
GLEPL  - propietary GE compression algorithm for sinograms, used in MICE

supports 'user block' : whatever data GE wants to put. 
E.g. keep track of changed records.

        3.2.1  /vobs/pet_platform/source/libH5Wrap/H5Wrap.cpp
HDF5 wrapper
[212680136@G9VK2GH2E:Sun Nov 19:~:]$ ssh ${USER_UNX}@${DEVM3} cat /home/de680136/st2

        3.2.2 /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp

        3.2.3
    3.3 RDF Data

        3.3.1 general
PET Raw Data Files (RDFs) are files that contain PET raw data.  RDFs come in two flavors: histogram RDFs and list RDFs.  Histogram RDFs contain histograms of PET raw data (Sinograms, Projections or Spectra).  List RDFs contain a list of coincidence stream events.  
In addition to their main bulk data, both histogram and list RDFs contain additional header and ancillary data.  Headers contain data such as system geometry parameters and configuration information.  Ancillary data is raw data such as detector Deadtime statistics or detector singles statistics that can be used for image reconstruction.
Although a host of different APIs can be used to access or modify the contents of RDFs, the PET RDF Data Access software unit provides the Core C++ RDF API.  The Core C++ RDF API is the primary API that exists for interfacing with RDFs.  The Core C++ RDF API contains functions to create, open, read, write, and close RDFs.  

Finally, the PET RDF Data Access software unit contains a few command line programs, collectively called the RDF Utilities.  These programs have requirements traceable to the SRS/SSRS.  They exist to allow users to quickly perform frequently-needed operations on RDFs.  The following list contains the RDF Utilities followed by a brief description of each:
-	rdfAccept  Verifies and converts if necessary legacy RDFs to current version
-	rdfTell  Prints contents of RDFs
-	ListDecode  Prints event list of list-based RDFs
-	ListTool  Analyzes and prints statistics of ancillary data and event list of list-based RDFs
-	rdfImportRawList  Creates List type RDF from a given bulk list data
-	rdfCompress  Compresses the Sinogram-based RDF specified in the command line args.
-	rdfDecompress  Decompresses the Sinogram-based RDF specified in the command line args.
-	glepl  Compresses the List-based RDF specified in the command line args.
-	unglepl  Decompresses the List-based RDF specified in the command line args.
-	rdfReduce  Reduce a list based raw data file geometry wrt axial blocks per module

Starting with RDF version 10 the utilities rdfCompress, rdfDecompress, glepl and unglepl will be replaced with a single Utility to be known as rdfRepack. More information on rdfRepack can be found in [16]

The RDF Librarys header file /vobs/pet_raw/source/rdfAPI/librdf/rdfExternal.h is considered the definitive description of the PET Raw Data Files format, content and remaining C code library of access functions. There are three major classes CRdfBase, CRdfFile and CRdfList that together make the API for RDF Library.
CRdfBase is abstract base class for RDF functionality that is common to both List and Sinograms RDFs. It provides member functions for read, write and update, members can be categorized in sections such as members that deal with general RDF file open and close issues, members that help RDF header read write, methods that are specific to singles, members that read write Deadtime and methods specific to detector signature data.
CRdfFile is used exclusively for Sinogram RDFs it extends CRdfBase which contains functionality common to List and Sinogram RDFs. This class adds several function that are very specific to Sinograms data including 2D Sinogram, 3D TOF/Non TOF Sinogram, energy spectra and position spectra.
CRdfList is used exclusively for List RDFs it extends CRdfBase which contains functionality common to List and Sinogram RDFs. It adds convenience operations functions for List files.

        3.3.2 Versions

            3.3.2.1 RDFv10.0
A summary of the more significant RDFv10.0 API and RDF content changes are:
-	More intuitive dataset names, greater use of Attributes
-	Registered User-defined Compression Filters
-	GLEPLMI
-	OBRIVN
-	List data organized in MICE format as:
-	Machine Independent Coincidence Events
-	Time index into MICE
-	Trigger index into MICE
-	GLEPLMI hdf5 compression filter
-	Optional coincidence events with Energies
-	Multi-Dimensional Data Arrays of simple data type
-	One hdf5 dataset (vs RDFV9 multi-dataset)
-	GZIP and Proprietary hdf5 compression filter(s) eg. OBRIVN 
-	Primary Targeted Data:
-	Singles[time][minor ring][crystal in ring]
-	Energy, Position and Timing Spectra
-	BlockBusy[time][major ring][block in ring]
-	3D Sinograms

In addition, a new set of C++ Classes representing encapsulated raw data objects, will serve as an extension of Raw Data Access application interface. These data objects extension provides high performance in-memory raw data manipulation of compressed datasets. More details can be found in [16]

            3.3.2.2 A summary of the more significant RDFv9.0 API and RDF content changes were:
	C++ RDF API defined in the classes CRdfFile and CRdfList, the old C RDF API is deprecated, all product code has been changed to use the C++ RDF API instead of the legacy C RDF API
	Underlying RDF file format changed from flat file to HDF5, format changes are encapsulated under C++ RDF API hidden for outer world
	The C++ RDF API has been moved to the new vobs.   CRdfFile is defined in /vobs/pet_raw/include/RdfFile.h and CRdfList is defined in /vobs/pet_raw/include/RdfList.h.  Header structs and RDF constants are defined in /vobs/pet_raw/include/rdfExternal.h.  An RDF base class has also been created (CRdfBase defined in /vobs/pet_raw/include/RdfBase.h) to contain functionality common to both List and Sinogram RDFs
	Elimination of Patient Information for safety related mis-association of patient data mitigations, and to simplify designed for HIPPA 
	Restructuring of the RDF System Geometry data 
	Separation of detector/electronics architecture specific Deadtime and Pile Up Coefficients (PUC) out of the RDF Geometry data structure, with corresponding new access methods for this data
	Updated RDF System Geometry headers to reflect PET detectors with modules, units, blocks, and crystals
	Added detector unit size fields
	Revamping of the Scanner / Detector Geometry for better correlation with the Common MR/PET and CT/PET Galileo System Geometry Worksheet 
	Identification of Galileo architecture  coincidence events  lists to be encapsulated in list-based RDFs
	Addition of a parameter eventIntegrationMode in EDCAT substruct indicating event energy integration mode in the RDF Acquisition Parameters for Dual Integration

        3.3.3 Backward Compatibility Strategy

The rdfAccept methods and executable may not allow RDFv10.0 raw files that were produced on a PET Scanner of a different (non-native) product family to be accepted onto the scanner. For E.g. the DMI configuration will support DMI DR product configurations data (and vice versa), but will not support Discovery IQ datasets. 

To check for a different product family the detector geometry parameters like crystals per block, detector radius, radial modules per major ring are checked. If this criterion is consistent, then the RDF is considered to come from a scanner that is in the scanners product family. Note that the number of major rings can vary and still be in the product family.

All RDFs produced with the current implementation of RDA SW will be marked as RDFv10.0 at the create time. 

With the backward compatibility strategy, the majority of RDFs made with the current RDA SW (i.e. all SINO, Spectra and non-compressed List Files) will be rdfAccepted by IB RDFv10.0 systems (with the exclusion of different product family restriction).

Note that the RDF Library file open methods check that the RDF MAJOR and MINOR VERSION are compatible with the compiled RDF MAJOR and MINOR VERSION. For this release of RDA SW, the compiled RDF MAJOR.MINOR version will default to 10.0.

-> RDFv9 to RDFv10
The RDFv10.0 rdfAccept methods and command line executables options can be configured by modifying the parameters in rdfAcccept.cfg file (in /usr/PET/systemConfig/local). This cfg file will have options to support, import and convert RDFv9.0 files from within the same product family (i.e. common detector geometry with exception of number of major rings), and will also include a * wildcard option, to discriminate which non-native RDFs can be accepted onto the system. 

The list and the sinogram files can be converted into HDF5 format RDFv10 files. The List event data is converted to MICE format.
-> RDFv8 to RDFv10
Support to import and convert RDFv8.0 files from within the same product family will be included in rdfAccept as well. The list and the sinogram files from the kittyhawk architecture can be directly converted into HDF5 format RDFv10 files. 
 
The List event data is converted from Kittyhawk event type to MICE format. 

Also, the rdfAccept in general, will restrict RDFv8 and RDFv9 files from other product families (with the exception of DMI family accepting DMI DR configurations). The segment data in the sinogram files will be OBRIVN compressed. 

        3.3.4 PET Raw File Systems
On a scanner, RDFs are stored on the PARC in either /petLists or /petRDFS.  These are both XFS file systems.  Each file system is its own software unit in the PAC subsystem.  These software units are named “PET List Data Storage” and “PET Sinogram Data Storage.”  
The /petLists and /petRDFS file systems utilize XFS as the underlying file system for the following primary reasons:
•	Journal File System (reliability)
•	Superior performance
•	Support of Direct I/O for bypassing the file system cache
•	Support for fast file space allocation 
•	Support for file truncation (recover previous allocated, but not used space)
The RDF Library utilizes the Direct IO, fast file space allocation and truncation capabilities to accomplish its performance requirements.

        3.3.5 HDF5
RDFv9 and RDFv10 are implemented with underlying HDF5 (Hierarchical Data Format 5) technology.  The HDF5 self-describing hierarchical data format and extensive interface it is BSD-style open source software distributed by the HDF Group. Reference www.hdfgroup.org/HDF5.
HDF5 is designed for management of large and complex data collections and has supported interfaces for a host of programming languages, including C, C++, Java, Python and MATLAB.
Although the PET Product Software has a traditional RDF API access library, to insulate the Product Software applications from the underlying HDF5 implementation specifics, HDF5 provides greater evolution of the PET Raw Data at lower development and maintenance cost. Backward compatibility support for PET Raw Data Files is less effort with the HDF5 implementation since all data components are referenced by name versus file offset.
Lossy TOF List Compression is supported from RDFv9.1 and forward to handle the minor update in the compressed list files which has the mashed deltaT data.

        3.3.6 Error Handling and Recovery
The strategy for exception handling and error detection, interpretation, and recovery is to use C++ try/catch exception handling where possible. RDF C++ API returns true or false for success or failure but in term of failures it also creates an error stack internally, it is client application’s responsibility to get error log form object and stdout and/or write it to gesyslog file via CRawDataAccessError class, (for an example see rdfTell utility source code). It is a thread safe class and can be used in multithreaded environment. Mutual exclusion is achieved by using ge_base::CMutex class to serialize calls to HDF5 API, name semaphores are used for write access to files remember Open() call will block if two files are opened for write access.
The Raw Data Access libraries functions maintains error stack for client applications and provide access to the error stack through the APIs GetErrorLog(), GetH5WrapErrorLog(), and GetH5WrapErrorStack() calls, these functions are member of CRfBase class. Utility rdfTell in error situation accesses the error log from RDA libraries and logs, it is good reference example to understand the usage of RDA error handling mechanism

        3.3.7 PET RDF Contents and File Format

The section describes what data can be expected to be in an RDF.  Access to this data (via libraries and command-line utilities) will be discussed in later sections of this document.
In short, RDFs are comprised of three components: header data, bulk data, and ancillary data.  Each of these three components is discussed below.

            3.3.7.1 Header Data
RDFs contain headers that describe the contents of the file. The RDF typically contains more than one type of data.  Some of the types of data include (not meant to be all-inclusive):
•	Bulk data of histogram or event list type (this typically represents the majority of the file total size)
•	Singles data
•	Deadtime data (with several different sub-types)
•	Temperature data
•	Scanner geometry data
•	Exam data
•	Acquisition Statistics
•	Acquisition Parameters

For each major type of data, there is a sub-header that describes the data (e.g. its size or format, or vintage).  All RDFs have a complete set of sub-headers, even if the RDF does not contain data of that type, in which case the sub-header will indicate no data of that type. These headers also indicate if file space was allocated for the type of data.

The collection of sub-headers (all of which are mandatory) is sometimes called the RDF “mega header”. The Mega Header represents a sequential with a “pre-defined order” organization of the headers. All RDFs of the same revision will have identical mega-header data structure. After the mega-header, there will be ancillary data. Ancillary data is data that is part of the acquired data but not the primary acquired data. The “Bulk data” is considered the primary data.  An example of Ancillary data is the Singles Data.  The Singles sub-header defines the Singles ‘meta-data’. The Singles sub-header describes how much file space is reserved for Singles Data, whether or not the allocated space has been written with valid Singles data, the type and format of the Singles Data and a file offset of where to find the Singles Data.  The other sub-headers define the meta-data associated with their specific ancillary or bulk data.

            3.3.7.2 Bulk Data
Bulk Data is the principal data in an RDF.  In histogram RDFs, the bulk data is a histogram (or sinogram).  In list RDFs, the bulk data is a coincidence event list.

                3.3.7.2.1 Histograms
There will be a raw data event histogram type (type e.g. 2D_SINOGRAM, 3D_PROJECTION, 3D_TOF_PROJECTION, ENERGY_SPECTRA, POSIITON_SPECTRA, CRYSTAL_TIME_SPECTRA, etc.)  parameter added to the Database Schema for the scan information. This schema parameter will have a 1:1 correlation to the existing RDF_HISTOGRAM_FORMAT.

typedef enum {
S_RDF_SINOGRAM = 0, /* (z,theta,r) 2D sinograms */
S_RDF_BLOCK_TIMING, /* (z,theta,r,tof) CTC sinograms */
S_RDF_RECTILINEAR, /* Scout like - not implemented */
S_RDF_3D_SINOGRAM, /* Major Rev 2 add - (u,v,theta,phi) 3D projections */
S_RDF_3D_NORM_CORRECTION, /* Major Rev 2 add - Detector Normalization Vals */
S_RDF_LIST_ORIENTATION, /* Major Rev 6 add - A List versus Data Segments */
S_RDF_2D_TOF_SINOGRAM, /* Major Rev 6 - (z,theta,r,tof) - not implemented */
S_RDF_3D_TOF_SINOGRAM, /* (phi,u,tof,theta,v) 3D projection with TOF */
S_RDF_ENERGY_SPECTRA, /* (module,block,y crystal,x crystal,energy bin) */
S_RDF_POSITION_SPECTRA, /* (module, block, Z bin, X bin) */
S_RDF_CRYSTAL_TIMING_SPECTRA /* (module, block, y crystal, x crystal, dT bin) */
} RDF_HISTOGRAM_FORMAT;

Raw Data File histograms are compressed transparent to the application using a GEHC proprietary compression algorithm, RIVN. Decompression occurs on-the-fly by means of the RDF Library 'read' histogram functions. The level of data reduction is dependent on the number of histogram cells, size of cells (8-bit or 16-bit), and the density (counts per cell). For most clinical scans, non-TOF byte mode histograms are typically reduced in size by at least 40%, TOF byte mode histograms are typically reduced in size by at least 90%.

For the Dayton program the RIVN compression algorithm was enhanced to get better reduction in file size for TOF histograms with minimal impact on time to compress or decompress. This optimization was achieved by using a more sophisticated run-length encoding of consecutive nibbles of zero count. Refer to DOC0334336 for details of RIVN.

id=__Galileo_And_Mice_List_Headers__
                3.3.7.2.2 Coincidence Event List
The Galileo Scanner Architecture introduces a new set of coincidence event definitions (Reference [12] ).

RDFv9.0 and later versions will have an additional enumerated value to identify this type of event list data, RDF_GALILEO_LIST_TYPE. 

RDFv10.0 and later versions will have an additional enumerated value to identify MICE type of event list data, RDF_MICE_V1_LIST_TYPE. 

typedef enum {
RDF_COINC_STREAM_LIST_TYPE, /* Event list from a DST, DSTE or DST RX scanner */
RDF_ORDERED_LOR_LIST_TYPE, /* A LOR re-ordered event list from a DST/DSTE/DST RX */
RDF_TOF_GEN1_COINC_STREAM_LIST, /* Event list from a TOF Gen1 - DFE based scanner */
RDF_GALILEO_LIST_TYPE 	/* Event list from a Galileo Architecture Scanner */
RDF_MICE_V1_LIST_TYPE     /*List data in MICE format type*/
} RDF_LIST_TYPES;


The type of events is recorded in the List Header of a list-based RDF file. The RDF_LIST_HEADER is included below for reference:

typedef struct RDF_LIST_HEADER RDF_LIST_HEADER;
struct RDF_LIST_HEADER {
    n32 listType;           /* Ref enum RDF_LIST_TYPES            */
    n32 numAssocListFiles;  /* Number of list files to complete one List. Filesystem max file
                                                 * size may require multiple files to complete one List. */
    n32 whichAssocLFile;    /* This file is 'n' of numAssocListFiles (starting with '1') */
    n32 listAcqTime;             /* Total milliseconds of List Data for all assocListFiles */
    n32 listStartOffset;          /* Byte offset from start of RDF to Start of List Data */
    n32 isListCompressed;   /* booleen. SYS_TRUE if the event list is compressed */
    n32 listCompressionAlg; /* Set to RDF_LIST_COMPRESSION_ALG_TYPE if isListCompressed=SYS_TRUE */
    n32 evalAsBadCompress;  /* Compression has been attempted on this list file and is assessed as 
                                                     * not a candidate for compression (eg. negative compression ratio, 
                                                     * autoverification failures, etc.) */
    
    /* The next group of parameters reflect the first and last absolute time stamps of Time Mark events
     * in the event list. The 'areEvtTimeStampsKnown' must equal SYS_YES, else the time stamps have not 
     * been determined (i.e. are invalid).  Units of the time stamps are listType specific.
     */
    n32 areEvtTimeStampsKnown;  /* SYS_YES | SYS_NO */
    n32 firstTmAbsTimeStamp;    /* Absolute time stamp of first Time Mark event in list. */
    n32 lastTmAbsTimeStamp;     /* Absolute time stamp of last Time Mark event in list.  */
    n32 tofMashFactor                   /*tofMashFactor used for compression of this list file*/
    n64 sizeOfCompressedList;   /* Total bytes of compressed List Data in this RDF    */
    n64 sizeOfList;             /* Total bytes of uncompressed List Data in this RDF. 
                                           * Note: If compressed, this would still reflect the uncompress */
    /* The next group of parameters are list compression coeficients that are specific to the 
     * 'listCompressionAlg'. 
     */
    f64 listCompAlgCoefs[RDF_NUM_LIST_COMPRESS_ALG_COEFS];    /* type cast to structure that is 'listCompressionAlg' sepcific */

} __attribute__ ((__aligned__(8)));

The RDFv10 List based RDFs will have a major re-organization of the ‘list’ of Coincidence Stream events. The former ‘list of events’  will be reformatted and organized as a Group of datasets known as ‘MICE’, which stands for Machine Independent Coincidence Events. The MICE group includes event tables of separated-by-type events (eg. coincidence events vs timemarker events or trigger events), but cross-correlated to allow efficient random access processing of the ‘list’. The following hierarchy of datasets will be associated with the MICE group of datasets.
/MICE			{Group of Machine Independent Coincidence Event datasets}
/MICE/TofEvents	{Table of TOF Coincidence Events}
/MICE/EvtTimeIndex	{Coincidence Event Time Index}
/MICE/EvtEnergies	{Optional Table of Energies, from Coincidence Events that included Energies}
/MICE/EvtXZPositions	{Optional Table of ‘X’ & ‘Z’ Positions, from Coincidence Events that included X/Z data}
/MICE/TriggerIndex	{Group of Trigger Indexes}
/MICE/TriggerIndex/ExtCardiacTrigIndex	
{Table of External Device Cardiac Trigger Index into the TofEvents Table}
/MICE/TriggerIndex/ExtRespTrigIndex	
{Table of External Device Respiratory Trigger Index into the TofEvts Table}

The following structs will be used for the various types of events and words that occur in the list stream of data. These will be defined in /vobs/pet_raw/source/rdfAPI/libMice/MicePub.h
/* A 'basic' coincidence, minimum content = identification of two crystals in coincidence w.r.t. gamma event detection. */
    typedef struct BasicEvt {
        uint16_t hiXtalAxialID;     // High Crystal Axial Id
        uint16_t hiXtalTransAxID;   // High Crystal Trans-Axial Id
        uint16_t loXtalAxialID;     // Low Crystal Axial Id
        uint16_t loXtalTransAxID;   // Low Crystal Trans-Axial Id
    } BASICEVT; 

    /*   A coincidence event that includes Time Of Flight info */
    typedef struct TofEvt {
        uint16_t hiXtalAxialID;     // High Crystal Axial Id
        uint16_t hiXtalTransAxID;   // High Crystal Trans-Axial Id
        uint16_t loXtalAxialID;     // Low Crystal Axial Id
        uint16_t loXtalTransAxID;   // Low Crystal Trans-Axial Id
        int16_t  deltaT;            // TOF 'signed' delta time (units defined by electronics)
    } TOFEVT;

    /* A coincidence event that includes TOF and the measured Energies of the two gamma detections */
    typedef struct TofEnergyEvt {
        uint16_t hiXtalAxialID;     // High Crystal Axial Id
        uint16_t hiXtalTransAxID;   // High Crystal Trans-Axial Id
        uint16_t loXtalAxialID;     // Low Crystal Axial Id
        uint16_t loXtalTransAxID;   // Low Crystal Trans-Axial Id
        int16_t  deltaT;            // TOF 'signed' delta time (units defined by electronics)
        uint16_t hiEnergy;          // High Crystal measured energy (units: Analog-to-Digital Converter lsb's)
        uint16_t loEnergy;          // Low Crystal measured energy (units: Analog-to-Digital Converter lsb's)
    } TOFENERGYEVT;

    /*   A 'CAL' coincidence event that is used for Detector Calibration of timing, energy/gain and position maps */
    typedef struct CalEvt {
        uint16_t hiXtalAxialID;     // High Crystal Axial Id
        uint16_t hiXtalTransAxID;   // High Crystal Trans-Axial Id
        uint16_t loXtalAxialID;     // Low Crystal Axial Id
        uint16_t loXtalTransAxID;   // Low Crystal Trans-Axial Id
        int16_t  deltaT;            // TOF 'signed' delta time (units defined by electronics)
        uint16_t hiEnergy;          // High Crystal measured energy in ADC lsb's
        uint16_t loEnergy;          // Low Crystal measured energy in ADC lsb's
        uint16_t hiAngerX;          // High Crystal Anger Math X position in ADC lsb's
        uint16_t hiAngerZ;          // High Crystal Anger Math Z position in ADC lsb's
        uint16_t loAngerX;          // Low Crystal Anger Math X position in ADC lsb's
        uint16_t loAngerZ;          // Low Crystal Anger Math Z position in ADC lsb's
    } CALEVT;

    /*  The coincidence event energies separated out as independent dataset */
    typedef struct EvtEnergies {
        uint16_t hiEnergy;          // High Crystal measured energy in ADC lsb's
        uint16_t loEnergy;          // Low Crystal measured energy in ADC lsb's
    } EVTENERGIES;

    /*  The coincidence event X-Z Positional information relative to the Bloc separated out as independent dataset */
    typedef struct EvtXZPositions {
        uint16_t hiAngerX;          // High Crystal Anger Math X position in ADC lsb's
        uint16_t hiAngerZ;          // High Crystal Anger Math Z position in ADC lsb's
        uint16_t loAngerX;          // Low Crystal Anger Math X position in ADC lsb's
        uint16_t loAngerZ;          // Low Crystal Anger Math Z position in ADC lsb's
    } EVTXZPOSITIONS;

/*  Time tags that will be used to identify the time of each event */
    typedef struct TimeMarkData {
        uint64_t timeStamp;         // Absolute timestamp (milliseconds)
        uint64_t coincEvtIndex;     // Index into mice array (list) of event that preceded the timemark
    } TIMEMARKDATA;

    /* Note that a unique 'trigger index' will be created per trigger type (eg. external EKG) and be comprised 
     of a set of the following TriggerData data structures */
    typedef struct TriggerData {
        uint64_t timeStamp;         // Absolute timestamp (milliseconds) that preceded the trigger event
        uint64_t coincEvtIndex;     // Index into mice array (list) of event that preceded the trigger
    } TRIGGERDATA;

The RDF Libraries include a method for compressing RDF event lists.  The event list compression algorithm utilized is a GEHC proprietary algorithm referred to as Geometry Leveraged Encoded Pet List (GLEPL), US Patent 8014614. By default, due to the CPU intensive overhead of compressing at max required count rate, the event list is not compressed at acquisition time. The Acquisition application uses the RDF Libraries functions to compress the event lists as a batch job when PET scanning is inactive and majority of the routine workflow replays of the given list have most likely been accomplished.
The Galileo event definition will impact the GLEPL compression in that it has to be modified for the new event definitions. Since the Galileo events for clinical imaging are so close to the Kitty Hawk definition, the anticipated impact is insignificant and negligible, either in the level of data reduction, nor compress, decompress performance.

            3.3.7.3 Ancillary Data
Ancillary data is data that is part of the acquired data but not the primary acquired data. The “Bulk data” is considered the primary data. An example of Ancillary data is the Singles Data. The Singles sub-header defines the Singles ‘meta-data’. The Singles sub-header describes how much file space is reserved for Singles Data, whether or not the allocated space has been written with valid Singles data, the type and format of the Singles Data and a file offset of where to find the Singles Data. The other sub-headers define the meta-data associated with their specific ancillary or bulk data.

The following are different types of ancillary data that can be found in histogram and list RDFs:
•	Singles data
•	Deadtime data
•	Detector signature data
•	CTC crystal timing difference data

                3.3.7.3.1 Singles Data
Singles samples are generated on a periodic basis and are transmitted (via a TCP connection) to the downstream (back-end) Acquisition Server.  The period of the periodic packets will be programmable by the detector client application.  Additionally, it is important to note that the periodic packets are generated asynchronous to coincidence framing. 

Singles data is a histogram of single events (not coincidence events) on a per-crystal basis.  In a process called Randoms from Singles, image reconstruction can produce estimates of random coincidence events from singles data.  Histogram RDFs will include one singles sample per frame.  List RDFs will include 1-second singles samples interleaved with the coincidence event stream.

                3.3.7.3.2 Deadtime Data
Similar to singles data, Deadtime samples are generated on a periodic basis and are transmitted (via a TCP connection) to the downstream (back-end) Acquisition Server.  The period of the periodic packets will be programmable by the detector client application.  Additionally, it is important to note that the periodic packets are generated asynchronous to coincidence framing. 

Some of the Deadtime counters and values will be condensed and coalesced to fit into the historical frame-based RDF Deadtime structures.  Deadtime parameters that don’t fit the historical RDF Deadtime data structures, but are critical for producing quantitative results, will be added to the Deadtime related RDF data structures.  
It will be the responsibility of the Acquisition application to perform the condensing of Deadtime data, and the framing of Deadtime data to be phase and period matched to the “coincidence frame”. That logic is out of scope for this SDD.
In summary, we group Deadtime data into the following subcategories, to be recorded in the RDF as Deadtime data associated with one frame (or sample):
•	Block Busy Deadtime
•	Block Event Mux Losses
•	Coincidence Processor Singles Losses
•	Coincidence Processor Coincidence Events Losses
•	Event Loss Into Coincidence Processor Singles Histogrammer

                3.3.7.3.3 Block Busy Deadtime
DFE event loss due to DMOD event integration circuit “busy” is measured on a per Block basis in a similar fashion as its predecessors. For each block in the detector a block busy floating point ratio is calculated:
(block busy / (block busy + block not busy))

The array of Block Busy values is stored in the RDF as a three dimensional array that can be interpreted as: 
BlockBusy[time][Major Ring][Block in the ring]
Detector block and module IDs are defined by the SDS for the system (detector geometry) which is associated with the RDF.

                3.3.7.3.4 Block Event Mux Losses
DFE has a type of Deadtime characteristic to its Detector Module (DMOD) Block design and referred as “Block Event Mux Losses” in the RDF context. This category of Deadtime is Singles losses attributed to the DMOD multiplexed event transmit buffers.  This form of event loss will occur at high event count rate at the block level, at which point, there is block biasing with respect to what Singles get propagated to the PROP. 
Since this type of Deadtime may be clinically relevant, appropriate data structures have been defined in the RDF format for recording. Two different types of data structures that will be used to record Block Event Mux Loss related information, a ‘ratio’ type for Sinogram-based RDFs, and a ‘counts’ type for List-based RDFs. The Deadtime Header in the RDF will indicate the type saved in the file per the following enumeration:
typedef enum deadTimeBlkMuxLossType {
    RDF_BLK_MUX_LOSS_RATIO_TYPE = 0, /* An array of RDF_BLOCK_MUX_EVT_LOSS */
    RDF_BLK_MUX_LOSS_COUNTS_TYPE     /* An array of RDF_BLOCK_MUX_LOSS_COUNTS */
} RDF_BLOCK_MUX_LOSS_TYPES;

Block Mux Loss Ratio
For ‘sinogram based’ RDFs, the RDF_BLK_MUX_LOSS_RATIO_TYPE will be used. This type of mux loss data consists of a set of computed Block Event Mux Losses ratios (one ratio per block in detector ring). The ratios data is defined to be an array of floating point numbers that can be indexed as:
BlockMuxDeadtimeRatio[blocks in the system]
The Block Event Mux Loss ratios will be calculated by the Acquisition application as the ratio of :
block events not sent  / (block events sent + block events not sent)
All of the counts in the ratio calculation are totals for the prescribed acquisition.
Note that the DFE subsystem, at a frequency (nominally 1 HZ) per the scan prescription, resets, counts and distributes the two counts required to compute the ratio. The intermediate samples must be totaled for the prescribed acquisition and then ratioed for Sinogram frame based RDFs. 
The set of ratios will be recorded in the ‘unitMuxDeadtime’ data structure.

Block Mux Loss Counts
For list RDFs, the RDF_BLK_MUX_LOSS_COUNTS_TYPE will be used. This type of mux loss data consists of a set of counts generated by the DFE, per the following data structure definition:
typedef struct {
    n32 singlesXmitLoss;      /* Singles generated at block but not sent due to mux busy */
    n32 singlesXmitCount;     /* Singles generated at block and transmitted to CPM */
    n32 singlesTDCReject;     /* Singles rejected due to TDC Mismatch at the block level */
    n32 singlesEnergyReject;  /* Singles rejected due to Energy Discrimination at the block level */
} RDF_BLOCK_MUX_LOSS_COUNTS;

RDF List files will nominally have multiple Deadtime Samples, and in the case of the Deadtime Mux Loss category, the data recorded per sample will be the RDF_BLOCK_MUX_LOSS_COUNTS data structure. Note that from the singlesXmitLosses and singlesXmitCount, the ‘ratio’ type of Deadtime Mux Loss can be calculated for any subset of samples.

Coincidence Processor Singles Losses
The DFE coincidence processor (PROP) has several points of potential Singles losses in the generation of coincidence events. These loses are assumed to be non-biased to a Block, Module or LOR for clinical count rates of interest.  
This form of event loss is recorded in the coincProcessorSinglesLosses term of the RDF_DEADTIME_EVENTS_DATA data structure.

Coincidence Processor Coincidence Events Losses
The RDF_DEADTIME_EVENTS_DATA data structure reflects miscellaneous event counts and event-loss counts that are assumed to be non-biased to a Block, Module or LOR for the clinical event count rates.  The RDF definition of the structure consists of the following elements:
•	coincProcessorLosses
 This reflects the coincidence losses at the different PROP coincidence event forming stages are summed and placed here.
•	sorterInputCoincCount
This reflects a total count of coincidence events produced AND placed on the coincidence link by the Coincidence Processor (DFE PROP). It should not include coincidence events lost on the Coincidence Processor and accounted for in coincProcessorLosses.
•	sorterOverrunLosses 
This is computed as total coincidence events consumed by the PET Acquisition Server Sorter for the frame minus the sorterInputCoincCount for the frame.
•	coincProcessorSinglesLosses
•	coincProcessorFovFiltEvts
•	coincProcessorInFovCoincEvts
•	singlesHistogrammerLosses

Therefore, the RDF_DEADTIME_EVENTS_DATA data structure is defined as follows:
typedef struct {
    uint64_t sorterInputCoincCount;    	      /* Total coincidence events transmitted to the sorter */
    uint64_t sorterOverrunLosses;      	      /* Event Loss associated with Sorter bandwidth limited */
    uint64_t coincProcessorLosses;     	      /* Total # of coinc events lost in latter stages of CPM */
    uint64_t coincProcessorSinglesLosses;     /* Total # of singles events lost in coincidence engine of CPM */
    uint64_t coincProcessorFovFiltEvts;	      /* Total # of coinc events FOV filtered out by CPM */
    uint64_t coincProcessorInFovCoincEvts; /* Total # of non-FOV filtered coinc events made by CPM */
    uint64_t singlesHistogrammerLosses;	      /* Total # of Singles lost as input to CPM Singles Histogrammer  */
}RDF_DEADTIME_EVENTS_DATA;

Note each term’s data type is f64 to preserve thirteen digits of significance, and avoid counter overflow. Previous RDF versions had used the ‘f32’ data type.

Event Loss Into Coincidence Processor Singles Histogrammer
The DFE PROP performs Singles Histogramming in support of Randoms Corrections from Singles.  There is potential event loss into the Singles Histogrammer that is not reflected in the Singles Events presented to the Coincidence Engine.  It is important to capture these losses for scaling the Randoms from Singles estimates.  These losses will be counted and stored in the singlesHistogrammerLosses term of the aforementioned RDF_DEADTIME_EVENTS_DATA data structure. 

                Detector Signature Data
An RDF ancillary data category called Detector Signature Data supports features such as Temperature Compensated Gain and Fault Tolerant Recon (FTR).  
The Detector Module Signature data will include the following data sub-types:
•	Detector Module Serial Number 
•	Detector Module runtime measured temperatures
•	Detector Blocks Valid Flags

It is important to note that the granularity of the data will differ for some of the above types of Detector Signature Data.  For instance, some data will reflect measurements taken at the detector block level, some data will reflect measurements taken at the detector unit level, and some measurements will reflect data taken at the detector module level.
The Signature data will have a corresponding RDF header, similar to the arrangement for Singles, Deadtime, and Crystal Efficiency.  The Detector Module Signature header will include information on what sub-categories are included, a version parameter, Signature data size and file offsets that point to the data, and information on the type of Detector Module.

Detector Serial Numbers
PET Data Acquisition will produce histogram RDFs that include detector serial numbers.  In order to be forward compatible, the serial numbers will exist at the finest detector granularity: the block level.  In a system in which detector serial numbers are supplied only at the detector unit or detector module level, all of the RDF entries for blocks that comprise that unit or module will have the same serial number.

Detector Temperature Data
The acquisition of information characterizing the temperature of the PET detectors (regardless of whether they are PMT-based or SiPM-based) is important for image quality.  In PET/MR systems, temperature data is important so that we can understand the effect of different MR pulse sequences and gradients during a PET scan.  In both PET/CT and PET/MR systems, temperature data is used by Daily Quality Assurance (DQA) for tracking the detector temperatures during calibration scans to ensure accurate calibrations.
Due to their different detectors, PMT-based and SiPM-based systems will acquire temperature data differently.  In particular, the granularity of temperature measurements will differ.  See Table 3.  PMT-based systems will rely on temperature data at the detector module level while SiPM-based systems will rely on temperature data at the detector module level and at the detector block level.  
Table 3. Temperature sample contents for SiPM- and PMT-based detectors.
Detector	Temperature Sample Contents
SiPM	For every Module- Electronic and Scintillator temperature
For every Block - Temperature Start and End of the frame,  Minimum and Maximum temperature during the frame
PMT	For every Module- Electronic and Scintillator temperature

Histogram RDFs will optionally contain 1 temperature sample at the start of the scan and at the end of a scan.  Additionally, the histogram RDFs may contain a temperature sample reflecting the maximum temperature and minimum temperature measured during the scan.  List RDFs may contain one temperature sample per second.

Detector Valid Flags
To support FTR, PET Data Acquisition will produce histogram RDFs that include detector valid flags.  In order to be forward compatible, the flags will exist at the finest detector granularity: the block level.  In a system in which detector valid flags are supplied only at the detector unit or detector module level, all of the RDF entries for blocks that comprise that unit or module will have the same valid flag.

Flag for Energy Integration Mode for BGO Big Block
PMT based BGO Big Block detectors have a large surface area when compared with the previous configuration. Due to the surface area in the clinical scenario, this will lead to increased probability of event pile up. With Big Block there is the need to implement dual integration for clinical imaging.  Two sets of calibrated Energy peaks will be required by DMODs for dual energy discrimination.
Energy calibration is done in long and short integration mode, with energy spectra acquired twice once in normal/ long integration time and next in short integration time. RDF Acquisition Parameters header accommodates recording the event integration mode for subsequent inspection. 

CTC crystal timing difference data
The CTC crystal timing difference ancillary data is different from a CTC timing spectra that is found as a histogram in the RDF segment data after running a CTC calibration scan.  The CTC Timing Spectra that is found in the RDF segment data represents the distribution of TOF deltaT events for a crystal in-coincidence with a fan of other crystals.  On the other hand, the CTC crystal timing difference ancillary data is a record of the average time difference per crystal.

                3.3.7.3.5 RDF code
Overview of Functionality
RDF Libraries provide the following functionality to the RDF files:
•	Create: Create a RDF file with proper data structure in place, and pre-allocate file space associated with the bulk data.
•	Delete: Delete the specified RDF file.
•	Open: Open RDF file for applications to access.
•	Read: Read specific header data of the RDF. Read specified data segment of bulk data. Read ancillary data.
•	Write: Write specific header data of the RDF. Write specified data segment of bulk data. Write ancillary data.
•	Close: Close opened RDF file.

Implementation
The RDF Libraries provide APIs to applications in order to achieve functionalities listed above. The libraries encapsulate low-level file access function calls. The API functions validate parameters passed by applications. The libraries utilize identifiers of RDF headers, offset values, etc., to provide easier, consistent and regulated access to RDF files.

The “RDF Libraries” consists of two different Linux C++ libraries:
a) The Core C++ RDF API (librdfCpp.so)
b) The RDF List API (libEvtList.so)

There is also a C library that contains some low-level access functions for creating, opening, reading and writing an RDF’s data components, but for the most part, this library is strictly utilized by the C++ RDF layer, and will be phased out as the Raw Data Access libraries evolve.  The C RDF Library dates back to first version of PET RDF. Most users imply this library when they mention “the RDF Library”. Today, “RDF Library” collectively implies all those mentioned above.

The C++ Class CRdfList has enhanced accessibility to RDFs of List type. The library represents a C++ abstraction layer on top of the core C++ RDF library with methods for creating, opening, reading, writing and processing data contained in List data.  This library was introduced in the context of the Kitty Hawk platform, first making it into raw data at RDFv7.1.

Core C++ RDF API
Both static and dynamic shared library version of the Core C RDF Libraries are produced.  The dynamic library is named librdf.so and the static library is named librdf.a.  Both a 32-bit and a 64-bit version of the libraries are generated.

 
librdf Class Diagram

Core C++ RDF API heavily uses library libH5Wrap that is wrapper of open source HDF5 (Hierarchical Data Format 5) library, The HDF5 is self-describing hierarchical data format and extensive interface it is BSD-style open source software distributed by the HDF Group.
CRdBase contains members to provide functionality for Pile Up Coefficients (PUC), Read_3dpileUp_factors() reads the 3D Pile Up factors, Write_3dpileUp_factors() is used to write factors similarly Read_3dcrystalpileUp_factors() and Write_3dcrystalpileUp_factors() are used.

 
libH5Wrap Class Diagram

Source Location
The Core C and C++ RDF API header and source files are located in /vobs/pet_raw/source/rdfAPI/librdf, /vobs/pet_raw/source/rdfAPI/librdfCpp and /vobs/pet_raw/source/rdfAPI/libEvtList.

The header files contain the function definitions and are named:
•	rdfExternal.h
•	rdfInternal.h
•	RdfFile.h
•	RdfList.h
•	RdfBase.h

The primary library code (API) is distributed in the following sources:
•	RdfBase.cpp
•	RdfFile.cpp
•	RdfList.cpp

Class CRdfList is implemented that inherits from CRdfBase, this class encapsulates all the logic necessary for RDF file IO. rdfExternal.h defines RDF data format, APIs, and rdfInternal.h defines structures and data access to the library’s internal functions.

C++ RdfList Library
The C++ RdfList Library is a ‘shared’ library. The library file name is libEvtList.so. Both a 32-bit and a 64-bit version of the library exist. This enables support for HOST applications on 32-bit architecture and PARC applications. The library uses libH5Wrap Library internally, and it provides enhanced access methods for compressed list-based RDFs.

 
libEvtList Class Diagram

Source Location
The C++ RdfList Library source is locaed in /vobs/pet_raw/source/rdfAPI/libEvtList.

The header files contain the function definitions and are named:
•	RdfList.h
•	ListPrivate.h
•	IsticeEvtBuff.h
•	ListPacker.h
•	RandomsCalc.h
•	GleplIsticeBuff.h
•	Glepl.h
•	ListControl.h
•	ListWorker.h
•	TofMash.h

The library code includes underlying (internal implementation) logic from the following sources:
•	Glepl.cpp 
•	ListWorker.cpp 
•	ListControl.cpp 
•	RandomsCalc.cpp
•	ListReader.cpp 
•	ListWriter.cpp 

RdfList.h defines classes and methods that enable the use of the library. Applications need to create a CRdfList class object to access the RDF using the library’s methods

                3.3.7.3.6 DDG groups and datasets
The HDF5 hierarchy for respiratory waveform dataset is described as following:
HDF5  {
FILE_CONTENTS {
group      /
group      /Waveform/respiratory/full_afov
}
}

Note: HDF5 Waveform data hierarchy definition includes a ‘respiratory’ subgroup anticipating ‘cardiac’ waveform (and set of cardiac triggers) will be added to the list file in future. The cardiac waveform dataset would be defined as following if implemented in future.
HDF5  {
FILE_CONTENTS {
group      /
group      /Waveform/cardiac/full_afov
}
}

Currently RDA software can be implemented only to include respiratory waveform (and associated triggers) included in list files. A complete respiratory waveform is described as follows:
HDF5 {
FILE_CONTENTS {
 group      /Waveform
 group      /Waveform/respiratory
 group      /Waveform/respiratory/full_afov
 dataset    /Waveform/respiratory/full_afov/acqStartUTC
 dataset    /Waveform/respiratory/full_afov/afovSizeMM
 dataset    /Waveform/respiratory/full_afov/avgSliceCounts
 group      /Waveform/respiratory/full_afov/ddg_stats
 dataset    /Waveform/respiratory/full_afov/ddg_stats/method
// selected Principal Component used to generate the waverform (i.e. 1 or 2, or 3)
 dataset    /Waveform/respiratory/full_afov/ddg_stats/selectedPC
// "R" (i.e. Respiratory Signal Strength) value for Principal Component #1, #2 & #3
 dataset    /Waveform/respiratory/full_afov/ddg_stats/signalStrengthPCs
 group      /Waveform/respiratory/full_afov/dss_info
 dataset    /Waveform/respiratory/full_afov/dss_info/dim
 dataset    /Waveform/respiratory/full_afov/dss_info/format
 dataset    /Waveform/respiratory/full_afov/dss_info/millisecsPerSample
 dataset    /Waveform/respiratory/full_afov/lmAbbrev
 dataset    /Waveform/respiratory/full_afov/midSliceLoc
 dataset    /Waveform/respiratory/full_afov/origin
// Each ‘trigger’value is recorded as an absolute coincidence stream timestamp where the derived
// trigger is intended to fall timewise.
 dataset    /Waveform/respiratory/full_afov/triggers
 group      /Waveform/respiratory/full_afov/wave
 dataset    /Waveform/respiratory/full_afov/wave/amplitude
 dataset    /Waveform/respiratory/full_afov/wave/amplitudeTimeIncrement
 dataset    /Waveform/respiratory/full_afov/wave/firstAmplitudeTimeStamp
}
}

wave group does not maintain every timestamp value rather it contains firstAmplitudeTimestamp and amplitudeTimeIncrement dataset from which the timestamp can be derived.
ddg_stats group contains information about ‘R Value’ of three principle components (PC), selected PC and string that stats the DDG algorithm used to generate the waveform.
dss_info group contains information about the down sampled sinogram dimension, format and time in millisecond per sample.
 
Name	Type	Description
stats	Path level for statistics.	Multivalued level for statistics parameters.
amplitude	n32	Array of amplitude.
triggers	n32	Array of triggers.
info	Path level for information.	Multivalued level for information parameters.
Data types of datasets

Another forward thinking design consideration for laying out the waveform and trigger data was to consider that there may one day be multiple respiratory waveforms or waveform stats and info in a given list file, for example to support a DDG segmented AFOV processing.  The segmented AFOV waveform data might be organized as follows. 

HDF5  {
FILE_CONTENTS {
group      /Waveform
group      /Waveform/respiratory
group     /Waveform/respiratory/seg_afov
group      /Waveform/respiratory/seg_afov/dss_info
group    /Waveform/respiratory/seg_afov/segment1
dataset    /Waveform/respiratory/seg_afov/segment1/triggers
 group      /Waveform/respiratory/seg_afov/segment1/wave
 dataset    /Waveform/respiratory/seg_afov/segment1/wave/amplitude
 dataset    /Waveform/respiratory/ seg_afov/segment1/wave/amplitudeTimeIncrement
 dataset    /Waveform/respiratory/seg_afov/segment1/wave/firstAmplitudeTimeStamp
 dataset    /Waveform/respiratory/seg_afov/segment1/midSliceLoc

{ Note: Same pattern goes on for segments {1, 2..n} }
}
}

Note that in this hypothetical seq_afov (not required or implemented in initial RDA DDG support) dataset definition, each segment {1,2, … n} waveform will have unique midSliceLoc.
	
RDA API Support for DDG
The RDF Library supports several APIs to perform read and write for waveform dataset, APIs are members of CRdfBase class. 
Function Name	Description
WriteWaveform	Writing generated waveform data to the file (amplitude, firstAmplitudeTimeStamp, amplitudeTimeIncrement) 
WriteTriggers	Writing generated trigger data to the file
WriteWaveformAndTriggers	Method to write waveform and trigger info
WriteWaveformInfo	Method for writing waveform info to the file (midSliceLoc, afovSizeMM, avgSliceCounts)
WriteWaveformStats	Writing Waveform Stats to the file (method of DDG, signalStrengthPCs, selectedPC)
WriteDerivedWaveDownSampling	Writing Waveform Derived Wave Down Sampling Info to the file
WriteWaveformOrigin	Writing Waveform Origin Info to the file
ReadSignalStrength	Getting Signal Strength from if exist
ReadWaveformOrigin	Reading Waveform Origin from RDF 
ReadDerivedWaveDownSampling	Reading Derived Wave Down Sampling from RDF
ReadWaveform	Reading waveform data from the RDF file (amplitude, firstAmplitudeTimeStamp, amplitudeTimeIncrement) 
ReadWaveformStats	Reading Waveform Stats from RDF (method of DDG, signalStrengthPCs, selectedPC)
ReadWaveformInfo	Reading waveform info from RDF (afovSizeMM, midSliceLoc, avgSliceCounts)
ReadTriggers	Reading triggers from RDF
CopyWaveformTo	Copying entire Waveform group to destination HDF5 file from the opened Hdf5 file 
CopyWaveformFrom	Copying entire Waveform group from the passed HDF5 file to the opened HDF5 file
DeleteWaveform	Deleting entire Waveform group from RDF
DoWaveformStatsExist	Checking that Waveform Stats exist in the file
DoTriggersExist	Checking that triggers exist in the file
DoesWaveFormExist	Checking for waveform group in the file 

                3.3.7.3.7

        3.3.8 RDF tools

            3.3.8.1 rdfTell

                3.3.8.1.1 Description


rdfTell is a utility that prints contents or summaries from a raw data file and displays them in a readable format. It can handle both the sinogram-based and the list-based raw data files.   The user uses arguments to specify which pieces of information to print out.  This utility uses the Core C++ RDF API to read header and bulk data from RDF files.

To read the slice stats of the segment data using multiple threads singleton CSliceStats class can be implemented. This class will be responsible for spawning multiple thread to read the segment data, calculate minimum and maximum counts of the slice, checksum of the prompts in the slice and total counts in the segment.

rdfTell is called as described below to output RDF data to the console.

rdfTell <-r> <-h eafdigsvoSlCcm> <-v> <-s> <-d> <-m> <-H tsfa> <-e> <-D> <-l> <-L> <-c> <-S> <-t 1|2> <-T> <-U> filename
          -r : Do not show landmarkDateTime,Exam ID,ScanID,Scan & Frame Start Time where
          -h : show header(s), where
               e=exam, a=acq rx, C=CTC Crystal, f=frame stats, d=deadtime g=sys geometry
               s=segment/sorter, v=version, o=offsets, S=singles, l=list, c=compression
               i=cal data, m=DMOD signature
          -v : verbose show
          -s : extract segment data, if present
          -d : extract deadtime & singles data, if present
          -m : extract Detector Module Temperatures data, if present
          -N : Number of threads for reading the segment data should be used with -S (Default 4 threads used)
          -H : display Detector Module Signature data, where
               t=temperatures, s=serial nos, f=block valid flags, a=all available signatures
          -B : display Detector BLOCK Signatures data, where
               t=temperatures, s=serial nos
          -e : extract 3D Norm Crystal Efficiency, if present
          -l : extract List Data, if present
          -L : extract List Data, if present. And byte swap.
          -C : extract CTC Crystal specific data, if present
          -D : turn on Debug printf's
          -c : display Checksums for sinograms, Singles, Deadtime, etc.
          -S : min/max and total sinogram/projection view counts per slice, totals per
               data segment and produce Singles & Deadtime min/max/avgi/BBD/BMD statistics
          -E : extract Singles data, BBD and BMD sample values to .CSV files (For -S and -B options)
          -A : set All Prompts read mode for data segments
          -t : display only the time taken for reading the data segments.
               Note :: can be used in conjunction with -S/-T option, else defaults to the time taken to read
                       data segments using rdfReadAcq3dPlaneSet(), for sinograms.
                       -t 1 excludes checksum & total slice counts, -t 2 excludes only checksum
          -T : sum the sinogram/projection view counts in a data segment using different data access methods
               Note :: use 1 to get the counts/checksum using rdfReadAcqDataSeg()
                       use 2 to get the counts/checksum using rdfReadAcq3dPlaneSet()
                       use 3 to get the counts/checksum using rdfReadRadialSubset()
                       use 4 to get the counts/checksum using rdfReadTOFSummary()
                       use 5 to get the counts/checksum using rdfReadRadialSubsetWithTOF()
          -U : extract TOF summary data, using rdfReadTOFSummary()
          -W : extract Waveform summary data

Informal Test Strategy
The informal test strategy will center upon the use of RDF files with known data.  We will use rdfTell to extract data from these known RDFs.  Then, we will verify that the output from rdfTell matches the content of RDF files.

The list raw data file used in rdfTell verification procedure is OrthogLines3D.BLF.  This List raw data file has been filled with known data and therefore the data that rdfTell displays for various switches should match with this known data.  This procedure utilizes a set of RDFs that are created as part of PAARTF containing known set of data.  The strategy to use “canned RDFs” is chosen in order to make output of rdfTell predictable, and thus the output is verifiable in detail.  The files are under /vobs/pet_acq_test/.

The verification also uses rdfCreateSinoTest which is an application used to create a sinogram-based raw data file.  The sinogram based raw data file created by rdfCreateSinoTest contains known data and can be used to verify some of the rdfTell switches.

Source Location
The sources associated with rdfTell reside in ClearCase for version control of the software.  The source files can be found at /vobs/pet_raw/source/rdfUtils/rdfTell/

                3.3.8.1.2 Source code
All the code is in one file 
rdfUtils/rdfTell/rdfTell.cpp

                3.3.8.1.3
            3.3.8.2 ListDecode
Overview of Functionality
Similar to rdfTell, ListDecode is a tool that decodes and prints the events list in user-friendly format with options to print a subset of the event list based on event type, or summarize all events in the list.  ListDecode also takes statistics such as for time marks, triggers, and counts.  The data generated by ListDecode will be used for purposes such as verification and validation and to examine the contents of event lists. The user uses arguments to specify which pieces of information extract.  ListDecode is specialized for List type RDF files.  ListDecode is a tool to show all the events in a List File.  Events can, however, be filtered to give more specific output, such as just Time Markers or just Physiological Trigger Events.  Some statistics, such as for time marks or triggers, may also be viewed.
ListDecode tool is updated based on the new Galileo platform event format. Some of the parameters passed as part of the Coin Event/ time marker/ triggers from Event Processing Subsystem (PROP) is revised and the tool is updated to support the new format. ListDecode will no longer support the KH event definition.

Usage
Decode events from a DFE vintage List File:

ListDecode <various opts> <-o start_offset> <-e end_offset> <-R period> list_file
-o : file offset for start of list decoding
-e : file offset for end of list decoding

The default is to show all events.
To filter, use combination of the following switches.
-t : show Time Markers
-T : show Physiological Trigger Events
-D : show Derived Triggers
-s : show statistics for time, triggers, counts etc.
-r : show Count Rates (see also <-R period>)
-c : Coinc Count Events
-C : show CheckSum

Miscellaneous options:
-R : period for rates calculation, default is 1 sec
-v : verbose output
-b : binary vs. ascii output (not implemented)
-B : List File is big endian, default is little endian
-O : Use O_DIRECT for performance. Files system must support.

Informal Test Strategy
The test strategy for ListDecode is to test each option for ListDecode with known data. Using this strategy, the expected output of the test cases is also known and can be included in the verification procedure.

Source Location
The sources associated with ListDecode and the shared library libEvtList.so that ListDecode requires reside in ClearCase for version control of the software. The ListDecode sources reside at /vobs/pet_raw/source/rdfUtils/ListDecode and the libEvtList sources can be found at /vobs/pet_raw/source/rdfAPI/libEvtList/.

            3.3.8.3 ListTool
Overview of Functionality
The List tool will be used to extract data and statistics from list files (RDF version 9.0 ) generated by PET scans. The data generated by ListTool will be used for purposes such as verification and validation, system health, and calibration.

ListTool operates in two main modes: Inspection Mode and Statistic Mode:
(a) Inspection Mode
Inspection Mode allows for inspection of the singles header, the Deadtime header and the Deadtime event samples. When inspecting the Deadtime event samples, ListTool will perform an integrity check on the timestamps that is the ListTool will attempt to verify that the timestamps follow a logical order with no repeated or missing samples. This mode is intended to be a quick access to data contained in the file with no statistics processing.

(b) Statistics Mode
Statistics Mode allows for a variety statistics gathering from data contained in the list file. ListTool can obtain statistics about prompt rates from the singles and Deadtime data or the raw data in the list. ListTool can compare the difference between the prompt rate of the Deadtime data and the prompt rate of the raw data in the list and determine if prompt loss of the list file raw data.  Using the singles data stored in a list file ListTool can generate statistics about the singles each block in the system generated in each singles sample.  ListTool can perform similar statistics gathering for the block busy ratio for each block of the system.  ListTool can also obtain the number of singles events seen by a specified crystal across a specified number of time samples.

ListTool uses the following naming convention for prompts:
Prompts(T): Theoretical Prompt Count (Prompts on Coinc Link + CPM Losses)
Prompts(C): Prompts on Coinc Link
Prompts(L): Prompts in List

Additional information about ListTool can be found in the user’s guide (DOC0561895).
ListTool is updated based on the new Galileo platform event format. Some of the parameters passed as part of the Coin Event/ time marker/ triggers from Event Processing Subsystem (PROP) is revised and the tool is updated to support the new format. ListTool will no longer support the KH event definition.

Usage
ListTool Commands:
Usage ListTool <-D> <-I sde> <-M tTlsbmp> <-b ?,?> <-C ?,?,?,?,?> <-f Output File Name> <-d stc> <-t ar> <-W?> Input File Name

ListTool has two primary operating modes, Inspection Mode and Statistics Mode.
Inspection Mode is a fast operating mode that will displays data to the screen.
Statistics Mode is a slower mode that will gather data from specified Listfile and perform analysis on the file before writing the contents to the specified output file.
Simple statistics are also displayed to the screen in Statistics Mode.
-I Selects Inspection mode
s will output singles header
d will output deadtime header
e will output deadtime events and perform an integrity check on them
-M Selects style of data analysis output file
t obtains Prompts, Randoms, Trues and coincidence deadtime TAC, this is the default
T obtains Prompts, Randoms, and Trues TAC
l obtains List File losses
s obtains Singles per Block statistics
b obtains Block Busy statistics
m obtains Mux Data (additional parameter r,l,x,t,e)
r obtains Mux Loss Ratio (Singles Lost/Total Singles), this is the default
l obtains Singles Lost from Mux Busy
x obtains Singles Transmitted
t obtains Singles rejected because of TDC Mismatch
e obtains Singles rejected because of Energy Discrimination
p obtains statistics about Physio Triggers
-b specifies an additional block to gather data from when -Ms or -Mb
where first ? is the module number and second ? is the block within the module a character value of a in either module number or block acts as a wildcard
Ex: 5,a gets all blocks in module 5
-f Name of output file to save data to (defaults to ListToolResult)
If an existing file is specified the data contained in the file will be overwritten
-D Turns debug print statements on
-S selects source of data. Used with -M switch
l selects list file data
h selects singles and deadtime data, this is the default
-d Select delimiter for ouput file
s Selects the space character as the delimiter
t Selects the tab character as the delimiter
c Selects the comma character as the delimiter, this is the default
If the output file will be analzyed by the ListToolPlot then the delimiter should be a comma.
-t Selects between absolute and relative time display
a selects absolute time display, this is the default
r selects relative time display
-C allows for summing the singles data for a single crystal
first ? is module, second ? is block, third ? is cyrstal,
fourth ? is start sample number, fifth ? is end sample number
Module, Block and Crystal start at 0, the sample numbers start at 1.
-W specifying a number >0 will cause ListTool to generate warnings when the difference between timemarkers is detected to be equal or greater to the specified number.
A value of 0 will disable the warnings. Default is 0.
This switch is only utilized in modes that scan the list (-Mt -Sl), (-Ml), and (-Mp)

Informal Test Strategy
The test strategy for ListTool is to test each mode of operation for ListTool with known data created by
rdfCreateListTest. The majority of the modes of ListTool require only one test case as the modes will start at the beginning of the required data and proceed until the end of that data. However, one mode of ListTool operates on two sets of data acquired asynchronously, as such three test cases have been derived to test the possible conditions under which that data can be presented to ListTool, hence the reason for three sets of known data.

The test procedures utilize a list file generation tool to put known data into a list file. Due to the limitations of the generation tool, prompt rates higher than 200kcps cannot be achieved and as such cannot be tested. The test generation tool has a maximum coincidence stream generation of 200KCPS to Testing at rates higher than 200kcps is not needed as ListTool goes through the entire set of list file data regardless of the size of the list file.

Source Location
The sources associated with ListTool and the static library libEvtList that ListTool requires to reside in clearcase for version control of the software. The ListTool sources reside at /vobs/pet_raw/source/rdfUtils/ListTool, and the libEvtList sources can be found at /vobs/pet_raw/source/rdfAPI/libEvtList/.
The source associated with RdfCreateListTest, a program used to generate known data for ListTool verification it will reside at /vobs/pet_raw/source/rdfTest.

            3.3.8.4 RDF Import Raw List
Overview of Functionality
rdfImportRawList is a Linux executable software verification tool used to create PET List Files. These PET List Files are primarily used in the verification of the PET Acquisition Server application. The tool and its output also assists verification of the Linux C/C++ programming language “RDF Access Library”, and/or other tools used to inspect PET Raw Data Files (RDFs).

The rdfImportRawList tool is used to create a PET Raw Data Files (RDFs) of type List. It takes as input, a path to a binary file containing a list of pet detector “coincidence stream events” and encapsulates the event list in a PET Raw Data File (RDF) of type List.  The binary file of coincidence stream events encapsulated into a PET RDF is assumed to be of Galileo platform event format.

Usage
rdfImportRawList is used as follows:

 ./rdfImportRawList <various options> raw_list
options:        <-l> <-a alt_rdfs_root> <-O list_start_offset> <-o> <-s related_RDF> <-D>
                <-F start time (msec) -L end time (msec)> <-S datetime (sec)> <-A det_arch> <-e event_mode>
                <-i import_cnt> <-m max_SDT_samples> <-V>
where:
          -A : detector arch - 0:XR, 1:BGO8x8_2_TUBEQAT, 2:BGO8x8_3_TUBEQAT, 3:BGO8x8_4_TUBEQAT, 4:BGO8x8_5_TUBEQAT, 5:PMR1 ,6:LYSO4x9_3_SIPMGEN1, 7:LYSO4x9_4_SIPMGEN1, 8:LYSO4x9_5_SIPMGEN1
          -a : alt_rdfs_root - alternate root of Raw Data File System
          -D : use this for DST (default is Galileo)
          -l : Raw List File is little endian, default is little endian anyway
          -O : Start importing at raw_list list_start_offset
          -o : Use O_DIRECT for import (must be on filesystem that supports)
          -F -L : use these first/last time marks in msecs (ref. ListDecode -s)
          -S : use this start time stamp in seconds since '00:00:00 1970-01-01 UTC' (ref. date +%s)
          -e : event mode - ref idbConstants.h Coinc Output mode, default is 802 (6-byte nom coinc event)
          -i : import_cnt - repeat the import of the data file for import_cnt.
               A import_cnt of zero implies repeat import until file space exhausted.
          -m : max_SDT_samples - override max # of Singles & Deadtime samples (default=2000)
          -V : write alternate values for headers. Ref DOC1386187
          -s : Use sinogram based related_RDF for Exam, Scan info, Singles & Deadtime

Informal Test Strategy
The test strategy for the rdfImportRawList tool relies on the tool acqListDataGen that generates list files using custom algorithms using known data, the tool rdfImportRawList uses this generated data (.dat files) to create RDF files using test spec‎[5].

The rdfImportRawList tool is used to create a PET Raw Data Files (RDFs) of type List. It takes as input, a path to a binary file containing a list of pet detector “coincidence stream events” and encapsulates the event list in a PET Raw Data File (RDF) of type List.  The binary file of coincidence stream events encapsulated into a PET RDF is assumed to be of Galileo platform event format.

The test strategy has a dependency on Linux executables ListTool and rdfTell tools. These two tools should be verified prior to officially verifying rdfImportRawList.

Source Location
The sources associated with rdfImportRawList reside in clearcase for version control of the software. The source files, including a Makefile, can be found at /vobs/pet_raw/source/rdfUtils/rdfImportRawList. Both 32-bit and 64-bit versions of the tool are available.  

The binary data files, referred generically herein as “kha_event_list.dat” file(s), imported by rdfImportRawLists in this verification procedure are produced by scripts found in ClearCase at: /vobs/pet_acq_test/source/acqGenListData/genListData/.

            3.3.8.5 RDF Reducer
Overview of Functionality
rdfReducer is a Linux executable used to create PET List Files which is reduced in the axial direction from an source list file that higher number of blocks axially. These PET List Files are primarily used in the verification of the PET Acquisition Server application. The tool and its output also assists verification of the Linux C/C++ programming language “RDF Access Library”, and/or other tools used to inspect PET Raw Data Files (RDFs). rdfReduce Tool can be verified in PAARTF with certain prequalified results that consist of rdfTell and ListDecode output of the reduced list file.

Usage
RDF reducer can be used as follows,

rdfReduce sourceFile destinationFile <axialBlocksPerModule>

Where,
sourceFile – Input uncompressed list file with higher number of axial blocks
destinationFile – copy of the source file which will be reduce axially
axialBlocksPerModule – Number of axial blocks to which the destinationFile file should be reduced
			The value should be less than the source file axialBlocksPerModule
			ex. If source axialBlocksPerModule is 5, this param can be 4 or 3

The input file should be uncompressed because the list can be uncompressed using the geometry information which is available in the list file. rdfReducer will change the geometry information in the List file headers.
Source Location
The sources associated with rdfReduce reside in ClearCase for version control of the software. The rdfReduce sources reside at /vobs/pet_raw/source/rdfUtils/ rdfReduce. 

            3.3.8.6 rdfImportRawList 
ctuser@jaws:~> ssh par
Last login: Mon Apr 23 10:52:56 2018 from oc
ctuser@par:~> cd ~
ctuser@par:~> pwd
/home/ctuser
ctuser@par:~> cd /usr/g/ctuser/yosi/stage64
ctuser@par:/usr/g/ctuser/yosi/stage64> ./rdfImportRawList 

Import a raw coincidence event stream list into a PET Raw Data File per DOC1386187

usage: ./rdfImportRawList <various options> raw_list

options:        <-l> <-a alt_rdfs_root> <-O list_start_offset> <-o> <-s related_RDF> <-D> 
                <-F start time (msec) -L end time (msec)> <-S datetime (sec)> <-A det_arch> <-e event_mode>
                <-i import_cnt> <-m max_SDT_samples> <-V>
where:                                                               
          -A : detector arch - 0:LYSO9x6_4_TUBEQAT, 1:BGO8x8_2_TUBEQAT, 2:BGO8x8_3_TUBEQAT, 3:BGO8x8_4_TUBEQAT, 4:BGO8x8_5_TUBEQAT, 5:PMR1 ,6:LYSO4x9_3_SIPMGEN1, 7:LYSO4x9_4_SIPMGEN1, 8:LYSO4x9_5_SIPMGEN1
          -a : alt_rdfs_root - alternate root of Raw Data File System 
          -D : use this for DST (default is Galileo) 
          -l : Raw List File is little endian, default is little endian anyway 
          -O : Start importing at raw_list list_start_offset
          -o : Use O_DIRECT for import (must be on filesystem that supports)
       -F -L : use these first/last time marks in msecs (ref. ListDecode -s)
          -S : use this start time stamp in seconds since '00:00:00 1970-01-01 UTC' (ref. date +%%s)
          -e : event mode - ref idbConstants.h Coinc Output mode, default is 802 (6-byte nom coinc event) 
          -i : import_cnt - repeat the import of the data file for import_cnt. 
               A negative value for import_cnt implies repeat import until file space exhausted.
          -m : max_SDT_samples - override max # of Singles & Deadtime samples (default= 2000
          -V : write alternate values for headers. Ref DOC1386187 


            3.3.8.7 SyntheticListData , generate Synthetic List Data, GenRawEvent, rdfImportRawList and addMotion 

                3.3.8.7.1 how to run
- First deploy
a. set view
cd /vobs/pet_acq_test/source/acqGenListData/ && cmakedc64 
b. run
./download <Machine>
e.g.  ./download $JAWS

c.  install on par
ssh $USER_CT <Machine>
ssh par
cd /petLists/acqGenListData && ./install
ctuser@par:/petLists/acqGenListData> ./install 

d. temporary. download modified executables that convert to MICE format and addMotion on MICE format list files.
[de680136@nmpetdev64:2018-04-29 11:02:28:/vobs/pet_raw/source:]6457$ deployRDFBinaries.sh  -a 64 -m $TURTLE  -r /usr/g/ctuser/yosi/ | tee log

on par
ctuser@par:/petLists/acqGenListData> mv bin bin.orig
ctuser@par:/petLists/acqGenListData> mkdir bin
ctuser@par:/petLists/acqGenListData> cd bin
ctuser@par:/petLists/acqGenListData/bin> cp ../bin.orig/system_geometry.xml  .
ctuser@par:/petLists/acqGenListData/bin> cp /usr/g/ctuser/yosi/stage64/generateListData  .
ctuser@par:/petLists/acqGenListData/bin> cp /usr/g/ctuser/yosi/stage64/rdfImportRawList  .
ctuser@par:/petLists/acqGenListData/bin> cd ..

- remove semaphores locks
ctuser@par:/dev/shm> rm -f *.BLF

-tail log
ctuser@par:/petLists/acqGenListData> tailf log/syntheticListData.out
e.  run script:
ctuser@par:/petLists/acqGenListData> ./SyntheticListData LYSO4x9_5_SIPMGEN1 8
note:
            LYSO4x9_5_SIPMGEN1      Columbia 5 Ring Configuration
            8. HotSpotsForMotion

f. addMotion
/usr/g/ctuser/yosi/stage64/addMotion -p 10 -a 100 -m 130 -M 200 $(pwd)/LYSO4x9_5_SIPMGEN1/CirclesPerSlice.BLF


    -- download script
    [de680136@nmpetdev64:2018-04-26 11:38:39:/vobs/pet_acq_test/source/acqGenListData:]6497$ cat download
#!/bin/bash
binDir="setupScripts/"
destDir="/petLists/acqGenListData"                              # relative to ~/ctuser
file1="generateListData/sles11-x86_64/generateListData"
file2="generateListData/system_geometry.xml"
file3="setupScripts/SyntheticListData"
file4="setupScripts/rdfImportRawList"

downloadToTarget()
{
        local tarFile="SyntheticListData.tgz"
        local fileList="$tarFile install"
        if ! tar -chzf ${tarFile} ${file1} ${file2} ${file3} ${file4}; then
                exit 3
        fi

        for filePath in $fileList ; do
                if ! ${binDir}ftp-ctuser $destHost $destDir $filePath ; then
                        exit 4
                fi
        done

#       if ! ${binDir}ftp-ctuser $desitHost $destDir ${binDir}rdfImportRawList rdfImportRawList; then
#               exit 4
#       fi

#        if ! ${binDir}ftp-ctuser $destHost $destDir ${binDir}SyntheticListData SyntheticListData; then
#                exit 4
#        fi


        rm -f $tarFile
}

usageMsg()
{
    cat << EOF
Usage: $scriptName <host address>

EOF
    exit 1
}

# ***** script starts here *****

scriptName=`basename $0`
while getopts ":o" opt; do
        case $opt in
                o ) omitListData=1 ;;
                \? ) usageMsg ;;
        esac
done
shift $(($OPTIND - 1))

destHost=$1

if [ -z $destHost ]; then
        usageMsg
fi

if ! ping -q -c 1 $destHost > /dev/null         # verify host address is available
then
        echo
        exit 2
fi

# get rid findmerge & .contrib files
#${binDir}find-exec '*.contrib' 'rm -f'
#${binDir}find-exec 'findmerge.*' 'rm -f'

downloadToTarget

cat << EOF

Download completed.
To install:
  1) login to $destHost as ctuser
  2) rsh par
  2) cd $destDir
  3) run "./install"

EOF

exit 0

    -- run Download
[de680136@nmpetdev64:2018-04-26 11:44:04:/vobs/pet_acq_test/source/acqGenListData:]6500$ cmakedc64 

[de680136@nmpetdev64:2018-04-26 11:44:12:/vobs/pet_acq_test/source/acqGenListData:]6500$ ./download $JAWS
ftp "SyntheticListData.tgz" (396228 bytes) to "ctuser@3.87.141.219:/petLists/acqGenListData/SyntheticListData.tgz" with permissions 644
ftp "install" (1158 bytes) to "ctuser@3.87.141.219:/petLists/acqGenListData/install" with permissions 555

Download completed.
To install:
  1) login to 3.87.141.219 as ctuser
  2) rsh par
  2) cd /petLists/acqGenListData
  3) run "./install"

    -- install on par
ctuser@par:/petLists/acqGenListData> ./install 
generateListData/sles11-x86_64/generateListData
generateListData/system_geometry.xml
setupScripts/SyntheticListData
setupScripts/rdfImportRawList

*** Run './SyntheticListData' for usage 

    --
- Then on par

[ctuser@jaws4:2018-04-26 03:09:16:/petLists/acqGenListData:]52$ ./SyntheticListData LYSO4x9_5_SIPMGEN1 8 
must be run on the par
ctuser@jaws4:~> ssh par
Last login: Wed Apr 25 17:23:31 2018 from oc
ctuser@par:~> cd /petLists/
ctuser@par:/petLists> cd acqGenListData/
ctuser@par:/petLists/acqGenListData> ls
bin               log                     LYSO4x9_5_SIPMGEN1_mww_3D_dat        LYSO4x9_5_SIPMGEN1_mww_current        LYSO4x9_5_SIPMGEN1_orig  LYSO4x9_5_SIPMGEN1.vikas  save4.txt
importCircles     LYSO4x9_5_SIPMGEN1      LYSO4x9_5_SIPMGEN1_mww_circles       LYSO4x9_5_SIPMGEN1_mww_gated_3d       LYSO4x9_5_SIPMGEN1.save  save1.txt                 save.txt
LISTBlkTemps.csv  LYSO4x9_5_SIPMGEN1_mww  LYSO4x9_5_SIPMGEN1_mww_circles_rev2  LYSO4x9_5_SIPMGEN1_mww_gated_3d_rev2  LYSO4x9_5_SIPMGEN1.try1  save3.txt                 SyntheticListData
ctuser@par:/petLists/acqGenListData> ./SyntheticListData LYSO4x9_5_SIPMGEN1 8
ctuser@par:/petLists/acqGenListData> ./SyntheticListData LYSO4x9_5_SIPMGEN1 8
Generating Synthetic List Files...
40000+0 records in
1440000+0 records out
1440000 bytes (1.4 MB) copied, 1.23662 s, 1.2 MB/s
361607430+0 records in
361607430+0 records out
361607430 bytes (362 MB) copied, 306.983 s, 1.2 MB/s
1768800+0 records in
1768800+0 records out
1768800 bytes (1.8 MB) copied, 1.49419 s, 1.2 MB/s
2511906+0 records in
2511906+0 records out
2511906 bytes (2.5 MB) copied, 2.11049 s, 1.2 MB/s
3904122+0 records in
3904122+0 records out
3904122 bytes (3.9 MB) copied, 3.22434 s, 1.2 MB/s
Completed!

[ctuser@jaws4:2018-04-26 03:26:01:/petLists/acqGenListData:]56$ tailf log/syntheticListData.out 
For Axial Acceptance -35
For Axial Acceptance -34
For Axial Acceptance -33
For Axial Acceptance -32
For Axial Acceptance -31
For Axial Acceptance -30
For Axial Acceptance -29
For Axial Acceptance -28
For Axial Acceptance -27
For Axial Acceptance -26

                3.3.8.7.2 code

|        $ cat SyntheticListData
|        #!/bin/bash
|        
|        if [ "par" != `hostname` ]; then
|                echo "must be run on the par"
|                exit 1
|        fi
|        
|        if [ -z $1 ]; then
|                cat << EOF
|        
|                    Synthetic List File Tool Generator
|                   ====================================
|        Description:
|            Generate Synthetic data in .dat format, converts them to .BLF using 
|            rdfImportRawList tool in un-compressed format.
|        
|        Usage:
|            ./SyntheticListData <Configuration Type> <File Number> [OPTIONAL]
|        
|            Valid Galileo configurations are 
|            <Configuration Type>    <Description>
|            --------------------    -------------
|            PMR1                    MR/PET Everest Ring
|            BGO8x8_2_TUBEQAT        Comet 2 Ring Configuration
|            BGO8x8_3_TUBEQAT        Comet 3 Ring Configuration
|            BGO8x8_4_TUBEQAT        Comet 4 Ring Configuration
|            BGO8x8_5_TUBEQAT        Comet 5 Ring Configuration
|            LYSO4x9_3_SIPMGEN1      Columbia 3 Ring Configuration
|            LYSO4x9_4_SIPMGEN1      Columbia 4 Ring Configuration
|            LYSO4x9_5_SIPMGEN1      Columbia 5 Ring Configuration
|            LYSO9x6_4_TUBEQAT       Blackbird 4 Ring Configuration
|        
|        File Number Options:  [Optional]
|            By default it will generate for all file if no Number is given!
|            0. All Files 
|            1. CirclesPerSlice
|            2. CrossHairPerSlice
|            3. LorTofIncSpectrumLongTrigs
|            4. OrthogLines3D
|            5. Gated3D_DwellPrecision
|            6. TofListData
|            7. RateCurves
|            8. HotSpotsForMotion
|        
|        Example:
|            ./SyntheticListData BGO8x8_2_TUBEQAT 1  (Comet/Ody 2R CirclesPerSlice only)
|            ./SyntheticListData BGO8x8_5_TUBEQAT    (Comet/Ody 5R all list files)
|            ./SyntheticListData LYSO4x9_5_SIPMGEN1 8 (COL 5R, HotSpotsForMotion only)
|        
|        Output:
|            Log file will created under /petLists/acqGenListData/log
|            Output BLF are generated in /petLists/acqGenListData/<Configuration Type>
|        
|        
|        EOF
|                exit 1
|        fi
|        
|        
|        if [ -z $1 ]; then
|                echo "You must specify the Detector type < BGO8x8_2_TUBEQAT | BGO8x8_3_TUBEQAT | BGO8x8_4_TUBEQAT | BGO8x8_5_TUBEQAT | LYSO4x9_3_SIPMGEN1 | LYSO4x9_4_SIPMGEN1 | LYSO4x9_5_SIPMGEN1 | L
|        YSO9x6_4_TUBEQAT>"
|                exit 1  
|        fi
|        
|        fileNumber=$2
|        
|        if [ -z $fileNumber ]; then
|                fileNumber=0
|        elif [ $fileNumber -lt 0 ] || [ $fileNumber -gt 8 ] ; then
|                echo "Invalid File Number. Generating default files."
|                fileNumber=0
|        fi
|        export LD_LIBRARY_PATH=/petLists/acqGenListData/bin
|        
|        mkdir -p log
|        
|        echo "Generating Synthetic List Files..."
|        bin/generateListData $1 $fileNumber > log/syntheticListData.out
|        echo "Completed!"

                3.3.8.7.3 generateListData binary code

                    3.3.8.7.3.1 generateListData ClearCase location


[de680136@nmpetdev64:2018-04-26 13:28:58:/vobs/pet_acq_test/source/acqGenListData/generateListData:]6504$ grep main *
Defs.h:#define NUM_MOD_PER_CEM         3       /* Number of modules in a CEM domain */
Defs.h:#define NUM_MOD_PER_CEM11       2       /* Number of modules in the 11th CEM domain (counting from 0..11) */
GenRawEvent.cpp:int main(int argc, char *argv[])
GenRawEvent.cpp:    // Since these patient/exam/scan values are hard-coded in rdfImportRawList, the directory path remains the same.
GenRawEvent.cpp:    // The LIST0000.BLF file name remains the same because the .BLF file is always moved after the rdfImportRawList program is run.

                    3.3.8.7.3.2 Code
/*
* Filename:	GenRawEvent.cpp
*
* Copyright (c) 2003-2012, GE Healthcare.  All rights reserved. 
*
* For use only by GE Healthcare.
* This document contains proprietary information.
* It must not be reproduced or disclosed to others
* without prior written approval.
*
*
* Description:	The following file contains the 
*
* Original Creation Date:	22 Oct 2012
* Original Author:			Vikas Parihar (GE Healthcare) <vikas.parihar@ge.com>
*/

#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <exception>
#include "GEtypes.h"
#include "Enums.h"
#include "Defs.h"
#include "DetectorGeometry.h"
#include "DataGenFactory.h"
#include "SyntheticDataGen.h"

using namespace std;


// Forward Decleration
CONFIGURATION getProductConfiguration(const char* p_productConfiguration);
void splitGated3DDwellListFile();
void convertToBLFFile(string fileName , string eventType , string configStr , string configNumberStr);
string runCommand(const char* cmd);
string convertConfigNumToString(CONFIGURATION config);


/** 
  * Main()
  *  This method is Starting Point for Generating Synthetic Data
  *
  * @param argc
  * @param *argv[]
  *
  * @returns
  */
int main(int argc, char *argv[])
{
    if(argc == 2 || argc == 3)   // command line arg with or without list file number are supported. 2= without list file number, 3 = with list file number.
    {
        string configStr = argv[1];
        CONFIGURATION config = getProductConfiguration(configStr.c_str());
        if(UNKNOWN == config)
        {
            cout<<configStr<<" Configuration Not Supported!"<<endl;	
            return 1;
        }

        string configNumberStr = convertConfigNumToString(config);

        // Remove all BLF and dat file from current dir.
        char cleanUp_Command[] = "rm -f *.dat *.BLF";
        int status = system(cleanUp_Command);

        string remove_old_dir_Command = "rm -r -f " + configStr;
        status = system(remove_old_dir_Command.c_str());	

        string createDirCommand;
        createDirCommand = "mkdir -p " + configStr;				// Create folder as per Input config
        status = system(createDirCommand.c_str());				// All generated files will be dumpped in this newly created directory.

        int fileNumber = 0;							// default 0 for generating all list files
        if(argc == 3)
            fileNumber = atoi(argv[2]);					// if user specifies file number

        if(fileNumber > 7 || fileNumber < 0)
        {
            fileNumber = 0;							// file number handled for all invalid numbers, set value to zero
            cout<<"Invalid File Number (Range 0 to 7). Generating All List Files"<<endl;
        }

        if(!CDetectorGeometry::setProductConfiguration(argv[1])) 	// parameter passed : configStruration
        {
            cout<<"ERROR in Product Configuration file. "<<endl;		// If tags are not read properly in XML congfig file..
            exit(0);
        }

        // Move all generated .BLF and .dat file to input configStruration folder.
        string moveFiles = "mv *.dat " + configStr;

        cout<<endl<<endl<<"==== SYNTHETIC DATA FOR "<<argv[1]<<" Configuration ===="<<endl<<endl;  
        CDataGenFactory* dataGenFactory = new CDataGenFactory();
        CSyntheticDataGen* syntheticDataGen = dataGenFactory->createObject(SD_CIRCLEPERSLICE);		// creating data object for CirclePerSlice class using data factory

        if(NULL != syntheticDataGen && (0 == fileNumber || 1 == fileNumber))
        {
            cout<<"================== Generating CirclesPerSlice.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());	// move generated .dat file to corresponding configStr folder
            cout<<"------------------- CirclesPerSlice.dat file Generated -------------------"<<endl<<endl;
            convertToBLFFile("CirclesPerSlice" , "802" ,configStr ,configNumberStr);	
            convertToBLFFile("CirclesPerSliceRampDown" , "802" ,configStr ,configNumberStr);
        }

        syntheticDataGen = dataGenFactory->createObject(SD_CROSSHAIRPERSLICE);
        if(NULL != syntheticDataGen && (0 == fileNumber || 2 == fileNumber))
        {
            cout<<"================== Generating CrossHairPerSlice.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"------------------- CrossHairPerSlice.dat file Generated -------------------"<<endl<<endl;
            convertToBLFFile("CrossHairPerSlice" , "802" ,configStr ,configNumberStr);
        }        

        syntheticDataGen = dataGenFactory->createObject(SD_LORTOFINCSPECTRUMLONGTRIGS);
        if(NULL != syntheticDataGen && (0 == fileNumber || 3 == fileNumber))
        {
            cout<<"================== Generating LorTofIncSpectrumLongTrigs.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();

            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"------------------- LorTofIncSpectrumLongTrigs.dat file Generated -------------------"<<endl<<endl;
            convertToBLFFile("LorTofIncSpectrumLongTrigs" , "802" ,configStr ,configNumberStr);
        }

        syntheticDataGen = dataGenFactory->createObject(SD_ORTHOGLINES3D);
        if(NULL != syntheticDataGen && (0 == fileNumber || 4 == fileNumber))
        {
            cout<<"================== Generating OrthogLines3D.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"------------------- OrthogLines3D.dat file Generated -------------------"<<endl<<endl<<endl<<endl;
            convertToBLFFile("OrthogLines3D" , "802" ,configStr ,configNumberStr);
        }

        syntheticDataGen = dataGenFactory->createObject(SD_GATED3DDWELL);
        if(NULL != syntheticDataGen && (0 == fileNumber || 5 == fileNumber))
        {
            cout<<"================== Generating Gated3D_DwellPrecision.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            cout<<"-------------------  Gated3D_DwellPrecision.dat file Generated -------------------"<<endl<<endl<<endl<<endl;
            splitGated3DDwellListFile();
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            convertToBLFFile("Gated3D_DwellPrecision" , "802" ,configStr ,configNumberStr);
            convertToBLFFile("GatedDP_PART0000" , "802" ,configStr ,configNumberStr);
            convertToBLFFile("GatedDP_PART0001" , "802" ,configStr ,configNumberStr);
            convertToBLFFile("GatedDP_PART0002" , "802" ,configStr ,configNumberStr);
            convertToBLFFile("GatedDP_PART0003" , "802" ,configStr ,configNumberStr);	
	    convertToBLFFile("GatedDP_PART0004" , "802" ,configStr ,configNumberStr);
        }
        
        syntheticDataGen = dataGenFactory->createObject(SD_CALCOINEVENT);
        if(NULL != syntheticDataGen && (0 == fileNumber || 6 == fileNumber))
        {
	    cout<<"================== Generating TofListData.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"------------------- TofListData.dat file Generated -------------------"<<endl<<endl<<endl<<endl;
            convertToBLFFile("TofListData" , "803" ,configStr ,configNumberStr);
        }        

        syntheticDataGen = dataGenFactory->createObject(SD_RATECURVES);
        if(NULL != syntheticDataGen && (0 == fileNumber || 7 == fileNumber))
        {
	    cout<<"================== Generating RatesCurve.dat file =================="<<endl;
            syntheticDataGen->generateSyntheticData();
            delete syntheticDataGen;
            syntheticDataGen = NULL;
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"-------------------RatesCurve.dat file Generated -------------------"<<endl<<endl<<endl<<endl;
            convertToBLFFile("RatesCurve" , "802" ,configStr ,configNumberStr);	
        }

        cout<<endl<<endl<<"==== SYNTHETIC DATA GENERATED ===="<<endl<<endl;
    }
    else
    {
        // Usage printing	

        cout<<endl;
        cout<<"Usage: "<<endl;
        cout<<"\tSyntheticListData <Configuration> <File Number> [OPTINAL]"<<endl<<endl;
        cout<<"\tValid Configurations are LYSO9x6_4_TUBEQAT | PMR1 | BGO8x8_2_TUBEQAT | BGO8x8_3_TUBEQAT | BGO8x8_4_TUBEQAT | BGO8x8_5_TUBEQAT | ";
        cout<<"LYSO4x9_3_SIPMGEN1 | LYSO4x9_4_SIPMGEN1 | LYSO4x9_5_SIPMGEN1"<<endl<<endl;
        cout<<"File Number Options:  [Optinal]"<<endl;
        cout<<"\t0. All Files [Optional, by default it will generate for all file if no Number is given!]"<<endl;
        cout<<"\t1. CirclesPerSlice"<<endl;
        cout<<"\t2. CrossHairPerSlice"<<endl;
        cout<<"\t3. LorTofIncSpectrumLongTrigs"<<endl;
        cout<<"\t4. OrthogLines3D"<<endl;
        cout<<"\t5. Gated3D_DwellPrecision"<<endl;
        cout<<"\t6. TofListData"<<endl;
        cout<<"\t7. RatesCurve"<<endl<<endl;
        cout<<"Example:"<<endl;
        cout<<"\t./SyntheticListData LYSO9x6_4_TUBEQAT"<<"        (for Galileo KittyHawk, ALL list files)"<<endl ;
        cout<<"\t./SyntheticData LYSO9x6_4_TUBEQAT 6"<<"      (For Galileo KittyHawk, TofListData.BLF list file only)"<<endl;
        cout<<"\t./SyntheticData BGO8x8_5_TUBEQAT"<<"    (for Galileo 25cm , ALL list files)"<<endl<<endl;

    }

    return 1;
}

/** 
 * getProductConfiguration()
 *  This method is used to convert String based Product Configuration to Enum
 *
 * @param p_productConfiguration String based Product Configuration
 *
 * @returns CONFIGURATION Enum based Product Configuration
 */
CONFIGURATION getProductConfiguration(const char* p_productConfiguration )
{
    CONFIGURATION productConfuguration = UNKNOWN;
    if(!(strcmp(p_productConfiguration,"LYSO9x6_4_TUBEQAT")))
    {
        productConfuguration = LYSO9x6_4_TUBEQAT;	// kittyhawk LYSO9x6_4_TUBEQAT  
    }
    else if(!(strcmp(p_productConfiguration,"PMR1")))
    {
        productConfuguration = 	PMR1;
    }
    else if(!(strcmp(p_productConfiguration,"BGO8x8_2_TUBEQAT")))
    {
        productConfuguration = 	BGO8x8_2_TUBEQAT;
    }
    else if(!(strcmp(p_productConfiguration,"BGO8x8_3_TUBEQAT")))
    {
        productConfuguration =  BGO8x8_3_TUBEQAT;
    }	
    else if(!(strcmp(p_productConfiguration,"BGO8x8_4_TUBEQAT")))
    {
        productConfuguration =  BGO8x8_4_TUBEQAT;
    }
    else if(!(strcmp(p_productConfiguration,"BGO8x8_5_TUBEQAT")))
    {
        productConfuguration = 	BGO8x8_5_TUBEQAT;
    }
    else if(!(strcmp(p_productConfiguration,"LYSO4x9_3_SIPMGEN1")))
    {
        productConfuguration = 	LYSO4x9_3_SIPMGEN1;
    }
    else if(!(strcmp(p_productConfiguration,"LYSO4x9_4_SIPMGEN1")))
    {
        productConfuguration = 	LYSO4x9_4_SIPMGEN1;
    }
    else if(!(strcmp(p_productConfiguration,"LYSO4x9_5_SIPMGEN1")))
    {
        productConfuguration = 	LYSO4x9_5_SIPMGEN1;
    }
    else
    {
        productConfuguration = 	UNKNOWN;
    }

    return productConfuguration;
}

void splitGated3DDwellListFile()
{
    // Splitting the Gated3D_DwellPrecision.dat using 'dd' command which takes start offset and end offset of file.

    char command1[] = "dd if=Gated3D_DwellPrecision.dat of=GatedDP_PART0000.dat bs=1 skip=0 count=1440000";
    system( command1 );
    cout<<endl<<endl;
    cout<<"GatedDP_PART0000.dat File Generated"<<endl;

    char command2[] = "dd if=Gated3D_DwellPrecision.dat of=GatedDP_PART0001.dat bs=1 skip=1506000 count=361607430";
    system( command2 );        
    cout<<"GatedDP_PART0001.dat File Generated"<<endl;

    char command3[] = "dd if=Gated3D_DwellPrecision.dat of=GatedDP_PART0002.dat bs=1 skip=363185430 count=1768800";
    system( command3 );  
    cout<<"GatedDP_PART0002.dat File Generated"<<endl;

    char command4[] = "dd if=Gated3D_DwellPrecision.dat of=GatedDP_PART0003.dat bs=1 skip=365032230 count=2511906";
    system( command4 );  
    cout<<"GatedDP_PART0003.dat File Generated"<<endl;

    char command5[] = "dd if=Gated3D_DwellPrecision.dat of=GatedDP_PART0004.dat bs=1 skip=367628136 count=3904122";
    system( command5 );
    cout<<"GatedDP_PART0004.dat File Generated"<<endl;


}
void convertToBLFFile(string fileName , string eventType , string configStr , string configNumberStr)
{
    // Converting generated .dat list file to .BLF by invoking standalone executable 'rdfImportRawList'
    // This executable requires Start Time Stamp and End Time Stamp of  list file which is extracted running 'ListDecode' tool on each .dat file 

    cout<<"======= Converting "<<fileName<<".dat "<<"to "<<fileName<<".BLF ======="<<endl<<endl;

    // file name is without extension, eventType is 802 for 6byte event & 803 for 16 byte event
    int status;	
    // The value of studyDirPath is determined by running rdfImportRawList and observing the output directory path.
    // The 3-level scan directory path is derived from /petLists/<patientID & hospitalName>/<examId>/<scanId>.
    // Since these patient/exam/scan values are hard-coded in rdfImportRawList, the directory path remains the same.
    // The LIST0000.BLF file name remains the same because the .BLF file is always moved after the rdfImportRawList program is run.
    string studyDirPath       = CDetectorGeometry::getStudyPath();
    string clean_command      = "rm -f " + studyDirPath + "*.BLF";
    string temp_BLF_File_Path = studyDirPath + "LIST0000.BLF ";	// The output of 'rdfimportRawList' directory
    char pwd[256];
    getcwd(pwd,255);
    string splitter = "/";
    string toConfigDirectory = pwd + splitter + configStr ;     		// current working directory + configStr folder

    string deleteDATfile = "rm -f " + toConfigDirectory + splitter + fileName + ".dat";

    // Running 'ListDecode and Extracting Start Time stamp (ST) and End Time stamp (ET) from .dat list file	
    string listDecodeCmd = "ListDecode -o 0 -s " + toConfigDirectory + splitter + fileName + ".dat | grep First";
    cout<<listDecodeCmd<<endl;
    string out = runCommand(listDecodeCmd.c_str())  ;
    out.erase(out.length()-1);						// remove new line '\n' character from string 
    string startTimeCmd = "echo " + out + " | awk '{print $4}'"; 		// Extract Start Time Event
    string ST = runCommand(startTimeCmd.c_str());
    ST.erase(ST.length()-1);						// remove new line '\n' character from string
    string stopTimeCmd = "echo " + out + "| awk '{print $8}'"; 		// Extract End Time Event
    string ET = runCommand(stopTimeCmd.c_str());
    ET.erase(ET.length()-1);						// remove new line '\n' character from string


    // Convert .dat File to BLF file by invoking 'rdfImportRawList' standalone executable on .dat file with ST & ET parameters.
    string commandGenerate1 = "bin/rdfImportRawList -A " + configNumberStr + " -e " + eventType + " -F "+ ST + " -L " + ET + " " + toConfigDirectory + splitter + fileName + ".dat";
    string commandMove1 = "mv -f " + temp_BLF_File_Path  + toConfigDirectory + splitter + fileName + ".BLF";
    cout<<commandGenerate1<<endl;

    status = system( clean_command.c_str() );				// Clear temp_BLF_File_Path directory.
    status = system( commandGenerate1.c_str() );				// Invoke rdfImportRawList. The output will be dumpped in temp_BLF_File_Path directory. (not really)
    status = system( commandMove1.c_str() );				// Once .BLF is generated, move the file to configStr folder.
    status = system( deleteDATfile.c_str() );				// Delete .dat file from config folder
    cout<<"================ Conversion Finished ================="<<endl<<endl;
}

string runCommand(const char* cmd) 
{
    // Method to RUN command and get the output back from the commandline in form of string.	
    FILE* pipe = popen(cmd, "r");

    if (!pipe) 
        return "ERROR";

    char buffer[128];
    std::string result = "";

    while(!feof(pipe)) 
    {
        if(fgets(buffer, 128, pipe) != NULL)
        {
            result += buffer;
        }
    }

    pclose(pipe);
    return result;
}

string convertConfigNumToString(CONFIGURATION config)
{
    string configNumber = "";
    switch(config)
    {
        case LYSO9x6_4_TUBEQAT:
            {
                configNumber = "0";
                break;
            }
        case BGO8x8_2_TUBEQAT:
            {
                configNumber = "1";
                break;
            }
        case BGO8x8_3_TUBEQAT:
        {
            configNumber = "2";
            break;
        }
        case BGO8x8_4_TUBEQAT:
        {
            configNumber = "3";
            break;
        }
        case BGO8x8_5_TUBEQAT:
        {
            configNumber = "4";
            break;
        }        
        case PMR1:
        {
            configNumber = "5";
            break;
        }        
        case LYSO4x9_3_SIPMGEN1:
        {
            configNumber = "6";
            break;
        }        
        case LYSO4x9_4_SIPMGEN1:
        {
            configNumber = "7";
            break;
        }        
        case LYSO4x9_5_SIPMGEN1:
        {
            configNumber = "8";
            break;
        }        
        default:
        {
            configNumber = "8";     // Default is Columbia 5 Ring Config
            break;
        }  
    }
    
    return configNumber;
}

                    3.3.8.7.3.3 Functionality breakdown

main cleans old *.BLF *.dat
generate Synthetic Data
            syntheticDataGen->generateSyntheticData();
            ...
            status = system(moveFiles.c_str());   // move generated .dat file to corresponding configStr folder
            cout<<"-------------------RatesCurve.dat file Generated -------------------"<<endl<<endl<<endl<<endl;
            convertToBLFFile("RatesCurve" , "802" ,configStr ,configNumberStr);	

convertToBLFFile:
    // Running 'ListDecode and Extracting Start Time stamp (ST) and End Time stamp (ET) from .dat list file	
    string listDecodeCmd = "ListDecode -o 0 -s " + toConfigDirectory + splitter + fileName + ".dat | grep First";
    cout<<listDecodeCmd<<endl;
    string out = runCommand(listDecodeCmd.c_str())  ;
    out.erase(out.length()-1);						// remove new line '\n' character from string 
    string startTimeCmd = "echo " + out + " | awk '{print $4}'"; 		// Extract Start Time Event
    string ST = runCommand(startTimeCmd.c_str());
    ST.erase(ST.length()-1);						// remove new line '\n' character from string
    string stopTimeCmd = "echo " + out + "| awk '{print $8}'"; 		// Extract End Time Event
    string ET = runCommand(stopTimeCmd.c_str());
    ET.erase(ET.length()-1);						// remove new line '\n' character from string


    // Convert .dat File to BLF file by invoking 'rdfImportRawList' standalone executable on .dat file with ST & ET parameters.
    string commandGenerate1 = "bin/rdfImportRawList -A " + configNumberStr + " -e " + eventType + " -F "+ ST + " -L " + ET + " " + toConfigDirectory + splitter + fileName + ".dat";
    string commandMove1 = "mv -f " + temp_BLF_File_Path  + toConfigDirectory + splitter + fileName + ".BLF";
    cout<<commandGenerate1<<endl;
                    3.3.8.7.3.4

                3.3.8.7.4
        3.3.9 Source files RDF
Core C++ RDF API	 rdfExternal.h, rdfInternal.h, 
RdfBase.cpp
RdfList.cpp
RdfFile.cpp
 	/vobs/pet_raw/source/rdfAPI/librdf
/vobs/pet_raw/source/rdfAPI/librdfCpp

C++ RDF List API	IsticeEvtBuff.cpp, ListWorker.h, IsticeEvtBuff.h, ListWriter.cpp, ListControl.cpp, ListWriter.h, ListControl.h, ListPacker.cpp, ListPacker.h, ListPrivate.h, RdfList.cpp, ListReader.cpp, RdfList.h, IsticeCollector.cpp, ListReader.h, RdfListPrivate.h, IsticeCollector.h, ListWorker.cpp	/vobs/pet_raw/source/rdfAPI/libEvtList
RDF file Command line Compression	rdfCompress.cpp	/vobs/pet_raw/source/rdfUtils/rdfCompress/
RDF file Command line Decompression	rdfDecomp.cpp	/vobs/pet_raw/source/rdfUtils/rdfDecompress/

RIVN Compression	compressRIVN.c, compressRIVN.h	/vobs/pet_raw/source/rdfCompression/librivn/
GLEPL Compression	Glepl.cpp, GleplDecCtrl.cpp, GleplDecCtrl.h, GleplDecCtrlPrivate.h, Glepl.h, GleplIsticeBuff.h, GleplWorker.cpp, GleplWorker.h	/vobs/pet_raw/source/rdfAPI/libEvtList
List file Command line Decompression	unglepl.cpp	/vobs/pet_raw/source/rdfUtils/unglepl/
List file Command line Compression	glepl.cpp	/vobs/pet_raw/source/rdfAPI/libEvtList
rdfAccept	rdfAccept.cc, rdfAccept.h	/vobs/pet_raw/source/rdfUtils/rdfAccept/
rdfTell	rdfTell.cpp, SliceStats.cpp
SliceStats.h	/vobs/pet_raw/source/rdfUtils/rdfTell/

id=__ListDecode__source__
ListDecode	EvtListFile.cpp, EvtListFile.h, ListDecode.cpp	/vobs/pet_raw/source/rdfUtils/ListDecode/
ListTool	ListProcess.cpp, ListProcess.h, ListTool.cpp, ListToolPlot.py, PTrigger.h	/vobs/pet_raw/source/rdfUtils/ListTool/
RDF Import Raw List	rdfImportRawList.cpp	/vobs/pet_raw/source/rdfUtils/rdfImportRawList/

id=__rdf_accept_breakdown__

        3.3.10 RDF accept, rdfAccept

            3.3.10.1 RDF Accept breakdown

a. main
/vobs/pet_raw/source/rdfUtils/rdfAccept/rdfAccept.cc
parsed command line args and calls
exit_stat = rdfAccept(arg1, arg2);

b. accept code
librdfAccept/rdfAcceptLib/rdfAccept.cc

    b1. rdfTestProductCompatibility
    various compatability checks

    b2. rdfAccept
    ultimately calls
    RDF_ACC_PET conversionStatus = p.execute(sourceFile, targetDirFullPath);

c. converter code, ConversionPipeline 
librdfAccept/rdfAcceptLib/ConversionPipeline.cc

    c1. register converter
typedef map<RdfVersion, ConversionPipeline::ConvertUtilPtr>::iterator FuncMapIter;
void ConversionPipeline::registerConverter(ConvertUtilPtr converter)
{
    std::vector<RdfVersion>::iterator it;
    // Query the version that this function can actually convert / accept
    std::vector<RdfVersion> supportedVersions = converter->getSupportedVersions();
    // Register the conversion utility with each supported version (key)
    for (it=supportedVersions.begin(); it < supportedVersions.end(); it++)
    {
        m_utilMap.insert(pair<RdfVersion, ConvertUtilPtr>(*it, converter));
    }
}

    c2. converters are registered on CTOR
ConversionPipeline::ConversionPipeline()
{
    registerConverter(ConvertUtilPtr(new RdfConvert70to71));
    registerConverter(ConvertUtilPtr(new RdfConvert71to80));
    //registerConverter(ConvertUtilPtr(new RdfConvert80to90));
    registerConverter(ConvertUtilPtr(new RdfConvert90to100));
    registerConverter(ConvertUtilPtr(new RdfConvert100));
}

    c3. convert
RDF_ACC_PET ConversionPipeline::execute(char * sourceFileName, char * destPath)
        ...
    do
    {
        // Search for the conversion function in the map
        FuncMapIter it = m_utilMap.find(currentFileVersion);
        if (it == m_utilMap.end())
        {
            // Could not find a converter. We were likely given an unsupported file to convert.
            LOG_MSG_WARN("Failed to find conversion function for version %u.%u", currentFileVersion.majorVersion, currentFileVersion.minorVersion);
            retVal = RDF_ACC_UNSUPPORTED_VERSION;
            break;
        }

        ConvertUtilPtr converter = it->second;
        cout << "Starting RDFv" << currentFileVersion << " conversion..." << endl;
        bool convertStatus = converter->convertRdf((char*)nextFilePath.c_str(), (char*)destDirPath.c_str());
        if (convertStatus != true)
        {
            //Conversion failed.
            LOG_MSG_ERROR("Failed to convert file (v%u.%u) with name: %s", currentFileVersion.majorVersion, currentFileVersion.minorVersion, nextFilePath.c_str());
            retVal = RDF_ACC_INVALID_FILE;
            break;
        }

        //Update the path to the intermediate file
        nextFilePath = destDirPath + srcName;

        // Retrieve the newly converted files version and store the old version
        previousFileVersion = currentFileVersion;
        RdfVersion::getRdfVersion((char*)nextFilePath.c_str(), currentFileVersion);

        cout << "Conversion from RDFv" << previousFileVersion << " to RDFv" << currentFileVersion << " succeeded." << endl;
        retVal = RDF_ACC_SUCCESS;

        // Sanity check to make sure we are not stuck in an infinite conversion loop
        // The only reason curr. version should equal prev. is if there was no conversion
        // to perform and we are only accepting (moving) the data.
        if (currentFileVersion <= previousFileVersion && currentFileVersion < currentAPIVersion)
        {
            LOG_MSG_ERROR("Conversion was not successful, as the new version is not greater than the legacy file version.");
            retVal = RDF_ACC_UNKNOWN_ERROR;
            break;
        }
    }
    while (currentFileVersion < currentAPIVersion);
        ...

d. A concrete converter
librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.h

    d1. interface
librdfAccept/rdfAcceptLib/rdfAccept.h
class ConvertUtilInterface
{
public:
    // Destructor
    virtual ~ConvertUtilInterface() {}
    // Executes the conversion of the RDF to whatever version the converter supports.
    virtual bool convertRdf(char * sourceFile, char * destPath) = 0;
    // Reads the geometry information used to determine product compatibilty from the
    // origial RDF version.
    virtual bool readGeometry(char * sourceFilename, ProductFamilyGeometryData &sysGeom) = 0;
    // Returns a list of versions that this conversion function is able to convert from.
    virtual std::vector<RdfVersion> getSupportedVersions(void) =0;
};

    d2. converter

const RdfVersion RdfConvert90to100::supportedVersions[] = { RdfVersion(9,0), RdfVersion(9,1) };
...
bool RdfConvert90to100::convertRdf(char * sourceFile, char * destPath)

            3.3.10.2 rdfAccept configuration - /usr/PET/systemConfig/rdfAccept.cfg  

                3.3.10.2.1 Michael mail


You will need to establish a /usr/PET/systemConfig/local/rdfAccept.cfg that allows acceptance and conversion of legacy raw data.

At some point, we need to update the ‘default’ coded in clearcase product sw related to install/config, because the default is no longer acceptable for systems that will be generating Raw Data that is > RDFv9.1.

For development systems, like jaws and elephant, I typically manually establish a ‘wide-open’ acceptance/conversion such as the following:

{ctuser@jaws}pwd
/usr/PET/systemConfig/local
{ctuser@jaws}ls -ltr rdfAccept.cfg*
-rwxrwxrwx 1 ctuser ctuser 1597 May 10  2017 rdfAccept.cfg.7.1*
-rwxrwxrwx 1 ctuser ctuser 1513 May 10  2017 rdfAccept.cfg.LYSO9x6_4_TUBEQAT*
-rw-rw-rw- 1 root   ctuser  715 Jan  5 14:17 rdfAccept.cfg.LYSO4x9_5_SIPMGEN1
-rw-rw-rw- 1 ctuser ctuser  713 Jan  5 15:04 rdfAccept.cfg.dev
-rw-rw-rw- 1 ctuser ctuser  713 Jan  6 16:09 rdfAccept.cfg
{ctuser@jaws}
{ctuser@jaws}
{ctuser@jaws}cat rdfAccept.cfg.dev
# auto-generated build date/time: Jan  4 2018 12:00:08
# Status of this version
version-1.0: stable

# *** 
# *** Section 1 - RDF API Level
# *** 
# Minimum (oldest) RDF (major) version to allow for conversion.
legacyAcceptMajorVersion: 7
# Corresponding minor RDF version to allow for conversion.
legacyAcceptMinorVersion: 0

# *** 
# *** Section 2 - Product Family Compatibility
# *** 
# Detector Geometry (radial x axial crystals per block)
detectorGeometry: 4x9

# *** 
# *** Section 3 - RDF Accept Overrides
# *** 
# Accept RDFs from non-native detector (geometry/photosensor)
allowNonNativeRDF: True
# Attempt conversion of RDFs older than the legacy accept major/minor version.
allowLegacyConversion: True


Note however, that setting legacyAcceptMajorVersion=7 is a little dangerous unless you are trying to ‘evaluate’ our ability to convert really old PET Raw Data.
I would suggest ‘9’ is for more appriate for most of our short term development needs.

Also of our PAC team that does PAARTF, please note, 
our PAARTF ‘acqSetup’ will replace the current rdfAccept.cfg with a link to the old default. ☹ We should change this. After I do a PAARTF ‘acqSetup’, I immediately do a  “rm /usr/PET/systemConfig/loca/rdfAccept.cfg; cp /usr/PET/systemConfig/loca/rdfAccept.cfg.dev /usr/PET/systemConfig/loca/rdfAccept.cfg”

I don’t like copying directly over soft links

                3.3.10.2.2 Fix error ConversionPipeline.Warn  ConversionPipeline.cc(137) in readGeometry(): There is no handler registered for this RDF version.
a. determine file version
[ctuser@jaws:2018-02-27 08:09:46:~/yosi/stage:]24$ ~/yosi/prntRdfVer.py CirclesPerSlice.BLF
CirclesPerSlice.BLF RDF version: 9.7

b.  check config:
[ctuser@jaws:2018-02-27 08:12:48:~/yosi/stage:]27$ ed /usr/PET/systemConfig/local/rdfAccept.cfg 
713
,p
# auto-generated build date/time: Feb 22 2018 02:13:48
# Status of this version
version-1.0: stable

# *** 
# *** Section 1 - RDF API Level
# *** 
# Minimum (oldest) RDF (major) version to allow for conversion.
legacyAcceptMajorVersion: 8
# Corresponding minor RDF version to allow for conversion.
legacyAcceptMinorVersion: 0

# *** 
# *** Section 2 - Product Family Compatibility
# *** 
# Detector Geometry (radial x axial crystals per block)
detectorGeometry: 5x9

# *** 
# *** Section 3 - RDF Accept Overrides
# *** 
# Accept RDFs from non-native detector (geometry/photosensor)
allowNonNativeRDF: True
# Attempt conversion of RDFs older than the legacy accept major/minor version.
allowLegacyConversion: True

c. config is fine problem is that current ver matches file ver. look for older version
[ctuser@jaws:2018-02-27 08:17:47:~/yosi/stage:]33$ for file in $(find /petLists/ -name '*.BLF'); do ~/yosi/prntRdfVer.py $file; done | grep '9.0'
/petLists/acqAutoTest/NON_NATIVE/BGO8x8_5_TUBEQAT_RDFv9.BLF RDF version: 9.0

                3.3.10.2.3 Error - [rdfAccept.cc] Failed product compatibility check.

                    3.3.10.2.3.1 code


rdfAccept config Manager:
/vobs/pet_raw/source/librdfAccept/rdfAcceptLib/RdfAcceptConfig.cc
RdfAcceptConfig::Parse() ->
    
    if (!m_cfgFile->GetStr("detectorGeometry", crystalGeometryStr)) { return false; }
    if (!parseCrystalGeoString(crystalGeometryStr, m_crystalGeometry)) { return false; }

       -> parse by token, delimiter set to |

        bool RdfAcceptConfig::parseCrystalGeoString(const std::string &str, std::vector<CrystalGeometry> &list)
        {
            std::istringstream iss(str);
            std::string token;
            while (std::getline(iss, token, '|'))
            {
                CrystalGeometry geom;    
                std::size_t loc = token.find("x");
                if (loc == std::string::npos)
                {
                    cout << "Unable to parse string: " << token << endl;
                }
        
                string radStr = token.substr(0, loc);
                string axiStr = token.substr(loc+1);
                geom.radialCrystalsPerBlock = atoi(radStr.c_str());
                geom.axialCrystalsPerBlock = atoi(axiStr.c_str());
        
                if (geom.radialCrystalsPerBlock == 0 || geom.axialCrystalsPerBlock == 0)
                {
                    cout << "Unable to parse string: " << token << endl;
                }
        
                list.push_back(geom);
            }
        
            if (list.size() < 1)
                return false;
            return true;
        } 

                3.3.10.2.4 Another mail re. product compatibility check
Thank you Mike!

Plz note that I wasn’t suggesting that rdfAccept is not working as designed. Was assuming there’s a right config for that…

I certainly plan to take the time and read thoroughly the req. docs. Will probably have to postpone a bit since I want to keep the fast pace for completing the rdfAccept ASAP.

From: Cook, Michael J (GE Healthcare) 
Sent: Wednesday, February 28, 2018 4:27 PM
To: Izaq, Yosi (GE Healthcare) <Yosi.Izaq@ge.com>
Cc: Prepyalo, Roman (GE Healthcare, consultant) <roman.prepyalo@ge.com>; Voldman, Elena (GE Healthcare) <Elena.Voldman@med.ge.com>; Douglas, Kevin (GE Healthcare) <KevinDouglas@ge.com>
Subject: Re: [rdfAccept.cc] Failed product compatibility check.

Yosi,
As our current ‘point-man’ for rdfAccept development, it is key that you understand the relevant requirements.

The following requirements come from the Columbia DMI & DMI DR common PAC SSRS DOC1590750 Rev5

SSRS.PAC.2175 Information - For the purpose of PET Raw Data import and data conversion, scanners that have common detector geometry with exception of the number of Detector Unit major rings, and minimum RDFv8 format shall be considered in the product family.

SSRS.PAC.2137 Requirement - Import of non-product family Raw Data, both Sinogram and List, other than identified exceptions, shall not be permitted with default system configuration.

SSRS.PAC.2169 Requirement - Import (and format conversion if needed) of Raw Data, both Sinogram and List, from a matching product family scanner, shall be supported. 

SSRS.PAC.2176 Requirement - Import (and format conversion if needed) of non-product family D690 (RDFv8), D710 or Discovery MI DR Raw Data, both Sinogram and List, shall be supported. 

The SSRS.PAC.2176 was recently added (Sept 5, 2017), and only applies to DMI scanners. We have yet to implement this requirement. Plan is to do so ‘in-stride’ as we head to ME2 if it makes sense, but more likely a M3 deliverable. Be thinking about how to extend our product compatibility checks and rdfAccept.cfg to handle the requirement.

Also note, that we have yet to do ‘flow-down’ requirements for some of the SSRS requirements added at M1 (Sept 2017) to the PAC SWRSs.  SSRS.PAC.2176 is one of those that requires some RDA SWRS & SWVP updates, and includes designing the solution and verification test, thereof.

Please share this information with team members that will be working with you on ‘rdfAccept’.

Mjc
If you understand your requirements, you are more apt to get the design right the first time.



From: Michael Cook <michael.cook@med.ge.com>
Date: Wednesday, February 28, 2018 at 7:59 AM
To: "Izaq, Yosi (GE Healthcare)" <Yosi.Izaq@ge.com>
Cc: "Prepyalo, Roman (GE Healthcare, consultant)" <roman.prepyalo@ge.com>
Subject: Re: [rdfAccept.cc] Failed product compatibility check.

Yosi,
By design, and as ‘required’, the product compatibility check is working.
 
We have requirements to not allow raw data that is not of the ‘Product Family’ or ‘allowed by special requirement’ onto the system that is doing the ‘rdfAccept’.
 
It sounds like you are trying to accept a DIQ list file onto a DMI system. That is ‘required’ to be ‘denied’ on a clinical DMI system.
 
You can override the product compatibility check for ‘development’ by creating or editing /usr/PET/systemConfig/local/rdfAccept.cfg, such as how I routinely do for systems that we are going to run PAARTF ‘non-native’ Replay support and or do non-native rdfAccept testing, such as what you are doing:
 
 
# auto-generated build date/time: Jan 23 2018 14:35:44
# Status of this version
version-1.0: stable
 
# *** 
# *** Section 1 - RDF API Level
# *** 
# Minimum (oldest) RDF (major) version to allow for conversion.
legacyAcceptMajorVersion: 8
# Corresponding minor RDF version to allow for conversion.
legacyAcceptMinorVersion: 0
 
# *** 
# *** Section 2 - Product Family Compatibility
# *** 
# Detector Geometry (radial x axial crystals per block)
detectorGeometry: 4x9
#detectorGeometry: 5x9
 
# *** 
# *** Section 3 - RDF Accept Overrides
# *** 
# Accept RDFs from non-native detector (geometry/photosensor)
allowNonNativeRDF: True
# Attempt conversion of RDFs older than the legacy accept major/minor version.
allowLegacyConversion: True
 
At some point, we should go over the PAC SSRS Requirements for importing (with conversion to current RDF format) of PET Raw Data. It’s good to know your requirements.
 
☺
mjc
 
 
From: "Izaq, Yosi (GE Healthcare)" <Yosi.Izaq@ge.com>
Date: Wednesday, February 28, 2018 at 6:01 AM
To: Michael Cook <michael.cook@med.ge.com>
Cc: "Prepyalo, Roman (GE Healthcare, consultant)" <roman.prepyalo@ge.com>
Subject: [rdfAccept.cc] Failed product compatibility check.
 
Hi Mike,
 
My rdfAccept test is failing b/c of above error.
It fails on check: 
rdfTestProductCompatibility()
        …
        int status = getIntParam("SYSTEM_PM_TYPE", &native_pm_type);
                …
        // Checking for product compatibility based on PM Type
        if(native_pm_type != alien_pm_type)
 
 
gdb:
(gdb) info local
function = 0xf781e752 "rdfTestProductCompatibility"
native_pm_type = 2
status = 1
native_crystals_per_block = 36
native_detector_radial_size = 372
native_rad_modules_per_system = 34
alien_pm_type = 1
 
 
I started digging into CM but since had to make progress settled into hacking this to work.
 
Can you kindly point me towards the correct way to make this work?
 
Thx!
Yosi

                3.3.10.2.5

            3.3.10.3

        3.3.11 logging

            3.3.11.1 instructions for using logging infrastructure in PET.

________________________________________
To enable logging, add this to your source file:

#include <string>
#include <iostream>
#include "BaseLogMsg.h"
#include "BaseToStr.h"
#include "PetAcqDebug.h"

// Use Detector PDD log and debug control, different scopes are defined in CPetAcqDebug class in \pet_acq\source\pet_acq\PetAcqDebug.h
static ge_base::CLogControl * LOG_MSG_CONTROL __attribute__((unused)) = &CPetAcqDebug::m_logControlPdd;

using namespace ge_base;

________________________________________

Using the macros in your code:
LOG_MSG_DEBUG("buffCnt=" + StrInt(buffCnt) + ", buffLen=" + StrInt(buffLen));

Note endl is added automatically, note usage of StrInt(), this and more are defined in BaseToStr.h included above.
________________________________________

Controlling of logging level in runtime:
/usr/PET/systemConfig/local/pet_acq.debug.cfg
Find a section for your scope and change flags to allow/block logging of specific level.


            3.3.11.2 LOG_MSG_ERROR , LOG_MSG_DEBUG macros
All macros and class for log facility in

/vobs/pet_platform/source/libgebase2/BaseLogMsg.h
#ifndef LOG_MSG_DEBUG_DISABLE
#define LOG_MSG_DEBUG(fmt, ...)         { if (LOG_MSG_CONTROL->IsDebugEnabled()) { LOG_MSG_WRITE(ge_base::CLogControl::TYPE_DEBUG, fmt, ## __VA_ARGS__); } }
#else
#define LOG_MSG_DEBUG(fmt, ...)
#endif

            3.3.11.3
        3.3.12
    3.4 Acquisition flow

        3.4.1 high level description
icloud notes. search  PET Acquisition flow

        3.4.2 Source code pointer

            3.4.2.1 Pre mice 

                3.4.2.1.1 useful greps
    a1. [de680136@ctds64-1:2018-02-06 05:16:57:/vobs/pet_acq/source:]2727$ find . -type f -print0 | xargs -0 grep -is rxreceiv
./libcldevices/clRecvGbe.cpp:        rbufQueueFirst( &(m_zBufQueues->rxReceive), pDesc );
./libcldevices/clRecvGbe.cpp:volatile n32 rxFree, rxReceive, rxConsume, rxListable;
./libcldevices/clRecvGbe.cpp:    rxReceive = m_zBufQueues->rxReceive.cnt;
./libcldevices/clRecvGbe.cpp:    printf("rxFree %lu rxReceive %lu rxConsume %lu rxListable %lu\n",
./libcldevices/clRecvGbe.cpp:        (ulong)rxFree, (ulong)rxReceive, (ulong)rxConsume, (ulong)rxListable );
./libcldevices/clRecvGbe.cpp: *                 the m_zBufQueues->rxReceive and rxListable queues. 
./libcldevices/clRecvGbe.cpp:        *pDesc = rbufDequeueFirst( &(m_zBufQueues->rxReceive) );
./libcldevices/clRecvGbe.cpp:    rbufQueueInit( &(m_zBufQueues->rxReceive) );
./libcldevices/clUnlist.cpp:    rbufQueueFirst(&(m_zBufQueues->rxReceive), pDesc);
./libcldevices/clUnlist.cpp:        rbufQueueFirst(&(m_zBufQueues->rxReceive), pDesc);
./libcldevices/clUnlist.cpp:        rbufQueueFirst(&(m_zBufQueues->rxReceive), pDesc);
./libcldevices/clUnlist.cpp:            rbufDequeueAllFirst( &(m_zBufQueues->rxFree), &(m_zBufQueues->rxReceive) );
./libcldevices/clUnlist.cpp:    volatile n32 rxFree, rxReceive, rxConsume, rxListable;
./libcldevices/clUnlist.cpp:    rxReceive = m_zBufQueues->rxReceive.cnt;
./libcldevices/clUnlist.cpp:    printf("rxFree %u rxReceive %u rxConsume %u rxListable %u\n",
./libcldevices/clUnlist.cpp:        (uint)rxFree, (uint)rxReceive, (uint)rxConsume, (uint)rxListable );
./libcldevices/clUnlist.cpp: *                 the rxReceive and rxListable queues. 
./libcldevices/clUnlist.cpp:    rbufQueueInit( &(m_zBufQueues->rxReceive) );
./libcldevices/commlink.cpp:    // Get buffers from the rxReceive queue. There may be multiple packets per buffer.
./libcldevices/commlink.cpp:        pDesc = rbufDequeueLast( &(m_zBufQueues->rxReceive) );
./libcldevices/test/unlist_test.cpp:                    EventPacket pkt( rbufDequeueFirst( &(zbufData->rxReceive) ) );
./libcldevices/unlistdev.cpp:    // Get buffers from the rxReceive queue. There may be multiple packets per buffer.
./libcldevices/unlistdev.cpp:    pDesc = rbufDequeueLast( &(m_zBufQueues->rxReceive) );
./libcldevices/ZbufQueues.cpp:    rxReceive.cnt = 0;
./libcldevices/ZbufQueues.cpp:    rxReceive.pFirst = NULL;
./libcldevices/ZbufQueues.cpp:    rxReceive.pLast = NULL;
./libcldevices/ZbufQueues.cpp:    rbufDequeueAllFirst( &rxFree, &rxReceive );
./libcldevices/ZbufQueues.h:    RbufDescQueue rxReceive;
./libcldevices/clRecvKhEvt.cpp:        rbufQueueFirst( &(clRecvGbe::m_zBufQueues->rxReceive), pDesc );

                3.4.2.1.2 Allocates memory
/vobs/pet_acq/source/libcldevices/clRecvGbe.cpp
ZBUF_RING *clRecvGbe::createZbufRing(void)

    deallocate memory
CL_STATUS clRecvGbe::destroyZbufRing(void)
{
int i;

    if ( zbufData ) 
    {   
        for ( i=0; i<RX_RING_SIZE; ++i )
        {
            if ( zbufData->rxRingSpace[i].pkt.soa )
            {
                free( zbufData->rxRingSpace[i].pkt.soa );
                zbufData->rxRingSpace[i].pkt.soa = NULL;
                zbufData->rxRingSpace[i].pkt.data = NULL;
            }
        }
        free( zbufData );
    }

    zbufData = NULL;

    if ( m_zBufQueues != NULL )
    {
        delete m_zBufQueues;
    }

    m_zBufQueues = NULL;

    return CL_SUCCESS;
}

    access memory
ZBUF_RING *clRecvGbe::getZbufRing(void)

    access zbuf queues
ZbufQueues *clRecvGbe::getZbufQueues(void)




    b1. size
#define CL_CRITICAL_SIZE ( sizeof(ZBUF_RING) + 1024 )
    ...
typedef struct zbufRing
{
    n32 rxDriverId;
    n32 rxListFlags;     // List mode enable flags
    n32 rxRingSize;
    int linkStatus;
    RBUFDESC *rxCurrent;      /* Current packet buffer used for receive buffer allocation */
    n32 rxMaxPkts;  /* Max packets before ignoring interrupt */

    /* rxRing must be last in this structure */
    RBUFDESC *rxRing;
    RBUFDESC rxRingSpace[RX_RING_SIZE];
} ZBUF_RING;
32 bytes + rxRingSpace array ( RBUFDESC * RX_RING_SIZE == 512 )

                3.4.2.1.3 libcldevices main receive loop
 *   Description: Loop which receives coincidence packets into the linked
 *                list for consumption by the sorter.

void clRecvGbe::RunCyclic()
{
int length;
RBUFDESC *pDesc;
RPKTDESC *pPkt;

struct timespec reqSleep, remSleep;

    // Set the thread name
    SH_Thread::SetThreadName( "CL:clRecvGbe" );

    SetAffinity();

    // Assumes that the socket is already open 
    pDesc = NULL;

    while( !m_bShutdown )
    {
        if ( !pDesc )
        {
            // Get a packet descriptor (reuseBuffers flag must be set)
            clGetReceiveBuffer( &pDesc, 1 );
        }

        if ( !pDesc )
        {
            // This should not happen but what if it does?

            // Wait for the consumer to use up buffers

            reqSleep.tv_sec = 0;
            reqSleep.tv_nsec = CLRECV_NO_BUFFER_SLEEP; 
            nanosleep( &reqSleep, &remSleep ); 

            ++(clStats->rxTimeout);
            continue;
        }

        // Get the packet buffer 
        pPkt = &(pDesc->pkt);

        // Wait for incoming packet
        length = recvfrom( rxSock, pPkt->data, RX_BUFFER_SIZE, 0, NULL, NULL );

        if ( length < 0 )
        {
            // TO DO:  We've got a socket problem here.  Is this a timeout?
            perror("recvfrom:");
            zbufData->linkStatus = LINK_DOWN;

            ++(clStats->rxTimeout);
            continue;
        }

        pPkt->len = length;  // returned by recvfrom
        m_coinData.ParseBuff(pPkt->data, pPkt->len);    // maintain galileo coin link data statistics

        // Update statistics 
        ++(clStats->rxPacketcnt);

        // Count only packets that have data
        clStats->rxBytes += length; // returned by recvfrom

        zbufData->linkStatus = LINK_UP;

        // We are in sequence so just queue the received packet

        // Save the next expected transaction number
        m_nextTnsw++;
        pPkt->tnsw = m_nextTnsw;

        // Acquire the shared memory lock
        m_zBufQueues->clLockAcquire();

        // Queue the received packet 
        rbufQueueFirst( &(m_zBufQueues->rxReceive), pDesc );

        // Done with this descriptor
        pDesc = NULL;

        // Release the shared memory lock
        m_zBufQueues->clLockRelease();

    }  // End FOREVER loop

    if ( pDesc )
    {
        // Acquire the shared memory lock
        m_zBufQueues->clLockAcquire();

        // Free the packet 
        rbufQueueLast( &(m_zBufQueues->rxFree), pDesc );

        // Release the shared memory lock
        m_zBufQueues->clLockRelease();
    }
}

                    3.4.2.1.3.1 Some linked list Q references

    d1.  /vobs/pet_acq/source/libcldevices/clBuf.h
inline void rbufQueueFirst(RbufDescQueue *pQueue, RBUFDESC *pDesc)
{
   pDesc->rbufNext = pQueue->pFirst;
   pDesc->rbufPrev = RQ_NULL;

   if ( pQueue->pFirst != RQ_NULL )
   {
       /* Link into top */
       pQueue->pFirst->rbufPrev = pDesc;
   }

   pQueue->pFirst = pDesc;

   if (pQueue->pLast == RQ_NULL)
      pQueue->pLast = pDesc;

   /* bump queue count */
   pQueue->cnt += 1;
} /* end of rbufQueueFirst() */

                    3.4.2.1.3.2

                3.4.2.1.4 Main processing, /vobs/pet_acq/source/libsortMain/SorterMain.cpp

                    3.4.2.1.4.1 class CSorterMain 
class CSorterMain: public SH_Thread
{
public:
	
	CSorterMain( CSorterCtrlIf* pSorterCtrl );
	
	virtual ~CSorterMain();

	bool Initialize( SH_Thread* pHistoIf, SH_Thread * pClRecv );
	void ProcessMsgFromSortCtrl(SH_MsgBase * pMsg );
	void ProcessInternalDirective();
	void RunCyclic();
	void StartScan( CE_SORT_TYPE sortType );
	int  ProcessCoinEvents();
	void SetSortType(SAI_SORTER_INIT_REQ_DATA * pInitRx ,CE_SORT_TYPE &ceSortType );
	void PrintSorterState();
	int SetDefaultMonitorMode();
	CSortStats * GetSortStatsPtr() { return m_pFrameControl->GetSortStatsPtr(); }

	// Update randoms counts for live scan or replay 
	void UpdateRandomsCount( RandomsCountSample *pRandomsCountSample );

	// List sync
	void SendListSync( n32 directive, bool exactEvent );

	// called from ZCH event cache thread (aka histoMain)
	void SetMaxEventRate(double maxEventsPerSec, unsigned int weightingFactor, unsigned long calcEventRatioMsecs)
	{
		ge_base::CSpinLockAuto	lock(m_spinLock);	// provide fast mutual exclusion, release spin lock in destructor

		m_maxEventsPerSec     = maxEventsPerSec;
		m_weightingFactor     = weightingFactor;
		m_calcEventRatioMsecs = calcEventRatioMsecs;
	}

	// get a snapshot copy of the parameters in SetMaxEventRate()
	void GetMaxEventRate(double &maxEventsPerSec, unsigned int &weightingFactor, unsigned long &calcEventRatioMsecs)
	{
		ge_base::CSpinLockAuto	lock(m_spinLock);	// provide fast mutual exclusion, release spin lock in destructor

		maxEventsPerSec     = m_maxEventsPerSec;
		weightingFactor     = m_weightingFactor;
		calcEventRatioMsecs = m_calcEventRatioMsecs;
	}
	
	double GetCurrEventsPerSec() const { return m_currEventsPerSec; }
	double GetEventsToHistoRatio() const { return m_eventsToHistoRatio; }

        // List enable flags by frame
        n32 m_listModeEnable[S_ACQ_MAX_FRAME_SPECS]; /* Enable list mode for this frame */

    clDevice * GetCldevicePtr() { return (m_pSortInPool == NULL) ? NULL : m_pSortInPool->GetCldevicePtr(); } 

protected:
	void WaitForHisto(double start);
	void WaitForClData(double start);
	// next 'dereference' method used if the histo evt buffer pool will be destroyed/re-initialized
	void DerefOutHistoBuffer() { m_pHistoOut = NULL; }	// forget about previous output hist buff 	
	bool GetHistoOutBuff();
	int GetClData( double start );
	void ProcessPseudoEvent( int state, SorterInputBuffer *pSortInBuf );
	void MoveDataToHisto( int hEvts );
    void SleepTrack( unsigned int uSleepVal );

private:
	double dWaitForHistoBuf;
	double dWaitForUnlistData;
	double dSorterTime;
	double dSpecEventProccTime;
	double dMoveDataToHisto;
    
	CSorterCtrlIf* m_pSorterCtrl;
	SH_MsgHistoEventBuf * m_pHistoBufMsg;

	SH_Thread * m_pClRecv;
	CSort * m_pSort;
	CSortTables * m_pLUTs;
	CSortSetup * m_pSetup;
	class CFrameControl * m_pFrameControl;
	CHistoEventPool * m_pHistoPool;
	SH_Thread* m_pHistoIf;
	class CSorterCounts * m_pSorterCounts;
	class CSorterFrame * m_pSorterFrame;
	DO_HISTO_FLAG m_iDoHisto;
	n64 m_iHistogramCells;      // total number of cells in the frame's histogram

	// scan counters
	bool m_bProcessCL;
	CE_SORT_TYPE m_scanSortType;
	CHistoEventBuff * m_pHistoOut;

	// stats
	unsigned long m_iPacketsReceived;
	unsigned long m_iBuffersSent;
	unsigned long m_iEventsSent;
	unsigned long m_iWaitHistoBuf;
	CE_SORT_TYPE m_ceSortType;
	bool m_bTOF_EventStream;

	clDevice *clInterface;
	clDevice *clCommInterface;
	clDevice *clUnlistInterface;

	int m_maxClPackets, m_maxCommPackets, m_maxUnlistPackets;
	int m_eBinningMode;
	int m_iProcSleeps;
	int m_iHistoSleep ;
	int m_iclRcSleep;

	bool m_bGotEndOfList;
	SorterInputPool *m_pSortInPool;

	// rate-dependent uniform event discard 
	void	InitEventsToHistoRatio();
	void	CalcEventsToHistoRatio();

	double	m_maxEventsPerSec;
	unsigned int m_weightingFactor;
	double	m_currEventsPerSec;
	unsigned long m_calcEventRatioMsecs; // calculate event rate time interval

	ge_base::CTimer	m_sleepTimer;	    // used for SorterMain high level sleep vs. non-sleep timing
    double m_iNonSleepSecs;             // non-sleep accumulated SorterMain secs
    double m_iSleepSecs;                // sleep accumulated SorterMain secs

	double	m_eventsToHistoRatio;		// ratio of events to histogram over total events
	ge_base::CTimer	m_eventRateTimer;	// used to measure event rate
	ge_base::CSpinLock m_spinLock;		// used for mutual exclusion in GetMaxEventRate()/SetMaxEventRate()
	unsigned long m_calcAccumEvents;	// accumulated events over the calc event rate time interval

};

                    3.4.2.1.4.2 void CSorterMain::StartScan( CE_SORT_TYPE sortType )
{
    ...
	InitEventsToHistoRatio();
	m_pClRecv->SendMsg(new SH_MsgBase(SH_MSG_START_SCAN));
}

                    3.4.2.1.4.3 void CSorterMain::RunCyclic() -> ProcessCoinEvents()

                    3.4.2.1.4.4 get events
void CSorterMain::RunCyclic()
    calls to
//-------------------------------------------------------------------------------------------
///ProcessMsgFromSortCtrl -- process messages received from SorterCtrl thread.
/// THis messages have higher priorities than internal sorter messages
//-------------------------------------------------------------------------------------------
void CSorterMain::ProcessMsgFromSortCtrl(SH_MsgBase * pMsg )
    calls to
int CSorterMain::GetClData( double start )
{
	// Get the current buffer in the pool and check for empty
	SorterInputBuffer *pSorterInBuffer = m_pSortInPool->CurrentBuffer();

	if ( !pSorterInBuffer || pSorterInBuffer->IsEmpty() )
	{
		// Current buffer is empty or doesn' exist.  Get the next buffer.
		pSorterInBuffer = m_pSortInPool->NextBuffer();

		if ( !pSorterInBuffer )
		{
			// Refill the pool through from current coinlink interface.
			int numBufs = m_pSortInPool->FillPool(m_maxClPackets, m_eventsToHistoRatio);

			if ( numBufs )
			{
				m_iPacketsReceived += numBufs;
			}
			else
			{
				// No coinlink data available to fill pool
				WaitForClData(start);
				return 0;
			}
		}
	}

	// At this point, we should have a working buffer
	pSorterInBuffer = m_pSortInPool->CurrentBuffer();

	if ( pSorterInBuffer )
	{
/*** TODO:  MWW - What packet type are we getting????    Should we discard if NOT coincidence data of some sort ????????
		if ( pSorterInBuffer->EventType() != COINLINK_COIN_DATA )
		{
			// If not coincidences (i.e. SINGLES DATA), discard for now
			pSorterInBuffer->Clear();
			return 0;
		}
****/
		// Yes we have a sorter input buffer
		return 1;
	}
	// No we don't have a sorter input buffer
	return 0;
}

                3.4.2.1.5 Control thread     pet_acq/libacqCtrl/acqmain.cpp

g.

            3.4.2.2 post mice

            3.4.2.3

        3.4.3

    3.5 infrastructure

        3.5.1  libgebase2

            3.5.1.1  /vobs/pet_raw/source/rdfAPI/libRawPrimitives/MemDataBuf.h
#ifndef MEM_DATA_BUF_H
#define MEM_DATA_BUF_H 1

#include <cstdlib>
#include <stdexcept>

//#define MDA_TRACK_MEM_ALLOC
#ifdef MDA_TRACK_MEM_ALLOC
# include <iostream>
#endif

/**
 * Simple memory buffer with helper functions for allocating, freeing
 * and efficiently resizing memory. Uses the standard C library
 * functions <code>realloc</code> and <code>free</code> to allocate memory.
 * Assignment and copies are shallow. Memory is freed on destruction.
 *
 * <em>This class does not throw exceptions.</em>
 *
 * @tparam T Underlying plane data type (i.e. <code>uint16_t</code> or <code>float</code>).
 *
 * @code
 * typedef CSimpleMemBuf<uint16_t> MyDataType;
 * MyDataType * data = new MyDataType(100); // Allocates 200 bytes of data
 * data->Alloc(125); // Realloc space for 25 additional elements; the first 100 are unchanged
 * data->Free();
 * @endcode
 *
 * @ingroup raw_primitives
 */
template<typename T>
struct CSimpleMemBuf
{
    /** Raw data pointer. */
    T * data;

    /** Number of elements (not bytes) allocated for <code>data</code> pointer. */
    size_t allocated;

    /** Default constructor. Does not allocate memory. */
    CSimpleMemBuf() : data(NULL), allocated(0) { }

    /** Constructor with initial element allocation. */
    CSimpleMemBuf(size_t elements) : data(NULL), allocated(0) { Alloc(elements); }

    /** Allow constructor type conversion to a different template type. <em>Use
     *  with caution!</em> */
    template <typename OT>
    explicit CSimpleMemBuf(const CSimpleMemBuf<OT> & other)
    {
        this->data = reinterpret_cast<T*>(other.data);
        this->allocated = other.allocated * sizeof(OT) / sizeof(T);
    }

    /** Free any memory allocated by this class. */
    virtual ~CSimpleMemBuf() { Free(); }

    /**
     * Allocate new memory or reallocate existing memory. The contents of
     * <code>data</code> will be unchanged to the minimum of the old and new
     * element count.
     * @throw std::runtime_error If the new memory cannot be allocated. The old memory is untouched.
     */
    inline virtual void Alloc(size_t totalElements)
    {
        if (this->allocated == totalElements) return;

        bool badAllocEx = false;
        void * newptr = NULL;

        try
        {
            // Emulates 'malloc' if data is NULL, otherwise does a true 'realloc'. With realloc,
            // the contents will be unchanged to the minimum of the old and new sizes.
            newptr = realloc(this->data, totalElements * sizeof(T));
        }
        catch (const std::bad_alloc & ex)
        {
            badAllocEx = true;
        }

        // Note: We could consider an additional combination of results: if the allocation failed
        // and the new requests was for a smaller number of elements (i.e. to downsize the amount
        // of memory). In this specific case, the original pointer would still be valid.

        if (badAllocEx or (newptr == NULL and totalElements))
        {
            // Add some additional detail to the standard 'std::bad_alloc' error
            std::stringstream s;
            s << "memory realloc failed from " << (this->allocated * sizeof(T)) << " bytes to "
              << (totalElements * sizeof(T)) << " bytes";
            throw std::runtime_error(s.str());
        }

        this->data = static_cast<T*>(newptr);

#ifdef MDA_TRACK_MEM_ALLOC
        std::cout << "CSimpleMemBuf: realloc " << static_cast<void*>(this->data) << " from "
                  << (this->allocated * sizeof(T)) << " bytes to "
                  << (totalElements * sizeof(T)) << " bytes" << std::endl;
#endif

        if (this->data != NULL) {
            this->allocated = totalElements;
        } else {
            this->allocated = 0;
        }
    }

    /**
     * Increase the memory allocated by this class. The contents of
     * <code>data</code> will be unchanged to the minimum of the old and new
     * element count.
     */
    inline virtual void Grow(size_t incElements)
    {
        Alloc(this->allocated + incElements);
    }

    /** Free any memory associated with this object. */
    inline virtual void Free()
    {
        free(this->data);
        Reset();
    }

    /** Reset the internal values of this class without freeing memory. */
    inline virtual void Reset()
    {
        this->data = NULL;
        this->allocated = 0;
    }

    /** Create and return a deep copy of the current data buffer. */
    inline virtual void CopyTo(CSimpleMemBuf<T> & dest) const
    {
        dest.Alloc(this->allocated);
        memcpy(dest.data, this->data, this->allocated * sizeof(T));
    }

    inline virtual void Memset(int value)
    {
        memset(this->data, value, this->allocated * sizeof(T));
    }
};

/**
 * Specialization of the simple data buffer that adds tracking for memory used. The value
 * of <code>used</code> must be updated by the caller.
 *
 * <em>This class does not throw exceptions.</em>
 *
 * @ingroup raw_primitives
 */
template<typename T>
struct CMemDataBuf : public CSimpleMemBuf<T>
{
    /** Number of elements (not bytes) actually in use by this class. Meant to
     *  be updated and maintained by caller. */
    size_t used;

    /** Default constructor. Does not allocate memory. */
    CMemDataBuf() : used(0) { }

    /** Constructor with initial element allocation. */
    CMemDataBuf(size_t elements) : CSimpleMemBuf<T>(elements), used(0) { }

    /** Allow constructor type conversion to a different template type. <em>Use
     *  with caution!</em> */
    template <typename OT>
    explicit CMemDataBuf(const CMemDataBuf<OT> & other)
    {
        this->data = reinterpret_cast<T*>(other.data);
        this->allocated = other.allocated * sizeof(OT) / sizeof(T);
        this->used = 0;
    }

    /** Reset the internal values of this class without freeing memory. */
    inline virtual void Reset()
    {
        CSimpleMemBuf<T>::Reset();
        this->used = 0;
    }

    /** Create and return a deep copy of the current data buffer. */
    inline virtual void CopyTo(CMemDataBuf<T> & dest) const
    {
        dest.Alloc(this->allocated);
        memcpy(dest.data, this->data, this->allocated * sizeof(T));
        dest.used = this->used;
    }
};

#include <ostream>

/** Convenience stream operator to easily output the members of a buffer. */
template<typename T>
std::ostream & operator<<(std::ostream & stream, const CSimpleMemBuf<T> & buf)
{
    stream << "dataptr=" << static_cast<void*>(buf.data) << " allocated=" << buf.allocated;
    return stream;
}

/** Convenience stream operator to easily output the members of a buffer. */
template<typename T>
std::ostream & operator<<(std::ostream & stream, const CMemDataBuf<T> & buf)
{
    stream << "dataptr=" << static_cast<void*>(buf.data) << " allocated=" << buf.allocated << " used=" << buf.used;
    return stream;
}

#endif // MEM_DATA_BUF_H

        3.5.2



    3.6 MICE events format

        3.6.1 convert Galileo To Mice 

A. Main conversion loop - RMiceConverter.cpp
//////////////////////////////////////////////////////////////////////////////////////////////////////////
bool RMiceConverterAccept::ProcessBuff(const PBYTE pBuff, unsigned int dataLen, uint32_t nIndex, bool &bTmLast, uint64_t *pOffset, uint64_t *pUnkEvents)
{
	bool 		bOk 		= true;
	bool 		bDone 		= false;
	bool		bHaveMemory = true;
	uint64_t	nUnknownEvt = 0;
    
    LOG_MICE_INFO("Called with dataLen="+ge_base::StrInt(dataLen)+", nIndex= "+ge_base::StrInt(nIndex)+", "+(bTmLast? "last" : "not last"));

	RMiceAccept *pBuffer = &m_pBuffer[nIndex];
	if (!pBuff || !pBuffer)
	{
		LOG_MICE_ERROR("One of the parameters is NULL");
		return false;
	}

    uint16_t eventLen = GetEventLen(pBuff);        // determine event length of first event
    if (eventLen == 0)
    {
    	LOG_MICE_ERROR("Empty buffer or failed to retrieve Buffer Event length");
        return false;
    }


    uint32_t 	   	nTotalEvents 		= dataLen / eventLen;
    uint32_t		nPromptCount 		= 0;
    PBYTE 			pByteHeader 		= pBuff;

    LOG_MICE_INFO("Event len= "+ge_base::StrInt(eventLen)+", nTotalEvents= "+ge_base::StrInt(nTotalEvents));

	while (nPromptCount < nTotalEvents && bOk && !bDone)
    {
        //temp log
        LOG_MICE_INFO("In main conversion loop. nPromptCount= "+ge_base::StrInt(nPromptCount));
    	int 					nAlignedEvents 	= 0;
		PET_LINK_EVT_HEADER_GAL *pHeader 		= reinterpret_cast<PET_LINK_EVT_HEADER_GAL *>(pByteHeader);
		PET_LINK_EVT_HEADER_GAL	*pAlignEvent 	= pHeader;

    	while(nPromptCount + nAlignedEvents < nTotalEvents && pAlignEvent->eventType == COINC_EVT)
    	{
   			++nAlignedEvents;
   			pAlignEvent = reinterpret_cast<PET_LINK_EVT_HEADER_GAL *>(pByteHeader + (nAlignedEvents * eventLen));
    	}

		if (nAlignedEvents)
		{
			if (!PutCoinc((PBYTE)pHeader, eventLen, nAlignedEvents))
			{
				LOG_MICE_ERROR("Failed to convert PutCoinc into memory");
				bOk = false;
				break;
			}
            LOG_MICE_INFO("In main conversion loop. Successfuly converted block of "+ge_base::StrInt(nAlignedEvents)+" events");

			bTmLast						= false;
			m_nCurrCoinCountTotal 		 += nAlignedEvents;
			pBuffer->m_counts[EVT_COINC] += nAlignedEvents;
			nPromptCount				 += nAlignedEvents;
			pHeader 					 = pAlignEvent;
			pByteHeader 				 += (eventLen * nAlignedEvents);
			nAlignedEvents 				 = 0;
		}

		if ( nPromptCount + nAlignedEvents < nTotalEvents && pHeader->eventType != COINC_EVT )
    	{
    		switch (pHeader->eventTypeExt)
    		{
				case TIME_MARKER_EVT:
					PutTimeMarker(pBuffer, pByteHeader, bHaveMemory);
					bDone 	= !bHaveMemory;
					bTmLast = true;
					break;

				case EXTERN_TRIG_EVT:               // 4 byte event type
					PutTrigger(pBuffer, pByteHeader, bHaveMemory);
					bDone 	= !bHaveMemory;
					bTmLast = true;
					break;

				case COINC_COUNT_EVT:               // 4 byte event type
				case TABLE_POS_EVT:                 // 6 byte event typenEvents
				case SINGLE_EVT:                    // 16 byte event type
				case END_LIST_EVT:                  // list file synthetic event
					nUnknownEvt++;
					break;

				default:
					nUnknownEvt++;
					LOG_MICE_TRACE("Unknown event type. Skipping the event");
					break;
    		}

    		if (bHaveMemory)
    		{
    			pByteHeader += eventLen;
    			++nPromptCount;
    		}
            else
            {
                LOG_MICE_ERROR("Warning, out of memory!");
            }
		}
    }

	if (pOffset)
		*pOffset = nPromptCount * eventLen;

	if (pUnkEvents)
		*pUnkEvents = nUnknownEvt;
    return bOk;
}

B. convert Galileo event to Mice 
bool RMiceConverterBase::PutCoinc(PBYTE pEvent, uint16_t EventLen, uint64_t nIndex, RPacketCoin *pNode)
{
	TOFDATA	  	*pTof		= NULL;
	ENERGYDATA 	*pEnergy	= NULL;
	CALDATA    	*pCal		= NULL;

	switch (EventLen)
	{
		case EVENT_LEN_NOM_MODE:
			{
				PET_LINK_EVT_NOM_COINC *pSrc = (PET_LINK_EVT_NOM_COINC *)pEvent;
				pTof 					= &pNode->pTof[nIndex];
				pTof->hiXtalAxialID		= pSrc->hiXtalAxialID;
				pTof->hiXtalTransAxID	= pSrc->hiXtalTransAxID;
				pTof->loXtalAxialID		= pSrc->loXtalAxialID;
				pTof->loXtalTransAxID	= pSrc->loXtalTransAxID;
				pTof->deltaT			= pSrc->deltaTime;
			}
			break;

		case EVENT_LEN_ENERGY_MODE:
			{
				PET_LINK_EVT_ENERGY_COINC *pSrc = (PET_LINK_EVT_ENERGY_COINC *)pEvent;
				RPacketCoin *pDst 				= (RPacketCoin *)pNode;
				if (pDst->pEnergy)
				{
					pEnergy							= &pDst->pEnergy[nIndex];
					pEnergy->hiEnergy				= pSrc->hiXtalEnergy;
					pEnergy->loEnergy				= pSrc->loXtalEnergy;
				}

				pTof 							= &pDst->pTof[nIndex];
				pTof->hiXtalAxialID				= pSrc->nomCoincPart.hiXtalAxialID;
				pTof->hiXtalTransAxID			= pSrc->nomCoincPart.hiXtalTransAxID;
				pTof->loXtalAxialID				= pSrc->nomCoincPart.loXtalAxialID;
				pTof->loXtalTransAxID			= pSrc->nomCoincPart.loXtalTransAxID;
				pTof->deltaT					= pSrc->nomCoincPart.deltaTime;
			}
			break;

		case EVENT_LEN_CAL_MODE:
			{
				PET_LINK_EVT_CALIB_COINC *pSrc 	= (PET_LINK_EVT_CALIB_COINC *)pEvent;
				RPacketCoin *pDst 				= (RPacketCoin *)pNode;

				pTof 							= &pDst->pTof[nIndex];
				pTof->hiXtalAxialID				= pSrc->hiXtalAxialID;
				pTof->hiXtalTransAxID			= pSrc->hiXtalTransAxID;
				pTof->loXtalAxialID				= pSrc->loXtalAxialID;
				pTof->loXtalTransAxID			= pSrc->loXtalTransAxID;
				pTof->deltaT					= pSrc->deltaTime;

				if (pDst->pEnergy)
				{
					pEnergy							= &pDst->pEnergy[nIndex];
					pEnergy->hiEnergy				= pSrc->hiXtalEnergy;
					pEnergy->loEnergy				= pSrc->loXtalEnergy;
				}

				if (pDst->pCal)
				{
					pCal							= &pDst->pCal[nIndex];
					pCal->hiAngerX					= pSrc->hiXtalAngerX;
					pCal->hiAngerZ					= pSrc->hiXtalAngerZ;
					pCal->loAngerX					= pSrc->loXtalAngerX;
					pCal->loAngerZ					= pSrc->loXtalAngerZ;
				}
			}
			break;

			default:
				return false;
	}

	return true;
}

C. convert time marker
void RMiceConverterAccept::PutTimeMarker(RMiceAccept *pBuffer, const PBYTE pEvent, bool &haveMemory)
{
	PET_LINK_EVT_TIME_MARKER *pSrc = reinterpret_cast<PET_LINK_EVT_TIME_MARKER *>(pEvent);
	if (pSrc->timeMarker > 0 && !m_bFirstTimeStamp && m_nCurrCoinCountTotal > 0)
		PutTimeMarkerFirst(pBuffer, pSrc->timeMarker - 1, haveMemory);

	if (haveMemory)
	{
		uint64_t count = pBuffer->m_counts[EVT_TIME_MARKERS];
		if (count + 1 > pBuffer->m_timestamps.size())
		{
			haveMemory = false;
			LOG_MICE_TRACE("No more memory");
		}
		else
		{
			MiceTimeStamp *pTm = &pBuffer->m_timestamps[count];

			pTm->dlType 	= EVT_TIME_MARKERS;
			pTm->eventIndex = m_nCurrCoinCountTotal;
			pTm->timeStamp	= pSrc->timeMarker;
			m_tm 			= pTm->timeStamp;

			++pBuffer->m_counts[EVT_TIME_MARKERS];

			if (!m_bFirstTimeStamp)
				m_bFirstTimeStamp = true;
		}
	}
}

D. convert external triggers 
void RMiceConverterAccept::PutTrigger(RMiceAccept *pBuffer, const PBYTE pEvent, bool &haveMemory)
{
	PET_LINK_EVT_EXTERN_TRIG *pSrc 	= (PET_LINK_EVT_EXTERN_TRIG *)pEvent;
	MiceType trgType 				= (pSrc->externTrigInput == PHYS2_TRIG_GAL_EVT) ? EVT_EXT_RESP_TRIGGER : EVT_EXT_CARD_TRIGGER;
	uint64_t count 					= pBuffer->m_counts[trgType];
	MiceTimeStamp *pTrg				= NULL;

	if (trgType == EVT_EXT_CARD_TRIGGER)
	{
		if (count + 1 > pBuffer->m_extcardtriggers.size())
		{
			LOG_MICE_ERROR("No more memory for card triggers");
			haveMemory = false;
		}
		else
		{
			pTrg = &pBuffer->m_extcardtriggers[count];
		}
	}
	else
	{
		if (count + 1 > pBuffer->m_extresptriggers.size())
		{
			LOG_MICE_ERROR("No more memory for resp triggers");
			haveMemory = false;
		}
		else
		{
			pTrg = &pBuffer->m_extresptriggers[count];
		}
	}

	if (haveMemory)
	{
		pTrg->dlType 		= trgType;
		pTrg->eventIndex 	= m_nCurrCoinCountTotal > 0 ? m_nCurrCoinCountTotal - 1 : 0;
		pTrg->timeStamp		= m_tm;

		++pBuffer->m_counts[trgType];
	}
}


        3.6.2
    3.7




4.  Machines

    4.1  Dev
local:
Below are the address for the Haifa build and dev machines:

Host nmpetbld32
HostName 3.213.176.185

Host nmpetdev64
HostName 3.213.176.186

remote:
| 3.87.209.42

1) ctds64-1        3.87.209.39
2) ctds64-2        3.87.209.40
3) ctds32-1        3.87.209.35
4) ctds32-2        3.87.209.36        

    4.2 Set X-11 display to laptop
    a. check IP
ipconfig

    b. set on host
 export DISPLAY=3.213.176.141:0.0

    4.3 Reserve, Register time to work on test machine
http://grendel.ct.med.ge.com/signup/signup.cgi


    4.4 test Machines

        4.4.1  List of test machines


http://rdarc1.ct.med.ge.com/~ctbuild/petbayinfo/
PET Bay/Console information as of Sun Nov 12 06:11:01 CST 2017 

System Name Pole Bay/Console Network Node IP Address Software Version Console PARC # Rings PET Type ClassC ClassM 
bay82ct MKE Bay petddg 3.87.141.226 pet_col_bb.24 REAL_IN_ONE parc4 5 4 4 x 9 9 pet_col_bb.24 pet_col_bb.24 
bay88ct MKE Bay bay85ct 3.87.143.175 pet_coreload.44 REAL_IN_ONE parc3 4 9 x 6 pet_coreload.44 - 
bay96ct MKE Bay bay96ct 3.87.140.113 pet_coreload.87 REAL_IN_ONE parc3 4 9 x 6 pet_coreload.87 pet_coreload.87 
bay90ct MKE Bay bay89ct 3.87.140.219 pet_mict_plus.44 GOC6.5 bcpar 4 9 x 6 pet_mict_plus.44 pet_mict_plus.44 
bay93ct MKE Bay bay93ct 3.87.140.208 pet_odyssey.67 NIO16 parc4 5 8 x 8 pet_odyssey.67 pet_odyssey.67 
bay85ct MKE Bay unknown 3.87.143.172 unknown unknown unknown unknown unknown unknown unknown 
bay89ct MKE Bay unknown 3.87.142.227 unknown unknown unknown unknown unknown unknown unknown 
bay91ct MKE Bay unknown 3.87.140.221 unknown unknown unknown unknown unknown unknown unknown 
bay92ct MKE Bay unknown 3.87.140.224 unknown unknown unknown unknown unknown unknown unknown 
bay94ct MKE Bay unknown 3.87.140.206 unknown unknown unknown unknown unknown unknown unknown 
bay94pet MKE Bay unknown 3.87.140.234 unknown unknown unknown unknown unknown unknown unknown 
bay96pet MKE Bay unknown 3.87.140.114 unknown unknown unknown unknown unknown unknown unknown 
pad3 MKE Bay unknown 3.87.140.103 unknown unknown unknown unknown unknown unknown unknown 
jaws MKE Console jaws 3.87.141.219 pac_col_ddg.3 NIO64 parc4 5 4 4 x 9 9 - - 
petddg MKE Console fender 3.231.15.215 pet_columbia.122 NIO64 parc3 5 4 4 x 9 9 pet_columbia.122 pet_columbia.122 
jaws2 MKE Console jaws2 3.87.140.237 pet_comet.81 NIO16 parc3 5 8 x 8 pet_comet.81 pet_comet.81 
scooter MKE Console scooter 3.87.141.225 pet_coreload.87 REAL_IN_ONE parc4 4 9 x 6 pet_coreload.87 pet_coreload.87 
fender MKE Console unknown 3.87.141.228 unknown unknown unknown unknown unknown unknown unknown 
bay94ds MKE Console unknown 3.87.140.214 unknown unknown unknown unknown unknown unknown unknown 
jaws4 MKE Console+PARC jaws4 3.87.141.251 pac_col_ddg.4 REAL_IN_ONE parc3 5 4 4 x 9 9 pac_col_ddg.4 pac_col_ddg.4 
engcti MKE Console+PARC engcti 3.231.15.209 pet_col_bb.34 NIO64 parc3 4 4 4 x 9 9 - - 
bay91pet MKE Console+PARC bay91ct 3.87.140.225 pet_col_bb.35 NIO64 parc4 4 4 4 x 9 9 pet_col_bb.35 pet_col_bb.35 
bay92pet MKE Console+PARC bay92pet 3.87.140.227 pet_columbia.103 NIO64 parc3 5 4 4 x 9 9 - - 
bay93pet MKE Console+PARC dim2 3.87.140.207 pet_comet.81 NIO16 parc3 5 8 x 8 - - 
bay88ds MKE Console+PARC unknown 3.87.140.240 unknown unknown unknown unknown unknown unknown unknown 
bay90pet MKE Console+PARC unknown 3.87.140.222 unknown unknown unknown unknown unknown unknown unknown 
bay96ds MKE Console+PARC unknown 3.87.140.115 unknown unknown unknown unknown unknown unknown unknown 
lion HFA Bay unknown 3.213.40.142 unknown unknown unknown unknown unknown unknown unknown 
elephant HFA Console+PARC elephant 3.213.40.141 pet_columbia.122 NIO64 parc4 4 4 4 x 9 9 pet_columbia.122 pet_columbia.122 
turtle HFA Console+PARC unknown 3.213.40.140 unknown unknown unknown unknown unknown unknown unknown 
falcon BLR Bay falcon 3.204.27.228 pet_odyssey.68 NIO16 parc4 5 8 x 8 pet_odyssey.68 pet_odyssey.68 
pigmy1 BLR Console+PARC Pigmy1 3.204.31.229 pet_odyssey.67 NIO16 parc3 3 8 x 8 pet_odyssey.67 pet_odyssey.67 
pigmy2 BLR Console+PARC Pigmy2 3.204.31.227 pet_odyssey.67 NIO16 parc3 3 8 x 8 pet_odyssey.67 pet_odyssey.67 
Mercedes BLR Console+PARC unknown 3.204.31.25 unknown unknown unknown unknown unknown unknown unknown 
ferrari BLR Console+PARC unknown 3.204.31.247 unknown unknown unknown unknown unknown unknown unknown 
Mclaren BLR Console+PARC unknown 3.204.31.194 unknown unknown unknown unknown unknown unknown unknown 
mars BLR Console+PARC unknown 3.204.31.13 unknown unknown unknown unknown unknown unknown unknown 


        4.4.2 Test machines Wiki guides

            4.4.2.1 Working with PET machines 
            https://devcloud.swcoe.ge.com/devspace/display/UMCOA/Working+with+PET+machines

                4.4.2.1.1 Connecting
VNC doesn't show display 0:0 so we use gemsvnc.  On ssh write 
gemsvnc -display :0.0
And connect regularly (to port 5900).
This will create a VNC session with the real active desktop and not some virtual desktop.
Logs
They sit at /usr/g/service/log/
Each app has a log that records stdout, stderr etc.
gesys_<console name>.log - is a top level log file. Usually you start debugging from reviewing this log file.

                4.4.2.1.2 Config files
They sit at /usr/PET/systemConfig/local/
Each config file has different meaning. See software code to see where they are read (mostly wrapped with a class) and what they do.
System related configuration files sit in /usr/g/config.

                4.4.2.1.3 UI actions
Alt+F3 opens the utilities menu, from there we can access a terminal.

                4.4.2.1.4 Shell commands
st - starts the applications.
clearMon - exits the applications.
reconfig - run as root. Allows changing system configuration (number of rings and such). Changes require different calibration and list files for different sets of values.
sprsnap - saves current logs of the system. $LOGSDIR is the log directory.

                4.4.2.1.5 Applications
scanDataMgr - Scan Data Manager, a utility for fetching list files from DVD disks, USB drives and network. Available through Service Desktop.

                4.4.2.1.6 App management:
pwho - which of our services work and not.
cupShutdown - a manager app. Use `cupShutdown stop <app name>`, `cupShutdown start <app name>` and `cupShutdown restart <app name>`. See also PET logfiles and CupMonitor.
ptimers -nr <log name> opens a timers log file in a readable display.
viewlog - opens gesys_<console name>.log in more readable format.
what - displays the config spec used for compilation of a lib.

                4.4.2.1.7 Env variables
$PETACQ_BIN - binaries dir.
$CONFIGDIR - config files dir.
$LOGDIR - logs dir.

                4.4.2.1.8
Testing new versions
Today, we are working in the /usr/g/PET/lib{,64} folders. In them you may find the linux2 directory which contains the current version libraries, and linux2.### which contains different versions from people working on it.
~ctuser/devscripts contains scripts to update the libs:
pet_refresh shuts down pet_acq, replaces the current libs with libs from ~/uplioads and restarts pet_acq. An alternative to this crap is simply copy using rsync, which is similar to scp, with incremental capabilities. Shy's favorite flags for it are -avLHP (all, verbose, follow links, human readable and another thing, see man rsync).
The cdbin script changes dir to the binaries directory.
            4.4.2.2 PAARTF  wiki
            https://devcloud.swcoe.ge.com/devspace/display/UMCOA/PAARTF

PET Acquisition Auto Regression Test Facility
 
                4.4.2.2.1 Installing PAARTF on a console
If PAARTF is not already installed -
Connect to a dev system (e.g. ctds64-1 / ctds64-2)
Set your view ( ct setview <viewname> )
Go to acqAutoTest folder ( cd /vobs/pet_acq_test/source/acqAutoTest )
Run -    ./ downloadPAARTF.sh <target> 
Where <target> is the IP address or name of the bay/console
( e.g. -   ./ downloadPAARTF.sh jaws4 )
 
                4.4.2.2.2 Connecting with VNC to a console
Connect with SSH to a bay/console (e.g. jaws4)
Run -    vncserver :<display#> -geometry 1280x1024
Where <display#> is a random number on which the vnc will run, select something special for you (e.g. 13)
From your computer, run a VNC viewer (from MobaXTerm click Session -> VNC)
Type the IP address of the console (e.g. if using jaws4 - 3.87.141.251), and the Port (e.g. if your display# is 13, then the port is 5913) and connect.
 
                4.4.2.2.3 Intalling PAARTF on console:
Connect with VNC to the console (or SSH to console and run xterm).
Run -   
cd /usr/g/ctuser/acqAutoTest/
./Install
rehash

                4.4.2.2.4 Running PAARTF on a console
Turning on debug - 
From the console, edit /usr/PET/systemConfig/local/pet_acq.debug.cfg.
It has different sections, and we can enable/disable debug, trace, perf and others, for each section.
If you want to return to the default settings, you can delete this file and a new file with the default settings will be created.
You can add - LOG_MSG_DEBUG("message"), to the code, and see those messages if you turn on the debug.
Results - 
All test results are saved under   /usr/g/ctuser/acqAutoTest/newResults
Before running tests - verify that the newResults folder is empty. 
If it is not empty - make a backup of it (e.g. rename it to newResults_<name of last person who used the console>)
After making sure that you won't run over anyone else's results, you should clean the test env by running:
acqKillEnv (kills any running PAARTF)
acqCleanup (empty the results)
Running the tests -
Run -    acqStartEnv
This will open 3 terminal windows (which prints some useful info), and the ScanRunner GUI.
From ScanRunner, choose a sequence (e.g. DataAcq_sequence).
You will see all the available tests. Check the tests you would like to run (all tests in DataAcq_sequence takes about 2:15 hours to complete)
Click start to run the test you selected. You will see the Status column updating while it runs. 
After the test is completed, PAARTF performs some diffs of the results with the gold results, and then it sill show on the Status if the test passed or failed.
If a test failed, you can go to   /usr/g/ctuser/acqAutoTest/newResults/Failed
In this folder you can see the test result, and you can see the diff from the gold result by running -     acqDiffGold <result_file>
Skipping expected differences -
If you know that there should be a difference from the gold result in a specific data set, and you want the test to pass if everything else matches the gold, you can set it.
Edit -    /usr/g/ctuser/acqAutoTest/protocols/rdfTellFilter.sed
Add lines with names of data sets that you want to skip in when comparing with gold.

                4.4.2.2.5 Extending PAARTF (PAARTF behind the scenes)
Test protocols
/usr/g/ctuser/acqAutoTest/protocols contain what we call test protocols.
The file acq.cfg.append contains a protocol tag in each line.
A protocol tag is a string with the format: LT#_$* param: value, where # is the LT number, $ is a case identifier, param is the parameter for changing and value is its new value.
Tags with similar LT#_$ belong to the same test preset.
Tests to run
ScanRunnerDatabase.xml has the list of tests to execute. Each test has its own perscription, which inherits from a preset from the test protocols.
Whenever a test case doesn't specify a certain value, it will go up the hierarchy to the protocol tag until finding a value to set that parameter with.
The ProtocolTag tag defines which series of tags define parameters for this test, to override defaults.
Example: LT22_LR_QSTATIC_BASE_REC_1 has a 4 - 60sec beds scan. Find it in the file to see which parameters it sets and how.
Putting it all together
On PAARTF setup, the acq.cfg.append is appended (ha ha) to the acq.cfg file, which is a pet_acq configuration file.
acq.cfg has certain configurations to the system.
Testing accessories
/usr/g/ctuser/acqAutoTest/bin/acqSetup is a script to setup the system. It allows changing system configurations such as geometry (e.g. 5R to 4R)
/usr/g/ctuser/acqAutoTest/bin/GenerateReducedListFile reduces a list file to contain events from a more rings geometry to less rings geometry.
/vobs/pet_acq_test/source/acqGenListData/generateListData creates list data for tests.
/vobs/pet_raw/source/rdfUtil/rdfImportRawList adds headers, singles and deadtime data to list files.
/vobs/pet_raw/source/rdfUtil/addMotion adds motion to a list file, to simulate patient movement (for testing gated scans).

                4.4.2.2.6
        4.4.3
    4.5 My local dev machine yosiidev 
    
        4.5.1  passwords
ctuser / ctuser

de680136 / SSO pwd

root / install

        4.5.2 login
- sshdm

- setup my env
[212680136@G9VK2GH2E:Thu Dec 07:~:]$ scp ~/.aliases  ${USER_UNX}@${DEVMain}:/home/de680136 
.aliases                                                       100%   34KB   4.2MB/s   00:00    
[212680136@G9VK2GH2E:Thu Dec 07:~:]$ scp ~/.bashrc  ${USER_UNX}@${DEVMain}:/home/de680136 
.bashrc                                                        100% 4065   558.9KB/s   00:00    
[212680136@G9VK2GH2E:Thu Dec 07:~:]$ scp ~/.vimrc  ${USER_UNX}@${DEVMain}:/home/de680136 
.vimrc                                                         100%   22KB   3.8MB/s   00:00  
scp  /cygdrive/c/TEMP/backups/yosi_backup_07_12_17.tar.bz2 ${USER_UNX}@${DEVMain}:/home/de680136
yosi_backup_07_12_17.tar.bz2  

        4.5.3 configure DHCP
incase /sbin/ifconfig shows only ipv6 Address
GUI: system-settings->network-settings->automatically detected proxy configuration
system-config-network 

    4.6 Host machines

        4.6.1 :/home/de680136//work/scripts/


bay89ct MKE Bay bay89ct 3.87.140.219 pet_mict_plus.44 GOC6.5 bcpar 4 9 x 6 pet_mict_plus.44 
pet_mict_plus.44 bay82ct MKE Bay unknown 3.87.143.172 unknown unknown unknown unknown unknown 
Bay unknown 3.87.143.175 unknown unknown unknown unknown unknown unknown unknown 
bay88ct MKE Bay unknown 3.87.140.240 unknown unknown unknown unknown unknown unknown unknown 
bay90ct MKE Bay unknown 3.87.140.222 unknown unknown unknown unknown unknown unknown unknown 
bay91ct MKE Bay unknown 3.87.140.225 unknown unknown unknown unknown unknown unknown unknown 
bay92ct MKE Bay unknown 3.87.140.228 unknown unknown unknown unknown unknown 
bay93ct MKE Bay unknown 3.87.140.208 unknown unknown unknown unknown unknown 
bay94ct MKE Bay unknown 3.87.140.206 unknown unknown unknown unknown unknown unknown unknown 
bay94pet MKE Bay unknown 3.87.140.234 unknown unknown unknown unknown unknown unknown unknown 
bay96ct MKE Bay unknown 3.87.140.113 unknown unknown unknown unknown unknown unknown unknown 
bay96pet MKE Bay unknown 3.87.140.114 unknown unknown unknown unknown unknown unknown unknown 
pad3 MKE Bay unknown 3.87.140.103 unknown unknown unknown unknown unknown unknown unknown 
jaws MKE Console jaws 3.87.141.219 pac_col_ddg.4 NIO64 parc4 5 4 4 x 9 9 pac_col_ddg.4 pac_col_ddg.4 
petddg MKE Console petddg 3.87.141.226 pet_col_bb.24 REAL_IN_ONE parc4 5 4 4 x 9 9 pet_col_bb.24 pet_col_bb.24 
fender MKE Console fender 3.231.15.215 pet_columbia.126 NIO64 parc3 4 4 4 x 9 9 pet_columbia.126 pet_columbia.126 
jaws2 MKE Console jaws2 3.87.140.237 pet_comet.81 NIO16 parc3 5 8 x 8 pet_comet.81 pet_comet.81 
scooter MKE Console scooter 3.87.141.225 pet_coreload.87 REAL_IN_ONE parc4 4 9 x 6 pet_coreload.87 pet_coreload.87 
turtle MKE Console unknown 3.87.141.228 unknown unknown unknown unknown unknown unknown unknown 
bay94ds MKE Console unknown 3.87.140.214 unknown unknown unknown unknown unknown unknown unknown 
jaws4 MKE Console+PARC jaws4 3.87.141.251 pac_col_ddg.4 REAL_IN_ONE parc3 5 4 4 x 9 9 pac_col_ddg.4 pac_col_ddg.4 
engcti MKE Console+PARC engcti 3.231.15.209 pet_blackhawk.1 NIO64 parc3 4 9 9 x 6 6 pet_blackhawk.1 pet_blackhawk.1 
bay92pet MKE Console+PARC bay92pet 3.87.140.227 pet_columbia.103 NIO64 parc3 5 4 4 x 9 9 - - 
bay93pet MKE Console+PARC dim2 3.87.140.207 pet_comet.81 NIO16 parc3 5 8 x 8 - - 
bay88ds MKE Console+PARC unknown 3.87.142.227 unknown unknown unknown unknown unknown unknown unknown 
bay90pet MKE Console+PARC unknown 3.87.140.221 unknown unknown unknown unknown unknown unknown unknown 
bay91pet MKE Console+PARC unknown 3.87.140.224 unknown unknown unknown unknown unknown unknown unknown 
bay96ds MKE Console+PARC unknown 3.87.140.115 unknown unknown unknown unknown unknown unknown unknown 
lion HFA Bay lion 3.213.40.142 pet_columbia.122 NIO64 parc4 5 4 4 x 9 9 pet_columbia.122 pet_columbia.122 
turtle HFA Console+PARC turtle 3.213.40.140 pac_col_ddg.4 NIO64 parc4 4 4 4 x 9 9 pac_col_ddg.4 pac_col_ddg.4 
elephant HFA Console+PARC elephant 3.213.40.141 pet_columbia.126 NIO64 parc4 4 4 4 x 9 9 pet_columbia.126 pet_columbia.126 
falcon BLR Bay FALCON 3.204.27.228 pet_odyssey.69 NIO16 parc4 5 8 x 8 pet_odyssey.69 pet_odyssey.69 
ferrari BLR Console+PARC ib1 3.204.31.247 pet_comet.81 NIO16 parc3 5 8 x 8 - - 
Mclaren BLR Console+PARC mclaren 3.204.31.194 pet_comet.81 NIO16 parc3 5 8 x 8 pet_comet.81 pet_comet.81 
pigmy2 BLR Console+PARC Pigmy2 3.204.31.227 pet_odyssey.68 NIO16 parc3 5 8 x 8 pet_odyssey.68 pet_odyssey.68 
pigmy1 BLR Console+PARC unknown 3.204.31.229 unknown unknown unknown unknown unknown unknown unknown 
Mercedes BLR Console+PARC unknown 3.204.31.25 unknown unknown unknown unknown unknown unknown unknown 
mars BLR Console+PARC unknown 3.204.31.13 unknown unknown unknown unknown unknown unknown unknown 
        CometIB 3.204.188.4
         


    4.7
5. Test enviroment

    5.1 PAARTF petack test 

        5.1.1 Workflow for tests
a. register time slot on machine
http://grendel.ct.med.ge.com/signup/signup.cgi
use drop down to choose machine. e.g. jaws4

b. login to machine. open vnc server
sshj4 
{ctuser@jaws4}vncserver :41

or w/ geometry
{ctuser@jaws4}vncserver :76 -geometry 1920x1080

New 'X' desktop is jaws4:76

Starting applications specified in /usr/g/ctuser/.vnc/xstartup
Log file is /usr/g/ctuser/.vnc/jaws4:76.log


c. connect w/ VNC
MobaXterm -> session -> 
ip 3.87.141.251 
port 4976

Note that when new xterms are opened you need to click where you want to position them.

d. preliminary steps 
cd acqAutoTest
    -> set path
ctuser@jaws:~/acqAutoTest> export PATH="$PATH:/usr/g/ctuser/acqAutoTest/bin/"
ctuser@jaws:~/acqAutoTest> echo $PATH
/usr/local/cli:/usr/local/cli:/usr/g/ctuser/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/opt/kde3/bin:/usr/lib64/jvm/jre/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:~/yosi/:/usr/g/ctuser/yosi:/usr/PET/release/dragon/bin/linux2/::/usr/g/ctuser/acqAutoTest/bin/
    ->
acqKillEnv
acqCleanup

e. acqStartEnv
Note, will open 3 xterms (so click to position)
plus GUI window (scanRunner)
select DataAcq_Sequence from drop down
Select tests to run
start

f. logs
newResults/pet_acq.out

g. Failed tests gold results
[ctuser@jaws:2018-03-26 04:25:12:~/acqAutoTest/newResults/Failed:]108$ ls
LT15_01_0.2018.03.26-00.55.40  LT15_01_0.2018.03.26-00.55.40.tmp  LT15_01_1.2018.03.26-00.56.06  LT15_02_0.2018.03.26-00.56.37  LT15_02_1.2018.03.26-00.57.10

h. compare gold files. -f for applying Default sed filter. -g for graphical
[ctuser@jaws:2018-03-26 04:28:19:~/acqAutoTest/newResults/Failed:]923$ acqDiffGold -f -g LT*

i. view list file
[ctuser@jaws:2018-03-26 00:52:08:~/acqAutoTest/bin:]916$ hdfview /petLists/acqAutoTest/listData/CirclesPerSlice.BLF 

j. [ctuser@jaws:2018-03-26 04:33:11:~/acqAutoTest/newResults/Failed:]114$ acqHelp 

acqAutoTest Commands
--------------------
acqCleanup    - cleanup files after automated regression
acqDiffGold   - diff a newResults file with a corresponding gold file
acqHelp       - help on acqAutoTest related commands
acqMakeGold   - make new gold files
acqSetup      - configure scanner type
acqStartEnv   - run ScanRunner and "xterm -e acqUnlist - &"
acqKillEnv    - kill ScanRunner and pet_acq on par.
acqQueLists4Compress - queue list files for pet_acq batch list compress
acqMoreSetup   - set up additional config such as NPOFiducialMarker.cfg. Currently only needed to run PSRM sequence
acqRestore     - restore additional config done by acqMoreSetup. Currently only needed to run PSRM sequence

Typical PAARTF run cycle
------------------------
- run "acqMoreSetup" ( not needed if run first time after install)
- run "acqStartEnv"
- select tests to run in ScanRunner
- save PAARTF results (cd ~/acqAutoTest; mv newResults{,.<n>}"
                - run "acqCleanup"
                - run "acqKillEnv"
                - run "acqRestore" 

k. PAARTF patch install instructions by Mike
    k1. 
Procedure to download, install PAARTF for current  pac_col_ddg sw build:
-----------------------------------------------------------------------

1) on build server, ct setview to most recent pac_col_dd build view, then :
   cd /vobs/pet_acq_test/source/acqSutoTest
   ./installPAARTF.sh <target system IP>
   
2) after download completes, ssh into target system as ctuser, and then :
   cd acqAutoTest
   ./install
   rehash

3) make copy of PAARTF RDFv9 lists files used for PAARTF by doing:
   petsh par
   cd /petLists
   cp acqAutoTest{,.clearcase}

Ex:
[ctuser@jaws:2018-03-27 07:35:01:/petLists:]10$ petsh par
Last login: Mon Mar 26 14:58:30 2018 from oc
ctuser@par:~> cd /petLists/
ctuser@par:/petLists> cp -r acqAutoTest acqAutoTest.clearcase


4) make a cook directory on target system under ctuser account home dir
   ssh <unix user>@3.57.51.65             note: kevin's pacsw2 pc
   cd /export/data1/cook/paartf_stuff/
   scp paartf_patches_for_pac_col_ddg_7.tar ctuser@<ip of target system>:cook
   on target host, cd ~/cook
   tar xf paartf_patches_for_pac_col_ddg_7.tar  

Ex:
[212680136@G9VK2GH2E:2018-03-27 15:39:22:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv/mike:]129$  scp ${USER_UNX}@${PACSW2}:/export/data1/cook/paartf_stuff/paartf_patches_for_pac_col_ddg_7.tar .
paartf_patches_for_pac_col_ddg_7.tar                                                                                                                       100%   29MB 533.3KB/s   00:55    
[212680136@G9VK2GH2E:2018-03-27 15:42:15:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv/mike:]132$ scp paartf_patches_for_pac_col_ddg_7.tar  ${USER_CT}@${JAWS}:$USER_CT_HOME 
[ctuser@jaws:2018-03-27 07:43:21:~/cook:]5$ mv ../paartf_patches_for_pac_col_ddg_7.tar  .
[ctuser@jaws:2018-03-27 07:43:34:~/cook:]6$ tar xf paartf_patches_for_pac_col_ddg_7.tar 
[ctuser@jaws:2018-03-27 07:43:40:~/cook:]7$ ls
paartf_patches_for_pac_col_ddg_7/  paartf_patches_for_pac_col_ddg_7.tar



5) on target host, setup an rdfAccept.cfg for 'development' :
   unlink /usr/PET/systemConfig/local/rdfAccept.cfg
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfAccept.cfg.dev /usr/PET/systemConfig/local
   ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg

   Ex:
   unlink /usr/PET/systemConfig/local/rdfAccept.cfg && cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfAccept.cfg.dev /usr/PET/systemConfig/local && ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg

6) on host, perform:
   cd ~/acaAutotest
   rm acceptListData.log
   acceptListData

   Ex:
   cd ~/acqAutotest && rm acceptListData.log && acceptListData

7) on host, run 'acqSetup' to get some derivative lists files/links required by some PAARTF tests
   ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg

   Ex:
[ctuser@jaws:2018-03-27 07:50:14:~/acqAutoTest:]10$ acqSetup  && ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg
Current /usr/PET/systemConfig/local/acq.cfg soft link scannerType found is "LYSO4x9_5_SIPMGEN1"
/usr/PET/systemConfig/local/acq.cfg soft link scannerType found is "LYSO4x9_5_SIPMGEN1"

ScanRunnerSeup LYSO4x9_5_SIPMGEN1 completed. 

Installing DPT Data ....
************** Generating reduced list files ************
*************** Completed reducing the list files *************
Running hdfModify...
Done.

acqSetup LYSO4x9_5_SIPMGEN1 completed.



   

8) cd ~/acqAutoTest/goldresults
   mv LYSO4x9_5_SIPMGEN1 LYSO4x9_5_SIPMGEN1.clearcase
   tar xf ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/LYSO4x9_5_SIPMGEN1.RDFv9.7.6.tar
   ln -sf LYSO4x9_5_SIPMGEN1.RDFv9.7.5 LYSO4x9_5_SIPMGEN1

   Ex:
cd ~/acqAutoTest/goldResults && mv LYSO4x9_5_SIPMGEN1 LYSO4x9_5_SIPMGEN1.clearcase && tar xf ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/LYSO4x9_5_SIPMGEN1.RDFv9.7.6.tar && ln -sf LYSO4x9_5_SIPMGEN1.RDFv9.7.5 LYSO4x9_5_SIPMGEN1
[ctuser@jaws:2018-03-27 08:09:39:~/acqAutoTest/goldResults:]13$ ls -l !$
ls -l LYSO4x9_5_SIPMGEN1
lrwxrwxrwx 1 ctuser users 28 Mar 27 08:09 LYSO4x9_5_SIPMGEN1 -> LYSO4x9_5_SIPMGEN1.RDFv9.7.5/

9) cd ~/acqAutoTest/protocols
   mv rdfTellFilter.sed{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/dfTellFilter.sed .

Ex:
cd ~/acqAutoTest/protocols && mv rdfTellFilter.sed rdfTellFilter.orig && cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfTellFilter.sed .

10) cd ~/acqAutoTest/bin
   mv acqUnlistPar{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/acqUnlistPar .

   Ex:
cd ~/acqAutoTest/bin && mv acqUnlistPar{,.orig} && cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/acqUnlistPar .

11) cd ~/acqAutoTest/bin/ScanRunner
   mv rdfSnoop{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfSnoop .

Ex:
cd ~/acqAutoTest/bin/ScanRunnerScripts && mv rdfSnoop{,.orig} && cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfSnoop .

launch vnc
[ctuser@jaws:2018-03-27 08:18:34:~/acqAutoTest/bin/ScanRunnerScripts:]32$ vncPetHost 

You will require a password to access your desktops.

Password:  123456
Verify:   123456
Would you like to enter a view-only password (y/n)? n

New 'X' desktop is jaws:1

Creating default startup script /usr/g/ctuser/.vnc/xstartup
Starting applications specified in /usr/g/ctuser/.vnc/xstartup
Log file is /usr/g/ctuser/.vnc/jaws:1.log

12) Now you should be ready to run PAARTF DACQ sequence
   cd ~/acqAutoTest
   acqCleanup
   acqStartEnv
   use ScanRunner UI to select Data Acq sequence, then hit Start
   
   for first time also save new results





    k2.



[ctuser@jaws:2018-03-26 04:34:55:~/cook/paartf_patches_for_pac_col_ddg_7:]120$ cat README 


l.

        5.1.2  PAARTF documents
https://devcloud.swcoe.ge.com/devspace/display/UMCOA/PAARTF

            5.1.2.1  PET Acquisition Auto Regression Test Facility
 
                5.1.2.1.1  Installing PAARTF on a console
If PAARTF is not already installed -
Connect to a dev system (e.g. ctds64-1 / ctds64-2)
Set your view ( ct setview <viewname> )
Go to acqAutoTest folder ( cd /vobs/pet_acq_test/source/acqAutoTest )
Run -    ./ downloadPAARTF.sh <target> 
Where <target> is the IP address or name of the bay/console
( e.g. -   ./ downloadPAARTF.sh jaws4 )
 
                5.1.2.1.2 Connecting with VNC to a console
Connect with SSH to a bay/console (e.g. jaws4)
Run -    vncserver :<display#> -geometry 1280x1024
Where <display#> is a random number on which the vnc will run, select something special for you (e.g. 13)
From your computer, run a VNC viewer (from MobaXTerm click Session -> VNC)
Type the IP address of the console (e.g. if using jaws4 - 3.87.141.251), and the Port (e.g. if your display# is 13, then the port is 5913) and connect.
 
                5.1.2.1.3 Intalling PAARTF on console
Connect with VNC to the console (or SSH to console and run xterm).
Run -   
cd /usr/g/ctuser/acqAutoTest/
./Install
rehash

                5.1.2.1.4 Running PAARTF on a console
Turning on debug - 
From the console, edit /usr/PET/systemConfig/local/pet_acq.debug.cfg.
It has different sections, and we can enable/disable debug, trace, perf and others, for each section.
If you want to return to the default settings, you can delete this file and a new file with the default settings will be created.
You can add - LOG_MSG_DEBUG("message"), to the code, and see those messages if you turn on the debug.
Results - 
All test results are saved under   /usr/g/ctuser/acqAutoTest/newResults
Before running tests - verify that the newResults folder is empty. 
If it is not empty - make a backup of it (e.g. rename it to newResults_<name of last person who used the console>)
After making sure that you won't run over anyone else's results, you should clean the test env by running:
acqKillEnv (kills any running PAARTF)
acqCleanup (empty the results)
Running the tests -
Run -    acqStartEnv
This will open 3 terminal windows (which prints some useful info), and the ScanRunner GUI.
From ScanRunner, choose a sequence (e.g. DataAcq_sequence).
You will see all the available tests. Check the tests you would like to run (all tests in DataAcq_sequence takes about 2:15 hours to complete)
Click start to run the test you selected. You will see the Status column updating while it runs. 
After the test is completed, PAARTF performs some diffs of the results with the gold results, and then it sill show on the Status if the test passed or failed.
If a test failed, you can go to   /usr/g/ctuser/acqAutoTest/newResults/Failed
In this folder you can see the test result, and you can see the diff from the gold result by running -     acqDiffGold <result_file>
Skipping expected differences -
If you know that there should be a difference from the gold result in a specific data set, and you want the test to pass if everything else matches the gold, you can set it.
Edit -    /usr/g/ctuser/acqAutoTest/protocols/rdfTellFilter.sed
Add lines with names of data sets that you want to skip in when comparing with gold.

            5.1.2.2 Test and gold qualification
https://devcloud.swcoe.ge.com/devspace/display/UMCOA/Session+with+Mike+-+test+and+gold+qualification
to start of metadata


relevant docs
DOC1589505 - Test Data Specification
DOC1591934 - gold result qualification
DOC1496522 - synthetic list data generation

test files
acqAutoTest/protocols/ScanRunnerDatabases/paartf.xml
acqAutoTest/protocols/ScanRunnerSequences/DataAcq_sequence.LYSO4x9_5_SIPMGEN1.xml
documents - SSRS (doors at /MICT DB/SSRS/PET) OET Acquisition Controller
CSV - Computer System for Validation
doesn't ship with the product
assists in SW validation and verification
Paartf generates a synthetic Event pattern and adds singles and deadtime into it based on DOC1589505, (see document DOC1591934  for spread sheets and parameters)
rdfTell -d on rawListSample gives the repeating pattern of the samples, helps calculate deadtime & singles.
"linking" raw data file to PAARTF test
 original synthetic data files could be found in DOC1591934 .
ListDecode - utility to see lists
the already generated List files are found at - /vobs/pet_acq_test/acqGenListData/
DOC? - 
 
open questions
Is our target is to qualify all the tests?
Where did the LT16_03_5 gold results for RDFv9.5 came from? What are they?
generateListData examples/Doc.

            5.1.2.3 myworkshop docs. search paartf
https://myworkshop.health.ge.com/enovia/common/emxNavigator.jsp?timeZoneOffset=-2

                5.1.2.3.1 PAARTF SDD

                    5.1.2.3.1.1 High level
         ScanRunner
The ScanRunner Interface runs the diagnostic acquisitions scans. It queues up scans to be run automatically in sequence and displays pass or fail information for each scan. ScanRunner communicates either with the PetAcqMgr service or DetCalServer service (only one service at a time) to prescribe and monitor scans, receives RTS updates from the acqRTS service, and runs a results snoop utility that is sequence dependent (e.g. rdfTell & rdfSnoop, calTell & calSnoop, or dbQuery & petQueryTool, or dcsSnoop) for determining a PASS/FAIL resolution for each scan. More information can be found in the ScanRunner SDD, refer to reference document section.

PetAcqMgr {Galileo SW Unit name: PET Scan Request Manager}
Pet Acq Manager  manages communication between clients like ScanRunner and pet_acq service by providing the scan prescription from its client ScanRunner. It translates scan prescriptions from its client (ScanRunner) to pet_acq service and relays scan status events from pet_acq service to its clients (ScanRunner).
      
pet_acq {Galileo SW Unit name: PET Data Acq}
Manages the actual acquisition in unlist mode. In the unlist mode, the DFE, TGP, and PSC subordinate systems are not used. Instead, pet_acq uses a simulation of events using a valid RDF based List File being replayed.  More information on pet_acq in its entirety can be found in Design of PARC Acquisition SW modules, refer to reference document section.

DetCalServer {Galileo SW Unit name: PET Detector Calibration}
DetCalServer sends request to Scan Request Manager (which internally sends calibration scan prescription from ScanRunner to pet_acq) by providing the scan prescription and calibration prescription from ScanRunner. More information on DetCalServer can be found in PET Detector Cal Server SDD, refer to reference document section.

rtsClient
Captures the Real Time Statistics socket output of the Acquisition Service. The statistics are provided to the System and later rdfSnoop compares them with the gold Results.

RTS Processing Scripts
These are scripts used to inform rtsClient when to start, end, and write its acquired RTS data for the current scan.
       
rdfTell, rdfSnoop & objEvRdfSnoop     
The rdfTell and rdfSnoop utilities determine the PASS/FAIL resolution for each scan in the Data Acq sequence.  The rdfTell tool reads the sinogram files and a list raw data file produced by each scan and creates reports of the data in each raw data file. The rdfSnoop tool also uses ListDecode tool to fetch the count rate from newly created list file. The rdfSnoop tool then combines these various outputs to create a final report with the RTS data produced by rtsClient and compares them to gold Results to determine if the scans passed. The objEvRdfSnoop calls rdfSnoop and runs the createObjEvMain.py python script to create objective evidence files which can be used to show pertinent information relating to the test case grouping. 

calTell, calSnoop, objEvCalSnoop
The calTell and calSnoop utilities determine the PASS/FAIL resolution for each scan in the Detector Cal sequence.   The calTell tool dumps out information about the calibration files produced and creates reports of the data in each calibration.   The calSnoop tool compares these resports to gold Results to determine if the scans passed.  The objEvCalSnoop script currently does not compile objective evidence, but has the potential to do so in the same way as objEvRdfSnoop.

objEvCalLogSnoop, dcsSnoop, cleanDCSLog, saveDCSLog
The objEvCalLogSnoop script determines PASS/FAIL resolution for each scan in the Det Cal Server sequence. The cleanDCSLog script deletes the CAL.LOG file before each test. The dcsSnoop scripts fetches the MostRecent RDF file and dumps out the scan description  

dbQuery, petQueryTool
The dbQuery and petQueryTool utilities determine PASS/FAIL resolution for each scan in the ScanReqMgr sequence.   The petQueryTool tool dumps out DICOM information about the Raw Data DB entries produced and creates reports of the data in each image.   dbQuery then compares these reports to gold results to determine if the scans passed.

PAARTF can be found in /vobs/pet_acq_test/source/acqAutoTest
Note: Pre-Galileo PAARTF can be found under /vobs/gre/pet/platform/acqAutotest.

                    5.1.2.3.1.2 ClearCase tree
/vobs/pet_acq_test/source/acqAutoTest/
|-- common
|   |-- bin
|   |   |-- AutoObjEvScripts
|   |   \-- ScanRunnerScripts
|   |-- newResults
|   |   |-- Failed
|   |   \-- objEvResults
|   |-- rawDataAccess
|   |   |-- bin32
|   |   \-- bin64
|   |-- ScanRunnerDatabases
|   \-- utilities
\-- productFamily
    |-- columbia
    |   |-- calData
    |   |-- configFiles
    |   |-- dbFiles
    |   |-- goldResults
    |   |   |-- LYSO4x9_3_SIPMGEN1
    |   |   |-- LYSO4x9_4_SIPMGEN1
    |   |   |   \-- goldObjEv
    |   |   \-- LYSO4x9_5_SIPMGEN1
    |   |       \-- goldObjEv
    |   |-- listData
    |   |-- seqFiles
    |   \-- sinoData
    |-- galileo
    |   |-- calData
    |   |-- goldResults
    |   |   |-- BGO8x8_2_TUBEQAT
    |   |   |   \-- goldObjEv
    |   |   |-- BGO8x8_3_TUBEQAT
    |   |   |   \-- goldObjEv
    |   |   |-- BGO8x8_4_TUBEQAT
    |   |   |   \-- goldObjEv
    |   |   \-- BGO8x8_5_TUBEQAT
    |   |       \-- goldObjEv
    |   |-- listData
    |   \-- seqFiles
    \-- kittyHawk
        |-- calData
        |-- configFiles
        |-- dbFiles
        |-- goldResults
        |   \-- LYSO9x6_4_TUBEQAT
        |       \-- goldObjEv
        |-- listData
        |-- seqFiles
        \-- sinoData

PetQuery Tool

/vobs/pet_acq_test/source/petQueryTool/
|-- Makefile            This directory is built during a software build
|-- petQueryTool.cxx    The source
|-- petQueryTool        The binary
`-- pqt                 A wrapper script which sets LD_LIBRARY_PATH and calls 
                        petQueryTool
CmdLineServer
/vobs/pet_acq_test/source/CmdLineServer/
|-- Makefile            This directory is built during a software build
|-- CmdClientProxy.cpp  The client proxy source
|-- CmdClientProxy.h    The client proxy header
|-- CmdLineExternal.h   The definitions related to CmdLineServer needed by its Clients
|-- CmdLineServer.cpp   The Main service source
|-- CmdLineServer.h     The Main service header
`-- CmdLineServer.init  The cupMonitor specific file

RTSClient
/vobs/pet_acq_test/source/rtsClient/
|-- Makefile            This directory is built during a software build
|-- RtsClient.cpp       The source
`-- RtsClient.h         The header

                        5.1.2.3.1.2.1 Detailed tree


/vobs/pet_acq_test/source/acqAutoTest/
|-- common						Has files common across product families
|   |-- bin
|   |   |-- acqAnalysis			Invokes investigator through the diagAnalysis scripts
|   |   |-- acqAutoTestDelete
|   |   |-- acqCleanup			Cleans up PAARTF test result artifacts
|   |   |-- acqDiag				Legacy script to start the GUI for diagnostic acquisition
|   |   |-- acqDiffGold			Allows comparison between result & goldResult equivalents
|   |   |-- acqDiffObjEvGold		Script to view differences with objEv gold file
|   |   |-- acqDynamicScan
|   |   |-- acqGatedInfo			Attains information from GATED test scans including	but not
|	|	|	|				limited to the acceptedTriggers, rejectedTriggers, frame duration 
|	|	|	|				and number of bins.
|	|	|-- acqHelp			Gives instructions on how to run PAARTF GUI ScanRunner
|	|	|-- acqHistoInfo			Parses the designated list of LT* files for Histogram related info 
|	|	|	|				and abbreviates the info to facilitate auditing of Acq Auto Test results
|   |   |-- acqHistoCellSize
|   |   |-- acqKillEnv			Kills the ScanRunner GUI environment
|   |   |-- acqLongAcq
|   |   |-- acqLongTrigInterval
|   |   |-- acqMakeGold			Allows user to make gold files
|   |   |-- acqMakeObjEvGold		Allows user to make gold files for objective evidence files
|   |   |-- acqMaxGatedBin
|   |   |-- acqMaxTriggerWait
|   |   |-- acqMFOV
|   |   |-- acqMoreSetup
|   |   |-- acqNonNative
|   |   |-- acqQStaticStats
|	|	|-- acqQueLists4Compress	Continually adds an uncompressed list file to the 
|	|	|	|				pet_acq batch compress queue whenever the 
|	|	|	|				queue goes empty. This does not stop unless a kill
|	|	|	|				process command (Ctl-C) is invoked
|	|	|-- acqRdfTell			Invokes rdfTell with special parameters used in PAARTF
|   |   |-- acqRecFromRpl
|   |   |-- acqRestore
|   |   |-- acqSDTInfo			Parses the designated list of LT* files for Singles and Deadtime
|   |   |   |				related info and abbreviates the info to facilitate auditing of 
|   |   |   |				acqAutoTest results
|   |   |-- acqSetup				Creates soft links to various files and directories based on the 
|   |   |   |				scanner type specified
|   |   |-- acqSpectraInfo			Parses the designated list of LT* files for Position, Timing and 
|   |   |   |				Energy Spectra related info and abbreviates the info to 
|   |   |   |				facilitate
|   |   |-- acqStartEnv			Start the ScanRunner GUI environment
|   |   |-- acqStaticScan
|   |   |-- acqStats				Parses the designated list of LT* files for Dynamic related info 
|   |   |   |				and abbreviates the info to facilitate auditing of Acq Auto Test results
|   |   |-- acqStopOnCounts
|   |   |-- acqSumSinoCounts		Invokes on a list of files to run rdfSumSinoCnts
|   |   |-- acqTofInfo			Parses the designated list of LT* files for Time Of Flight (TOF) 
|   |   |   |				related info and abbreviates the info to facilitate auditing of Acq Auto Test results
|   |   |-- acqUnlist				Invokes acqUnlistPar on pet_acq
|   |   |-- acqUnlistPar			Invokes pet_acq in unlist mode on the par blade. Saving the result to pet_acq.out.
|   |   |-- acqUserEnv.sh
|   |   |-- acqViewLog			Can see a log of PAARTF
|   |   |-- AutoObjEvScripts		This directory contains scripts that create .objEv files
|   |   |   |-- acqMakeObjEvGold.py
|   |   |   |-- checkConfig.py
|   |   |   |-- constants.py
|   |   |   |-- createHelper.py
|   |   |   |-- createObjEvMain.py
|   |   |   |-- create_obj.py
|   |   |   |-- README.txt
|   |   |   \-- StringIter.py
|   |   |-- cleanlog.py			Cleans a specified log
|   |   |-- dbFilter
|   |   |-- DCalDefault
|   |   |-- DCalDmodSerialNo
|   |   |-- DCalDmodTemperature
|   |   |-- DCalEnergy
|   |   |-- DCalPMTGain
|   |   |-- DCalPositionMap
|   |   |-- DCalSIPMGain
|   |   |-- DCalTiming
|   |   |-- DCSBackupTimer
|   |   |-- DCSCtc
|   |   |-- DCSDqa
|   |   |-- DCSEnergyGain
|   |   |-- DCSPositionMap
|   |   |-- DPTInfo
|   |   |-- genCountRate
|   |   |-- genDCSWorkFlowAutoTest.py
|   |   |-- GenerateReducedListFile
|   |   |-- installDPTCal
|   |   |-- installListData			Installs list data by calling installListDataPar
|   |   |-- installListDataPar
|   |   |-- installSinoData			Installs sino data by calling installSinoDataPar
|   |   |-- installSinoDataPar
|   |   |-- RDAHeader
|   |   |-- RDAImportList
|   |   |-- RDAListDecode
|   |   |-- RDAListTool
|   |   |-- RDASegmentData
|   |   |-- RDASignData
|   |   |-- RDATools
|   |   |-- rdfSumSinoCounts
|   |   |-- ReduceFileList.cfg
|   |   |-- ScanRunnerScripts		This directory contains the PAARTF processing scripts 	startRTSClient, saveRTSData, endRTSData , rdfSnoop, 
|   |   |   |					dbQuery, and calSnoop which will be discussed in the 
|   |   |   |					detailed design section
|   |   |   |-- calSnoop			Runs command line calibration processing and then
|   |   |   |-- cleanDCSLog.pl		Deletes /usr/g/service/log/CAL.LOG file.
|   |   |   |-- cleanDPTLog			Delete previous DPT log file.
|   |   |   |-- cleanObjEvFiles
|   |   |   |-- dbQuery			Runs petQueryTool to generate results compared to gold
|   |   |   |-- dcsSnoop			Fetches scan description from MostRecent 
|   |   |	 |					SINO file and invokes saveDCSLog.pl
|   |   |   |-- endRTSClient_cleanup
|   |   |   |-- endRTSClient.pl		Cleanup script
|   |   |   |-- executeDPT			File used by CmdLineServer to run DPT
|   |   |   |-- executeRDATools		Invoke RDA tools
|   |   |   |-- genericSnoop		Generic snoop file to compare result with gold file.
|   |   |   |-- logMemUsage			Logs memory usage of PetAcqMgr and pet_acq
|   |   |   |-- objEvCalLogSnoop		Generate ObjEv for DCS tests.
|   |   |   |-- objEvCalSnoop		Generates ObjEv for calibration tests
|   |   |   |-- objEvDbQuery		Generates ObjEv for PSRM tests. 
|   |   |   |-- objEvDPTSnoop		Generates ObjEv for DPT tests
|   |   |   |-- objEvRDASnoop		Generates ObjEv for RDATools tests.
|   |   |   |-- objEvRdfSnoop		Generates Objective Evidence for DataAcq sequences
|   |   |   |-- rdfSnoop			Runs rdfTell to produce results for DataAcq Sequences
|   |   |   |-- README_DB.txt
|   |   |   |-- saveDCSLOG.pl		File to copy content from CAL.LOG to respective LT file.
|   |   |   |-- saveDPTLOG			File used to save DPT log file for result
|   |   |   |-- saveRTSData.pl		This and next script start and save rtsClient data
|   |   |   |-- startRTSClient.pl	This script starts the RTS client.
|   |   |   \-- touchDPTCalFiles		File used to update date/time of cal files used by DPT sequence.
|   |   |-- ScanRunnerSetup			This script sets up the system to required config. This is called by acqSetup
|   |   |-- seplines.py
|   |   \-- whatfail
|   |-- newResults
|   |   |-- Failed
|   |   \-- objEvResults
|   |-- rawDataAccess
|   |   |-- bin32
|   |   |   |-- rdfCreateListTest
|   |   |   |-- rdfCreateSinoTest
|   |   |   |-- rdfEdit
|   |   |   |-- rdfImportRawList
|   |   |   \-- rdfReduce
|   |   |-- bin64
|   |   |   |-- rdfCreateListTest
|   |   |   |-- rdfCreateSinoTest
|   |   |   |-- rdfEdit
|   |   |   |-- rdfImportRawList
|   |   |   \-- rdfReduce
|   |   |-- dsrTiming.py
|   |   \-- rdfvp.pl
|   |-- ScanRunnerDatabases			Directory containing scanRunner database files
|   |   |-- CommandLineToolsDatabase.xml
|   |   |-- DetCalFileServerCmdDatabase.xml
|   |   \-- paartf.xml
|   \-- utilities
|       |-- extended_rx.pl
|       |-- genProtocols.py
|       |-- paartf.pl
|       |-- rx_extensions.pl
|       |-- rx.pl
|       \-- vmset2print.py
|-- create-archive.sh				Creates an archive of all PAARTF files which will be installed on target system
|-- download					This script downloads PAARTF to target system
|-- downloadPAARTF.sh				This script automatically determines product family, creates archive and downloads PAARTF
|-- ftp-ctuser					Auxiliary scripts to assist with the download of PAARTF to the target system
|-- install					Installs PAARTF on the target system. Calls acqSetup to set up files in the appropriate locations
|-- productFamily				This directory contains calData, configFiles, sinoData, database files, goldResults, 
|	|						listData, seqFiles for each product families respectively
|   |-- clearcase_view
|   |-- columbia
|   |   |-- calData
|   |   |   |-- DPTCalData.tgz
|   |   |   |-- LYSO4x9_3_SIPMGEN1.tgz
|   |   |   |-- LYSO4x9_4_SIPMGEN1.tgz
|   |   |   \-- LYSO4x9_5_SIPMGEN1.tgz
|   |   |-- clearcase_view
|   |   |-- configFiles
|   |   |   |-- acq.cfg.append
|   |   |   |-- autoObjEv.config
|   |   |   |-- cal.cfg.append
|   |   |   |-- calCmdOptions.cfg
|   |   |   |-- calTellFilter.sed
|   |   |   |-- dbQueryFilter.sed
|   |   |   |-- DetCal_DQA_WorkflowProto.xml.append
|   |   |   |-- dptFilters.sed
|   |   |   |-- dptOptions.cfg
|   |   |   |-- NPOFiducialMarker_PAARTF.cfg
|   |   |   |-- rdaToolOptions.cfg
|   |   |   |-- rdaToolsFilters.sed
|   |   |   |-- rdfTellFilter.sed
|   |   |   |-- rdfTellFilter.sed.DXR
|   |   |   |-- rdfTellFilter.sed.example1
|   |   |   |-- rdfTellFilter.sed.example2
|   |   |   |-- rdfTellFilter.sed.example3
|   |   |   |-- rdfTellFilter.sed.example4
|   |   |   |-- replayTagFileDB
|   |   |   \-- tagFileDB
|   |   |-- dbFiles
|   |   |   \-- DetCalServerCmdDatabase.xml
|   |   |-- goldResults
|   |   |   |-- LYSO4x9_3_SIPMGEN1 
|   |   |   |-- LYSO4x9_4_SIPMGEN1 
|   |   |   \-- LYSO4x9_5_SIPMGEN1 
|   |   |-- listData
|   |   |   |-- CtcOCCListFile.tar.bz2
|   |   |   |-- LYSO4x9_3_SIPMGEN1.tar.bz2
|   |   |   |-- LYSO4x9_4_SIPMGEN1.tar.bz2
|   |   |   |-- LYSO4x9_5_SIPMGEN1.tar.bz2
|   |   |   \-- TurkeyPhantomCol5R.tar.bz2
|   |   |-- seqFiles
|   |   |   |-- ART-SWVP_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- DataAcq_sequence.LYSO4x9_3_SIPMGEN1.xml
|   |   |   |-- DataAcq_sequence.LYSO4x9_4_SIPMGEN1.xml
|   |   |   |-- DataAcq_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- DetCalFileServer_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- DetCalServer_sequence.LYSO4x9_4_SIPMGEN1.xml
|   |   |   |-- DetCalServer_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- DetectorCal_sequence.LYSO4x9_4_SIPMGEN1.xml
|   |   |   |-- DetectorCal_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- DPT_sequence.LYSO4x9_4_SIPMGEN1.xml
|   |   |   |-- DPT_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- RDA_sequence.LYSO4x9_4_SIPMGEN1.xml
|   |   |   |-- RDA_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- ScanReqMgr_sequence.LYSO4x9_3_SIPMGEN1.xml -> ScanReqMgr_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   |-- ScanReqMgr_sequence.LYSO4x9_4_SIPMGEN1.xml -> ScanReqMgr_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   |   \-- ScanReqMgr_sequence.LYSO4x9_5_SIPMGEN1.xml
|   |   \-- sinoData
|   |       |-- LYSO4x9_4_SIPMGEN1.tar.bz2
|   |       \-- LYSO4x9_5_SIPMGEN1.tar.bz2
|   |-- galileo
|   |   |-- calData
|   |   |   |-- BGO8x8_2_TUBEQAT.tgz
|   |   |   |-- BGO8x8_3_TUBEQAT.tgz
|   |   |   |-- BGO8x8_4_TUBEQAT.tgz
|   |   |   \-- BGO8x8_5_TUBEQAT.tgz
|   |   |-- goldResults
|   |   |   |-- BGO8x8_2_TUBEQAT 
|   |   |   |-- BGO8x8_3_TUBEQAT 
|   |   |   |-- BGO8x8_4_TUBEQAT 
|   |   |   \-- BGO8x8_5_TUBEQAT 
|   |   |-- listData
|   |   |   |-- BGO8x8_3_TUBEQAT.tar.bz2
|   |   |   \-- BGO8x8_5_TUBEQAT.tar.bz2
|   |   \-- seqFiles
|   |       |-- ART-SWVP_sequence.BGO8x8_5_TUBEQAT.xml
|   |       |-- DataAcq_sequence.BGO8x8_2_TUBEQAT.xml
|   |       |-- DataAcq_sequence.BGO8x8_3_TUBEQAT.xml
|   |       |-- DataAcq_sequence.BGO8x8_4_TUBEQAT.xml
|   |       |-- DataAcq_sequence.BGO8x8_5_TUBEQAT.xml
|   |       |-- DetectorCal_sequence.BGO8x8_2_TUBEQAT.xml
|   |       |-- DetectorCal_sequence.BGO8x8_3_TUBEQAT.xml
|   |       |-- DetectorCal_sequence.BGO8x8_4_TUBEQAT.xml
|   |       |-- DetectorCal_sequence.BGO8x8_5_TUBEQAT.xml
|   |       |-- ScanReqMgr_sequence.BGO8x8_2_TUBEQAT.xml -> ScanReqMgr_sequence.BGO8x8_5_TUBEQAT.xml
|   |       |-- ScanReqMgr_sequence.BGO8x8_3_TUBEQAT.xml -> ScanReqMgr_sequence.BGO8x8_5_TUBEQAT.xml
|   |       |-- ScanReqMgr_sequence.BGO8x8_4_TUBEQAT.xml -> ScanReqMgr_sequence.BGO8x8_5_TUBEQAT.xml
|   |       \-- ScanReqMgr_sequence.BGO8x8_5_TUBEQAT.xml
|   \-- kittyHawk
|       |-- calData
|       |   |-- DPTCalData.tgz
|       |   \-- LYSO9x6_4_TUBEQAT.tgz
|       |-- clearcase_view
|       |-- configFiles
|       |   |-- acq.cfg.append
|       |   |-- autoObjEv.config
|       |   |-- cal.cfg.append
|       |   |-- calCmdOptions.cfg
|       |   |-- calTellFilter.sed
|       |   |-- dbQueryFilter.sed
|       |   |-- DetCal_DQA_WorkflowProto.xml.append
|       |   |-- dptFilters.sed
|       |   |-- dptOptions.cfg
|       |   |-- rdaToolOptions.cfg
|       |   |-- rdaToolsFilters.sed
|       |   |-- rdfTellFilter.sed
|       |   |-- replayTagFileDB
|       |   \-- tagFileDB
|       |-- dbFiles
|       |   \-- DetCalServerCmdDatabase.xml
|       |-- goldResults
|       |   \-- LYSO9x6_4_TUBEQAT
|       |-- listData
|       |   |-- LYSO9x6_4_TUBEQAT.tar.bz2
|       |   \-- TurkeyPhantomBlackbird.tar.bz2
|       |-- seqFiles
|       |   |-- ART-SWVP_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   |-- DataAcq_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   |-- DetCalServer_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   |-- DetectorCal_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   |-- DPT_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   |-- RDA_sequence.LYSO9x6_4_TUBEQAT.xml
|       |   \-- ScanReqMgr_sequence.LYSO9x6_4_TUBEQAT.xml
|       \-- sinoData
|           \-- LYSO9x6_4_TUBEQAT.tar.bz2
|-- README
\-- TODO

                    5.1.2.3.1.3 Install
Target System Directory Tree
After download and installation  the files associated with PAARTF will be on the target machine under /usr/g/ctuser/acqAutoTest.   

In addition, upon PAARTF installation list files are placed in the following directory:
/petLists/acqAutoTest/<system-config>, with a link named ‘listData’ which points to the list data for the current configuration.

Sinogram files are placed in the following directory:-
/petRDFS/acqAutoTest/<system-config>, with a link named ‘sinoData’ which points to the sino data for the current configuration.

Detector Calibration files are placed in /petLists/acqAutoTest/<system-config>_caldata and contain the base, gold and is also the location of files generated during the detector cal sequence.    A link named ‘calData’ points to the cal data for the current configuration.


The additional programs, pqt and petQueryTool, are installed at system load from cold into /usr/PET/release/dragon/bin/linux2.

Detector Performance Tool calibration data files are present in /usr/PET/systemConfig/cal/ and are installed from there every time ‘acqSetup’ is performed to requested config type.


Installing and Running PAARTF
To install PAARTF on a bay or console, run the following commands on a Clearcase 
Server:
•	PAARTF download from blackbird views:
cleartool setview <viewname>
cd /vobs/pet_acq_test/source/acqAutoTest
./ downloadPAARTF.sh <target> [product family]  
[Where, <target> is the IP address or name of the bay or lab system
 “product family” is an optional argument to download content related to inputted product family]
Example:
./downloadPAARTF.sh jaws2
		Or
./downloadPAARTF.sh	 jaws2 columbia
•	PAARTF download from non-blackbird views:
cleartool setview <viewname>
cd /vobs/pet_acq_test/source/acqAutoTest
./create-archive.sh./download <target>   
[Where <target> is the IP address or name of the bay or lab system)]
Example:
  	./download jaws2
•	Installation of PAARTF on target system:
Telnet to, or sit down at, the target system.    Run the following commands:
cd /usr/g/ctuser/acqAutoTest/
./install
	  rehash

PAARTF Directories
Following directories are created by “download” and “install” scripts.
-.	/petLists/acqAutoTest
-.	/petRDFS/acqAutoTest
-.	/usr/g/ctuser/acqAutoTest
-.	/usr/PET/systemConfig/cal/calAutoTest

PAARTF Soft-Links
Following soft-links are created by “install” scripts.
-     /petLists/acqAutoTest/listData
-     /petRDFS/acqAutoTest/sinoData
-     /usr/PET/systemConfig/cal/calAutoTest/calData
-     /usr/PET/systemConfig/local/acq.cfg
-     /usr/PET/systemConfig/local/cal.cfg
-     /usr/PET/systemConfig/protocols/DetCal_DQA_WorkflowProto.xml
-     /usr/g/ctuser/acqAutoTest/gold
-     /usr/g/ctuser/func
-     /usr/g/service/ScanRunner/ScanRunner
-	/usr/g/service/ScanRunner/bin
-	/usr/g/service/ScanRunner/databases
-	/usr/g/service/ScanRunner/sequences

PAARTF Default configuration
By default PAARTF will read the current scanner type set from cmcfg file and will configure the PAARTF setup to the current scanner type.  No addition steps required to configure PAARTF with the same scanner type as Bay/console currently configured.

To configure for a different configuration scanner type (see Section 5.3 for additional info) run below command.
acqSetup <config>
		Example:  	acqSetup LYSO4x9_5_SIPMGEN1

                    5.1.2.3.1.4 Running PAARTF 
To launch PAARTF UI run below command.
acqStartEnv
Select the sequence from the dropdown and click the Start button to perform the tests.
The results will be stored in /usr/g/ctuser/acqAutoTest/newResults and the 
Objective Evidence files will be stored in files in an additional subdirectory, 
objEvResults. The Objective Evidence files are to be used for V&V.

Stopping PAARTF
To stop PAARTF UI, first click the STOP button (if enabled) and then run below command to close all related UI.
acqKillEnv			Answer ‘y’ to the y/n question about pet_acq (if asked).


                    5.1.2.3.1.5 Configuration 
PAARTF can be used on multiple configurations. It defaults to match the machine in which PAARTF was initially installed.
The system can be modified to switch configurations with the command 
acqSetup <config>   i.e.  acqSetup DXR
This will set up the appropriate sequences of tests for that system. ScanRunner will use the respective /usr/g/ctuser/acqAutoTest/protocols/ScanRunnerSequences/
*_sequence.<confg>.xml files.  Links to these files are created in /usr/g/service/ScanRunner/sequences/.   This script also changes the /usr/PET/systemConfig/local/acq.cfg to link to the respective configuration with additional parameters added for PAARTF. 
These modifications affect other parts of the target system not associated with PAARTF, so the target needs to be reset to the original configuration upon completion of use.  
PAARTF can be configures for below configurations (using acqSetup command):-

                    5.1.2.3.1.6 PAARTF Database files
A PAARTF database file holds all the required scan parameters (scanRx). Database file is used by ScanRunner to read and prescribe scan to the required service/tool. The PAARTF database scan prescription parameters are enclosed under <scanRx> xml tag in database file. The database file contains default values for all scan prescription parameters. These default values are then override in respective sequence file based on test case criteria.  


DataAcq, DetectorCal and ScanReqMgr (PSRM) sequence Database File (paartf.xml)
This database (paartf.xml) file contains scan prescription (scanRx) parameters default value. This database (paartf.xml) file is shared by three PAARTF sequence, DataAcq_sequence, DetectorCal sequence and ScanReqMgr_sequence (PetAcqMgr or PSRM sequence). This is because in all these sequences the ScanRunner communicates to PetAcqManager service which requires PetAcqManager scan prescription (scanRx) as input to initiate the PET scan. As this database file contains all scan prescription parameters with their default values, its ScanRunner job to read this database file along with its respective sequence file to merge scanRx contents of both and pass the final scanRx to PetAcqManager.

DetCalServer (DCS) sequence Database File (DetCalServerCmdDatabase.xml)
This database (DetCalServerCmdDatabase.xml) file contains Detector Calibration Server (DCS or DetCalServer) service request prescription (scanRx) parameters default value. Hence, only DCS request can be invoked using this database file. This database file is used by DetCalServer_sequence under ScanRunner UI.

CommandLine Tool Database File (CommandLineToolsDatabase.xml)
This database (CommandLineToolsDatabase.xml) file contains parameters to invoke any PAC command line tools. These parameters contains name of tool, executionFilePath, and architecture type. This file along with its respective sequence file contents are merged by ScanRunner and the required tool command is executed. This database file is used by DPT_sequence and RDA_sequence under ScanRunner UI.

                    5.1.2.3.1.7 PAARTF Sequence Files
As stated in section 5, PAARTF (ScanRunner) communicates with various services and tools (RDA, CAL, DPT), all test cases with same type of communication are grouped together to form one sequence. These sequences are termed as PAARTF sequences. 
•	Each sequence has its default database file and ScanRunner communicates to only one service directly for each sequence. 
•	Sequence file contains all required LT test case indexed in the order of their execution in ascending order starting with index = 0.
•	Only the tests listed in sequence file are executed. 
•	Sequence file may also contain overriding values of certain scanRx parameters which are listed in corresponding database file (default value). 
•	Sequence file decides the GROUP TYPE for each test case. 
•	Similar group types are group in objective evidence results which are then dumped into their respective GROUP_TYPE.objEv file. 
•	Sequence file provide placeholder for pre/post sequence/scan scripts for each test. 
These sequence scripts are discussed in details below. 

The various sequences and their functionality provided by PAARTF are listed below:-

ART-SWVP Sequence
•	This sequence is a stripped down sequence to demonstrate some of the basic capabilities of PAARTF.
•	ScanRunner communicates with PetAcqMgr Directly to prescribe a PET scan.
•	Prescription is passed from ScanRunner to PetAcqMgr and Data is acquired by running pet_acq in unlist mode. Synthetic List file is replayed to simulate events.
•	RDA tools like rdfTell is used to fetch the result from acquired sino file and result is dumped to respective LT file name.
•	Script like rdaSnoop and createObjMain.py are used to produce objective evidence.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

DataAcq sequence
•	This sequence file is used to test pet_acq service functionality.
•	ScanRunner communicates with PetAcqMgr Directly to prescribe a PET scan.
•	Prescription is passed from ScanRunner to PetAcqMgr and Data is acquired by running pet_acq in unlist mode. Synthetic List file is replayed to simulate events.
•	ListDecode RDA tool is used to fetch result from List file during the Record from replay scan and result is dumped to respective LT file name.
•	RDA tools like rdfTell is used to fetch the result from acquired sino file and result is dumped to respective LT file name.
•	Script like rdaSnoop and createObjMain.py are used to produce objective evidence.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

DetCalServer sequence (also called DCS sequence) 
•	This sequence file is used to test Detector Calibration Server (DCS) functionality.
•	ScanRunner communicates with DetCalServer Directly to prescribe a PET scan.
•	DCS then pass the prescription to PetAcqMgr to prescribe Scan by running pet_acq in unlist mode. Synthetic List file is replayed to simulate events.
•	RDA tools like rdfTell is used to fetch the scan description from generated sino file.
•	After completion, DCS write Calibration statistics to CAL.LOG file.
•	Script like dcsSnoop is used to copy the statistics to the respective result file and generate the objective evidence file.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

DetectorCal sequence
•	This sequence file is used to test various Detector Calibration Processing functionalities.
•	 Calibration Tools like EnergyTool, CtcTool, SipmGainTool, PhantomPresenceTool, CrystalMapTool, and also Cathode Search and Phantom Load/Unload feature are tested.
•	ScanRunner communicates with PetAcqMgr Directly to prescribe a PET scan.
•	Prescription is passed from ScanRunner to PetAcqMgr and Data is acquired by running pet_acq in unlist mode. Synthetic List file is replayed to simulate events.
•	ScanRunner then communicates with various Calibration tools in-directly using calSnoop script to fetch the data from acquired sinogram file.
•	These Calibration tools then uses the input calibration files or Calibration options to process the sinogram file to produce the final calibrated calibration files. 
•	RDA tools like rdfTell is used to fetch the result from generated sino file.
•	CAL tools like calTell is used to fetch the calibration related information from generated calibration file.
•	Both RDA and CAL tool output are dumped to respective result LT files.
•	Script like calSnoop is used to generate the objective evidence file.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

ScanReqMgr sequence
•	This sequence file is used to test PetAcqMgr (or PET Scan Request Manager or PSRM).
•	ScanRunner communicates with PetAcqMgr Directly to prescribe a PET scan.
•	Prescription is passed from ScanRunner to PetAcqMgr to pet_acq.
•	For prescribed live scans, data is acquired by running pet_acq in unlist mode with Synthetic List files is replayed to simulate events.
•	For prescribed unlist scans, data is acquired by replaying previously acquired list record files is to simulate events.
•	petQueryTool and scripts like dbFilter are used to fetch the result from Raw Data DB entries and result are dumped to respective LT file name
•	Script like objEvDbQuery is used to produce objective evidence file.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

RDA sequence
•	RDA tools like ListDecode, ListTool, rdfTell, features are tested.
•	ScanRunner communicates with CmdLineServer Directly to invoke executeRDATools script.
•	The executeDPT script read RDA tools options from rdaToolsOptions.cfg file and constructs the required RDA tool command and executes that command. The standard output of tool is captured in result LT file.
•	Post-scan sequence script objEvRDASnoop is invoked to produce objective evidence file.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

DPT sequence
•	This sequence file is used to test various DPT tools functionality.
•	ScanRunner communicates with CmdLineServer Directly to invoke executeDPT script.
•	The executeDPT script read DPT options from dptOptions.cfg file and constructs the DPT command and executes the DPT command. The standard output of DPT is captured in result LT file.
•	Post-scan sequence script objEvDPTSnoop is invoked to append the DPT log result to LT* file and to produce objective evidence file.
•	Finally, both result LT file and objective evidence files are checksum verified with gold.

                    5.1.2.3.1.8 PAARTF Sequence Scripts
As described in PAARTF Sequence File section, each sequence files contains placeholder for various scripts to be executed before and after each test and sequence. These scripts are used to fulfill the pre and post conditions required by each test case and by each sequence. Hence, these four types of script play a key role in executing test case in all PAARTF sequence. But for certain test case they may be not used by the sequence. Below are the four types of PAARTF sequence scripts used by sequence file:-

Pre-Sequence Scripts
•	Invoked once per sequence.
•	Invoked just before starting of FIRST test case in a sequence.
	startRTSClient.pl
	touchDPTCalFiles

Pre-Scan Scripts
•	Invoked once per test in a sequence.
•	Invoked before starting of EACH test case in a sequence
	saveRTSData.pl
	cleanDCSLog.pl
	cleanDPTLog

Post-Scan Scripts
•	Invoked once per test in a sequence.
•	Invoked after completion of EACH test case in a sequence.
	objEvRdfSnoop
	rdaSnoop
	objEvCalLogSnoop
	objEvCalSnoop
	objEvRdaSnoop
	objEvDbQuery
	objEvDPTSnoop

Post-Sequence Scripts
•	Invoked once per sequence.
•	Invoked after completion of LAST test case in a sequence.
	endRTSClient
	cleanObjEvFiles

                    5.1.2.3.1.9 PAARTF Supporting Files
When PAARTF setup is installed on any bay/console, there are certain supporting PAARTF files content that get appended to the required system configuration files. This is done to add extra functionality which is required to execute PAARTF test cases without affecting the system functionality. Following are the files which are used by PAARTF infrastructure: -

Acq Cfg Append File
•	File name /usr/g/ctuser/acqAutoTest/protocols/acq.cfg.append
•	This file’s contents get appended to /usr/PET/systemConfig/local/acq.cfg
•	Use to add extra Protocol information to acq.cfg file.
•	File includes parameters like eventSimData, eventSource, unListRepearcnt, singlesCollect, deadtimeCollect, etc based on test case type.

Cal Cfg Append File
•	File name /usr/g/ctuser/acqAutoTest/protocols/cal.cfg.append
•	This file’s contents get appended to /usr/PET/systemConfig/local/cal.cfg
•	Use to override calibration information to cal.cfg file.
•	File includes parameters like StopOnCounts, and MaxAcqSecs.

DetCal DQA WorkflowProto XML file
•	File name /usr/g/ctuser/acqAutoTest/protocols/DetCal_DQA_WorkflowProto.xml.append
•	This file’s contents get appended to /usr/PET/systemConfig/protocol/DetCal_DQA_WorkflowProto.xml
•	Use to add extra ACQ_RX_INFO to DetCal_DQA_WorkflowProto.xml file.
•	File includes parameters like acquisition type, protocolTag, isUnlistAcquisition, scanDesc, listMode, scanType, etc. 

                    5.1.2.3.1.10 PetAcqMgr
Pet Acq Manager communicates between clients like ScanRunner and pet_acq service by providing the scan prescription from its client ScanRunner. The scan prescription is one of the LT test cases, which are defined in the PAARTF database for ScanRunner. Once ScanRunner sends PetAcqMgr a scan request then the prescription is forwarded to pet_acq.  Pet_acq informs PetAcqMgr of each frame progress and subsequently the completion of the scan. PetAcqMgr informs ScanRunner of the status in order for it to update the GUI as appropriately.   

                    5.1.2.3.1.11 Calibration Processing Libraries 
PET Detector Calibration Processing libraries comprise the logic and algorithms required to fine tune the detector hardware and electronics for clinical scanning. The tuning varies based on the underlying detector hardware and electronics. The sinogram or spectra files from PET data Acquisition are processed by the calibration libraries based on the calibration sequence type and each type has its specific processing algorithm. For more details refer to PET Detector Cal Processing SDD in reference document section.

                    5.1.2.3.1.12 DetCalServer 
DetCalServer (or DCS) is responsible for processing calibration request from ScanRunner (in PAARTF context) and sending an acquisition request to PET scan request manager to acquire raw spectra data, processing raw spectra and generating calibration results in cal files and dumping the calibration statistics to CAL.LOG file. DCS request are read by ScanRunner from database and sequence files and are send to DCS by LWC connection. For more details refer to PET Detector Cal Server SDD in reference document section.

                    5.1.2.3.1.13 Calibration Tools
PET Calibration tools are standalone tool which is used to Pet Calibration Processing libraries. Each tool uses its corresponding Calibration Library to fine tune the detector hardware and electronics for clinical scanning. 

                    5.1.2.3.1.14 DetPerfTool
DetPerfTool (Detector Performance Tool) take a command line argument passed from ScanRunner and it computes detector performance parameters from the input RDF & calibration files. The parameters are: energy and timing FWHM, peak to valley, peak distance min and anode gains. At high level it computes energy and timing resolution for AERB requirement for all the crystals in a PET system. All these parameters are arranged in a HDF file for easy access and viewing which is output of DPT tool. Detailed design of the tool can be found in PET Detector Performance Tool SDD, refer to document reference section.

                    5.1.2.3.1.15 rtsClient
The rtsClient executable captures the Real Time Statistics socket output of the Acquisition Service. The processing script startRTSclient informs rtsClient to register to the acqRTS output of the pet_acq service. After each scan saveRTSData informs rtsClient to record the information from acqRTS to a temporary file. Once pet_acq finishes the sequences endRTSclient informs rtsClient to deregister from acqRTS output of the pet_acq service. The statistics that are written to a temporary file are stored on the System and later analyzed by rdfSnoop.  

The rtsClient binary is packaged and distributed with the product software.

The rtsClient source code can be found on the Clearcase directory /vobs/pet_acq_test/source/rtsClient

The following real time statistics are captured from the output of the Acquisition Service.

•	A1RT - avgPhys1TrigRate <average cardiac bpm>
•	A2RT - avgPhys2TrigRate <average respiratory bpm>
•	ATRG - acceptedTrigs

•	C1RT - curPhys1TrigRate <current cardiac bpm>
•	C2RT - curPhys2TrigRate <current respiratory bpm>
•	CTS  - cardiacTriggerState [goodTrigs(0), badTrigs(1), noTrigs(2)]

•	FNUM - frameNumber
•	FRCT - frameRandomCts
•	FRRT - frameRandomRate
•	FTCT - frameTrueCts <kcps>
•	FTRT - frameTrueRate <kcps>

•	GBS  - totalGatedBinSecs

•	LTMK - lostTimeMarkers
•	LTRG - lostTriggers

•	PGT  - physioGatingType [cardiac(0), respiratory(1)]

•	RSTS - readyToScanTimeStamp
•	RTRG - rejectedTrigs
•	RTS  - respTriggerState  [goodTrigs(0), badTrigs(1), noTrigs(2)]

•	SEIF - secsElapsedInFrame
•	SEIS - secsElapsedInScan
•	SLIF - secsLeftInFrame
•	SLIS - secsLeftInScan
•	SPRT - sysPromptRate <kcps>

•	TS   - triggerState [goodTrigs(0), badTrigs(1), noTrigs(2)]
•	TSRS - timeSinceReadyToScan <msec>

The command “rtsClient  -h” provides usage options for rtsClient. The options used in PAARTF determined in startRTSClient are the following: 
      -d  Default Stats
                        timeSinceReadyToScan       readyToScanTimeStamp
                        sysPromptRate                      secsElapsedInScan
                        secsLeftInScan                       frameNumber

       -f   Frame Stats
                        secsElapsedInFrame             secsLeftInFrame
                        frameTrueCts                         frameRandomCts
                        frameTrueRate                      frameRandomRate
                        totalGatedBinSecs            

       -t   Trigger Stats
                        lostTimeMarkers                  triggerState
                        lostTriggers                            acceptedTrigs
                        rejectedTrigs                         avgTrigRate
                        currentTrigRate                    cardiacTriggerState
                                       respTriggerState                   physioGatingType
                    -R Regression mode.

                    5.1.2.3.1.16 CmdLineServer
CmdLineServer is responsible for processing command line tool request from ScanRunner and executing command line tool. CmdLineServer request are read by ScanRunner from database and sequence files and are send to CmdLineServer.  Once the request is send to CmdLineServer, it is blocked for that request until the command line tool execution is over. Upon completion of command line tool the response status is send back to ScanRunner.

                    5.1.2.3.1.17 Processing scripts (startRTSClient, saveRTSData, endRTSClient, logMemUsage)
PAARTF makes use of various scripts that provide access to the RTS information gathered during the scan.  At the beginning of each PAARTF sequence, ScanRunner calls the Perl script startRTSClient.pl, which initializes an instance of rtsClient on the system. The rtsClient tool is initialized with –dftR options, which enable recording of default stats (-d), frame stats (-f), and trigger stats (-t), as well as request that rtsClient run in Regression mode (-R); Regression mode forces rtsClient to only record stats when a scan is in progress. Prior to initialization, two sync files are created in the /tmp directory, one for reading and one for writing. These files allow PAARTF to communicate with rtsClient.
Prior to each PAARTF scan, the Perl script saveRTSData.pl is called. This script effectively tells rtsClient where to save RTS stats on the file system by writing to the temporary sync files created by startRTSClient.pl. 
Upon completion of a PAARTF sequence, the Perl script endRTSClient.pl is run. This script uses the sync files to indicate to rtsClient that it should exit. It also cleans up the temporary sync files from the file system.
Finally, logMemUsage.pl is a utility script used by PAARTF to track memory usage of the pet_acq and PetAcqmgr processes during a sequence. It is called indirectly before and after each scan (from saveRTSData.pl and rdfSnoop), and runs the following commands:
rsh par ps –C pet_acq --no-headers –o rss,vsz
ps –C PetAcqMgr –no-headers o rss,vsz
This collects rss and vsz memory usage information from pet_acq, which is written to the file memory_pet_acq.log and memory_PetAcqMgr.log in the PAARTF newResults/ directory, along with the scan ID associated with the call. This log file is used during verification to prove that there are no significant memory leaks in the application.
      
                    5.1.2.3.1.18 rdfTell, rdfSnoop and objEvRdfSnoop
The rdfTell and rdfSnoop utilities determine the PASS/FAIL resolution for each scan.  ScanRunner invokes objEvRdfSnoop through the sequence XML files after each scan as the post processing script.  The objEvRdfSnoop script invokes rdfSnoop followed by createObjEvMain.py which creates the objective evidence files. These files contain groupings of related test cases and the information that is important to the grouping. The rdfTell utility allows all headers of sinogram or list file RDF to be examined and be read in human readable form i.e acq rx, frame stats, deadtime & singles data, segment data, offsets, and sys geometry data.  For each scan rdfSnoop uses rdfTell tool to examine the RDF sinogram on the System that was generated from pet_acq.  

The rdfTell executable is invoked with the options of –r –h eafdgsvoS –Ha –S which captures the following information from the RDF file:
-r : Does not show landmarkDateTime, Exam ID, Scan ID, and Scan & Frame Start Time 
          -h : Shows the following headers where 
               e=exam, a=acq rx, f=frame stats, d=deadtime g=sys geometry
               s=segment/sorter, v=version, o=offsets, and S=singles
          -H : Displays the Detector Module Signature data, where
               a=all available signatures
          -S : Displays the min/max and total sinogram/projection view counts per slice, totals per
                              data segment and produce Singles & Deadtime min/max/avg statistics

The most recent scan is kept on the system at /petRDFS/MostRecentScan. For this scan, the rdfSnoop tool first checks if there was an RDF file produced to indicate that the scan actually completed. Once confirmed, the rdfSnoop tool loops through every RDF file produced for that test scan, attains the appropriate information with rdfTell, and then appends the collected RTS samples on the system to the rdfTell information. This resulting information is processed through a custom sed filter and then has its checksum compared with the installed gold file. The comparison ultimately provides the final PASS/FAIL resolution for each scan. This information is written to system on the PAARTF autoTestSummaryLog and ScanRunner is informed of the result for the GUI update. Each individual test PASS/FAIL as well as a cksum of the gold objEv files, determines the PASS/FAIL of the overall group. The autoTestSummaryLog log consists of the Date and Time of scan, Test Case ID, Test Results,  the RDF Directory Path and if the last RTS sample was missing or not from the scan.


                        5.1.2.3.1.18.1 /vobs/pet_acq_test/source/acqAutoTest/common/bin/ScanRunnerScripts/rdfSnoop
if [[ "$file_name" == *_REC ]] # Only for list record during replay tests
then
    waitForSymlink /petLists/MostRecentScan 45
    listdir=${targetLink}

    if [ -n "$listdir" ]; then
        for listFile in `/bin/ls -1 ${listdir}/*.BLF`
        do
            echo "++++++++++++++++++ List file headers ++++++++++++++++++" >> ${outFile}
            petsh par rdfTell -r -h eafgvS -Ha ${listFile} >> ${outFile}
            echo "++++++++++++++++++ List Block Signatures ++++++++++++++++++" >> ${outFile}
            petsh par rdfTell -Bs ${listFile} >> ${outFile}
            petsh par rdfTell -Bt ${listFile} > ${tmpFile}
            listBstLen=$(stat -c%s ${tmpFile})
            if [ $listBstLen -gt 2500000 ]
            then
                head -50000 ${tmpFile} >> ${outFile}
                tail -50000 ${tmpFile} >> ${outFile}
            else
                cat ${tmpFile} >> ${outFile}
            fi
            echo "++++++++++++++++++ List Singles and Deadtime ++++++++++++++++++" >> ${outFile}
            petsh par rdfTell -S ${listFile} > ${tmpFile}
            listSdtLen=$(stat -c%s ${tmpFile})
            if [ $listSdtLen -gt 2500000 ]
            then
                head -10000 ${tmpFile} >> ${outFile}
                tail -10000 ${tmpFile} >> ${outFile}
            else
                cat ${tmpFile} >> ${outFile}
            fi
            echo "++++++++++++++++++ List file checksums ++++++++++++++++++" >> ${outFile}
            petsh par ListDecode -R 10 -C ${listFile} >> ${outFile}
        done
    fi
fi

                    5.1.2.3.1.19 objEvDbQuery, dbQuery, petQueryTool and dbFilter
For the ScanReqMgr [PSRM] sequence, again, similar processing occurs as above, but it instead of using RDA tools for post processing PSRM sequence uses dbQuery, petQueryTool and dbFilter to analyze the images created, creating results files which are then compared to gold.

objEvDbQuery
After ScanReqMgr [PSRM] sequence is completed ScanRunner calls objEvDbQuery script to perform post processing. This script further invokes dbQuery and then it creates objective evidence files. It also returns the status of dbQuery as it is the real PASS/FAIL for the test, which will be summarized in the objective evidence file.
Usage:
objEvDbQuery <testID> <objective evidence group name>

dbQuery
dbQuery script is invoked by objEvDbQuery which looks up the most recent scan sinogram file and finds its UID and run petQueryTool(pqt) to dump DICOM fields defined in a $tagfile.

petQueryTool
petQueryTool is used to retrieve the DICOM tags listed in the tag file based on a UID.
It is called at the command line with wrapper script, pqt <arg list>.   pqt simply sets LD_LIBRARY_PATH and passes all of the arguments to petQueryTool.

Usage of petQueryTool:

petQueryTool [-h] [-f resultTags] [-l level] [-st uid] [-se uid] [-im uid] [-r] [-p] [-n]

Queries DICOM database
        -h           Print this message
        -f  tagFile  File containing result tags "0x0000,0x0000,description"
        -l  level    Level of query PATIENT|STUDY|SERIES|IMAGE
        -st  uid     Study Instance UID (exam)
        -se  uid     Series Instance UID (series)
        -im  uid     SOP Instance UID (frame)
        -r           Return only RAW data
        -p           Return only Patient RAW Data
        -n           Print only number of matches
        
tagFile:
    	This file is used to feed dbQuery for the PetAcqMgr sequence.
    	petQueryTool returns the DICOM tags listed in this file.

 tagfile file is formatted as:-
        	group , element , optional comment
       	 ...with the comment and scanRunner xml tag being free-format with
        	*no* commas!  Each tag line must have exactly 3 fields!  
        	The comment field can be blank, but must have a comma!

Example:
    	# LT_GENERAL_0_PSRM
    	0x0010 , 0x0020 , patient identifier
    	0x0008,0x0050,study_requisition/accession

dbFilter
This script filters out extraneous "stuff" from the output of petQueryTool, leaving only the DICOM fields.  The description of the tag is added for readability.

                    5.1.2.3.1.20 calTell, calSnoop
For the Detector Cal sequence, similar processing occurs as for the PetAcq sequence, but instead of rdfTell, etc, it uses calTell, calSnoop and objEvCalSnoop.   calSnoop calls various cal tools such as CrystalMapTool, EnergyTool, etc, to create cal files.   calTell is then called to analyze the cal files and generate the output which is compared to gold.   

                    5.1.2.3.1.21 dcsSnoop, cleanDCSLog, saveDCSLOG
For the DetCalServer sequence dcsSnoop script is used to process the result. First after the test case is completed the PET Calibration Statistics are dumped to /usr/g/service/log/CAL.LOG file by Detector Calibration Server (DCS/DetCalServer) service. From the post sequence script dcsSnoop is invoked. This snoop script does the following tasks:-
|      1.	Run ‘rdfTell’ command on /petRDFS/MostRecentScan sinogram file to get the scan description, and dump it to the corresponding LTXX_XX_X file.
|      a.	Phantom LOAD/UNLOAD and CATHODE SEARCH tests are exempted from running ‘rdfTell’ command as they do not produce any sinogram file.
|      2.	Invoke saveDCSLog.pl pearl script to read /usr/g/service/log/CAL.LOG file and dump the recent most calibration statistics to the corresponding LTXX_XX_X file.
|      a.	Before running each test, a pre-sequence script ‘cleanDCSLog.pl’ is run to delete CAL.LOG file, so that after each DCS test, CAL.LOG contains the recent most calibration statistics.
|      b.	Compare check-sum of generated file with GOLD, and update the ‘autoTestSummaryLog’ file with compared result.

                    5.1.2.3.1.22 System
The system is referring to the target machine in which PAARTF is installed. The target machine can be on a bay scanner or SW console of multiple configurations. The data repositories for PAARTF are located on the system in the /petLists, /petRDFS, and /usr/g/ctuser/acqAutoTest/newResults directories.
The /petLists directory contains all the list files to be used for PAARTF for each configuration.
DXR, BGO8x8_{2,3,4,5}.   The listData links one of the other directories for which the current system configuration that PAARTF is using.   Another link, calData, points to the detector calibration data used for the detector cal test sequence.

The /petRDFS directory contains RDF produced by PAARTF as well as from other pet_acq usage on the system. The /usr/g/ctuser/acqAutoTest/newResults directory contains the result files of the most recent ScanRunner test scan. All the scans that passed are in this directory. If the scans failed they are in the Failed/ subdirectory. The newResults directory has all the memory output information as mentioned previously.

                    5.1.2.3.1.23
                5.1.2.3.2


            5.1.2.4 Add PAARTF test

                5.1.2.4.1 Example CR
https://collaborator.engops.health.ge.com:443/ui#review:id=172530

- Configure CommandLineToolsDatabase to run new test
    -- File: /vobs/pet_acq_test/source/acqAutoTest/common/ScanRunnerDatabases/CommandLineToolsDatabase.xml
    -- Config
    <scanRequest index="37">
        <scanReference name="​LT_RDA_CREATECORR_RDF_GEOCAL_MATLABHDF5_​SEEDPATH">    
        </scanReference>
        <postScanScript>/usr/g/ctuser/​acqAutoTest/bin/ScanRunnerScripts/​objEvRDASnoop LT_RDA_CREATECORR_RDF_GEOCAL_MATLABHDF5_​SEEDPATH RDA_CREATECORR</postScanScript>
        </scanRequest>
    <scanRequest index="38">
            <scanReference name="​LT_RDA_CREATECORR_RDF_NORM_SEEDPATH">
        </scanReference>
            <postScanScript>/usr/g/ctuser/​acqAutoTest/bin/ScanRunnerScripts/​objEvRDASnoop LT_RDA_CREATECORR_RDF_NORM_SEEDPATH RDA_CREATECORR</postScanScript>
    </scanRequest>

    --

- Post run test verification tools enrollment
    -- File: /vobs/pet_acq_test/source/acqAutoTest/productFamily/columbia/configFiles/autoObjEv.config
    -- Diff (added tool)
RDA_CreateCorrRDF
  RDACreateCorrRDF

    --

-  Configure scan parameters
    -- File: /vobs/pet_acq_test/source/acqAutoTest/productFamily/columbia/configFiles/rdaToolOptions.cfg
    -- Code
# createCorrRDF Tool Test cases
LT_RDA_CREATECORR_RDF_GEOCAL_MATLABHDF5_​SEEDPATH -G <SINO_PATH>/​CREATECORR_RDF_GEOCAL_MATLABHDF5.h5
LT_RDA_CREATECORR_RDF_NORM_SEEDPATH -N <SINO_PATH>/​CREATECORR_RDF_NORM_SPECTRA_SINO0000 -g <SINO_PATH>/CREATECORR_RDF_NORM.3dgeom

    --

- Register tool (script)
        -- File /pet_acq_test/source/.../common/ScanRunnerDatabases/CommandLineToolsDatabase.xml 
code:
    <scanRx id="defaultCreateCorrRDF">
        <baseScan>defaultCmdLineToolsScan</​baseScan>
        <tool>createCorrRDF</tool>
        <executionFilePath>/usr/g/service/​ScanRunner/bin/executeCreateCorr</​executionFilePath>
    </scanRx>
...
    <!-- CreateCorrRDF Test cases -->
    <scanRx id="​LT_RDA_CREATECORR_RDF_GEOCAL_MATLABHDF5_​SEEDPATH">
       <baseScan>defaultCreateCorrRDF</baseScan>​
    <scanRx id="LT_RDA_CREATECORR_RDF_NORM_SEEDPATH">​
       <baseScan>defaultCreateCorrRDF</baseScan>

    -- File: /pet_acq_test/source/acqAutoTest/common/bin/ScanRunnerSetup 
    code:
                      "executeDDWaveGen" "objEvDDWaveGenSnoop" "executeCreateCorr")
- Actuall new tool 
/pet_acq_test/source/acqAutoTest/common/bin/ScanRunnerScripts/executeCreateCorr 

Bash script: /pet_acq_test/source/acqAutoTest/common/bin/RDACreateCorr 

- Odds and ends
    -- Sed filter File: /vobs/pet_acq_test/source/acqAutoTest/productFamily/columbia/configFiles/rdfTellFilter.sed

                5.1.2.4.2 Sravan's explanation
New Test to PAARTF Sequence:

|           1.	Identify the test you need and the sequence files in /usr/g/ctuser/acqAutoTest/protocols/ScanRunnerSequences
|           2.	Update the corresponding “DatabaseFile” in /usr/g/ctuser/acqAutoTest/protocols/ScanRunnerDatabases. First line in sequence file should tell you the corresponding Database file.
|           a.	Database file has common scan prescriptions for all tests. And the sequence file overrides as per the test needs. Refer tests in DataAcq Sequence file and paartf.xml and observe the parameters that change to understand.
|           3.	In case of RDA_Sequence/DPT_Sequence tests, the tool for each test is defined in dpt/rdaOptions.cfg file. Usual format is “TestID <options to tool> <input file to tool> <optionally output path>”. The CommandLineTools.xml file has the tool which needs to be run for each TestID.
|           a.	CommandLineTools.xml file has the script to run for a tool. For example, /usr/g/service/ScanRunner/bin/execute*. These scripts are actually located in /usr/g/ctuser/acqAutoTest/bin/ScanRunnerScripts up on PAARTF download. Whatever these scripts generates is outputted to LT file in /usr/g/ctuser/acqAutoTest/newResults directory.
|           b.	After generation of LT files, they are processed by python scripts in /usr/g/ctuser/acqAutoTest/bin/AutoObjEvScripts/.
|           
|           One question you might get is how do I make the gold files the first time:
|           1.	Obviously the first time the tests fail as there are no gold files. The acqAutoTest/newResults/Failed directory will have the LT files named in format “LT*.<date and time>”.
|           2.	“acqMakeGold” command/script will make the failed files as gold. Basically truncates the date and time stamp. Then we move them to acqAutoTest/gold directory and rerun the test to PASS. After visual and peer inspection of the gold files, they are clearcase’d. 
|           3.	“acqMakeObjEvGold” command/script is used to generate the goldObjEv files in acqAutoTest/gold/goldObjEv directory for a given sequence. The scripts located in /usr/g/ctuser/acqAutoTest/bin are used for this process.
|           
|           I guess covered most of the important aspects of adding a test case. Let me know if you need an help.
--
Sravan Yakkali
Senior System Specialist, MICT, PET Data Acquisition
GE Healthcare
T +91-80-40885583 | M +91-9880651515

                5.1.2.4.3


            5.1.2.5 Source code

                5.1.2.5.1 GUI
/vobs/jrx/scanRunner/src/com/ge/med/pet/scanRunner
Major classes
- scanRunner.java - main loads following
- scanRunnerUI.java - swing GUI, observer of following
- scanRunnerController.java - Event listeneter to petAcqMgr and acqRTS, observable (observed by scanRunnerUI)

                5.1.2.5.2 scanRunner
/vobs/pet_acq_test/source/acqAutoTest/


                5.1.2.5.3

            5.1.2.6 Mike's email

From: Cook, Michael J (GE Healthcare) 
Sent: Thursday, March 1, 2018 3:48 AM
To: Bennatan, Alon (GE Healthcare, consultant) <alon.bennatan@ge.com>; Douglas, Kevin (GE Healthcare) <KevinDouglas@ge.com>
Cc: Voldman, Elena (GE Healthcare) <Elena.Voldman@med.ge.com>; Wille, Mark (GE Healthcare, consultant) <Mark.Wille@ge.com>
Subject: Re: Build For pac_col_ddg.7

Alon,
Procedure to install and patch PAARTF for pac_col_ddg.7 
Mjc


Procedure to download, install PAARTF for current  pac_col_ddg sw build:
-----------------------------------------------------------------------

1) on build server, ct setview to most recent pac_col_dd build view, then :
   cd /vobs/pet_acq_test/source/acqSutoTest
   ./installPAARTF.sh <target system IP>
   Gets the original list files

2) after download completes, ssh into target system as ctuser, and then :
   cd acqAutoTest
   ./install
   rehash
   Installing the framework on console

3) make copy of PAARTF RDFv9 lists files used for PAARTF by doing:
   petsh par
   cd /petLists
   cp acqAutoTest{,.clearcase}

4) make a cook directory on target system under ctuser account home dir
   ssh <unix user>@3.57.51.65             note: kevin's pacsw2 pc
   cd /export/data1/cook/paartf_stuff/
   scp paartf_patches_for_pac_col_ddg_7.tar ctuser@<ip of target system>:cook
   on target host, cd ~/cook
   tar xf paartf_patches_for_pac_col_ddg_7.tar  
   This tar files includes (will be used later below) :
-	LYSO4x9_5SIPMGEN1.RDFv9.7.6.tar (new gold results)
-	acqUnlistPar
-	rdfAccecpt.cfg
-	rdfSnoop
-	RdfTellFilder.sed
-	README file (includes the instructions in this mail)


5) on target host, setup an rdfAccept.cfg for 'development' :
   unlink /usr/PET/systemConfig/local/rdfAccept.cfg
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfAccept.cfg.dev /usr/PET/systemConfig/local
   ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg
   Configuration file for rdfAccept

6) on host, perform:
   cd ~/acaAutotest
   rm acceptListData.log
   acceptListData
   This script is running “rdfAccept” on all BLF files in the console

7) on host, run 'acqSetup' to get some derivative lists files/links required by some PAARTF tests
   ln -sf /usr/PET/systemConfig/local/rdfAccept.cfg.dev /usr/PET/systemConfig/local/rdfAccept.cfg
   This script creates soft links to various files and directories based on the scanner type specified

8) cd ~/acqAutoTest/goldresults
   mv LYSO4x9_5_SIPMGEN1 LYSO4x9_5_SIPMGEN1.clearcase
   tar xf ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/LYSO4x9_5_SIPMGEN1.RDFv9.7.6.tar
   ln -sf LYSO4x9_5_SIPMGEN1.RDFv9.7.5 LYSO4x9_5_SIPMGEN1
   Create link to the updated gold results

9) cd ~/acqAutoTest/protocols
   mv rdfTellFilter.sed{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/dfTellFilter.sed .
   Not so sure what this file is for, also some sort of configuration file

10) cd ~/acqAutoTest/bin
   mv acqUnlitPar{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/acqUnlistPar .
   configuration file with environment variables

11) cd ~/acqAutoTest/bin/ScanRunner
   mv rdfSnoop{,.orig}
   cp ~ctuser/cook/paartf_patches_for_pac_col_ddg_7/rdfSnoop .
   script that helps to determine the PASS/FAIL resolution for each scan

12) Now you should be ready to run PAARTF DACQ sequence
   cd ~/acqAutoTest
   acqCleanup
   acqStartEnv
   use ScanRunner UI to select Data Acq sequence, then hit Start
   The commands for starting the PAARTF as you obviously know

            5.1.2.7
        5.1.3

    5.2 Manual test RDF tools

        5.2.1  Test RDF Accept

            5.2.1.0  my manual test procedure
[ctuser@jaws4:Thu Dec 21:~/yosi/stage:]$ cat !$
cat test_procedure
-> get raw print of HDF file
    9  h5ls -d 1Frame_Flood_Data.rdf/HeaderData/RDFConfiguration/fileVersion 
-> my script. prints version
   18  ./prntRdfVer.py 1Frame_Flood_Data.rdf  

-> RFD files dir
   53  cd /petRDFS/ReconAutotest/

-> my stage dir
  102  mkdir stage

-> Test rdfAccept
  223  export RDF_SKIP_USER_BLOCK_CHECK="TRUE"
  203  rdfAccept ~/yosi/1Frame_Flood_Data.rdf 
  359  ./rdfAccept  ../ReconAutotest/1Frame_Nema_Data.rdf 
  358  ../printRDFUserBlock.py 1Frame_Flood_Data.rdf 
  360  ../printRDFUserBlock.py 1Frame_Nema_Data.rdf 

-> Delete non 9.0 RDF files
  350   for f in  $(ls) ;do echo "check $f is 9.0"; if  ~/yosi/prntRdfVer.py $f |  grep '9.0'; then echo "$f is 9.0"; else echo "$f is not 9.0. delete"; rm -f $f; fi ;done | tee ~/rep

            5.2.1.1  Test without changes


Note, as convenience suggest to switch to bash, mkdir ~/yosi
Then from cygwin run pushrc_confj4 
[212680136@G9VK2GH2E:Wed Dec 06:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv/bashrc:]$ pushrc_confj4 
pushing PET test env .bashrc and .aliases to machine 3.87.141.251
make sure directory /usr/g/ctuser/yosi/ exists
recommended to export ssh RSA pub key first (export_ssh_pub_key)
.bashrc                                                                                                                                                                                                    100% 4064    19.3KB/s   00:00    
.aliases 
a. login
sshj4 

b. binaries
which rdfAccept
/usr/PET/release/dragon/bin/linux2/rdfAccept

c. Test files (RDF / list files)
    
    c1. tests are defined in paartf.xml
    user ctuser , password 4$apps
    root #bigguy

{ctuser@jaws4}find -name 'paartf.xml'
./acqAutoTest/protocols/ScanRunnerDatabases/paartf.xml

{ctuser@jaws4}find -name 'acq.cfg.append'
./acqAutoTest/protocols/acq.cfg.append

Now get list file list
{ctuser@jaws4}grep BLF `find -name 'acq.cfg.append' | sed -n '2p'`
...
LT23_DETECTOR_CAL_GAIN*eventSimData:/petLists/acqAutoTest/listData/DetCalListData.BLF
LT23_DETECTOR_CAL_CTC*eventSimData:/petLists/acqAutoTest/listData/DetCalListData.BLF
LT23_DETECTOR_CAL_DQA*eventSimData:/petLists/acqAutoTest/listData/DetCalListData.BLF
LT23_SRC_POS_DETCAL_LIST*eventSimData:/petLists/acqAutoTest/listData/DetCalListData.BLF
LT23_SRC_POSITION*eventSimData:/petLists/acqAutoTest/listData/CTCOCC.BLF
LT23_CTC_OCC*eventSimData:/petLists/acqAutoTest/listData/CTCOCC.BLF
LT22_LR_DYN_18_HR_RECORD*eventSimData: /petLists/acqAutoTest/listData/LorTofIncSpectrumLongTrigs.BLF

rdf files
{ctuser@jaws4}pwd
/petRDFS
{ctuser@jaws4}ls Recon*
ReconAutotest:
1Frame_Flood_Data.rdf*            3Frame_ATTN_ANN_pifa_Frame2.dat*      3R_Flood_Dyn_Data_Frame1.rdf  3R_Flood_HF_Data_Frame3.rdf   4R_Flood_Dyn_Norm.rdf        4R_Flood_HF_pifa_Frame2.dat  AAIYKAJR/
...

ReconAutotest_9.0:

ReconAutotest_9.7:

d. rdfTell
cd /petRDFS/ReconAutotest
{ctuser@jaws4}rdfTell 1Frame_Flood_Data.rdf

e. rdfAccept test. notice core dump 
{ctuser@jaws4}rdfAccept 1Frame_Flood_Data.rdf  accepted.rdf
Starting RDFv9.0 conversion...
01:04:36.453 rdfConvertUtils9.0to10.0.Error rdfConvertUtils9.0to10.0.cc(2023) in convertRdf(): Failed to specify an absolute source file path.
01:04:36.453 ConversionPipeline.Error ConversionPipeline.cc(92) in execute(): Failed to convert file (v9.0) with name: 1Frame_Flood_Data.rdf
[rdfAccept.cc] Failed to convert raw data file.
RDF not accepted
{ctuser@jaws4}
{ctuser@jaws4} rdfAccept ~/yosi/1Frame_Flood_Data.rdf 
Starting RDFv9.0 conversion...
01:05:04.742 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2165) in convertRdf(): new RDFv10.0 filename is /usr/g/ctuser/yosi//AAIYKAJR/AIVQTMJB/AJUWRBEU/SINO0000
01:05:04.742 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2181) in convertRdf(): Converting header data
01:05:04.742 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1043) in ConvertHeaderData(): Converting RDF configuration Header
01:05:04.745 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1084) in ConvertHeaderData(): Converting Sys Geo Header
01:05:04.754 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1096) in ConvertHeaderData(): Converting Acq Stats Header
01:05:04.758 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1109) in ConvertHeaderData(): Converting Sorter Header
01:05:04.777 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1122) in ConvertHeaderData(): Converting Acq Parameters Header
01:05:04.794 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1134) in ConvertHeaderData(): Converting Exam Data  Header
01:05:04.802 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1147) in ConvertHeaderData(): Converting DMOD Signature Header
01:05:04.805 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1160) in ConvertHeaderData(): Converting Cal Header
01:05:04.807 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1173) in ConvertHeaderData(): Converting Deadtime Header
01:05:04.810 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1194) in ConvertHeaderData(): Converting Singles Header
01:05:04.813 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1211) in ConvertHeaderData(): Converting 3D Xtal Efficiency Header
01:05:04.813 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1224) in ConvertHeaderData(): Converting CTC Timediff Header
01:05:04.814 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1243) in ConvertHeaderData(): Converting RDF configuration Header (again)
01:05:04.827 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2186) in convertRdf(): Done converting header data
Converting Segment 2 data01:05:04.834 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(502) in ConvertSegmentData(): Size of each slice is 25485565 elements
01:05:46.488 Error /vobs/pet_raw/source/rdfAPI/librdfCpp/SinogramDataset.cpp(159) in bool CSinogramList<SINO_DT>::Push(size_t, CSinogramSlice<SINO_DT>**) [with SINO_DT = unsigned char]: [Wed Dec  6 01:05:46 2017]memory realloc failed from 0 bytes to 25510461 bytes: unable to push to Sinogram Slice to the list
01:05:46.488 rdfConvertUtils9.0to10.0.Error rdfConvertUtils9.0to10.0.cc(589) in ConvertSegmentData(): Failed to push view 211 to new RDF
Segmentation fault

f. get file version
{ctuser@jaws4}h5ls -d 1Frame_Flood_Data.rdf/HeaderData/RDFConfiguration/fileVersion
majorVersion             Dataset {1}
    Data:
        (0) 9
minorVersion             Dataset {1}
    Data:
        (0) 0

My script
[212680136@G9VK2GH2E:Wed Dec 06:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/scripts/python:]$ scp ${USER_CT}@${JAWS4}:/usr/g/ctuser/yosi/prntRdfVer.py . 
prntRdfVer.py  


ctuser@jaws4:~/yosi> ./prntRdfVer.py 1Frame_Flood_Data.rdf  
RDF version: 9.0
[ctuser@jaws4:Wed Dec 06:~/yosi:]$ cat !$
cat prntRdfVer.py
#!/usr/bin/python

"""
Author: yosi izaq
Description: print RDF file version
"""

import sys,os
from subprocess import PIPE, Popen

def printHelp():
        print "Usage: {0} RDF_File".format(sys.argv[0])

def printRdfVer():
        if len(sys.argv) != 2:
                printHelp()

        file = sys.argv[1]
        fileVerStr=file+r"/HeaderData/RDFConfiguration/fileVersion"
        #print "Checking version of file {0} using string {1}".format(file, fileVerStr)

        # ver = subprocess.check_output(['h5ls', '-d', fileVerStr])
        proc = Popen(['h5ls', '-d', fileVerStr], stdout=PIPE)
        verList = proc.communicate()[0].split()
        if verList:
                print "RDF version: {0}.{1}".format(verList[verList.index('minorVersion')-1], verList[-1])
        else:
                print "RDF version not available"


if __name__=="__main__":
        printRdfVer()

flood4Rdata.rdf RDF version: 9.7
flood4Rnorm.rdf RDF version: 9.7
flood4Rpifa.dat/HeaderData/RDFConfiguration/fileVersion: unable to open file
flood4Rpifa.dat RDF version not available
Norm_Data.rdf RDF version: 9.7
Norm_NormFile.rdf RDF version: 9.7
Norm_pifa.dat/HeaderData/RDFConfiguration/fileVersion: unable to open file
Norm_pifa.dat RDF version not available
WCC_Data.rdf RDF version: 9.7
WCC_Norm.rdf RDF version: 9.7
WCC_pifa.dat/HeaderData/RDFConfiguration/fileVersion: unable to open file
WCC_pifa.dat RDF version not available
[ctuser@jaws4:Wed Dec 06:/petRDFS/ReconAutotest:]$ for f in $( ls ) ; do  prntRdfVer.py $f ; done  | tee ~/yosi/ver

    ->
g. 
        5.2.2 Test modified rdfAccept code
            5.2.2.1 a. modify code, build 
[de680136@ctds64-4:Thu Dec 07:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ cmake
...
check artifacts:

[de680136@ctds64-4:Thu Dec 07:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ ls sles11-x86_64/
ConversionPipeline.o  librdfAccept.so*   rdfAcceptIdent.c  rdfAccept.o            rdfConvertUtils7.0to7.1.o  rdfConvertUtils9.0to10.0.o
librdfAccept.a        RdfAcceptConfig.o  rdfAcceptIdent.o  rdfConvertUtils10.0.o  rdfConvertUtils7.1to8.0.o  RdfVersion.o

            5.2.2.2 b. deploy to test machine

                5.2.2.2.1 deployRDFBinaries


[de680136@ctds64-4:Thu Dec 07:/vobs/pet_raw/source/librdfAccept/rdfAcceptLib:]$ scp sles11-x86_64/librdfAccept.so  ${USER_CT}@${JAWS4}:/usr/g/ctuser/yosi/
librdfAccept.so   

new version:
[de680136@nmpetdev64:2018-04-24 18:01:36:~/work/scripts:]6442$ ./deployRDFBinaries.sh  -m $JAWS -r  /usr/g/ctuser/yosi -n --a 64
[de680136@ctds32-2:Sun Dec 17:~/work/scripts:]$ deployRDFBinaries.sh 3.87.141.251
[de680136@nmpetdev64:2018-04-24 18:03:01:~/work/scripts:]6442$ ./deployRDFBinaries.sh 
This tool deploys RDF binaries to a target PET host machine
For building binaries it requires to be run in Clearcase view
A mandatory parameter is machine name or IP -m --machine machine name/ip
optional, -r --remote for remote staging directory. defaults to /usr/g/ctuser/yosi/stage/ 
optional, -n --nobuild for skipping build phase
optional, -a --arch 32 or 64 for 32/64bit arch. defaults to 32 bit

    use deploy script, ex: deploy to jaws4, old version:
Then on jaws4:
-rwxrwxr-x 1 ctuser users 1.1M Dec 17 03:08 librdfAccept.so*
-rwxrwxr-x 1 ctuser users 118K Dec 17 03:08 rdfAccept*
[ctuser@jaws4:Sun Dec 17:~/yosi/stage:]$ ldd rdfAccept 
        ...
librdfAccept.so => ./librdfAccept.so (0xf6e56000)
        ...

        code of new deploy script
        code of old deploy script
[de680136@ctds32-2:Sun Dec 17:~/work/scripts:]$ cat deployRDFBinaries.sh 
#!/bin/bash

#Author yosi.izaq@ge.com
# Description, build and deploy RDF tools binaries to target machine

# scp sles11-x86_64/librdfAccept.so  ${USER_CT}@${JAWS4}:/usr/g/ctuser/yosi/stage/

if [[ $# -ne 1 ]];then
    echo "plz provide target machine name. e.g. jaws4: ${JAWS4}"
    exit 0
fi

Tmachine="$1"
Tstage_dir="/home/de680136/work/scripts/stage/"
Trg_dir="/usr/g/ctuser/yosi/stage/"
Trg_usr="ctuser"

wink=false
#build=true
build=false
petRawDir="/vobs/pet_raw/source/"
#alias cmake="clearmake -C gnu "

usage()
{
echo "This tool deploys binary to a target PET host machine"
echo "For building binaries it requires to be run in Clearcase view"
}

buildRdfAccpet()
{
    if [[ "$build" == true ]] ; then
        echo "Will build and deploy artifacts to machine $Tmachine, stage dir: $Tstage_dir"
        echo "building rdfAccept" 
        cd ${petRawDir}rdfUtils/rdfAccept
        if [[ "$wink" == true ]] ; then
            echo "pulling in artificats..."
            /vobs/util/scripts/winkrecursive --view pac_col_ddg.4 /vobs/pet_raw/source/rdfUtils/rdfAccept/sles11\-i686/rdfAccept
        fi
        echo "unset LD_LIBRARY_PATH"
        unset LD_LIBRARY_PATH
        clearmake -C gnu 
    else
        echo "skipping build"
    fi
}

buildLibRdfAccpet()
{
    if [[ "$build" == true ]] ; then
        echo "Will build and deploy artifacts to machine $Tmachine, stage dir: $Tstage_dir"
        echo "building librdfAccept.so" 
        cd ${petRawDir}librdfAccept/rdfAcceptLib/ 
        clearmake -C gnu 
    else
        echo "skipping build"
    fi
}

scpBinaries()
{
    for bin in $(ls $Tstage_dir) ; do
        echo "Running: scp ${Tstage_dir}/$bin ${Trg_usr}@${Tmachine}:/${Trg_dir}/   "
        scp ${Tstage_dir}/$bin ${Trg_usr}@${Tmachine}:/${Trg_dir}/   
       done;
}

if cleartool pwv | grep 'view:*NONE' > /dev/null ; then
    usage
    exit 1
else
    echo "working on view $( cleartool pwv)"
fi

buildRdfAccpet
echo "Running: cp ${petRawDir}rdfUtils/rdfAccept/sles11-i686/rdfAccept ${Tstage_dir}/"
cp ${petRawDir}rdfUtils/rdfAccept/sles11-i686/rdfAccept ${Tstage_dir}/

buildLibRdfAccpet
echo "Running: cp ${petRawDir}librdfAccept/rdfAcceptLib/sles11-i686/librdfAccept.so  ${Tstage_dir}/"
cp ${petRawDir}librdfAccept/rdfAcceptLib/sles11-i686/librdfAccept.so  ${Tstage_dir}

scpBinaries

                5.2.2.2.2
            5.2.2.3 c. Apply changed so

    c1. lay of the land
which rdfAccept 
/usr/PET/release/dragon/bin/linux2/rdfAccept
[ctuser@jaws4:Thu Dec 07:~/yosi:]$ ldd $( which rdfAccept )
        linux-gate.so.1 =>  (0xffffe000)
        libconfigMgr.so => /usr/PET/lib/linux2/libconfigMgr.so (0xf77b3000)
        libpetlwc.so => /usr/PET/lib/linux2/libpetlwc.so (0xf77a8000)
        libH5Wrap.so => /usr/PET/lib/linux2/libH5Wrap.so (0xf7775000)
        libgebase2.so => /usr/PET/lib/linux2/libgebase2.so (0xf7728000)
        libpetbase.so => /usr/PET/lib/linux2/libpetbase.so (0xf7701000)
        libpetcfg.so => /usr/PET/lib/linux2/libpetcfg.so (0xf76f5000)
        libpethwcfg2.so => /usr/PET/lib/linux2/libpethwcfg2.so (0xf76e9000)
        libErr.so => /usr/PET/lib/linux2/libErr.so (0xf76de000)
        librdf.so => /usr/PET/lib/linux2/librdf.so (0xf76d1000)
        librdfCpp.so => /usr/PET/lib/linux2/librdfCpp.so (0xf7586000)
        librivn.so => /usr/PET/lib/linux2/librivn.so (0xf757a000)
        libRawPrimitives.so => /usr/PET/lib/linux2/libRawPrimitives.so (0xf755f000)
        libobrivn.so => /usr/PET/lib/linux2/libobrivn.so (0xf753a000)
        libEvtList.so => /usr/PET/lib/linux2/libEvtList.so (0xf74d5000)
        libreadcfg.so => /usr/lib/libreadcfg.so (0xf73c7000)
        libmsghand.so => /usr/lib/libmsghand.so (0xf73b7000)
        libcupipc.so => /usr/lib/libcupipc.so (0xf73ab000)
        libdebug.so => /usr/lib/libdebug.so (0xf73a4000)
        libeventmgr.so => /usr/lib/libeventmgr.so (0xf7393000)
        libplatform_misc.so => /usr/lib/libplatform_misc.so (0xf738e000)
        libhdf5.so.10 => /usr/lib/libhdf5.so.10 (0xf70a7000)
        libhdf5_hl.so.10 => /usr/lib/libhdf5_hl.so.10 (0xf7085000)
        libpthread.so.0 => /lib/libpthread.so.0 (0xf706a000)
        librdfv7.0.so => /usr/PET/lib/linux2/librdfv7.0.so (0xf7040000)
        librdfv7.1.so => /usr/PET/lib/linux2/librdfv7.1.so (0xf7016000)
        librdfv8.0.so => /usr/PET/lib/linux2/librdfv8.0.so (0xf6fbf000)
        librdfv9.0.so => /usr/PET/lib/linux2/librdfv9.0.so (0xf6f39000)
        librdfAccept.so => /usr/PET/lib/linux2/librdfAccept.so (0xf6ef6000)
        libstdc++.so.6 => /usr/lib/libstdc++.so.6 (0xf6e0a000)
        libm.so.6 => /lib/libm.so.6 (0xf6de1000)
        libgcc_s.so.1 => /lib/libgcc_s.so.1 (0xf6dc3000)
        libc.so.6 => /lib/libc.so.6 (0xf6c51000)
        librt.so.1 => /lib/librt.so.1 (0xf6c46000)
        libz.so.1 => /lib/libz.so.1 (0xf6c2f000)
        libdl.so.2 => /lib/libdl.so.2 (0xf6c2a000)
        /lib/ld-linux.so.2 (0xf77c9000)
        libfile.so => /usr/PET/lib/linux2/libfile.so (0xf6c24000)
        libcfg.so => /usr/PET/lib/linux2/libcfg.so (0xf6c1d000)

[ctuser@jaws4:Thu Dec 07:~/yosi:]$ ll  /usr/PET/lib/linux2/librdfAccept.so
lrwxrwxrwx 1 ctuser users 44 Nov 28 23:30 /usr/PET/lib/linux2/librdfAccept.so -> /usr/PET/lib/linux2/librdfAccept.so.32.VIKAS*

    c2.  link lib to my .so
[ctuser@jaws4:Thu Dec 07:~/yosi:]$ cp librdfAccept.so   /usr/PET/lib/linux2/librdfAccept.so.yosi

    c3.

            5.2.2.4 d. patch/unpatch/display scripts
    d1. my patcher script
[212680136@G9VK2GH2E:Sun Dec 10:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/scripts/work_utils:]$ scp ${USER_CT}@${JAWS4}:/usr/g/ctuser/yosi/patcher.sh .
patcher.sh 

-> Run example
{ctuser@jaws4}./patcher.sh
1) help,                                4) unpatch revert back to LFC version,
2) backup LFC to .yosi,                 5) display current binaries status
3) patch to .yosi version,
Please enter choice: 4
4 option selected: unpatch revert back to LFC version,
unpatch revert back to LFC version
Removing 64 bit binary /usr/PET/lib64/linux2/libEvtList.so
Patching 64 bit binary /usr/PET/lib64/linux2/libEvtList.so
Removing 64 bit binary /usr/PET/lib64/linux2/libgleplMI.so
Patching 64 bit binary /usr/PET/lib64/linux2/libgleplMI.so

-> Code
r /cygdrive/c/Users/212680136/Desktop/Yosi/Work/scripts/work_utils/GE/patcher.sh 

#!/bin/bash

#Author: yosi.izaq@ge,com
# usage patcher.py , then follow menu for options

usage()
{
echo "Run patcher.py , then follow menu for options" 
}

PETLib64="/usr/PET/lib64/linux2"
PETLib64Files=("$PETLib64/libEvtList.so" "$PETLib64/libobrivn.so"  "$PETLib64/libRawPrimitives.so"  "$PETLib64/librdfAccept.so"  "$PETLib64/librdfCpp_JNI_wrap.so"  "$PETLib64/librdfCpp.so"  "$PETLib64/librdf.so"  "$PETLib64/librdfv7.0.so"  "$PETLib64/librdfv7.1.so"  "$PETLib64/librdfv8.0.so"  "$PETLib64/librdfv9.0.so"  "$PETLib64/librivn.so" "$PETLib64/hdf_plugins/libobrivn.so" )

PETLib="/usr/PET/lib/linux2" 
PETLibFiles=("$PETLib/libEvtList.so" "$PETLib/libobrivn.so"  "$PETLib/libRawPrimitives.so"  "$PETLib/librdfAccept.so"  "$PETLib/librdfCpp_JNI_wrap.so"  "$PETLib/librdfCpp.so"  "$PETLib/librdf.so"  "$PETLib/librdfv7.0.so"  "$PETLib/librdfv7.1.so"  "$PETLib/librdfv8.0.so"  "$PETLib/librdfv9.0.so"  "$PETLib/librivn.so" "/usr/PET/release/acq/bin/rdfTell" "/usr/local/hdf5/lib/plugin/libobrivn.so" )

PETRelease="/usr/PET/release/"
PETReleaseFiles=("$PETRelease/dragon/bin/linux2/rdfTell" "$PETRelease/dragon/bin/linux2/rdfAccept" "$PETRelease/acq/bin/pet_acq"  "$PETRelease/petig/pet_recon"  "$PETRelease/petig/pet_recon_0"  "$PETRelease/petig/pet_recon_1"  "$PETRelease/petig/pet_recon_2"  "$PETRelease/petig/pet_recon_3"  )

backup()
{
echo "backup LFC to .yosi" 
echo "============================================================"
for f in "${PETLib64Files[@]}"
do
#	echo "copying $f to ${f}.yosi"
	cp -f $f "${f}.yosi"
	ls -ltr  "${f}.yosi"
done
echo "============================================================"

for f in "${PETLibFiles[@]}"
do
#	echo "copying $f to ${f}.yosi"
	cp -f $f "${f}.yosi"
	ls -ltr  "${f}.yosi"
done
obrivn="/usr/local/hdf5/lib/plugin/libobrivn.so" 
cp $obrivn ~/yosi/bins/libobrivn.so.yosi
ls -l ~/yosi/bins/libobrivn.so.yosi
echo "============================================================"

for f in "${PETReleaseFiles[@]}"
do
#	echo "copying $f to ${f}.yosi"
	cp -f $f "${f}.yosi"
	ls -ltr  "${f}.yosi"
done
echo "============================================================"
}

display()
{
echo "display current binaries status" 
echo "============================================================"
#echo ${PETLib64Files[@]}
for f in "${PETLib64Files[@]}"
do
	ls -ltr $f
done
echo "============================================================"

for f in "${PETLibFiles[@]}"
do
	ls -ltr $f
done
echo "============================================================"

#echo ${PETReleaseFiles[@]}
for f in "${PETReleaseFiles[@]}"
do
	ls -ltr $f
done
echo "============================================================"
}

restart()
{
echo "Restarting PetAcqMgr, pet_acq and DetCalServer "
cupShutdown restart PetAcqMgr
cupShutdown restart pet_acq
cupShutdown restart DetCalServer
}

patch()
{

echo "patch to .yosi version" 

patch64libs=( "$PETLib64/libEvtList.so" "$PETLib64/libgleplMI.so" "$PETLib64/libobrivn.so" "$PETLib64/libRawPrimitives.so" "$PETLib64/librdfAccept.so" "$PETLib64/librdfCpp_JNI_wrap.so" "$PETLib64/librdfCpp.so" "$PETLib64/librdf.so" "$PETLib64/librdfv7.0.so" "$PETLib64/librdfv7.1.so" "$PETLib64/librdfv8.0.so" "$PETLib64/librdfv9.0.so" "$PETLib64/librivn.so" "$PETLib64/hdf_plugins/libobrivn.so" "$PETRelease/acq/bin/rdfTell" "$PETRelease/acq/bin/pet_acq")
patch32libs=("$PETLib/libEvtList.so" "$PETLib/libgleplMI.so" "$PETLib/libobrivn.so" "$PETLib/libRawPrimitives.so" "$PETLib/librdfAccept.so" "$PETLib/librdfCpp_JNI_wrap.so" "$PETLib/librdfCpp.so" "$PETLib/librdf.so" "$PETLib/librdfv7.0.so" "$PETLib/librdfv7.1.so" "$PETLib/librdfv8.0.so" "$PETLib/librdfv9.0.so" "$PETLib/librivn.so" "$PETRelease/dragon/bin/linux2/rdfTell" "$PETRelease/dragon/bin/linux2/rdfAccept")

echo "checking staging dir"
stageDir="$HOME/yosi/stage" 
for file in $( ls ${stageDir})
do

	filepath="${stageDir}/${file}"
	echo "Examining binary $filepath"
	file $filepath | grep '64-bit' > /dev/null
	if [[ $? == 0 ]]; then
		echo "$filepath is 64 bit"
		for lib in "${patch64libs[@]}"
		do
			#echo "check match to lib $lib vs $file"
			if [[ $lib =~ ${file} ]]; then
				echo "found lib $lib. Creating $lib.yosi"
				cp -f $filepath $lib.yosi
				ls -l $lib.yosi
			fi
		done
	else 
		echo "$filepath is 32 bit"
		for lib in "${patch32libs[@]}"
		do
			#echo "check match to lib $lib vs $file"
			if [[ $lib =~ ${file} ]]; then
				echo "found lib $lib. Creating $lib.yosi"
				cp -f $filepath $lib.yosi
				ls -l $lib.yosi
			fi
		done
	fi
done 
for f in "${patch64libs[@]}"
do
	echo "Removing 64 bit binary $f"
	rm -f $f
	echo "Patching 64 bit binary $f"
	ln -sf "${f}.yosi" $f
done


for f in "${patch32libs[@]}"
do
	echo " Removing 32 bit binary $f"
	rm -f $f
	echo "Patching 32 bit binary $f"
	ln -sf "${f}.yosi" $f
done

display
restart

}

unpatch()
{
echo "unpatch revert back to LFC version" 

patch64libs=( "$PETLib64/libEvtList.so" "$PETLib64/libgleplMI.so" "$PETLib64/libobrivn.so" "$PETLib64/libRawPrimitives.so" "$PETLib64/librdfAccept.so" "$PETLib64/librdfCpp_JNI_wrap.so" "$PETLib64/librdfCpp.so" "$PETLib64/librdf.so" "$PETLib64/librdfv7.0.so" "$PETLib64/librdfv7.1.so" "$PETLib64/librdfv8.0.so" "$PETLib64/librdfv9.0.so" "$PETLib64/librivn.so" "$PETLib64/hdf_plugins/libobrivn.so" "$PETRelease/acq/bin/rdfTell" "$PETRelease/acq/bin/pet_acq")
for f in "${patch64libs[@]}"
do
	echo "Removing 64 bit binary $f"
	rm -f $f
	echo "Patching 64 bit binary $f"
	ln -sf "${f}.LFC" $f
done

patch32libs=("$PETLib/libEvtList.so" "$PETLib/libgleplMI.so" "$PETLib/libobrivn.so" "$PETLib/libRawPrimitives.so" "$PETLib/librdfAccept.so" "$PETLib/librdfCpp_JNI_wrap.so" "$PETLib/librdfCpp.so" "$PETLib/librdf.so" "$PETLib/librdfv7.0.so" "$PETLib/librdfv7.1.so" "$PETLib/librdfv8.0.so" "$PETLib/librdfv9.0.so" "$PETLib/librivn.so" "$PETRelease/dragon/bin/linux2/rdfTell" "$PETRelease/dragon/bin/linux2/rdfAccept")

for f in "${patch32libs[@]}"
do
	echo " Removing 32 bit binary $f"
	rm -f $f
	echo "Patching 32 bit binary $f"
	ln -sf "${f}.LFC" $f
done

display
restart

}


PS3='Please enter choice: '
options=('help', 'backup LFC to .yosi', 'patch to .yosi version', 'unpatch revert back to LFC version', 'display current binaries status')
select opt in "${options[@]}"
do
	case $REPLY in 
		1)
			echo "$REPLY option selected: $opt"
			usage
			;;
		2)
			echo "$REPLY option selected: $opt"
			backup
			;;
		3)
			echo "$REPLY option selected: $opt"
			patch
			;;
		4) 
			echo "$REPLY option selected: $opt"
			unpatch
			;;
		5)
			echo "$REPLY option selected: $opt"
			display
			;;
		*) 
			echo "plz choose a valid option"
			usage
			;;
	esac
done

->
    d2. Sravan's patch scripts
Yakkali, Sravan (GE Healthcare):  
there are 3 scripts in /usr/g/ctuser/vikas directory
patch, unpath, display
that should help you
 

unpatch will revert?
 
Yakkali, Sravan (GE Healthcare):  
yes
 

display - show
 

?
 
Yakkali, Sravan (GE Healthcare):  
yes
 
patch, restore ur stuff?
 
->

            5.2.2.5 Test in sandbox
-> summary Workflow
    --> On 32bit dev machine
 3947  export_ssh_pub_key ${USER_CT} $JAWS
 3948  deployRDFBinaries.sh $JAWS 
 3952  cdpetGalLists 
 3955  scptm BGO8x8_5_TUBEQAT.tar.bz2 $JAWS


    --> On my laptop
 2055  export_ssh_pub_key $USER_CT  $JAWS
 2061  scptm yosit.tarz $JAWS
sshj

    --> on host test machine 
    tar xvf yosit.tarz 
    cp yosi/.screenrc .
    screen -R
    . ~/yosi/.bashrc
export RDF_SKIP_USER_BLOCK_CHECK="TRUE"
[ctuser@jaws:2018-03-01 02:05:18:~/yosi/stage:]6$ mv ~/BGO8x8_5_TUBEQAT.tar.bz2 .
[ctuser@jaws:2018-03-01 02:05:30:~/yosi/stage:]7$ tar xvf BGO8x8_5_TUBEQAT.tar.bz2
[ctuser@jaws:2018-03-01 02:08:07:~/yosi/stage:]8$ ./rdfAccept  $(pwd)/BGO8x8_5_TUBEQAT/CirclesPerSlice.BLF 
[ctuser@jaws:2018-03-01 02:11:50:~/yosi/stage:]9$ ed /usr/PET/systemConfig/local/rdfAccept.cfg
$-4,$s/False/True/
$-4,$p
[ctuser@jaws:2018-03-01 02:46:33:~/yosi/stage:]11$ ./rdfAccept  $(pwd)/BGO8x8_5_TUBEQAT/CirclesPerSlice.BLF
[ctuser@jaws:2018-03-01 02:46:33:~/yosi/stage:]11$ gdb --args ./rdfAccept  $(pwd)/BGO8x8_5_TUBEQAT/CirclesPerSlice.BLF


    

->
deploy binary + .so to /usr/g/ctuser/yosi/stage
Can use script e.g. deployRDFBinaries.sh 3.87.141.251
verify using costum .so
[ctuser@jaws4:Mon Dec 18:~/yosi/stage:]$ ldd rdfAccept  | grep '\./'
        libH5Wrap.so => ./libH5Wrap.so (0xf7703000)
        librdfCpp.so => ./librdfCpp.so (0xf7510000)
        librdfAccept.so => ./librdfAccept.so (0xf6e82000)

run:
[ctuser@jaws4:Mon Dec 18:~/yosi/stage:]$ ./rdfAccept  ~/yosi/1Frame_Flood_Data.rdf 
Source RDF version: 9.0
Starting RDFv9.0 conversion...
01:50:24.875 Error /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp(6847) in uint32_t CRdfBase::ReadUserBlock(RDF_H5_USER_BLOCK_BASE*): [Mon Dec 18 01:50:24 2017]/usr/g/ctuser/yosi/stage//AAIYKAJR/AIVQTMJB/AJUWRBEU/SINO0006 is not a valid GE RDF file
01:50:24.875 Error /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfBase.cpp(6930) in bool CRdfBase::VerifyUserBlock(): [Mon Dec 18 01:50:24 2017]No user block
01:50:24.875 Error /vobs/pet_raw/source/rdfAPI/librdfCpp/RdfFile.cpp(633) in bool CRdfFile::Open(const std::string&, int, bool): [Mon Dec 18 01:50:24 2017]Could not verify integrity of /usr/g/ctuser/yosi/stage//AAIYKAJR/AIVQTMJB/AJUWRBEU/SINO0006
Segmentation fault

user block check will cause crash. must disable it first.
[ctuser@jaws4:Mon Dec 18:~/yosi/stage:]$ export RDF_SKIP_USER_BLOCK_CHECK="TRUE"
[ctuser@jaws4:Mon Dec 18:~/yosi/stage:]$ ./rdfAccept  ~/yosi/1Frame_Flood_Data.rdf 
Source RDF version: 9.0
Starting RDFv9.0 conversion...
01:52:22.755 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2211) in convertRdf(): new RDFv10.0 filename is /usr/g/ctuser/yosi/stage//AAIYKAJR/AIVQTMJB/AJUWRBEU/SINO0008
01:52:22.755 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2227) in convertRdf(): Converting header data
01:52:22.755 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1089) in ConvertHeaderData(): Converting RDF configuration Header
01:52:22.758 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1130) in ConvertHeaderData(): Converting Sys Geo Header
01:52:22.767 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1142) in ConvertHeaderData(): Converting Acq Stats Header
01:52:22.772 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1155) in ConvertHeaderData(): Converting Sorter Header
01:52:22.792 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1168) in ConvertHeaderData(): Converting Acq Parameters Header
01:52:22.809 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1180) in ConvertHeaderData(): Converting Exam Data  Header
01:52:22.817 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1193) in ConvertHeaderData(): Converting DMOD Signature Header
01:52:22.820 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1206) in ConvertHeaderData(): Converting Cal Header
01:52:22.822 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1219) in ConvertHeaderData(): Converting Deadtime Header
01:52:22.826 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1240) in ConvertHeaderData(): Converting Singles Header
01:52:22.828 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1257) in ConvertHeaderData(): Converting 3D Xtal Efficiency Header
01:52:22.829 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1270) in ConvertHeaderData(): Converting CTC Timediff Header
01:52:22.829 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1289) in ConvertHeaderData(): Converting RDF configuration Header (again)
01:52:22.860 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2232) in convertRdf(): Done converting header data
Converting Segment 2 data01:52:22.867 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(502) in ConvertSegmentData(): Size of each slice is 25485565 elements

-> Test list files
[ctuser@jaws4:Sun Dec 24:~/yosi/stage:]$ for lfile in $( find /petLists/acqAutoTest_RDFv9/ -name '*.BLF'  ); do echo "-------------------------"; echo "Accepting $lfile"; ./rdfAccept $lfile ; ../printRDFUserBlock.py ${lfile##*/} ; done | tee accept_list_files_report

[ctuser@jaws4:Sun Dec 24:~/yosi/stage:]$ head -60 accept_list_files_report
-------------------------
Accepting /petLists/acqAutoTest_RDFv9/NON_NATIVE/BGO8x8_5_TUBEQAT_RDFv9.BLF
Source RDF version: 9.0
Starting RDFv9.0 conversion...
07:50:16.731 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2161) in convertRdf(): new RDFv10.0 filename is /usr/g/ctuser/yosi/stage//AIDSWVSW/ALAIEDLE/AHPVTAAP/LIST0000.BLF
07:50:16.731 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2170) in convertRdf(): Converting header data
07:50:16.732 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1092) in ConvertHeaderData(): Converting RDF configuration Header
07:50:16.735 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1133) in ConvertHeaderData(): Converting Sys Geo Header
07:50:16.746 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1145) in ConvertHeaderData(): Converting Acq Stats Header
07:50:16.751 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1158) in ConvertHeaderData(): Converting Sorter Header
07:50:16.770 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1171) in ConvertHeaderData(): Converting Acq Parameters Header
07:50:16.788 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1183) in ConvertHeaderData(): Converting Exam Data  Header
07:50:16.796 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1196) in ConvertHeaderData(): Converting DMOD Signature Header
07:50:16.798 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1209) in ConvertHeaderData(): Converting Cal Header
07:50:16.800 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1222) in ConvertHeaderData(): Converting Deadtime Header
07:50:16.803 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1243) in ConvertHeaderData(): Converting Singles Header
07:50:16.806 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1260) in ConvertHeaderData(): Converting 3D Xtal Efficiency Header
07:50:16.806 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1273) in ConvertHeaderData(): Converting CTC Timediff Header
07:50:16.807 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1292) in ConvertHeaderData(): Converting RDF configuration Header (again)
07:50:16.825 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2175) in convertRdf(): Done converting header data
07:50:16.842 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1980) in ConvertListData(): Converting List Header 
07:50:16.854 libH5Wrap.Info  H5Wrap.cpp(263) in OpenFile(): File /usr/g/ctuser/yosi/stage//AIDSWVSW/ALAIEDLE/AHPVTAAP/LIST0000.BLF opened with DIRECT_IO, with alignment=512, block_size=4096 and cbuf_size=33554432 flag.
07:50:17.200 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1329) in ConvertPUCData(): Converting 3D PUC factors
07:50:17.208 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1389) in ConvertPUCData(): New RDF dt_3dcrystalpileUp_factors checksum: 928962685
07:50:17.208 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1390) in ConvertPUCData(): Orig RDF dt_3dcrystalpileUp_factors checksum: 928962685
07:50:17.212 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1432) in ConvertPUCData(): New RDF dt_3dpileUp_factors checksum: 626395739
07:50:17.212 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1433) in ConvertPUCData(): Orig RDF dt_3dpileUp_factors checksum: 626395739
07:50:17.239 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1829) in Convert3DCrystalEfficiencyData(): No 3D Crystal Efficiency data in this RDF
07:50:17.248 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1478) in ConvertDetectorModSerialNumbers(): Converting detector module serial numbers
07:50:17.249 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1496) in ConvertDetectorModSerialNumbers(): 18 Detector Modules in this system
07:50:17.255 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1528) in ConvertDetectorModSerialNumbers(): Orig DMOD serial numbers Checksum: -1497122044
07:50:17.255 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1529) in ConvertDetectorModSerialNumbers(): New DMOD serial numbers Checksum: -1497122044
07:50:17.258 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1599) in ConvertDetectorModTemps(): Orig DMOD Temp Checksum: 1276379461
07:50:17.258 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1600) in ConvertDetectorModTemps(): New DMOD Temp Checksum: 1276379461
07:50:17.263 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1693) in ConvertDetectorBlockValidFlags(): Orig DMOD BlkValid Checksum: 533004379
07:50:17.263 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(1694) in ConvertDetectorBlockValidFlags(): New DMOD BlkValid Checksum: 533004379
07:50:17.280 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(799) in ConvertSinglesData(): Converting singles samples
07:50:17.772 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(252) in ConvertDeadTimeData(): isMuxTypeCounts 1
07:50:17.772 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(256) in ConvertDeadTimeData(): Reading Block busy samples
07:50:17.783 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(278) in ConvertDeadTimeData(): Reading mux samples
07:50:17.820 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(286) in ConvertDeadTimeData(): Reading DT Event samples
07:50:17.881 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(295) in ConvertDeadTimeData(): Converting Dead Time samples
07:50:17.904 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(417) in ConvertDeadTimeData(): Writing Dead Time samples
07:50:17.942 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(673) in ConvertUserBlock(): Attempt to open rdfv10 file /usr/g/ctuser/yosi/stage//AIDSWVSW/ALAIEDLE/AHPVTAAP/LIST0000.BLF
07:50:17.942 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(685) in ConvertUserBlock(): Attempt to initialize rdfv10 user block (size 512)
07:50:17.950 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(698) in ConvertUserBlock(): Attempt to write rdfv10 user block;
07:50:17.984 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(713) in ConvertUserBlock(): finished Successfully
07:50:18.003 rdfConvertUtils9.0to10.0.Debug rdfConvertUtils9.0to10.0.cc(2368) in convertRdf(): Destination NOT different....moving /usr/g/ctuser/yosi/stage//AIDSWVSW/ALAIEDLE/AHPVTAAP/LIST0000.BLF to /usr/g/ctuser/yosi/stage/
Conversion from RDFv9.0 to RDFv9.7 succeeded.
RDF accepted

Time taken to convert RDF :: 1 seconds 509 milli-seconds 
user block struct: (305441741, 1, 9, 7, -1830557531)
IS_GE_RDF_FILE magic num: 0x1234abcd. expected 0x1234abcd
UserBlock version: 1
RDF version: 9.7
CRC: decimal=-1830557531, hex=-0x6d1c175b

    --> Note disk quota exceeded so last tests faile. Fix, work on bigger disk...
 511  cd /petLists/
  516  cp -r acqAutoTest_RDFv9/ acqAutoTest_yosi
  517  cd acqAutoTest_yosi
  521  cp -r ~/yosi/stage/ .
  522  cd stage/
  523  for lfile in $( find /petLists/acqAutoTest_RDFv9/ -name '*.BLF'  ); do echo "-------------------------"; echo "Accepting $lfile"; ./rdfAccept $lfile ; ~/yosi/printRDFUserBlock.py ${lfile##*/} ; done | tee accept_list_files_report


    -->
->
            5.2.2.6  My 9.0 to 9.8 rdfAccept tester
script: /cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv/rdfAcceptTester.py
[ctuser@jaws:2018-03-22 04:59:13:~/yosi:]537$  ~/yosi/rdfAcceptTester.py /petLists/acqAutoTest/listData/9.7/GatedDP_PART0000.BLF && cp rdfAcceptTester.log rdfAcceptTesterGatedDP_PART0000.log
File GatedDP_PART0000.BLF has been accepted and verified via ListDecode -s and -t successfuly
[ctuser@jaws:2018-03-22 06:07:42:~/yosi:]538$  ~/yosi/rdfAcceptTester.py 1.BLF && cp rdfAcceptTester.log 1.log
[ctuser@jaws:2018-03-22 06:08:06:~/yosi:]538$  ~/yosi/rdfAcceptTester.py /petLists/acqAutoTest/listData/9.7/GatedDP_PART0001.BLF && cp rdfAcceptTester.log rdfAcceptTesterGatedDP_PART0001.log
File GatedDP_PART0001.BLF has been accepted and verified via ListDecode -s and -t successfuly
[ctuser@jaws:2018-03-22 06:08:40:~/yosi:]539$  ~/yosi/rdfAcceptTester.py /petLists/acqAutoTest/listData/9.7/GatedDP_PART0002.BLF && cp rdfAcceptTester.log rdfAcceptTesterGatedDP_PART0002.log
File GatedDP_PART0002.BLF has been accepted and verified via ListDecode -s and -t successfuly
[ctuser@jaws:2018-03-22 06:09:04:~/yosi:]540$  ~/yosi/rdfAcceptTester.py /petLists/acqAutoTest/listData/9.7/GatedDP_PART0003.BLF && cp rdfAcceptTester.log rdfAcceptTesterGatedDP_PART0003.log
File GatedDP_PART0003.BLF has been accepted and verified via ListDecode -s and -t successfuly
[ctuser@jaws:2018-03-22 06:09:45:~/yosi:]541$  ~/yosi/rdfAcceptTester.py /petLists/acqAutoTest/listData/9.7/GatedDP_PART0004.BLF && cp rdfAcceptTester.log rdfAcceptTesterGatedDP_PART0004.log
File GatedDP_PART0004.BLF has been accepted and verified via ListDecode -s and -t successfuly

            5.2.2.7


        5.2.3 Where are RDF files?

            5.2.3.1 RDF files
/petRDFS/ReconAutotest

            5.2.3.2 List files
[ctuser@jaws4:Sun Dec 24:/petLists:]$ for f in $(find -name '*.BLF'); do ~/yosi/prntRdfVer.py $f ;done  | grep '9.0'
./acqAutoTest_RDFv9/NON_NATIVE/BGO8x8_5_TUBEQAT_RDFv9.BLF RDF version: 9.0
...
./acqAutoTest_RDFv9/LYSO4x9_4_SIPMGEN1/TofListData.BLF RDF version: 9.0


            5.2.3.3 Norm Corrections files

            5.2.3.4

        5.2.4



    5.3 Test using real host GUI

        5.3.1 Connect to GUI
a. Launch gemsvnc
e.g.
ctuser@jaws4:~> gemsvnc 
Available pixmap depths: 1 4 8 15 16 24 32
Using SHM 1.1, shared pixmaps not supported.
Using display ":0.0": 2560x1024 at 24 bits (request 24 bit framebuffer tiles), 32 bits per pixel
26/12/2017 05:50:13 Listening for VNC connections on TCP port 5900
26/12/2017 05:50:13 Listening for HTTP connections on TCP port 5800
26/12/2017 05:50:13   URL http://jaws4:5800
GEMS VNC Server ready

b. connect using tightvnc


        5.3.2 Pull out specific image files using GUI

            5.3.2.1  Pull out norm Corrections  image files using GUI

 See icloud note re. add remote DB. get scan file

 use diagAnalysis to find out full path of file

                5.3.2.1.1  
                5.3.2.1.2

            5.3.2.2


        5.3.3


    
    5.4 customize test env

        5.4.1 Deploy My environment 
a. on laptop
[212680136@G9VK2GH2E:2018-01-16 14:13:23:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv:]1492$ scp yosi.tarz  ${USER_CT}@${JAWS4}:/usr/g/ctuser/

b. on target machine
{ctuser@jaws4}tar xvfz yosi.tarz 
yosi/
yosi/.aliases
yosi/.bashrc
yosi/.screenrc
yosi/bins/
yosi/cmd
yosi/display
yosi/gdb_cmds
yosi/history_copy
yosi/patch
yosi/patcher.sh
yosi/printRDFUserBlock.py
yosi/prntRdfVer.py
yosi/rdfAcceptDepends
yosi/st
yosi/unpatch
yosi/ver
{ctuser@jaws4}mv yosi/.screenrc  .

[212680136@G9VK2GH2E:2018-01-09 16:06:52:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv:]1420$ tar tvf yosi.tarz 
drwxr-xr-x 212680136/Domain Users 0 2018-01-09 09:19 yosi/
-rwx------ 212680136/Domain Users 35684 2018-01-09 16:06 yosi/.aliases
-rwx------ 212680136/Domain Users  4194 2017-12-25 11:39 yosi/.bashrc
-rw-r--r-- 212680136/Domain Users  1949 2018-01-09 16:04 yosi/.screenrc
drwxr-xr-x 212680136/Domain Users     0 2018-01-09 09:19 yosi/bins/
-rw-r--r-- 212680136/Domain Users   206 2017-12-06 11:38 yosi/cmd
-rwxr-xr-x 212680136/Domain Users  1903 2017-12-10 09:49 yosi/display
-rw-r--r-- 212680136/Domain Users   100 2018-01-08 10:13 yosi/gdb_cmds
-rw-r--r-- 212680136/Domain Users 25224 2018-01-08 09:51 yosi/history_copy
-rwxr-xr-x 212680136/Domain Users  3894 2017-12-10 09:51 yosi/patch
-rwxr-xr-x 212680136/Domain Users  6598 2017-12-10 14:57 yosi/patcher.sh
-rwxr-xr-x 212680136/Domain Users  1037 2017-12-20 17:41 yosi/printRDFUserBlock.py
-rwxr-xr-x 212680136/Domain Users   794 2017-12-06 16:39 yosi/prntRdfVer.py
-rwxr-xr-x 212680136/Domain Users  2230 2017-12-10 16:10 yosi/rdfAcceptDepends
-rw-r--r-- 212680136/Domain Users   135 2017-12-07 14:33 yosi/st
-rwxr-xr-x 212680136/Domain Users  3457 2017-12-10 09:49 yosi/unpatch
-rw-r--r-- 212680136/Domain Users    78 2017-12-07 08:31 yosi/ver

        5.4.2


    5.5 binaries locations

        5.5.1 PAR (PET Acquisition and Reconstruction inner host)
Note. PAR is a guest machine on the host.
It shares the same FS.

            5.5.1.1 pet_acq - main Acquisition Executable 
Note. pet_acq has all /vobs/pet_acq libraries staticaly linked
From pet_raw/cal/plat it dynamically loads the libraries.

ctuser@par:/usr/PET/release/acq/bin> file pet_acq 
pet_acq: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), for GNU/Linux 2.6.4, dynamically linked (uses shared libs), not stripped

ctuser@par:/usr/PET/release/acq/bin> ldd pet_acq | grep PET
        libCalFile.so => /usr/PET/lib64/linux2/libCalFile.so (0x00007fcf276a2000)
        libDetCalCommon.so => /usr/PET/lib64/linux2/libDetCalCommon.so (0x00007fcf2748a000)
        libCoincEvt.so => /usr/PET/lib64/linux2/libCoincEvt.so (0x00007fcf2725c000)
        libCalCfgFile.so => /usr/PET/lib64/linux2/libCalCfgFile.so (0x00007fcf27047000)
        libEvtList.so => /usr/PET/lib64/linux2/libEvtList.so (0x00007fcf26de8000)
        librdf.so => /usr/PET/lib64/linux2/librdf.so (0x00007fcf26bde000)
        librdfCpp.so => /usr/PET/lib64/linux2/librdfCpp.so (0x00007fcf26887000)
        librivn.so => /usr/PET/lib64/linux2/librivn.so (0x00007fcf2667c000)
        libRawPrimitives.so => /usr/PET/lib64/linux2/libRawPrimitives.so (0x00007fcf26463000)
        libobrivn.so => /usr/PET/lib64/linux2/libobrivn.so (0x00007fcf26245000)
        libH5Wrap.so => /usr/PET/lib64/linux2/libH5Wrap.so (0x00007fcf26012000)
        libpetcfg.so => /usr/PET/lib64/linux2/libpetcfg.so (0x00007fcf25e07000)
        libpethwcfg2.so => /usr/PET/lib64/linux2/libpethwcfg2.so (0x00007fcf25bfd000)
        libpetlwc.so => /usr/PET/lib64/linux2/libpetlwc.so (0x00007fcf259f2000)
        libErr.so => /usr/PET/lib64/linux2/libErr.so (0x00007fcf257e7000)
        libfile.so => /usr/PET/lib64/linux2/libfile.so (0x00007fcf255df000)
        libcfg.so => /usr/PET/lib64/linux2/libcfg.so (0x00007fcf253d8000)
        libconfigMgr.so => /usr/PET/lib64/linux2/libconfigMgr.so (0x00007fcf251c3000)
        libpetbase.so => /usr/PET/lib64/linux2/libpetbase.so (0x00007fcf24f9a000)
        libgebase2.so => /usr/PET/lib64/linux2/libgebase2.so (0x00007fcf24d51000)
        libwcgroup.so => /usr/PET/lib64/linux2/libwcgroup.so (0x00007fcf24b4a000)
        libhdf5.so.10 => /usr/PET/parc/lib64/libhdf5.so.10 (0x00007fcf2370e000)
        libhdf5_hl.so.10 => /usr/PET/parc/lib64/libhdf5_hl.so.10 (0x00007fcf234ed000)

        5.5.2 Host machine

        5.5.3

    5.6 Manage machine

        5.6.1  List services
        pwho


        5.6.2 stop all services
        cleanMon 
cleanMon.oc

Before running cleanMon make sure that NOHOSTSHUTDOWN environment variable is set. e.g.
ctuser@jaws:~> grep -i nohost .cshrc
setenv NOHOSTSHUTDOWN 1


        5.6.3 restart machine

cleanMon.oc
su
#bigguy
reboot

        5.6.4 patch machine
a. on 64bit dev machine
~/work/scripts/deployAcqBinaries_64.sh  $JAWS

b.
a. on 32bit dev machine
~/work/scripts/deployAcqBinaries_32.sh  $JAWS

        5.6.5 Get machine version

            5.6.5.1 swhwinfo 
[ctuser@puma:2018-04-03 17:54:02:/petRDFS/MostRecentScan:]95$ swhwinfo 
pet_columbia.133.H40_PN_CM64_G_GTLNI:16x9x3_lyso

            5.6.5.2  petbayinfo 
http://rdarc1.ct.med.ge.com/~ctbuild/petbayinfo/

            5.6.5.3
        5.6.6


    5.7



6. Development

    6.1 rdfAccept

        6.1.1 9.7 UserBlock support
https://collaborator.engops.health.ge.com/ui#review:id=172386
https://collaborator.engops.health.ge.com/ui#review:id=176704
https://collaborator.engops.health.ge.com/ui#file:review=178694

        6.1.2 MICE support

            6.1.2.1 MICE code
see, <URL:#r=__Galileo_And_Mice_List_Headers__>
data:
EvtEnergies
EvtTimeIndex 
EvtXZPositions
TofEvts


            6.1.2.2 rdfAccept Conversion

            6.1.2.3 CRdfList code list file 
Mice RDF Accept code


a.  struct RDF_LIST_HEADER 
librdfAccept/rdf9.0lib/rdfExternal9_0.h|1271| <<global>> typedef struct RDF_LIST_HEADER RDF_LIST_HEADER;
rdfAPI/librdf/rdfExternal.h|1225| <<global>> typedef struct RDF_LIST_HEADER RDF_LIST_HEADER;

b. it is part of RDF_MEGA_HEADER 
librdfAccept/rdf9.0lib/rdfExternal9_0.h|1436| <<global>> RDF_LIST_HEADER listHeader;

c. RDF methods
read/write list header
rdfAPI/librdfCpp/RdfBase.h|191| <<global>> bool ReadListHeader(RDF_LIST_HEADER* listHdr);
rdfAPI/librdfCpp/RdfBase.h|192| <<global>> bool WriteListHeader(RDF_LIST_HEADER* listHdr);

rdfAPI/libEvtList/RdfList.cpp|233| <<Create>> RDF_LIST_HEADER listHeader;
rdfAPI/libEvtList/RdfList.cpp|1014| <<WriteListInfo>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1072| <<InitList>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1263| <<ReadListData>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1694| <<SetListCompressed>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1726| <<WriteListLen>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1751| <<WriteListLen>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1778| <<ParseListAndUpdateListInfo>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|1841| <<GetListLen>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|2493| <<GetListDuration>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|2537| <<GetListStartTime>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|2617| <<GetListEndTime>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|2701| <<SetListStartNEndTime>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|2717| <<UpdateListStartNEndTimeEvenIfCompressed>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|3666| <<isEventListCompressed>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|3683| <<getListCompressionAlgorithm>> RDF_LIST_HEADER listHdr;
rdfAPI/libEvtList/RdfList.cpp|3703| <<isCandidateForCompression>> RDF_LIST_HEADER listHdr;
rdfAPI/librdf/rdfReadLib.c|1016| <<swapRDFHeader>> RDF_LIST_HEADER *tempStruct;
rdfAPI/librdfCpp/RdfBase.cpp|754| <<ReadHeader>> readStatus = ReadListHeader( (RDF_LIST_HEADER *)pHdr );
rdfAPI/librdfCpp/RdfBase.cpp|848| <<WriteHeader>> writeStatus = WriteListHeader( (RDF_LIST_HEADER *)pHdr );
rdfAPI/librdfCpp/RdfFile.cpp|119| <<Create>> RDF_LIST_HEADER listHeader;

                6.1.2.3.1 CRdfList create list command line


d. Test code
rdfUtils/rdfCreateListTest/rdfCreateListTest.cpp|37| <<global>> static RDF_LIST_HEADER listHdr;
Create list file steps:
    d1. Fill create parameters struct
	SHARC_RDF_CREATE_PARAMS createParms;

    d2. call CRdfList::create()
	CRdfList rdfListTmp;
	stat = rdfListTmp.Create( &createParms, myRDFs, &rdfCreateFailInfo );

    d3. Open first created file
	CRdfList rdfList; 
	bool retlistVal = rdfList.Open( myRDFs[0], O_RDWR | o_direct, false );

    d4. calculate and append list data
    bool retValbytesWritten = rdfList.AppendListData((s8 *) myCoincEvts, listsize );

    d5. write list header
	bytesWritten = rdfList.WriteHeader( S_RDF_LIST_HDR, &listHdr, sizeof(listHdr) );

    d6.
    if(!rdfList.WriteBlockBusySamples(0, duration+SAMPLE_OVERSHOOT, &dtList))
        retValSingSamp = retValSingSamp && rdfList.WriteSingles(index, 1, &singlesList);
    if(!rdfList.WriteDTEvents(0, index-1, &dtList))
    if(!rdfList.WriteSampleRecord(pddSampleRecord))

                6.1.2.3.2 rdfImportRawList CLI
e. CLI
rdfUtils/rdfImportRawList/rdfImportRawList.cpp|67| <<global>> static RDF_LIST_HEADER listHdr;

                6.1.2.3.3 rdfAccept convert list file
f. rdfAccept
librdfAccept/rdf9.0lib/RdfBaseV9.cpp|678| <<ReadHeader>> headerSize = sizeof( RDF_LIST_HEADER );
librdfAccept/rdfAcceptLib/rdfConvertUtils8.0to9.0.cc|798| <<ConvertListData>> RDF_LIST_HEADER listHdr;
librdfAccept/rdfAcceptLib/rdfConvertUtils8.0to9.0.cc|1918| <<ConvertHeaderData>> rdf8_0::RDF_LIST_HEADER origListHeader;

g.

                6.1.2.3.4 list dataset references

[de680136@ctds64-1:2018-01-31 00:12:07:/vobs/pet_raw/source:]2768$ find -type f | xargs grep -is '/ListData/listData' 
./librdfAccept/rdfAcceptLib/rdfConvertUtils9.0to10.0.cc:            string dsetName("/ListData/listData");
./rdfAPI/libEvtList/ListPacker.cpp:    if (!m_fileWriter.OpenDataset(h5FileUtility, "/ListData/listData", 2U, 2U*1024U*1024U, openFlags, offset)) {
./rdfAPI/libEvtList/ListReader.cpp:        if (!m_fileReader.OpenDataset(pReq->m_h5FileUtility, "/ListData/listData", m_nBufs, m_bufSize)) {
./rdfAPI/libEvtList/ListWriter.cpp:                if (!m_fileWriter.OpenDataset(pReq->m_h5FileUtility, "/ListData/listData", m_nBufs, m_bufSize, openFlags, pReq->m_offset)) {
./rdfAPI/libEvtList/RdfList.cpp:                        if ( m_h5FileUtility->DoesDatasetExistInFile( "/ListData/listData" ) )
./rdfAPI/libEvtList/RdfList.cpp:                        m_h5FileUtility->RemoveDataset( "/ListData/listData" );
./rdfAPI/libEvtList/RdfList.cpp:                if ( !m_h5FileUtility->CreateChunkedDataset( "/ListData/listData", H5Wrap::UINT_8_LE, listdata_rank, listdata_dims, listdata_chunks, LIST_GZIP_LEVEL ) )
./rdfAPI/libEvtList/RdfList.cpp:        uint64_t currentListSize = (uint64_t)m_h5FileUtility->GetNumElementsInDataset( "/ListData/listData" );
./rdfAPI/libEvtList/RdfList.cpp:        if ( !m_h5FileUtility->ExtendChunkedDataset( "/ListData/listData", newListDataDims ) )
./rdfAPI/libEvtList/RdfList.cpp:        bytesWritten = m_h5FileUtility->WriteDatasetSlab( "/ListData/listData", (void*)listData, startPoint, elemCount );
./rdfAPI/libEvtList/RdfList.cpp:        listSize = m_h5FileUtility->GetNumElementsInDataset( "/ListData/listData" );
./rdfAPI/libEvtList/RdfList.cpp:                bytesRead = m_h5FileUtility->ReadDatasetSlab( "/ListData/listData", (void*) pBuff, startPoint, elemCount );

More info:

read list data

a. ListReader
/vobs/pet_raw/source/rdfAPI/libEvtList/ListReader.cpp
void * CListReader::RunCyclic()
{
    LOG_MSG_TRACE("Thread started");

    for (;;) {
        m_threadGate.WaitForResumeTio(0/*tio_msecs*/);      // block until Resume() is called (no timeout)

        TListReaderReq *pReq = static_cast<TListReaderReq *>(m_reqQueue.Pop());
        if (pReq == NULL) { break; }                        // end the thread
        LOG_MSG_TRACE("file: %s", pReq->m_filePath);

        if (!m_fileReader.OpenDataset(pReq->m_h5FileUtility, "/ListData/listData", m_nBufs, m_bufSize)) {
            LOG_MSG_FATAL("Open()");
            break;
        }
        LOG_MSG_TRACE("Opened: %s (seek %zu)", pReq->m_filePath, pReq->m_offset);

        while (!m_fileReader.IsEndOfFile()) {
            m_threadGate.WaitForResumeTio(0/*tio_msecs*/);  // block until Resume() is called (no timeout)
            CHDF5FileReaderReq req;        
            LOG_MSG_TRACE("AllocBuff");
            if (!m_fileReader.AllocBuff(req)) {
                LOG_MSG_FATAL("AllocBuff()");
                break;
            }                       
            LOG_MSG_TRACE("ReadBuff");
            if (!m_fileReader.ReadBuff(req)) {
                LOG_MSG_FATAL("Read()");
                break;
            }                        
            LOG_MSG_TRACE("PushReq");
            if (!m_fileReader.PushReq(req)) {
                LOG_MSG_FATAL("Push()");
                break;
            }
        }
        // we can close the file here but the buffer pool must remain until CloseStream() is called
        LOG_MSG_TRACE("Waiting for close: %s", pReq->m_filePath);
        m_fileReader.WaitForCloseStream();
        if (!m_fileReader.CloseDataset()) {        
            LOG_MSG_FATAL("Close()");
            break;
        }
        LOG_MSG_TRACE("Closed: %s", pReq->m_filePath);
        m_reqQueue.Free(pReq);
    }
    LOG_MSG_TRACE("thread ended");
    return NULL;
}

b. HDF5 reader
/vobs/pet_platform/source/libH5Wrap/HDF5FileReader.cpp

c. pre-allocated memory buffer pool
/vobs/pet_platform/source/libgebase2/BaseBuffPool.cpp

d. E2E example of converting Galileo events to mice
/vobs/pet_raw/source/rdfUtils/l2mice/l2mice.cpp
ConvertEvtListToArray()

                6.1.2.3.5

            6.1.2.4 Integration points

                6.1.2.4.1 DSS, DDWave

                    6.1.2.4.1.1 email: Hello Roman and Yosi,

DDWAVE_PIPELINE is new label, which you can use to view the code in /vobs/pet_ddwave/source/libDDWavePipeLine after updates to your config spec.

/vobs/pet_ddwave/source/libDDWavePipeLine/DynDownSamplerTask.cpp, is the task which does the read of a MICE file and send populates the m_histoList variable after SimpleSorter and Histogrammer. Function run in that file is point of your interest.

Shall wait for your response on the MICE2. 


                6.1.2.4.2 My details
[de680136@ctds64-1:2018-01-24 00:53:22:/vobs/pet_raw/source/rdfAPI/libMice/gtest:]2356$ ct mkbrtype -pbr -nc  yosi21_pac_col_ddg@/vobs/pet_ddwave
Created branch type "yosi21_pac_col_ddg".

[de680136@ctds64-1:2018-01-24 00:54:21:/vobs/pet_raw/source/rdfAPI/libMice/gtest:]2357$ ct catcs
element * CHECKEDOUT
element /vobs/util/... UTIL1.71 -nocheckout
element /vobs/product-soup/... PRODUCT-SOUP1.31 -nocheckout
element /vobs/coreload/...  CSER_3_1_14_RFV1_V1_20170227 -nocheckout
element /vobs/commondisplay/... CT_DISPLAY_20160209 -nocheckout
element /vobs/com_platform/mak/environment.mk COM_MAKEFILES.4.4 -nocheckout
element /vobs/com_platform/mak/... COM_MAKEFILES.1 -nocheckout
element /vobs/3p/sysos/... SLES_11_5415620_REV3 -nocheckout
element /vobs/pet/3p/hdf5/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/hdf-java/... HDF5.SOUPRS_GROUP_C.1 -nocheckout
element /vobs/pet/3p/spectraeigen/... SPECTRA_EIGEN.SOUPRS_GROUP_A.1 -nocheckout
element /vobs/pet/3p/... PET_3P_KH -nocheckout
element /vobs/pet_detector/... PET_DET_GALILEO.53 -nocheckout
element /vobs/pet_detector/... PET_DET_ECOS_PLATFORM.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17_PET_CHAOS.1 -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17A -nocheckout
element /vobs/fw_platform/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/fw_tools/... CHAOS_DI_PLUS.17 -nocheckout
element /vobs/ACE_wrappers/... ACE_WRAPPERS_20120525 -nocheckout
element /vobs/iungo/... IUNGO_CJ3.5 -nocheckout
element /vobs/3p/boost/... BOOST2.7 -nocheckout
element /vobs/3p/QuadProg++/... QUADPROG2.0 -nocheckout
element /vobs/3p/hwloc/... HW_TOOLS2.0 -nocheckout
element /vobs/3p/intel/... INTEL2.8 -nocheckout
element /vobs/hdf5/... HDF51.2 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_PET1.17 -nocheckout
element /vobs/iungo_steps/... IUNGO_STEPS_CJ3.21 -nocheckout
element /vobs/3p/qpid/... QPID4.2 -nocheckout
element /vobs/obelus/... OBELUS_COMM_REVO_M3_1.8 -nocheckout
element /vobs/gbl_fw/... SH_FW_UTIL.1 -nocheckout
element /vobs/wind_sh/... SH_FW_UTIL.1 -nocheckout
element /vobs/com_util/bin/... SUN_UTILITIES.1 -nocheckout

# My config spec
element * .../yosi2_pac_col_ddg/LATEST
#MICE ver1
element * MICE_DELIVERABLE -mkbranch yosi2_pac_col_ddg
#ddwave pipeline code in /vobs/pet_ddwave/source/libDDWavePipeLine 
element * DDWAVE_PIPELINE -mkbranch yosi2_pac_col_ddg

#Toggle for seeing commits of other ppl to parent branch pac_col_ddg
#element * .../pac_col_ddg/LATEST -mkbranch yosi2_pac_col_ddg

element * PAC_COL_DDG.5 -mkbranch yosi2_pac_col_ddg
element * PET_COLUMBIA.122 -mkbranch yosi2_pac_col_ddg
element /vobs/pet_acq_test/... PET_ACQ_TEST.COM.3 -mkbranch yosi2_pac_col_ddg
element /vobs/pet_recon_test/... PET_RECON_TEST.COM.1 -nocheckout
element * PET_CORELOAD.71 -mkbranch yosi2_pac_col_ddg
element * PET_MICT_PLUS.48 -mkbranch yosi2_pac_col_ddg
element * CJ_KL.89 -mkbranch yosi2_pac_col_ddg
element * CORELOAD.118 -mkbranch yosi2_pac_col_ddg
element * GSI_MICT_PLUS.145 -mkbranch yosi2_pac_col_ddg
element * VISM3.6 -mkbranch yosi2_pac_col_ddg
element * KH_XAR.30 -mkbranch yosi2_pac_col_ddg
element * /main/0 -mkbranch yosi2_pac_col_ddg

                6.1.2.4.3
            6.1.2.5 l2mice makeDynData
Fyi… a resend… 

If we need to anon610_s951_LIST0004.mice again, I suggest we get a study from ‘petddg’, scp to fender or a system running pet_columbia.120+, and recreate the mice file per instruction below. If you use a system that is running pac_col_ddg sw, you will have to rdfAccept the list file(s) before running l2mice.

I think we should try to develop DDSWave pipeline and QSort pipeline as stand-alone executable, in the context of something similar to makeDynData

These two pipelines will one day be in a simpler ‘unlist’ application (i.e. not pet_acq).
Try to define the pipelines with nomenclature that is not so ‘PET Scan centric’, but rather in event/data processing terms specific to the pipeline data flow. Example, they don’t need to know about Scan Abort, Hard key stop scan, Frame has started….

A pipeline nomenclature that is more like, ‘consume till end of data’, register a fault handler that allows the pipeline creator to shutdown or ‘reset’ the pipeline, allow an entity a way to get notified if a fault occurs in the pipeline processing…. 

Ofer, 
I challenge you to give the makeDynData app an option to create an instance of ZCH….

mjc
From: Michael Cook <michael.cook@med.ge.com>
Date: Monday, December 11, 2017 at 2:31 PM
To: "Douglas, Kevin (GE Healthcare)" <KevinDouglas@ge.com>, "N, Smitha (GE Healthcare)" <Smitha.N@ge.com>, "Yakkali, Sravan (GE Healthcare)" <Sravan.Yakkali@ge.com>, "Jayakumar, Dhinesh (GE Healthcare)" <dhinesh.jayakumar@ge.com>, "Parihar, Vikas (GE Healthcare)" <vikas.parihar@ge.com>, "Voldman, Elena (GE Healthcare)" <Elena.Voldman@med.ge.com>, "Panizel, Omri (GE Healthcare, consultant)" <omri.panizel@ge.com>, "Prepyalo, Roman (GE Healthcare, consultant)" <roman.prepyalo@ge.com>, "Taouz, Leonid (GE Healthcare)" <Leonid.Taouz@ge.com>, "Izaq, Yosi (GE Healthcare)" <Yosi.Izaq@ge.com>, "Rybalsky, Yony (GE Healthcare)" <Yony.Rybalsky@ge.com>, "Varem, Shy (GE Healthcare)" <Shy.Varem1@ge.com>
Subject: a demo of l2mice and makeDynData

Yony, et al,
 
There was a request for a mice file that could be used as input to ‘makeDynData’…
 
On jaws4, under /petLists/cook, you will find:
 
ctuser@par:/petLists/cook> ls -ltr
total 925656
-rw-r--r-- 1 ctuser users 245436464 Dec 11 13:53 anon610_s951_LIST0004.BLF.v9
-rw-rw-rw- 1 ctuser users 238647013 Dec 11 13:54 anon610_s951_LIST0004.BLF
-rw-r--r-- 1 ctuser users 214472335 Dec 11 13:58 anon610_s951_LIST0004.mice
-rwxrwxr-x 1 ctuser users    912187 Dec 11 14:07 makeDynData
-rw-r--r-- 1 ctuser users     22015 Dec 11 14:14 makeDynData.out
 
I produced these files as follows:
 
I took a real clinical study list file, anon610_s951_LIST0004.BLF.v9, and made a copy to anon610_s951_LIST0004.BLF.
 
I then ran ‘rdfAccept /petLists/cook/anon610_s951_LIST0004.BLF’ to get a RDFv9.6 converted file.
 
On the par, I invoked the 64-bit app ‘l2mice -G -o anon610_s951_LIST0004.mice anon610_s951_LIST0004.BLF’ to produce anon610_s951_LIST0004.mice
 
I scp from pac_col_ddg.4, the 64-bit makeDynData to /petLists/cook
 
On the par, I invoked the 64-bit app ‘makeDynData -L anon610_s951_LIST0004.BLF -W anon610_s951_LIST0004.mice > makeDynData.out’
 
It appeared to make the downsampled sinograms, then call the ddwave processing, and made triggers and waveform.
 
See makeDynData.out for the stdout
 
Mjc
 
Note, here is the makeDynData usage:
 
Utility to easily create dynamic data files from MICE list data
 
Usage: makeDynData [options] <input mice file> [output dynamic data file]
 
Where [options] can be:
  -h, --help              Show command line help and exit
  -v, --verbose           Add additional debugging output (can be used
                            more than once)
  -L, --list-config <ARG>
                          Read HeaderData parameters from this list
                            file
  -f, --frame <ARG>       Process single (N) or range (N-M) of frames
  -t, --theta-comp <ARG>  Override theta compression value (default:
                            DSS ? 32 : 1)
  -r, --radial-comp <ARG>
                          Override radial compression value (default:
                            DSS ? 4 : 1)
  -s, --sample-period <ARG>
                          DSS sampling period in milliseconds (default:
                            500)
  -W, --ddwave            Enable DDWave processing


            6.1.2.6 Guidance on periodic GalileoCoincEvtDefs::PET_LINK_EVT_COINC_COUNT

                6.1.2.6.1 Mike's email 


Yony, Yosi, et al,
Take note of this guidance for ‘live scan’ and ‘rdfAccept’ Coincidence Event conversion to MICE.

The GalileoCoincEvtDef::PET_LINK_EVT_COINC_COUNT event is defined in /vobs/pet_raw/source/rdfAPI/libEvtList/petCoincLinkEvts.h :

/*************************************
 * Coinc Count Event
 *************************************/

typedef struct PetLinkEvtCoincCount
{
    uint16_t eventLength:2;     // Event Length : Enum for the number of bytes in the event
    uint16_t eventType:1;       // Event Type : Coin or Extended types
    uint16_t eventTypeExt:4;    // Extended Event Type : Time Marker, Trigger, Single..etc
    uint16_t unused1:5;         // Unused
    uint32_t coincCount:20;     // Coinc Count
} PET_LINK_EVT_COINC_COUNT;

This ‘periodic’ event in the ‘Galileo Architecture’ scanner’s Coincidence Stream is generated by the detector every one millisecond. They typically (unless UDP loss) occur immediately after a TimeMarker event. It includes a ‘coincCount’ of the Prompts that were made between the last two chronological Time Marker events.

This periodic event was introduced on GE scanners as part of the Galileo architecture. Scanners: PET/MR, DIQ, DMI
Its use is for detecting coincidence event (i.e. Prompt) loss on the PROP to PAC coincidence link. The detector H/W basically records the number of Prompts made and placed on the link every millisecond. The receive side can count the number of Prompts pulled out of UDP socket for any consecutive TimeMarker events, and then compare with the ‘coincCount’ of the PET_LINK_EVT_COINC_COUNT event.

Since the coincidence link is Ethernet, and the protocol is UDP, UDP packets can be dropped at the receive side (especially in scenarios when the PAC has a kernel issue or thread scheduling issue). 

Current IB sw for PET/MR, DIQ & DMI, includes these events during List Record, maintaining their chronological order in the recorded list file. 

PAC has some challenging List Record performance requirements, including a maximum Prompt event loss for a given Acquisition, and maximum Prompt loss during any one-second period of an Acquisition, while at or below the maximum required count rate capability.

We currently use ListTool app to assess these losses (see ListTool references in PAC Acq4D SSVP), and ListTool does not rely on the embedded periodic PET_LINK_EVT_COINC_COUNT events to measure ‘list loss’.

id=__ListDecode__Mike_Explain__
Note that you can see these events in previously recorded List Files, using the ListDecode rdf utility:

{ctuser@jaws}ListDecode -h
ListDecode: invalid option -- 'h'

Decode events from a DFE vintage List File

Usage:
  ListDecode [various opts] [-S seconds] [-o start_offset] [-e end_offset] [-R period] <list_file>

          -o : file offset for start of list decoding 
          -e : file offset for end of list decoding 
          -S : end after the given timestamp seconds of list decoding

       The default is to show all events.
       To filter, use combination of the following switches.
          -t : show Time Markers 
          -T : show Physiological Trigger Events 
          -s : show statistics for time, triggers, counts etc. 
          -r : show Count Rates (see also <-R period>)
          -c : Coinc Count Events
          -C : show CheckSum

       Miscellaneous options: 
          -R : period for rates calculation, default is 1 sec
          -v : verbose output
          -b : binary vs. ascii output (not implemented)
          -B : List File is big endian, default is little endian 
          -O : Use O_DIRECT for performance. Files system must support.

{ctuser@jaws}ListDecode -c turkeyPhntCol0000.BLF | head -20
# Offset(0x   35ca) : Coinc Count : ( 3379 )  Actual (1031)
# Offset(0x   4dac) : Coinc Count : ( 3421 )  Actual (1043)
# Offset(0x   668a) : Coinc Count : ( 3446 )  Actual (1017)
# Offset(0x   7ecc) : Coinc Count : ( 3403 )  Actual (1059)
# Offset(0x   9738) : Coinc Count : ( 3392 )  Actual (1033)
# Offset(0x   b14e) : Coinc Count : ( 3401 )  Actual (1040)
# Offset(0x   c9a8) : Coinc Count : ( 3373 )  Actual (1111)
# Offset(0x   e28c) : Coinc Count : ( 3522 )  Actual (1037)
# Offset(0x   fb52) : Coinc Count : ( 3400 )  Actual (1060)
# Offset(0x  1130a) : Coinc Count : ( 3445 )  Actual (1055)
# Offset(0x  12bc4) : Coinc Count : ( 3347 )  Actual (1010)
# Offset(0x  145b0) : Coinc Count : ( 3477 )  Actual (1053)
# Offset(0x  15e2e) : Coinc Count : ( 3512 )  Actual (1104)
# Offset(0x  176f4) : Coinc Count : ( 3363 )  Actual (1043)
# Offset(0x  19056) : Coinc Count : ( 3280 )  Actual (1055)
# Offset(0x  1a7d8) : Coinc Count : ( 3451 )  Actual (1081)
# Offset(0x  1c0fe) : Coinc Count : ( 3343 )  Actual (1001)
# Offset(0x  1da84) : Coinc Count : ( 3406 )  Actual (1071)
# Offset(0x  1f2ae) : Coinc Count : ( 3456 )  Actual (1087)
# Offset(0x  20bd4) : Coinc Count : ( 3361 )  Actual (1029)

{ctuser@jaws}ListDecode -tc turkeyPhntCol0000.BLF | head -20
# Offset(0x000051c) : TimeMark : TimeStamp(      2997) Prompts(       218)
# Offset(0x0001d52) : TimeMark : TimeStamp(      2998) Prompts(      1031)
# Offset(0x   35ca) : Coinc Count : ( 3379 )  Actual (1031)
# Offset(0x00035d0) : TimeMark : TimeStamp(      2999) Prompts(      1043)
# Offset(0x   4dac) : Coinc Count : ( 3421 )  Actual (1043)
# Offset(0x0004db2) : TimeMark : TimeStamp(      3000) Prompts(      1017)
# Offset(0x   668a) : Coinc Count : ( 3446 )  Actual (1017)
# Offset(0x0006690) : TimeMark : TimeStamp(      3001) Prompts(      1059)
# Offset(0x   7ecc) : Coinc Count : ( 3403 )  Actual (1059)
# Offset(0x0007ed2) : TimeMark : TimeStamp(      3002) Prompts(      1033)
# Offset(0x   9738) : Coinc Count : ( 3392 )  Actual (1033)
# Offset(0x000973e) : TimeMark : TimeStamp(      3003) Prompts(      1040)
# Offset(0x   b14e) : Coinc Count : ( 3401 )  Actual (1040)
# Offset(0x000b154) : TimeMark : TimeStamp(      3004) Prompts(      1111)
# Offset(0x   c9a8) : Coinc Count : ( 3373 )  Actual (1111)
# Offset(0x000c9ae) : TimeMark : TimeStamp(      3005) Prompts(      1037)
# Offset(0x   e28c) : Coinc Count : ( 3522 )  Actual (1037)
# Offset(0x000e292) : TimeMark : TimeStamp(      3006) Prompts(      1060)
# Offset(0x   fb52) : Coinc Count : ( 3400 )  Actual (1060)
# Offset(0x000fb58) : TimeMark : TimeStamp(      3007) Prompts(      1055)

My guidance for how to handle these events:

-	Drop the events (i.e. don’t convert and forward to MICE consumers
-	Consider adding debug support logic to ‘live scan’ event converter to display (and possibly save to a /tmp/TBD.h5 file if environment variable is set), and/or have some device statistics that show differences between counts recorded in PET_LINK_EVT_COINC_COUNT events as compared to Prompts actually converted per common time period. 

When we get into high Prompt Count Rate testing, and list loss testing, it would be good to see the loss as computed by the converter.

Mike Cook
Sr. Acquisition Software Architect

                6.1.2.6.2
            6.1.2.7
id=__rdfAcceptMice_Haifa_dev__
        6.1.3 Last dev cycle

            6.1.3.1 Clearcase details

                6.1.3.1.1  branch yosi4_pac_col_ddgv, view yosi1_haifa_pac_col_ddg



[de680136@nmpetdev64:2018-02-25 13:39:36:~:]2557$ ct mkbrtype -pbr -nc yosi4_pac_col_ddgv@/vobs/pet_acq_test
Created branch type "yosi4_pac_col_ddgv".

[de680136@nmpetdev64:2018-02-25 13:40:23:~:]2558$ ct mkbrtype -pbr -nc yosi4_pac_col_ddgv@/vobs/pet_acq
Created branch type "yosi4_pac_col_ddgv".

[de680136@nmpetdev64:2018-02-25 13:40:27:~:]2559$ ct mkbrtype -pbr -nc yosi4_pac_col_ddgv@/vobs/pet_raw
Created branch type "yosi4_pac_col_ddgv".

[de680136@nmpetdev64:2018-02-25 13:40:31:~:]2560$ ct mkbrtype -pbr -nc yosi4_pac_col_ddgv@/vobs/pet_platform
Created branch type "yosi4_pac_col_ddgv".

[de680136@nmpetdev64:2018-02-25 13:41:46:~:]2562$ ct mkview -tag yosi1_haifa_pac_col_ddg /view_store/ctbld_vws/yosi1_haifa_pac_col_ddg
Created view.
Host-local path: ilhaimiviews:/view_store/ctbld_vws/yosi1_haifa_pac_col_ddg
Global path:     /view_store/ctbld_vws/yosi1_haifa_pac_col_ddg
It has the following rights:
User : de680136 : rwx
Group: hmi_sw   : r-x
Other:          : r-x

                6.1.3.1.2


        6.1.4 rdfAccept MICE test strategy

            6.1.4.1  use ListDecode
<URL:#r=__ListDecode__source__>
<URL:#r=__ListDecode__Mike_Explain__>

note. flags:
-R n ; element rates every n seconds. default 1.
-C ; print event checksums
-s ; summary

Consider changing ListDecode.cpp to calculate MICE checksums correctly.
remove unused columns, shits strc shitj

Test strategy: run ListDecode on source Galileo list file. save output. rdfAccept file. run ListDecode. compare output.

Note, paartf has a rdfSnoop script that will accept and verify (to an extent) all paartf list files.
/usr/g/ctuser/acceptfunc/acceptListData

Next step. Run paartf Acquisition tests that unlist MICE files and run Acquisition

Last step. Run LT22. tests that produce sinograms and then record list

note:
acqAutoTest/protocols/rdfTellFilter.sed - filters gold files (the ListDecode reports) data that changed between versions

            6.1.4.2 Actuall tests

                6.1.4.2.1 tests history file 
                <URL:/cygdrive/c/Users/212680136/Desktop/Yosi/Work/PET/TestEnv/yosi/rdfAcceptTestsHistory_12_03_18>

                6.1.4.2.2 mail 2 mike
Hi Mike,

I wanted to share with you that we have promising test results of rdfAccept Galileo to Mice conversion 😊
We have used ListDecode and hdfview to compare events/TMs/Trigs counts. 
The numbers look good and give us some initial confidence.
The next step of verification would have us using modified ListDecode that Roman would provide.
The modified ListDecode would support -s, -R and -C flags.

Wanted to thank you, Roman and Yony for all the help you provided that allowed reaching this milestone so quickly!

Thanks!
Yosi





Details re. the tests so far. 

Machine: jaws

source lists:
    /petLists/acqAutoTest.clearcase/listData/CTCOCC.BLF
    /petLists/acqAutoTest.clearcase/listData/CirclesPerSlice.BLF
    /petLists/acqAutoTest.clearcase/listData/CirclesPerSliceRampDown.BLF
    /petLists/acqAutoTest.clearcase/listData/CrossHairPerSlice.BLF
    /petLists/acqAutoTest.clearcase/listData/DetCalListData.BLF
    /petLists/acqAutoTest.clearcase/listData/Gated3D_DwellPrecision.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedDP_PART0000.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedDP_PART0001.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedDP_PART0002.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedDP_PART0003.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedDP_PART0004.BLF
    /petLists/acqAutoTest.clearcase/listData/LorTofIncSpectrumLongTrigs.BLF
    /petLists/acqAutoTest.clearcase/listData/OrthogLines3D.BLF
    /petLists/acqAutoTest.clearcase/listData/RatesCurve.BLF
    /petLists/acqAutoTest.clearcase/listData/TofListData.BLF
    /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0000.BLF
    /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0001.BLF
    /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0002.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedAlignPDD_PART0003.BLF
    /petLists/acqAutoTest.clearcase/listData/GatedAlignPDD_PART0004.BLF

Converted files and logs:
    /usr/g/ctuser/yosi/stage/rdf10

Some time measurements:
    accepting /petLists/acqAutoTest.clearcase/listData/RatesCurve.BLF, log= RatesCurve.BLF.log 
    real    0m56.245s
    user    1m17.201s
    sys     0m2.716s
    
    accepting /petLists/acqAutoTest.clearcase/listData/TofListData.BLF, log= TofListData.BLF.log 
    real    0m16.945s
    user    0m14.665s
    sys     0m0.692s
    
    accepting /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0000.BLF, log= turkeyPhntCol0000.BLF.log 
    real    1m45.382s
    user    2m25.493s
    sys     0m3.464s
    
    accepting /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0001.BLF, log= turkeyPhntCol0001.BLF.log 
    real    0m43.253s
    user    0m56.128s
    sys     0m1.308s
    
    accepting /petLists/acqAutoTest.clearcase/listData/turkeyPhntCol0002.BLF, log= turkeyPhntCol0002.BLF.log 
    real    0m17.106s
    user    0m21.689s
    sys     0m0.512s
    
    accepting /petLists/acqAutoTest.clearcase/listData/GatedAlignPDD_PART0003.BLF, log= GatedAlignPDD_PART0003.BLF.log 
    real    0m1.923s
    user    0m1.740s
    sys     0m0.112s
    
    accepting /petLists/acqAutoTest.clearcase/listData/GatedAlignPDD_PART0004.BLF, log= GatedAlignPDD_PART0004.BLF.log 
    real    0m2.145s
    user    0m1.964s
    sys     0m0.076s

Total conversion time:
    real    10m58.487s
    user    12m9.554s
    sys     0m19.353s


                6.1.4.2.3

            6.1.4.3


        6.1.5
    6.2 PAARTF Development

        6.2.1 Important locations

            6.2.1.1 List files used for PAARTF

[de680136@nmpetdev64:2018-04-10 13:18:32:/vobs/pet_acq_test/source/acqAutoTest:]5693$ find -name '*.tar*'
./productFamily/columbia/listData/CtcOCCListFile.tar.bz2
./productFamily/columbia/listData/LYSO4x9_3_SIPMGEN1.tar.bz2
./productFamily/columbia/listData/LYSO4x9_4_SIPMGEN1.tar.bz2
./productFamily/columbia/listData/LYSO4x9_5_SIPMGEN1.tar.bz2
./productFamily/columbia/listData/TurkeyPhantomCol5R.tar.bz2
./productFamily/columbia/listData/AcceptTestLegacyData.tar.bz2
./productFamily/columbia/sinoData/LYSO4x9_4_SIPMGEN1.tar.bz2
./productFamily/columbia/sinoData/LYSO4x9_5_SIPMGEN1.tar.bz2
./productFamily/columbia/sinoData/AcceptTestLegacyData.tar.bz2
./productFamily/columbia/sinoData/LYSO4x9_3_SIPMGEN1.tar.bz2
./productFamily/galileo/listData/BGO8x8_3_TUBEQAT.tar.bz2
./productFamily/galileo/listData/BGO8x8_5_TUBEQAT.tar.bz2
./productFamily/galileo/listData/BGO8x8_2_TUBEQAT_calData.tar.bz2
./productFamily/galileo/listData/BGO8x8_2_TUBEQAT.tar.bz2
./productFamily/galileo/listData/BGO8x8_4_TUBEQAT.tar.bz2
./productFamily/galileo/sinoData/BGO8x8_5_TUBEQAT.tar.bz2
./productFamily/kittyHawk/listData/LYSO9x6_4_TUBEQAT.tar.bz2
./productFamily/kittyHawk/listData/TurkeyPhantomBlackbird.tar.bz2
./productFamily/kittyHawk/listData/AcceptTestLegacyData.tar.bz2
./productFamily/kittyHawk/sinoData/LYSO9x6_4_TUBEQAT.tar.bz2
./productFamily/kittyHawk/sinoData/AcceptTestLegacyData.tar.bz2
./productFamily/assorted/listData/AcceptTestLegacyData.tar.bz2
./productFamily/assorted/sinoData/AcceptTestLegacyData.tar.bz2


[de680136@nmpetdev64:2018-02-27 17:11:18:/vobs/pet_acq_test/source/acqAutoTest/productFamily/galileo/listData:]3843$ ls -l
total 1.7G
-r--r--r-- 1 vobadm hmi_sw 392K 2013-06-05 17:47 BGO8x8_2_TUBEQAT_calData.tar.bz2
-r--r--r-- 1 vobadm hmi_sw  12M 2017-07-20 18:57 BGO8x8_2_TUBEQAT.tar.bz2
-r--r--r-- 1 vobadm hmi_sw  21M 2013-09-11 17:21 BGO8x8_3_TUBEQAT.tar.bz2
-r--r--r-- 1 vobadm hmi_sw  31M 2013-09-11 17:21 BGO8x8_4_TUBEQAT.tar.bz2
-r--r--r-- 1 vobadm hmi_sw 1.7G 2017-07-20 18:55 BGO8x8_5_TUBEQAT.tar.bz2

Note, DIQ (Discovery IQ) productFamily is loosly referring to galileo events format

copy to host machine. ex.
[de680136@nmpetbld32:2018-02-28 09:58:09:/vobs/pet_acq_test/source/acqAutoTest/productFamily/galileo/listData:]3858$ scptm BGO8x8_5_TUBEQAT.tar.bz2 $JAWS
copy file to PET ACQ Host machine
BGO8x8_5_TUBEQAT.tar.bz2  

            6.2.1.2
        6.2.2
    6.3


7. CRs, Code reviews, code-review

    7.1 Offer

        7.1.1 SinoMath, https://collaborator.engops.health.ge.com/ui#review:id=182826

| Hi everyone,
| I’ve opened a code review for a preliminary version of SinoMath, based on the Pipeline framework.
| A few guidelines:
| 1.	Classes:
| a.	SinoMathTask is the main task.
| b.	The class called ConditionalNotification is a helper class that wraps the mutex & conditional combination for signal notifications. Shy, if you like it you can insert it to libpipeline.
| c.	HistogramMsg are two files that define the communication layer above pipes. 
| i.	It will probably change multiple times – currently the only place there is a complete CSinogramList is at FrameSaver right before saving. This will have to move back either to Packer (and then the messaging won’t change) or to SinoMath itself (meaning SinoMath will receive slices from packer and reconstruct them instead of FrameSaver). 
| ii.	My current direction is doing that in the SinoMath.
| d.	SinoMathConfigFile is a wapper for a config file. Currently, it has a timeout value used for waiting to quiescent histograms.
| 2.	The changes in pet_raw are the extension of subtraction of sinograms, based on the existing addition.
| 3.	The gtests test the subtraction logic, and also challenge the task with some of the failure conditions we’ve discussed (e.g. timeouts, unsynchronized quiescent and static paths, etc). You’re welcome to suggest more cases.
| Feel free to add anyone I forgot…
| Thanks
| Ofer.

        7.1.2
|   1.	Sinomath review – the SinoMath task implementation. The review now contains a version ready to be connected to both ZCH and FrameSaver using pipes. The previous review is still open for you to reference previous comments.
https://collaborator.engops.health.ge.com/ui#review:id=184233

|   2.	Histogrammer review – an implementation of the Histogrammer, using pipes.  HistoMain is the original histogrammer, that underwent a few changes to ease its extension. HistoMainPiped is the new histogrammer. Finally, HistogrammerCtrlPipe will connect QSort to the Histogrammer.
https://collaborator.engops.health.ge.com/ui#review:id=185214

|   3.	ZCH review – testing both items required minor changes to ZCH (mostly turning private to protected) and a bit refactorings. No major changes there.
https://collaborator.engops.health.ge.com/ui#review:id=185223

    7.2 Yony

        7.2.1 You are a Required reviewer for new Review #183224: "Mice1".
Created: Thu Feb 08 07:59:25 UTC 2018 by Yony Rybalsky
Deadline: N/A
Workflow: PET Code Review
Defect Log: 0 Total Issues: 0 Open; 0 Fixed; 0 External.



Select this link to display or participate in the review:
<https://collaborator.engops.health.ge.com:443/ui#review:id=183224>

    7.3 Roman

        7.3.1 ListDecode MICE 

https://collaborator.engops.health.ge.com/ui#review:id=190215

        7.3.2 Prepyalo, Roman has changed your role to Required reviewer in Review #181991: "IOThread - initial".
Created: Thu Feb 01 09:23:13 UTC 2018 by Prepyalo, Roman
Deadline: N/A
Workflow: PET Code Review
Defect Log: 2 Total Issues: 2 Open; 0 Fixed; 0 External.
170298	Status: Open
	Issue Creator: Prepyalo, Roman
	[PET] Severity: Enhancement
	[PET] Type: Coding Standards
	Description: change printf to use rda logger
170299	Status: Open
	Issue Creator: Prepyalo, Roman
	[PET] Severity: Minor
	[PET] Type: Control Flow
	Description: Mike,Kevin please note this and line 3110 , line 3106. when the file is initially being created via this API there is no way of filling those fields and they default to 0. so opening the file for the first time before you edit the header will FAIL. 
what is the meaning of there check in CRdfList::Open()?
I would like to suggest two options:
1) add the required fields to the CRdfList::Create() parameters.
2) not checking the header on open and provide specific functions for the user.

Select this link to display or participate in the review:
<https://collaborator.engops.health.ge.com:443/ui#review:id=181991>


    7.4 Michael Cook

        7.4.1 Subject: rdfAccept fix for making 'valid' Deadtime & Block Temperature datasets

        https://collaborator.engops.health.ge.com/ui#review:id=187295
Yosi,
Given you are our leader for upcoming ‘rdfAccept for MICE’ milestone, I made you the required reviewer of Code Review 187295:  rdfAccept fix for making 'valid' Deadtime & Block Temperature datasets

Please allow the optional reviewers a chance to ‘approve’ the change before you as Required reviewer approve.

The change is relatively simple and should only take a few minutes to review.
I would like to get this change approved ASAP and merged to _dev and our pac_col_ddg branch so developers can pick-up with the other pac_col_ddg.7 RDF and rdfAccept recent modifications.

Thank you
mjc

Review Title rdfAccept fix for making 'valid' Deadtime & Block Temperature datasets 
Role Required reviewer Created Mon Mar 05 17:28:42 GMT+200 2018 by Cook, Michael J Group PET Template PET Code Review Completed On N/A Restrict Access Anyone Restrict Uploads/Deletions No [PET] SPR ID (Mandatory)

[PET] Review Description (Mandatory)
For list files, rdfAccept was for making Deadtime & Block Temperature datasets that were based on the original 'allocated' vs 'valid' number of samples for the periodic data. As a result, the RDFv10 datasets had bogus data associated the later samples for space 'allocated' by not filled with 'valid' data.

The fix was to make datasets that were based on off of the valid number of samples. 
[PET] Static Analysis Evidence (Mandatory)
not performed, minor code change 
[PET] Root Cause
rdfAccept was for making Deadtime & Block Temperature datasets that were based on the original 'allocated' vs 'valid' number of samples for the periodic data
[PET] Testing Performed
run rdfAccept on PAARTF DMI 5R RDFv9 DetCalListData.BLF list file. 

run 'rdfTell -hSd | more' on the converted list file and confirm 13 valid samples for Singles, and the Deadtime datasets, and Block Temperatures

Run hdfview on the converted file and 
individually 'select' the datasets and observe slowset changing dimension of dimensions is 13.
[PET] How to Verify
un rdfAccept on PAARTF DMI 5R RDFv9 DetCalListData.BLF list file. 

run 'rdfTell -hSd | more' on the converted list file and confirm 13 valid samples for Singles, and the Deadtime datasets, and Block Temperatures

Run hdfview on the converted file and 
individually 'select' the datasets and observe slowset changing dimension of dimensions is 13.
[PET] Target integration branch
pac_col_ddg

        7.4.2
    7.5



8.  passwords

    8.1  PET Host machines (e.g. jaws4)


    user ctuser , password 4$apps
    root #bigguy

    8.2

9. Tools

    9.1 valgrind 
cat runValgrin.sh
valgrind -v --leak-check=full --show-reachable=yes "$@" 

usage:
runValgrin.sh ./sles11-x86_64/gtestsThingi arg1 ... argN

    9.2
10.



