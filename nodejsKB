.........................................Table Of Contents...............................................................
1. my Tutorial <URL:#tn=1. my Tutorial>
    1.1  nodejs. REPL (like python IDLE, Read, Eval, Print, Loop) <URL:#tn=    1.1  nodejs. REPL (like python IDLE, Read, Eval, Print, Loop)>
    1.2 Nodejs NPM <URL:#tn=    1.2 Nodejs NPM>
        1.2.1  basics <URL:#tn=        1.2.1  basics>
        1.2.2 my npm examples <URL:#tn=        1.2.2 my npm examples>
            1.2.2.1  install specific version , ^ - semantic range operator <URL:#tn=            1.2.2.1  install specific version , ^ - semantic range operator>
            1.2.2.2 <URL:#tn=            1.2.2.2>
        1.2.3 list dependencies, dependency tree, tags: node, npm, package.json, list dependencies, dependency tree, show outdated, latest, version <URL:#tn=        1.2.3 list dependencies, dependency tree, tags: node, npm, package.json, list dependencies, dependency tree, show outdated, latest, version>
        1.2.4 update dependencies , packages, upgrade, update, up to date packages <URL:#tn=        1.2.4 update dependencies , packages, upgrade, update, up to date packages>
            1.2.4.1 https://docs.npmjs.com/updating-packages-downloaded-from-the-registry <URL:#tn=            1.2.4.1 https://docs.npmjs.com/updating-packages-downloaded-from-the-registry>
            1.2.4.2 <URL:#tn=            1.2.4.2>
        1.2.5 top node modules, tags: leading npm modules and packages <URL:#tn=        1.2.5 top node modules, tags: leading npm modules and packages>
            1.2.5.1 express framework , tags:express framework <URL:#tn=            1.2.5.1 express framework , tags:express framework>
                1.2.5.1.1 blog https://appdividend.com/2022/03/05/node-js-express-tutorial-for-beginners/, tags: express tutorial <URL:#tn=                1.2.5.1.1 blog https://appdividend.com/2022/03/05/node-js-express-tutorial-for-beginners/, tags: express tutorial>
                    1.2.5.1.1.1 first steps <URL:#tn=                    1.2.5.1.1.1 first steps>
                    1.2.5.1.1.2 ejs templating engine <URL:#tn=                    1.2.5.1.1.2 ejs templating engine>
                    1.2.5.1.1.3 handle routes <URL:#tn=                    1.2.5.1.1.3 handle routes>
                    1.2.5.1.1.4 Create a form for adding coins <URL:#tn=                    1.2.5.1.1.4 Create a form for adding coins>
                    1.2.5.1.1.5 Install Mongoose Library. <URL:#tn=                    1.2.5.1.1.5 Install Mongoose Library.>
                    1.2.5.1.1.6 Install the body-parser module. <URL:#tn=                    1.2.5.1.1.6 Install the body-parser module.>
                    1.2.5.1.1.7 create a model <URL:#tn=                    1.2.5.1.1.7 create a model>
                    1.2.5.1.1.8 add coin post route <URL:#tn=                    1.2.5.1.1.8 add coin post route>
                    1.2.5.1.1.9 server.js <URL:#tn=                    1.2.5.1.1.9 server.js>
                    1.2.5.1.1.10 display coins list <URL:#tn=                    1.2.5.1.1.10 display coins list>
                    1.2.5.1.1.11 Make edit view and route. <URL:#tn=                    1.2.5.1.1.11 Make edit view and route.>
                    1.2.5.1.1.12 Delete the data. <URL:#tn=                    1.2.5.1.1.12 Delete the data.>
                    1.2.5.1.1.13 Full code <URL:#tn=                    1.2.5.1.1.13 Full code>
                        1.2.5.1.1.13.1 root level <URL:#tn=                        1.2.5.1.1.13.1 root level>
                        1.2.5.1.1.13.2 models <URL:#tn=                        1.2.5.1.1.13.2 models>
                        1.2.5.1.1.13.3 static <URL:#tn=                        1.2.5.1.1.13.3 static>
                        1.2.5.1.1.13.4 routes <URL:#tn=                        1.2.5.1.1.13.4 routes>
                        1.2.5.1.1.13.5 views <URL:#tn=                        1.2.5.1.1.13.5 views>
                    1.2.5.1.1.14 Run instructions <URL:#tn=                    1.2.5.1.1.14 Run instructions>
                    1.2.5.1.1.15 <URL:#tn=                    1.2.5.1.1.15>
                1.2.5.1.2 <URL:#tn=                1.2.5.1.2>
                1.2.5.1.3 <URL:#tn=                1.2.5.1.3>
            1.2.5.2 <URL:#tn=            1.2.5.2>
            1.2.5.2 koa.js  framework <URL:#tn=            1.2.5.2 koa.js  framework>
            1.2.5.3 meteor framework <URL:#tn=            1.2.5.3 meteor framework>
            1.2.5.4 socket.io for chat apps <URL:#tn=            1.2.5.4 socket.io for chat apps>
            1.2.5.5 nestjs <URL:#tn=            1.2.5.5 nestjs>
            1.2.5.6 fastify <URL:#tn=            1.2.5.6 fastify>
            1.2.5.7 lodash , tags: lodash <URL:#tn=            1.2.5.7 lodash , tags: lodash>
                1.2.5.7.1 getting-started <URL:#tn=                1.2.5.7.1 getting-started>
                1.2.5.7.2 unionWith <URL:#tn=                1.2.5.7.2 unionWith>
                1.2.5.7.3 nested json paths <URL:#tn=                1.2.5.7.3 nested json paths>
                    1.2.5.7.3.1 is there a lodash utility function that returns a list of nested paths of JSON object <URL:#tn=                    1.2.5.7.3.1 is there a lodash utility function that returns a list of nested paths of JSON object>
                    1.2.5.7.3.2 modify to get a nested list of key values of the paths <URL:#tn=                    1.2.5.7.3.2 modify to get a nested list of key values of the paths>
                    1.2.5.7.3.3 modify to get path of specific property recurring in nested objects. say an id property <URL:#tn=                    1.2.5.7.3.3 modify to get path of specific property recurring in nested objects. say an id property>
                    1.2.5.7.3.4 <URL:#tn=                    1.2.5.7.3.4>
                1.2.5.7.4 <URL:#tn=                1.2.5.7.4>
            1.2.5.8 axios <URL:#tn=            1.2.5.8 axios>
            1.2.5.9 karma <URL:#tn=            1.2.5.9 karma>
            1.2.5.10 grunt <URL:#tn=            1.2.5.10 grunt>
            1.2.5.11 PM2 <URL:#tn=            1.2.5.11 PM2>
            1.2.5.12 Mocha is a feature-rich JS test framework that runs on Node js and the browser, making asynchronous testing simple and enjoyable. <URL:#tn=            1.2.5.12 Mocha is a feature-rich JS test framework that runs on Node js and the browser, making asynchronous testing simple and enjoyable.>
            1.2.5.13 jsonwebtoken <URL:#tn=            1.2.5.13 jsonwebtoken>
            1.2.5.14 bcrypt <URL:#tn=            1.2.5.14 bcrypt>
            1.2.5.15 uuid <URL:#tn=            1.2.5.15 uuid>
            1.2.5.16 passport <URL:#tn=            1.2.5.16 passport>
            1.2.5.17 multer , tags: multer <URL:#tn=            1.2.5.17 multer , tags: multer>
                1.2.5.17.1 blog: https://blog.logrocket.com/multer-nodejs-express-upload-file , tags: multer express upload tutorial <URL:#tn=                1.2.5.17.1 blog: https://blog.logrocket.com/multer-nodejs-express-upload-file , tags: multer express upload tutorial>
                    1.2.5.17.1.1 forms <URL:#tn=                    1.2.5.17.1.1 forms>
                1.2.5.17.2 <URL:#tn=                1.2.5.17.2>
            1.2.5.18 https://www.npmjs.com/package/npkill <URL:#tn=            1.2.5.18 https://www.npmjs.com/package/npkill>
            1.2.5.19 nodejs unzipper module. description, use cases and code examples, tags: nodejs unzipper module. description use cases and code examples <URL:#tn=            1.2.5.19 nodejs unzipper module. description, use cases and code examples, tags: nodejs unzipper module. description use cases and code examples>
            1.2.5.20 <URL:#tn=            1.2.5.20>
        1.2.6 <URL:#tn=        1.2.6>
    1.3 nodejs Event Loop <URL:#tn=    1.3 nodejs Event Loop>
        1.3.1  basics <URL:#tn=        1.3.1  basics>
        1.3.2 nodejs event-loop timers and nexttick <URL:#tn=        1.3.2 nodejs event-loop timers and nexttick>
            1.3.2.1 background <URL:#tn=            1.3.2.1 background>
            1.3.2.2 Phases Overview <URL:#tn=            1.3.2.2 Phases Overview>
            1.3.2.3 Phases in Detail <URL:#tn=            1.3.2.3 Phases in Detail>
                1.3.2.3.1 timers <URL:#tn=                1.3.2.3.1 timers>
            1.3.2.4 <URL:#tn=            1.3.2.4>
        1.3.3 <URL:#tn=        1.3.3>
    1.4 buffers <URL:#tn=    1.4 buffers>
    1.5 streams <URL:#tn=    1.5 streams>
    1.6 filesystem <URL:#tn=    1.6 filesystem>
    1.7 globals <URL:#tn=    1.7 globals>
    1.8 utility Modules <URL:#tn=    1.8 utility Modules>
    1.9 web <URL:#tn=    1.9 web>
    1.10 Express, tags: Express framework <URL:#tn=    1.10 Express, tags: Express framework>
        1.10.0  intro <URL:#tn=        1.10.0  intro>
        1.10.1  Install <URL:#tn=        1.10.1  Install>
        1.10.2 Express and supertest <URL:#tn=        1.10.2 Express and supertest>
            1.10.2.1 https://www.codementor.io/knownasilya/testing-express-apis-with-supertest-du107mcv2 <URL:#tn=            1.10.2.1 https://www.codementor.io/knownasilya/testing-express-apis-with-supertest-du107mcv2>
            1.10.2.2 <URL:#tn=            1.10.2.2>
        1.10.3 passport, authentication library <URL:#tn=        1.10.3 passport, authentication library>
            1.10.3.1  web tutorials <URL:#tn=            1.10.3.1  web tutorials>
                1.10.3.1.1  https://scotch.io/tutorials/easy-node-authentication-setup-and-local <URL:#tn=                1.10.3.1.1  https://scotch.io/tutorials/easy-node-authentication-setup-and-local>
                1.10.3.1.2 http://www.passportjs.org/docs/ <URL:#tn=                1.10.3.1.2 http://www.passportjs.org/docs/>
                1.10.3.1.3 <URL:#tn=                1.10.3.1.3>
            1.10.3.2 <URL:#tn=            1.10.3.2>
        1.10.4 Schema validations <URL:#tn=        1.10.4 Schema validations>
            1.10.4.1 swagger validation , Schema validations <URL:#tn=            1.10.4.1 swagger validation , Schema validations>
                1.10.4.1.1 https://www.npmjs.com/package/express-openapi-validate <URL:#tn=                1.10.4.1.1 https://www.npmjs.com/package/express-openapi-validate>
                1.10.4.1.2 usage in semantic <URL:#tn=                1.10.4.1.2 usage in semantic>
                1.10.4.1.3 <URL:#tn=                1.10.4.1.3>
            1.10.4.2 <URL:#tn=            1.10.4.2>
        1.10.5 express FAQ <URL:#tn=        1.10.5 express FAQ>
            1.10.5.1 get request params and query params <URL:#tn=            1.10.5.1 get request params and query params>
            1.10.5.2 <URL:#tn=            1.10.5.2>
        1.10.6 X509 authentication <URL:#tn=        1.10.6 X509 authentication>
            1.10.6.1 https://medium.com/@sevcsik/authentication-using-https-client-certificates-3c9d270e8326 <URL:#tn=            1.10.6.1 https://medium.com/@sevcsik/authentication-using-https-client-certificates-3c9d270e8326>
            1.10.6.2 https://intown.biz/2016/11/22/node-client-auth/ <URL:#tn=            1.10.6.2 https://intown.biz/2016/11/22/node-client-auth/>
            1.10.6.3 My example <URL:#tn=            1.10.6.3 My example>
                1.10.6.3.1 Prepare certificates <URL:#tn=                1.10.6.3.1 Prepare certificates>
                1.10.6.3.2 setup node server app <URL:#tn=                1.10.6.3.2 setup node server app>
                1.10.6.3.3 client <URL:#tn=                1.10.6.3.3 client>
                    1.10.6.3.3.1 curl x509 client <URL:#tn=                    1.10.6.3.3.1 curl x509 client>
                    1.10.6.3.3.2 ssl x509 client (only connect, no http request) <URL:#tn=                    1.10.6.3.3.2 ssl x509 client (only connect, no http request)>
                    1.10.6.3.3.3  axios x509 client <URL:#tn=                    1.10.6.3.3.3  axios x509 client>
                    1.10.6.3.3.4 request x509 client <URL:#tn=                    1.10.6.3.3.4 request x509 client>
                    1.10.6.3.3.5 capture <URL:#tn=                    1.10.6.3.3.5 capture>
                    1.10.6.3.3.6 <URL:#tn=                    1.10.6.3.3.6>
                1.10.6.3.4 Troubelshooting guide <URL:#tn=                1.10.6.3.4 Troubelshooting guide>
                1.10.6.3.5 <URL:#tn=                1.10.6.3.5>
            1.10.6.4 Client side certificate based authentication <URL:#tn=            1.10.6.4 Client side certificate based authentication>
                1.10.6.4.1  axios, Client side certificate based authentication <URL:#tn=                1.10.6.4.1  axios, Client side certificate based authentication>
                    1.10.6.4.1.1   Examples <URL:#tn=                    1.10.6.4.1.1   Examples>
                    1.10.6.4.1.2 <URL:#tn=                    1.10.6.4.1.2>
                1.10.6.4.2 https agent <URL:#tn=                1.10.6.4.2 https agent>
                1.10.6.4.3 <URL:#tn=                1.10.6.4.3>
            1.10.6.5 DER files <URL:#tn=            1.10.6.5 DER files>
                1.10.6.5.1 read, write, compare DER certificate files <URL:#tn=                1.10.6.5.1 read, write, compare DER certificate files>
                1.10.6.5.2 <URL:#tn=                1.10.6.5.2>
            1.10.6.6 <URL:#tn=            1.10.6.6>
        1.10.7 <URL:#tn=        1.10.7>
    1.11 Express <URL:#tn=    1.11 Express>
    1.12 RESTful API <URL:#tn=    1.12 RESTful API>
    1.13 Spawning processes <URL:#tn=    1.13 Spawning processes>
    1.14 nodejs packaging, JXcore <URL:#tn=    1.14 nodejs packaging, JXcore>
    1.15 promise <URL:#tn=    1.15 promise>
        1.15.1 promises basics <URL:#tn=        1.15.1 promises basics>
        1.15.2 promise all <URL:#tn=        1.15.2 promise all>
        1.15.3 <URL:#tn=        1.15.3>
    1.16 authentication & authorization <URL:#tn=    1.16 authentication & authorization>
        1.16.1  Json Web Token, JWT <URL:#tn=        1.16.1  Json Web Token, JWT>
            1.16.1.1  web tutorials <URL:#tn=            1.16.1.1  web tutorials>
                1.16.1.1.1  https://stormpath.com/blog/nodejs-jwt-create-verify <URL:#tn=                1.16.1.1.1  https://stormpath.com/blog/nodejs-jwt-create-verify>
                    1.16.1.1.1.1  Generate the Secret Signing Key <URL:#tn=                    1.16.1.1.1.1  Generate the Secret Signing Key>
                    1.16.1.1.1.2 Authenticate the User <URL:#tn=                    1.16.1.1.1.2 Authenticate the User>
                    1.16.1.1.1.3 Prepare The Claims <URL:#tn=                    1.16.1.1.1.3 Prepare The Claims>
                    1.16.1.1.1.4 Generate the Token <URL:#tn=                    1.16.1.1.1.4 Generate the Token>
                    1.16.1.1.1.5 Send the Token to the Client <URL:#tn=                    1.16.1.1.1.5 Send the Token to the Client>
                1.16.1.1.2 https://medium.freecodecamp.org/securing-node-js-restful-apis-with-json-web-tokens-9f811a92bb52 <URL:#tn=                1.16.1.1.2 https://medium.freecodecamp.org/securing-node-js-restful-apis-with-json-web-tokens-9f811a92bb52>
                1.16.1.1.3 <URL:#tn=                1.16.1.1.3>
            1.16.1.2 <URL:#tn=            1.16.1.2>
        1.16.2 <URL:#tn=        1.16.2>
    1.17 regex <URL:#tn=    1.17 regex>
        1.17.1 https://www.w3schools.com/js/js_regexp.asp <URL:#tn=        1.17.1 https://www.w3schools.com/js/js_regexp.asp>
        1.17.2 My examples <URL:#tn=        1.17.2 My examples>
        1.17.3 <URL:#tn=        1.17.3>
    1.18 JSON validation <URL:#tn=    1.18 JSON validation>
        1.18.1 https://json-schema.org/learn/getting-started-step-by-step.html <URL:#tn=        1.18.1 https://json-schema.org/learn/getting-started-step-by-step.html>
    1.19 falsy values and tests <URL:#tn=    1.19 falsy values and tests>
        1.19.1 demo test falsy values and ternary ?: operator <URL:#tn=        1.19.1 demo test falsy values and ternary ?: operator>
        1.19.2 Nullish coalescing operator ?? Operator <URL:#tn=        1.19.2 Nullish coalescing operator ?? Operator>
        1.19.3 <URL:#tn=        1.19.3>
    1.20 <URL:#tn=    1.20>
2. Debugging <URL:#tn=2. Debugging>
    2.1 Running and Debugging Node.js with intellij <URL:#tn=    2.1 Running and Debugging Node.js with intellij>
    2.2 CLI debugger <URL:#tn=    2.2 CLI debugger>
        2.2.1 commands: https://nodejs.org/api/debugger.html <URL:#tn=        2.2.1 commands: https://nodejs.org/api/debugger.html>
        2.2.2 <URL:#tn=        2.2.2>
    2.3 <URL:#tn=    2.3>
3. Testing frameworks. tags: grunt, Mocha, sinon, chai, mockito, ts-mockito <URL:#tn=3. Testing frameworks. tags: grunt, Mocha, sinon, chai, mockito, ts-mockito>
    3.1 grunt <URL:#tn=    3.1 grunt>
        3.1.1 https://gruntjs.com/getting-started <URL:#tn=        3.1.1 https://gruntjs.com/getting-started>
        3.1.2 https://fairwaytech.com/2014/01/understanding-grunt-part-1-installation-linting-concatenation-and-minification/ <URL:#tn=        3.1.2 https://fairwaytech.com/2014/01/understanding-grunt-part-1-installation-linting-concatenation-and-minification/>
            3.1.2.1 Understanding Grunt – Part 1: Installation, Linting, Concatenation, and Minification <URL:#tn=            3.1.2.1 Understanding Grunt – Part 1: Installation, Linting, Concatenation, and Minification>
            3.1.2.2 <URL:#tn=            3.1.2.2>
        3.1.3 <URL:#tn=        3.1.3>
    3.2 Mocha <URL:#tn=    3.2 Mocha>
        3.2.1 Mocha tutorial <URL:#tn=        3.2.1 Mocha tutorial>
        3.2.2 another tutorial, tags: mocha tutorial <URL:#tn=        3.2.2 another tutorial, tags: mocha tutorial>
            3.2.2.1 INSTALLATION <URL:#tn=            3.2.2.1 INSTALLATION>
            3.2.2.2 setup project <URL:#tn=            3.2.2.2 setup project>
            3.2.2.3 run test <URL:#tn=            3.2.2.3 run test>
            3.2.2.4 RUN CYCLE OVERVIEW <URL:#tn=            3.2.2.4 RUN CYCLE OVERVIEW>
                3.2.2.4.1 SERIAL MODE <URL:#tn=                3.2.2.4.1 SERIAL MODE>
                3.2.2.4.2 #PARALLEL MODE <URL:#tn=                3.2.2.4.2 #PARALLEL MODE>
                3.2.2.4.3 <URL:#tn=                3.2.2.4.3>
            3.2.2.5 DETECTS MULTIPLE CALLS TO DONE() <URL:#tn=            3.2.2.5 DETECTS MULTIPLE CALLS TO DONE()>
            3.2.2.6 ASSERTIONS <URL:#tn=            3.2.2.6 ASSERTIONS>
            3.2.2.7 ASYNCHRONOUS CODE <URL:#tn=            3.2.2.7 ASYNCHRONOUS CODE>
                3.2.2.7.1  working with promises <URL:#tn=                3.2.2.7.1  working with promises>
                3.2.2.7.2 USING ASYNC / AWAIT <URL:#tn=                3.2.2.7.2 USING ASYNC / AWAIT>
                3.2.2.7.3 SYNCHRONOUS CODE <URL:#tn=                3.2.2.7.3 SYNCHRONOUS CODE>
                3.2.2.7.4 ARROW FUNCTIONS <URL:#tn=                3.2.2.7.4 ARROW FUNCTIONS>
                3.2.2.7.5 <URL:#tn=                3.2.2.7.5>
            3.2.2.8 HOOKS <URL:#tn=            3.2.2.8 HOOKS>
            3.2.2.9 ROOT-LEVEL HOOKS <URL:#tn=            3.2.2.9 ROOT-LEVEL HOOKS>
            3.2.2.10 #ROOT-LEVEL HOOKS <URL:#tn=            3.2.2.10 #ROOT-LEVEL HOOKS>
            3.2.2.11 #DELAYED ROOT SUITE <URL:#tn=            3.2.2.11 #DELAYED ROOT SUITE>
            3.2.2.12 #PENDING TESTS <URL:#tn=            3.2.2.12 #PENDING TESTS>
            3.2.2.13 #EXCLUSIVE TESTS <URL:#tn=            3.2.2.13 #EXCLUSIVE TESTS>
            3.2.2.14 #INCLUSIVE TESTS <URL:#tn=            3.2.2.14 #INCLUSIVE TESTS>
            3.2.2.15 #RETRY TESTS <URL:#tn=            3.2.2.15 #RETRY TESTS>
            3.2.2.16 DYNAMICALLY GENERATING TESTS , todo: write demo <URL:#tn=            3.2.2.16 DYNAMICALLY GENERATING TESTS , todo: write demo>
            3.2.2.17 TEST DURATION <URL:#tn=            3.2.2.17 TEST DURATION>
            3.2.2.18 TIMEOUTS <URL:#tn=            3.2.2.18 TIMEOUTS>
            3.2.2.19 inline-diffs <URL:#tn=            3.2.2.19 inline-diffs>
            3.2.2.20 COMMAND-LINE USAGE <URL:#tn=            3.2.2.20 COMMAND-LINE USAGE>
            3.2.2.21 <URL:#tn=            3.2.2.21>
        3.2.3 <URL:#tn=        3.2.3>
    3.3 sinon <URL:#tn=    3.3 sinon>
        3.3.1 https://www.sitepoint.com/sinon-tutorial-javascript-testing-mocks-spies-stubs/ <URL:#tn=        3.3.1 https://www.sitepoint.com/sinon-tutorial-javascript-testing-mocks-spies-stubs/>
            3.3.1.1 install Sinon. <URL:#tn=            3.3.1.1 install Sinon.>
            3.3.1.2 Spies <URL:#tn=            3.3.1.2 Spies>
            3.3.1.3 Sinon’s Assertions <URL:#tn=            3.3.1.3 Sinon’s Assertions>
            3.3.1.4 Stubs <URL:#tn=            3.3.1.4 Stubs>
            3.3.1.5 Mocks <URL:#tn=            3.3.1.5 Mocks>
        3.3.2 my example <URL:#tn=        3.3.2 my example>
        3.3.3 <URL:#tn=        3.3.3>
    3.4 My grunt file examples <URL:#tn=    3.4 My grunt file examples>
        3.4.1  /Users/i500695/Desktop/work/code/nodejs/tutorial <URL:#tn=        3.4.1  /Users/i500695/Desktop/work/code/nodejs/tutorial>
    3.5 <URL:#tn=    3.5>
4. eslint, for static analysis <URL:#tn=4. eslint, for static analysis>
    4.1  grunt setup eslint <URL:#tn=    4.1  grunt setup eslint>
    4.2 <URL:#tn=    4.2>
5. Packages <URL:#tn=5. Packages>
    5.1 sprintf <URL:#tn=    5.1 sprintf>
    5.2 nodemon, monitor nodejs code execution <URL:#tn=    5.2 nodemon, monitor nodejs code execution>
    5.3 jsonwebtoken <URL:#tn=    5.3 jsonwebtoken>
        5.3.1 web tutorials <URL:#tn=        5.3.1 web tutorials>
            5.3.1.1 https://medium.com/@siddharthac6/json-web-token-jwt-the-right-way-of-implementing-with-node-js-65b8915d550e <URL:#tn=            5.3.1.1 https://medium.com/@siddharthac6/json-web-token-jwt-the-right-way-of-implementing-with-node-js-65b8915d550e>
            5.3.1.2 <URL:#tn=            5.3.1.2>
        5.3.2 <URL:#tn=        5.3.2>
    5.4 rewire <URL:#tn=    5.4 rewire>
        5.4.1 https://www.npmjs.com/package/rewire <URL:#tn=        5.4.1 https://www.npmjs.com/package/rewire>
        5.4.2 How rewire is useful for unit tests <URL:#tn=        5.4.2 How rewire is useful for unit tests>
        5.4.3 <URL:#tn=        5.4.3>
    5.5 <URL:#tn=    5.5>
6. FAQ <URL:#tn=6. FAQ>
    6.1 printing <URL:#tn=    6.1 printing>
        6.1.1 Print JSON object <URL:#tn=        6.1.1 Print JSON object>
        6.1.2 <URL:#tn=        6.1.2>
    6.2 modules <URL:#tn=    6.2 modules>
        6.2.1 express <URL:#tn=        6.2.1 express>
            6.2.1.1 process.env vs app.get('env') on getting the express.js environment <URL:#tn=            6.2.1.1 process.env vs app.get('env') on getting the express.js environment>
        6.2.2 <URL:#tn=        6.2.2>
    6.3 general <URL:#tn=    6.3 general>
        6.3.1 Is nodejs interpreted or compiled? <URL:#tn=        6.3.1 Is nodejs interpreted or compiled?>
        6.3.2 V8 <URL:#tn=        6.3.2 V8>
        6.3.3 <URL:#tn=        6.3.3>
    6.4 arrays <URL:#tn=    6.4 arrays>
        6.4.1 convert array to json <URL:#tn=        6.4.1 convert array to json>
    6.5 functional programming <URL:#tn=    6.5 functional programming>
        6.5.1  reduce <URL:#tn=        6.5.1  reduce>
            6.5.1.1  reduce tutorial <URL:#tn=            6.5.1.1  reduce tutorial>
            6.5.1.2 reduce an array of string to set <URL:#tn=            6.5.1.2 reduce an array of string to set>
            6.5.1.3 reduce an array of string to map <URL:#tn=            6.5.1.3 reduce an array of string to map>
        6.5.2 <URL:#tn=        6.5.2>
    6.6  typescript use string variable as property name <URL:#tn=    6.6  typescript use string variable as property name>
    6.7 Objects <URL:#tn=    6.7 Objects>
        6.7.1 DFS traverse object properties <URL:#tn=        6.7.1 DFS traverse object properties>
        6.7.2 <URL:#tn=        6.7.2>
    6.8 <URL:#tn=    6.8>
7. OOD, polymorphism <URL:#tn=7. OOD, polymorphism>
    7.1 removing if/else, alternatives to statement branching <URL:#tn=    7.1 removing if/else, alternatives to statement branching>
        7.1.1 micro-branching <URL:#tn=        7.1.1 micro-branching>
            7.1.1.1 Guards (&&) and Defaults(||) <URL:#tn=            7.1.1.1 Guards (&&) and Defaults(||)>
            7.1.1.2 The Ternary operator <URL:#tn=            7.1.1.2 The Ternary operator>
            7.1.1.3 Function Delegation <URL:#tn=            7.1.1.3 Function Delegation>
        7.1.2 non-branching <URL:#tn=        7.1.2 non-branching>
            7.1.2.1 Property look-ups (a.k.a. dispatch tables) <URL:#tn=            7.1.2.1 Property look-ups (a.k.a. dispatch tables)>
            7.1.2.2 Array functions, map, filter, reduce <URL:#tn=            7.1.2.2 Array functions, map, filter, reduce>
            7.1.2.3 Functions as Data <URL:#tn=            7.1.2.3 Functions as Data>
        7.1.3 <URL:#tn=        7.1.3>
    7.2 What is polymorphism in Javascript? <URL:#tn=    7.2 What is polymorphism in Javascript?>
        7.2.1 A1 <URL:#tn=        7.2.1 A1>
            7.2.1.1 Parametric polymorphism (aka generics) <URL:#tn=            7.2.1.1 Parametric polymorphism (aka generics)>
            7.2.1.2 Ad-hoc polymorphism (aka overloading) <URL:#tn=            7.2.1.2 Ad-hoc polymorphism (aka overloading)>
            7.2.1.3 subtype (aka inheritance) polymorphism <URL:#tn=            7.2.1.3 subtype (aka inheritance) polymorphism>
                7.2.1.3.1 https://stackoverflow.com/questions/44391149/es6-classes-ability-to-perform-polymorphism <URL:#tn=                7.2.1.3.1 https://stackoverflow.com/questions/44391149/es6-classes-ability-to-perform-polymorphism>
                7.2.1.3.2 <URL:#tn=                7.2.1.3.2>
            7.2.1.4 Structural polymorphism (aka strutrual subtyping) <URL:#tn=            7.2.1.4 Structural polymorphism (aka strutrual subtyping)>
            7.2.1.5 <URL:#tn=            7.2.1.5>
        7.2.2 <URL:#tn=        7.2.2>
    7.3 <URL:#tn=    7.3>
8. ECMA6, ES6, Javascript6 <URL:#tn=8. ECMA6, ES6, Javascript6>
    8.1 lambda functions (aka => , fat arrow) <URL:#tn=    8.1 lambda functions (aka => , fat arrow)>
    8.2 classes <URL:#tn=    8.2 classes>
        8.1.1 ES6 classes <URL:#tn=        8.1.1 ES6 classes>
        8.1.2 Mock class <URL:#tn=        8.1.2 Mock class>
            8.1.2.1 https://medium.com/@madhanganesh/how-to-mock-es6-class-749da63268fc <URL:#tn=            8.1.2.1 https://medium.com/@madhanganesh/how-to-mock-es6-class-749da63268fc>
            8.1.2.2 <URL:#tn=            8.1.2.2>
        8.1.3 <URL:#tn=        8.1.3>
    8.3 <URL:#tn=    8.3>
9. Nodejs and C++ <URL:#tn=9. Nodejs and C++>
    9.1 How NodeJS requires native shared objects <URL:#tn=    9.1 How NodeJS requires native shared objects>
    9.2 <URL:#tn=    9.2>
10. Timers, tags: Timers, setTimeout, setImmediate, setInterval <URL:#tn=10. Timers, tags: Timers, setTimeout, setImmediate, setInterval>
    10.1  https://nodejs.org/en/docs/guides/timers-in-node/ <URL:#tn=    10.1  https://nodejs.org/en/docs/guides/timers-in-node/>
        10.1.1  "When I say so" Execution ~ setTimeout() <URL:#tn=        10.1.1  "When I say so" Execution ~ setTimeout()>
        10.1.2 "Right after this" Execution ~ setImmediate() <URL:#tn=        10.1.2 "Right after this" Execution ~ setImmediate()>
        10.1.3 "Infinite Loop" Execution ~ setInterval() <URL:#tn=        10.1.3 "Infinite Loop" Execution ~ setInterval()>
        10.1.4 Clearing the Future <URL:#tn=        10.1.4 Clearing the Future>
    10.2 The event loop <URL:#tn=    10.2 The event loop>
    10.3 <URL:#tn=    10.3>
11. troubleshooting <URL:#tn=11. troubleshooting>
    11.1 Error: Cannot find module '../lib/utils/unsupported.js' <URL:#tn=    11.1 Error: Cannot find module '../lib/utils/unsupported.js'>
    11.2 <URL:#tn=    11.2>
12. My demos <URL:#tn=12. My demos>
    12.1   /Users/i500695/work/code/nodejs/tutorial/Gruntfile.js <URL:#tn=    12.1   /Users/i500695/work/code/nodejs/tutorial/Gruntfile.js>
    12.2   /Users/i500695/work/code/nodejs/tutorial/arraysDemo.js <URL:#tn=    12.2   /Users/i500695/work/code/nodejs/tutorial/arraysDemo.js>
    12.3   /Users/i500695/work/code/nodejs/tutorial/asyncAwaitDemo.js <URL:#tn=    12.3   /Users/i500695/work/code/nodejs/tutorial/asyncAwaitDemo.js>
    12.4   /Users/i500695/work/code/nodejs/tutorial/buffers.js <URL:#tn=    12.4   /Users/i500695/work/code/nodejs/tutorial/buffers.js>
    12.5   /Users/i500695/work/code/nodejs/tutorial/classes.js <URL:#tn=    12.5   /Users/i500695/work/code/nodejs/tutorial/classes.js>
    12.6   /Users/i500695/work/code/nodejs/tutorial/client.js <URL:#tn=    12.6   /Users/i500695/work/code/nodejs/tutorial/client.js>
    12.7   /Users/i500695/work/code/nodejs/tutorial/dictionaryDemo.js <URL:#tn=    12.7   /Users/i500695/work/code/nodejs/tutorial/dictionaryDemo.js>
    12.8   /Users/i500695/work/code/nodejs/tutorial/eventEmitterListenersLeakDemo.js <URL:#tn=    12.8   /Users/i500695/work/code/nodejs/tutorial/eventEmitterListenersLeakDemo.js>
    12.9   /Users/i500695/work/code/nodejs/tutorial/evtHandlingDemo.js <URL:#tn=    12.9   /Users/i500695/work/code/nodejs/tutorial/evtHandlingDemo.js>
    12.10  /Users/i500695/work/code/nodejs/tutorial/expressDemo.js <URL:#tn=    12.10  /Users/i500695/work/code/nodejs/tutorial/expressDemo.js>
    12.11  /Users/i500695/work/code/nodejs/tutorial/fsDemo.js <URL:#tn=    12.11  /Users/i500695/work/code/nodejs/tutorial/fsDemo.js>
    12.12  /Users/i500695/work/code/nodejs/tutorial/globalsDemo.js <URL:#tn=    12.12  /Users/i500695/work/code/nodejs/tutorial/globalsDemo.js>
    12.13  /Users/i500695/work/code/nodejs/tutorial/helloWorld.js <URL:#tn=    12.13  /Users/i500695/work/code/nodejs/tutorial/helloWorld.js>
    12.14  /Users/i500695/work/code/nodejs/tutorial/helloWorldClass.js <URL:#tn=    12.14  /Users/i500695/work/code/nodejs/tutorial/helloWorldClass.js>
    12.15  /Users/i500695/work/code/nodejs/tutorial/jsObjectDemo.js <URL:#tn=    12.15  /Users/i500695/work/code/nodejs/tutorial/jsObjectDemo.js>
    12.16  /Users/i500695/work/code/nodejs/tutorial/promiseDemo.js <URL:#tn=    12.16  /Users/i500695/work/code/nodejs/tutorial/promiseDemo.js>
    12.17  /Users/i500695/work/code/nodejs/tutorial/regex.js <URL:#tn=    12.17  /Users/i500695/work/code/nodejs/tutorial/regex.js>
    12.18  /Users/i500695/work/code/nodejs/tutorial/server.js <URL:#tn=    12.18  /Users/i500695/work/code/nodejs/tutorial/server.js>
    12.19  /Users/i500695/work/code/nodejs/tutorial/serverRunner.js <URL:#tn=    12.19  /Users/i500695/work/code/nodejs/tutorial/serverRunner.js>
    12.20  /Users/i500695/work/code/nodejs/tutorial/sinonDemo.js <URL:#tn=    12.20  /Users/i500695/work/code/nodejs/tutorial/sinonDemo.js>
    12.21  /Users/i500695/work/code/nodejs/tutorial/sinonDemoManager.js <URL:#tn=    12.21  /Users/i500695/work/code/nodejs/tutorial/sinonDemoManager.js>
    12.22  /Users/i500695/work/code/nodejs/tutorial/streamsDemo.js <URL:#tn=    12.22  /Users/i500695/work/code/nodejs/tutorial/streamsDemo.js>
    12.23  /Users/i500695/work/code/nodejs/tutorial/switchStringDemo.js <URL:#tn=    12.23  /Users/i500695/work/code/nodejs/tutorial/switchStringDemo.js>
    12.24  /Users/i500695/work/code/nodejs/tutorial/uuidDemo.js <URL:#tn=    12.24  /Users/i500695/work/code/nodejs/tutorial/uuidDemo.js>
    12.25  /Users/i500695/work/code/nodejs/tutorial/watchDogDemo.js <URL:#tn=    12.25  /Users/i500695/work/code/nodejs/tutorial/watchDogDemo.js>
    12.26 <URL:#tn=    12.26>
    12.27 <URL:#tn=    12.27>
    12.28 <URL:#tn=    12.28>
    12.29 <URL:#tn=    12.29>
    12.30 <URL:#tn=    12.30>
    12.31 <URL:#tn=    12.31>
    12.32 <URL:#tn=    12.32>
    12.33 <URL:#tn=    12.33>
    12.34 <URL:#tn=    12.34>
    12.35 <URL:#tn=    12.35>
    12.36 <URL:#tn=    12.36>
    12.37 <URL:#tn=    12.37>
    12.38 <URL:#tn=    12.38>
    12.39 <URL:#tn=    12.39>
    12.40 <URL:#tn=    12.40>
    12.41 <URL:#tn=    12.41>
    12.42 <URL:#tn=    12.42>
    12.43 <URL:#tn=    12.43>
    12.44 <URL:#tn=    12.44>
    12.45 <URL:#tn=    12.45>
    12.46 <URL:#tn=    12.46>
    12.47 <URL:#tn=    12.47>
    12.48 <URL:#tn=    12.48>
    12.49 <URL:#tn=    12.49>
    12.50 <URL:#tn=    12.50>
    12.51 <URL:#tn=    12.51>
    12.52 <URL:#tn=    12.52>
    12.53 <URL:#tn=    12.53>
    12.54 <URL:#tn=    12.54>
    12.55 <URL:#tn=    12.55>
    12.56 <URL:#tn=    12.56>
    12.57 <URL:#tn=    12.57>
    12.58 <URL:#tn=    12.58>
    12.59 <URL:#tn=    12.59>
    12.60 <URL:#tn=    12.60>
    12.61 <URL:#tn=    12.61>
    12.62 <URL:#tn=    12.62>
    12.63 <URL:#tn=    12.63>
    12.64 <URL:#tn=    12.64>
    12.65 <URL:#tn=    12.65>
    12.66 <URL:#tn=    12.66>
    12.67 <URL:#tn=    12.67>
    12.68 <URL:#tn=    12.68>
    12.69 <URL:#tn=    12.69>
    12.70 <URL:#tn=    12.70>
    12.71 <URL:#tn=    12.71>
    12.72 <URL:#tn=    12.72>
    12.73 <URL:#tn=    12.73>
    12.74 <URL:#tn=    12.74>
    12.75 <URL:#tn=    12.75>
    12.76 <URL:#tn=    12.76>
    12.77 <URL:#tn=    12.77>
    12.78 <URL:#tn=    12.78>
    12.79 <URL:#tn=    12.79>
    12.80 <URL:#tn=    12.80>
    12.81 <URL:#tn=    12.81>
    12.82 <URL:#tn=    12.82>
    12.83 <URL:#tn=    12.83>
    12.84 <URL:#tn=    12.84>
    12.85 <URL:#tn=    12.85>
    12.86 <URL:#tn=    12.86>
    12.87 <URL:#tn=    12.87>
    12.88 <URL:#tn=    12.88>
    12.89 <URL:#tn=    12.89>
    12.90 <URL:#tn=    12.90>
    12.91 <URL:#tn=    12.91>
    12.92 <URL:#tn=    12.92>
    12.93 <URL:#tn=    12.93>
    12.94 <URL:#tn=    12.94>
    12.95 <URL:#tn=    12.95>
    12.96 <URL:#tn=    12.96>
    12.97 <URL:#tn=    12.97>
    12.98 <URL:#tn=    12.98>
    12.99 <URL:#tn=    12.99>
    12.100 <URL:#tn=    12.100>
    12.101 <URL:#tn=    12.101>
13. Language <URL:#tn=13. Language>
    13.1 Object API <URL:#tn=    13.1 Object API>
        13.1.1 Object.assign <URL:#tn=        13.1.1 Object.assign>
            13.1.1.1 Object.assign copy idiom, why should pass {} as first arg <URL:#tn=            13.1.1.1 Object.assign copy idiom, why should pass {} as first arg>
        13.1.2 <URL:#tn=        13.1.2>
    13.2 <URL:#tn=    13.2>
14. Axios <URL:#tn=14. Axios>
    14.1 axios 101 <URL:#tn=    14.1 axios 101>
    14.2 Set max response size <URL:#tn=    14.2 Set max response size>
    14.3 axios response headers <URL:#tn=    14.3 axios response headers>
        14.3.1  simple example <URL:#tn=        14.3.1  simple example>
    14.4 <URL:#tn=    14.4>
15. NodeJS tips and tricks <URL:#tn=15. NodeJS tips and tricks>
    15.1 python like idioms, tags: nodejs, python <URL:#tn=    15.1 python like idioms, tags: nodejs, python>
        15.1.1 python like range <URL:#tn=        15.1.1 python like range>
        15.1.2 python like list comprehension <URL:#tn=        15.1.2 python like list comprehension>
        15.1.3 JSON.stringfy <URL:#tn=        15.1.3 JSON.stringfy>
            15.1.3.1 my JSON.stringify demo <URL:#tn=            15.1.3.1 my JSON.stringify demo>
            15.1.3.2 <URL:#tn=            15.1.3.2>
        15.1.4 <URL:#tn=        15.1.4>
    15.2 <URL:#tn=    15.2>
16. Node features per version <URL:#tn=16. Node features per version>
    16.1 background <URL:#tn=    16.1 background>
    16.2  node version 0-4 <URL:#tn=    16.2  node version 0-4>
    16.3  node version 6-7 <URL:#tn=    16.3  node version 6-7>
    16.4  node version 8-9 <URL:#tn=    16.4  node version 8-9>
    16.5  node version 10-11 <URL:#tn=    16.5  node version 10-11>
    16.6  node version 12-13 <URL:#tn=    16.6  node version 12-13>
    16.7  node version 14-15 <URL:#tn=    16.7  node version 14-15>
    16.8  node version 16, tags: node 16 version <URL:#tn=    16.8  node version 16, tags: node 16 version>
        16.8.0  Platform support <URL:#tn=        16.8.0  Platform support>
        16.8.1  V8 version 9 <URL:#tn=        16.8.1  V8 version 9>
            16.8.1.1  RegExp match indices <URL:#tn=            16.8.1.1  RegExp match indices>
        16.8.2 Faster super property access <URL:#tn=        16.8.2 Faster super property access>
            16.8.2.1 v8 dev blog, https://v8.dev/blog/fast-super <URL:#tn=            16.8.2.1 v8 dev blog, https://v8.dev/blog/fast-super>
            16.8.2.2 <URL:#tn=            16.8.2.2>
        16.8.3 for ( async of disallowed <URL:#tn=        16.8.3 for ( async of disallowed>
            16.8.3.1 my demo <URL:#tn=            16.8.3.1 my demo>
            16.8.3.2 <URL:#tn=            16.8.3.2>
        16.8.4 WebAssembly <URL:#tn=        16.8.4 WebAssembly>
        16.8.5 Promises-based timer functions are supported in Node.js 16 <URL:#tn=        16.8.5 Promises-based timer functions are supported in Node.js 16>
        16.8.6  AbortController and AbortSignal APIs <URL:#tn=        16.8.6  AbortController and AbortSignal APIs>
            16.8.6.1  https://www.nearform.com/blog/using-abortsignal-in-node-js/ <URL:#tn=            16.8.6.1  https://www.nearform.com/blog/using-abortsignal-in-node-js/>
                16.8.6.1.1  Promise.race() <URL:#tn=                16.8.6.1.1  Promise.race()>
                16.8.6.1.2 AbortController() <URL:#tn=                16.8.6.1.2 AbortController()>
                16.8.6.1.3 My example <URL:#tn=                16.8.6.1.3 My example>
            16.8.6.2 https://javascript.info/fetch-abort <URL:#tn=            16.8.6.2 https://javascript.info/fetch-abort>
                16.8.6.2.1 The AbortController object <URL:#tn=                16.8.6.2.1 The AbortController object>
                16.8.6.2.2 Using with fetch <URL:#tn=                16.8.6.2.2 Using with fetch>
                16.8.6.2.3 AbortController is scalable <URL:#tn=                16.8.6.2.3 AbortController is scalable>
                16.8.6.2.4 my fetch abort example <URL:#tn=                16.8.6.2.4 my fetch abort example>
                16.8.6.2.5 <URL:#tn=                16.8.6.2.5>
            16.8.6.3 <URL:#tn=            16.8.6.3>
                16.8.6.3.1 <URL:#tn=                16.8.6.3.1>
            16.8.6.4 <URL:#tn=            16.8.6.4>
        16.8.7 Web Crypto API <URL:#tn=        16.8.7 Web Crypto API>
            16.8.7.1 Example generate key and use it to sign: <URL:#tn=            16.8.7.1 Example generate key and use it to sign:>
            16.8.7.2 webcrypto api <URL:#tn=            16.8.7.2 webcrypto api>
            16.8.7.3 Using the Web Cryptography APIs <URL:#tn=            16.8.7.3 Using the Web Cryptography APIs>
                16.8.7.3.1  Generating symmetric and asymmetric keys <URL:#tn=                16.8.7.3.1  Generating symmetric and asymmetric keys>
                16.8.7.3.2 <URL:#tn=                16.8.7.3.2>
            16.8.7.4 <URL:#tn=            16.8.7.4>
        16.8.8 Apple silicon processors supported <URL:#tn=        16.8.8 Apple silicon processors supported>
        16.8.9 base64 utility methods <URL:#tn=        16.8.9 base64 utility methods>
        16.8.10 ES 2021 support <URL:#tn=        16.8.10 ES 2021 support>
        16.8.11 deprecated <URL:#tn=        16.8.11 deprecated>
        16.8.12 <URL:#tn=        16.8.12>
    16.9  node version 17 <URL:#tn=    16.9  node version 17>
    16.10 node version 18, tags: node version 18 <URL:#tn=    16.10 node version 18, tags: node version 18>
        16.10.1 sources <URL:#tn=        16.10.1 sources>
        16.10.2 features <URL:#tn=        16.10.2 features>
            16.10.2.1 fetch finally arrives to NodeJS <URL:#tn=            16.10.2.1 fetch finally arrives to NodeJS>
            16.10.2.2 webstreams API <URL:#tn=            16.10.2.2 webstreams API>
                16.10.2.2.1 Read Demo <URL:#tn=                16.10.2.2.1 Read Demo>
                16.10.2.2.2 Other streams <URL:#tn=                16.10.2.2.2 Other streams>
                16.10.2.2.3 <URL:#tn=                16.10.2.2.3>
            16.10.2.3 HTTP timeouts <URL:#tn=            16.10.2.3 HTTP timeouts>
                16.10.2.3.1 - side note import.meta <URL:#tn=                16.10.2.3.1 - side note import.meta>
                    16.10.2.3.1.1 Use for Passing query parameters <URL:#tn=                    16.10.2.3.1.1 Use for Passing query parameters>
                    16.10.2.3.1.2 Getting current module's file path <URL:#tn=                    16.10.2.3.1.2 Getting current module's file path>
                        16.10.2.3.1.2.1 Before (CommonJS) <URL:#tn=                        16.10.2.3.1.2.1 Before (CommonJS)>
                        16.10.2.3.1.2.2 After (ES modules) <URL:#tn=                        16.10.2.3.1.2.2 After (ES modules)>
                        16.10.2.3.1.2.3 <URL:#tn=                        16.10.2.3.1.2.3>
                16.10.2.3.2 demo <URL:#tn=                16.10.2.3.2 demo>
                16.10.2.3.3 <URL:#tn=                16.10.2.3.3>
            16.10.2.4 Native Test Runner <URL:#tn=            16.10.2.4 Native Test Runner>
    1..2 <URL:#tn=    1..2>
1..2 <URL:#tn=1..2>
            16.10.2.5 V8 version 10.1 <URL:#tn=            16.10.2.5 V8 version 10.1>
            16.10.2.6 <URL:#tn=            16.10.2.6>
        16.10.3 <URL:#tn=        16.10.3>
    16.11 node version 19 <URL:#tn=    16.11 node version 19>
    16.12 node version 20 <URL:#tn=    16.12 node version 20>
17. NodeJS Design patterns <URL:#tn=17. NodeJS Design patterns>
    17.1  basics <URL:#tn=    17.1  basics>
        17.1.1  nodejs philosophy <URL:#tn=        17.1.1  nodejs philosophy>
        17.1.2 reactor pattern <URL:#tn=        17.1.2 reactor pattern>
            17.1.2.1 background <URL:#tn=            17.1.2.1 background>
            17.1.2.2 reactor pattern <URL:#tn=            17.1.2.2 reactor pattern>
            17.1.2.3 libuv <URL:#tn=            17.1.2.3 libuv>
            17.1.2.4 nodejs structure <URL:#tn=            17.1.2.4 nodejs structure>
            17.1.2.5 The callback pattern <URL:#tn=            17.1.2.5 The callback pattern>
            17.1.2.6 Node.js callback conventions <URL:#tn=            17.1.2.6 Node.js callback conventions>
            17.1.2.7 <URL:#tn=            17.1.2.7>
        17.1.3 The module system <URL:#tn=        17.1.3 The module system>
            17.1.3.1 The revealing module pattern <URL:#tn=            17.1.3.1 The revealing module pattern>
            17.1.3.2 Node.js modules explained <URL:#tn=            17.1.3.2 Node.js modules explained>
            17.1.3.3 module.exports vs exports <URL:#tn=            17.1.3.3 module.exports vs exports>
            17.1.3.4 require is synchronous <URL:#tn=            17.1.3.4 require is synchronous>
            17.1.3.5 The resolving algorithm <URL:#tn=            17.1.3.5 The resolving algorithm>
            17.1.3.6 The module cache <URL:#tn=            17.1.3.6 The module cache>
            17.1.3.7 Cycles <URL:#tn=            17.1.3.7 Cycles>
            17.1.3.8 Module definition patterns <URL:#tn=            17.1.3.8 Module definition patterns>
                17.1.3.8.1 Named exports <URL:#tn=                17.1.3.8.1 Named exports>
                17.1.3.8.2 Exporting a function <URL:#tn=                17.1.3.8.2 Exporting a function>
                17.1.3.8.3 Exporting a constructor <URL:#tn=                17.1.3.8.3 Exporting a constructor>
                17.1.3.8.4 Exporting an instance <URL:#tn=                17.1.3.8.4 Exporting an instance>
                17.1.3.8.5 Modifying other modules or the global scope <URL:#tn=                17.1.3.8.5 Modifying other modules or the global scope>
            17.1.3.9 <URL:#tn=            17.1.3.9>
        17.1.4 The observer pattern <URL:#tn=        17.1.4 The observer pattern>
            17.1.4.1 the EventEmitter <URL:#tn=            17.1.4.1 the EventEmitter>
                17.1.4.1.1 observer pattern in OOP language (e.g. c++) <URL:#tn=                17.1.4.1.1 observer pattern in OOP language (e.g. c++)>
                17.1.4.1.2 nodejs EventEmitter <URL:#tn=                17.1.4.1.2 nodejs EventEmitter>
                17.1.4.1.3 <URL:#tn=                17.1.4.1.3>
            17.1.4.2 Create and use an EventEmitter <URL:#tn=            17.1.4.2 Create and use an EventEmitter>
            17.1.4.3 <URL:#tn=            17.1.4.3>
        17.1.5 summary <URL:#tn=        17.1.5 summary>
    17.2 asynchronous control flow patterns <URL:#tn=    17.2 asynchronous control flow patterns>
    17.3 the module system patterns <URL:#tn=    17.3 the module system patterns>
    17.4 streams <URL:#tn=    17.4 streams>
    17.5 Design patterns <URL:#tn=    17.5 Design patterns>
    17.6 wiring modules <URL:#tn=    17.6 wiring modules>
    17.7 recipes <URL:#tn=    17.7 recipes>
18. Data structures <URL:#tn=18. Data structures>
    18.1  Map <URL:#tn=    18.1  Map>
        18.1.1  introduction <URL:#tn=        18.1.1  introduction>
        18.1.2 Map properties <URL:#tn=        18.1.2 Map properties>
        18.1.3 Map.prototype[@@toStringTag] <URL:#tn=        18.1.3 Map.prototype[@@toStringTag]>
        18.1.4 Map.prototype[@@iterator]() <URL:#tn=        18.1.4 Map.prototype[@@iterator]()>
        18.1.5 Map.prototype.clear() <URL:#tn=        18.1.5 Map.prototype.clear()>
        18.1.6 Map.prototype.delete() <URL:#tn=        18.1.6 Map.prototype.delete()>
    18.2 <URL:#tn=    18.2>
19. getters, setters and proxies <URL:#tn=19. getters, setters and proxies>
    19.1  https://www.invivoo.com/en/data-encapsulation-in-javascript-getters-and-setters/#:~:text=A%20getter%20is%20defined%20by,the%20property%20as%20a%20parameter. <URL:#tn=    19.1  https://www.invivoo.com/en/data-encapsulation-in-javascript-getters-and-setters/#:~:text=A%20getter%20is%20defined%20by,the%20property%20as%20a%20parameter.>
    19.2 <URL:#tn=    19.2>
20.  Node version managers, switchers, tags:Node version managers, switchers, toggle <URL:#tn=20.  Node version managers, switchers, tags:Node version managers, switchers, toggle>
    20.1  https://github.com/nvm-sh/nvm <URL:#tn=    20.1  https://github.com/nvm-sh/nvm>
        20.1.1  introduction <URL:#tn=        20.1.1  introduction>
        20.1.2 install <URL:#tn=        20.1.2 install>
        20.1.3 install and use a specific node version <URL:#tn=        20.1.3 install and use a specific node version>
        20.1.4 <URL:#tn=        20.1.4>
    20.2 n install and switch between different Node <URL:#tn=    20.2 n install and switch between different Node>
    20.3 <URL:#tn=    20.3>
21. commonly used patterns and idioms <URL:#tn=21. commonly used patterns and idioms>
    21.1 JSON.stringify <URL:#tn=    21.1 JSON.stringify>
    21.2 <URL:#tn=    21.2>
22. chatgpt Q&A <URL:#tn=22. chatgpt Q&A>
    22.1 arrays <URL:#tn=    22.1 arrays>
        22.1.1 splice <URL:#tn=        22.1.1 splice>
            22.1.1.1 q. Explain array splice nodejs <URL:#tn=            22.1.1.1 q. Explain array splice nodejs>
            22.1.1.2 izaqyos@me.com q. what does it do when passed just startIndex param <URL:#tn=            22.1.1.2 izaqyos@me.com q. what does it do when passed just startIndex param>
            22.1.1.3 splice demo <URL:#tn=            22.1.1.3 splice demo>
            22.1.1.4 <URL:#tn=            22.1.1.4>
        22.1.2 <URL:#tn=        22.1.2>
    22.2 <URL:#tn=    22.2>
23. compression <URL:#tn=23. compression>
    23.1  jszip <URL:#tn=    23.1  jszip>
        23.1.1  nodejs use jszip and fs to recursively compress a directory use import instead of require <URL:#tn=        23.1.1  nodejs use jszip and fs to recursively compress a directory use import instead of require>
        23.1.2 <URL:#tn=        23.1.2>
    23.2 <URL:#tn=    23.2>
24. <URL:#tn=24.>
.................................................END TOC..............................................



















1. my Tutorial


    1.1  nodejs. REPL (like python IDLE, Read, Eval, Print, Loop)


C02X632CJGH6:devVMSharedFolder i500695$ node
> 1+3
4
> console.log("node REPL")
node REPL
undefined
> 4+2
6
> console.log("_, last result: ", _)
_, last result:  6
undefined
> 


REPL Commands
* ctrl + c − terminate the current command.
* ctrl + c twice − terminate the Node REPL.
* ctrl + d − terminate the Node REPL.
* Up/Down Keys − see command history and modify previous commands.
* tab Keys − list of current commands.
* .help − list of all commands.
* .break − exit from multiline expression.
* .clear − exit from multiline expression.
* .save filename − save the current Node REPL session to a file.
* .load filename − load file content in current Node REPL session.REPL Commands
* ctrl + c − terminate the current command.
* ctrl + c twice − terminate the Node REPL.
* ctrl + d − terminate the Node REPL.
* Up/Down Keys − see command history and modify previous commands.
* tab Keys − list of current commands.
* .help − list of all commands.
* .break − exit from multiline expression.
* .clear − exit from multiline expression.
* .save filename − save the current Node REPL session to a file.
* .load filename − load file content in current Node REPL session.


    1.2 Nodejs NPM

        1.2.1  basics


Installing Modules using NPM
There is a simple syntax to install any Node.js module −
$ npm install <Module Name>
For example, following is the command to install a famous Node.js web framework module called express −
$ npm install express
Now you can use this module in your js file as following −
var express = require('express');

[i500695@C02X632CJGH6:2018-10-17 16:59:49:~/work/code/nodejs/tutorial:]538$ sudo npm install express
Password:
npm WARN saveError ENOENT: no such file or directory, open '/Users/i500695/Desktop/work/code/nodejs/tutorial/package.json'
npm WARN enoent ENOENT: no such file or directory, open '/Users/i500695/Desktop/work/code/nodejs/tutorial/package.json'
npm WARN tutorial No description
npm WARN tutorial No repository field.
npm WARN tutorial No README data
npm WARN tutorial No license field.

+ express@4.16.4
updated 1 package and audited 273 packages in 1.809s
found 0 vulnerabilities


List locally installed modules

[i500695@C02X632CJGH6:2018-10-17 17:00:15:~/work/code/nodejs/tutorial:]539$ npm ls
/Users/i500695/Desktop/work/code/nodejs/tutorial
└─┬ express@4.16.4
  ├─┬ accepts@1.3.5
  │ ├─┬ mime-types@2.1.20
  │ │ └── mime-db@1.36.0
  │ └── negotiator@0.6.1
  ├── array-flatten@1.1.1
  ├─┬ body-parser@1.18.3
  │ ├── bytes@3.0.0
…
[i500695@C02X632CJGH6:2018-10-17 17:05:49:~/work/code/nodejs/tutorial:]547$ ls ./node_modules/
accepts/		cookie-signature/	etag/			inherits/		mime-types/		qs/			setprototypeof/
array-flatten/		debug/			express/		ipaddr.js/		ms/			range-parser/		statuses/
body-parser/		depd/			finalhandler/		media-typer/		negotiator/		raw-body/		type-is/
bytes/			destroy/		forwarded/		merge-descriptors/	on-finished/		safe-buffer/		unpipe/
content-disposition/	ee-first/		fresh/			methods/		parseurl/		safer-buffer/		utils-merge/
content-type/		encodeurl/		http-errors/		mime/			path-to-regexp/		send/			vary/
cookie/			escape-html/		iconv-lite/		mime-db/


List globally installed modules

[i500695@C02X632CJGH6:2018-10-17 17:00:15:~/work/code/nodejs/tutorial:]539$ npm ls -g
…
[i500695@C02X632CJGH6:2018-10-17 17:05:12:~/work/code/nodejs/tutorial:]544$ ls /usr/local/lib/node_modules/
express/	grunt-cli/	npm/


nodejs package.json

Module structure file

ex.
[i500695@C02X632CJGH6:2018-10-17 17:05:52:~/work/code/nodejs/tutorial:]548$ ls /usr/local/lib/node_modules/express/package.json 
/usr/local/lib/node_modules/express/package.json[i500695@C02X632CJGH6:2018-10-17 17:05:52:~/work/code/nodejs/tutorial:]548$ ls /usr/local/lib/node_modules/express/package.json 
/usr/local/lib/node_modules/express/package.json

cat /usr/local/lib/node_modules/express/package.json 
{
  "_from": "express",
  "_id": "express@4.16.4",
  "_inBundle": false,
  "_integrity": "sha512-j12Uuyb4FMrd/qQAm6uCHAkPtO8FDTRJZBDd5D2KOL2eLaz1yUNdUB/NOIyq0iU4q4cFarsUCrnFDPBcnksuOg==",
  "_location": "/express",
  "_phantomChildren": {},
  "_requested": {
    "type": "tag",
    "registry": true,
    "raw": "express",
    "name": "express",
    "escapedName": "express",
    "rawSpec": "",
    "saveSpec": null,
    "fetchSpec": "latest"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "https://registry.npmjs.org/express/-/express-4.16.4.tgz",
  "_shasum": "fddef61926109e24c515ea97fd2f1bdbf62df12e",
  "_spec": "express",
  "_where": "/Users/i500695/Desktop/work/code/nodejs/tutorial",
  "author": {
    "name": "TJ Holowaychuk",
    "email": "tj@vision-media.ca"
  },
…

Attributes of Package.json
* name − name of the package
* version − version of the package
* description − description of the package
* homepage − homepage of the package
* author − author of the package
* contributors − name of the contributors to the package
* dependencies − list of dependencies. NPM automatically installs all the dependencies mentioned here in the node_module folder of the package.
* repository − repository type and URL of the package
* main − entry point of the package
* keywords − keywords



Uninstalling a Module
Use the following command to uninstall a Node.js module.
$ npm uninstall express
Once NPM uninstalls the package, you can verify it by looking at the content of /node_modules/ directory or type the following command −
$ npm ls
Updating a Module
Update package.json and change the version of the dependency to be updated and run the following command.
$ npm update express
Search a Module
Search a package name using NPM.
$ npm search express

Create a Module
Creating a module requires package.json to be generated. Let's generate package.json using NPM, which will generate the basic skeleton of the package.json.
$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sane defaults.

See 'npm help json' for definitive documentation on these fields
and exactly what they do.

Use 'npm install <pkg> --save' afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
name: (webmaster)
You will need to provide all the required information about your module. You can take help from the above-mentioned package.json file to understand the meanings of various information demanded. Once package.json is generated, use the following command to register yourself with NPM repository site using a valid email address.
$ npm adduser
Username: mcmohd
Password:
Email: (this IS public) mcmohd@gmail.com
It is time now to publish your module −
$ npm publish
If everything is fine with your module, then it will be published in the repository and will be accessible to install using NPM like any other Node.js module.

        1.2.2 my npm examples
 
  cat node_modules/valid-filename/index.js 
  cd node_modules/
  cd node_modules/valid-filename/
  cdnode 
  node
  node  helloWorld.js 
  node client.js 
  node helloWorld.js 
  node helloWorldTests.js 
  node promiseDemo.js 
  node regex.js 
  node sinonDemo.js 
  node uuidDemo.js 
  npm install --save valid-filename
  npm install --save-dev eslint
  npm install --save-dev filename-regex
  npm install --save-dev grunt-eslint
  npm install --save-dev grunt-mocha-test
  npm install --save-dev grunt-simple-nyc
  npm install --save-dev load-grunt-tasks
  npm install --save-dev mocha-test
  npm install --save-dev simple-nyc
  npm install --save-dev sinon
  npm install --save-dev uuid
  npm install --save-dev uuid-validate
  npm install --save-dev uuid-validator
  npm install -g grunt-cli
  npm install -g mocha
  npm install chai --save
  npm install grunt --save-dev
  npm install mocha --save
  npm test
  sudo npm install -g grunt-cli
  sudo npm install -g mocha
  vi node_modules/filename-regex/index.js 

            1.2.2.1  install specific version , ^ - semantic range operator
https://60devs.com/npm-install-specific-version.html

NPM: How to Install Specific Version of a Module

 
Newcomers to Node and NPM often ask how to install a specific version of a certain NPM package. There are several ways to accomplish this. First, let’s start with the basic NPM CLI syntax:

npm install lodash
This command installs lodash in the current folder and fetches the latest available version.

If you know the exact version of the package, you can append it to the package name after the @ character:

npm install lodash@4.17.4
You can look up the latest version for any NPM package at npmjs.com.

If you don’t know the exact version of the package, NPM allows using semantic ranges to define the version. For example,

npm install lodash@^4.0.0
This command will install the latest 4.x.x version. You can learn more about the syntax of semantic versioning at docs.npmjs.com.

Both aforementioned examples don’t modify package.json and don’t add installed modules to the list of dependencies. Use --save to add the installed module to the package.json’s dependencies and --save-dev to add it to devDependencies. If you install a module without defining a specific version (i.e. without any version or using a semantic range), NPM will add the semantic range to the package.json as is. To prevent this, use --save-exact flag in addition to --save or --save-dev. This flag will force NPM to store the exact module version in the package.json.

Examples
npm install lodash --save --save-exact - installs the latest version and saves the exact version in the dependencies in the package.json.
npm install lodash --save-dev --save-exact - installs the latest version and saves the exact version in the devDependencies map in the package.json.
npm install lodash --save - installs the latest version and saves the semantic range in the dependencies in the package.json. E.g. "lodash": "^4.17.4".

            1.2.2.2
        1.2.3 list dependencies, dependency tree, tags: node, npm, package.json, list dependencies, dependency tree, show outdated, latest, version
        
npm list
npm ls -all

        1.2.4 update dependencies , packages, upgrade, update, up to date packages

            1.2.4.1 https://docs.npmjs.com/updating-packages-downloaded-from-the-registry

$ cd /myproject
$ npm update
$ npm outdated

for global packages
npm install npm@latest -g 
npm outdated -g --depth=0

then either update one by one: npm update -g <package_name>
or all at once: npm update -g 

            1.2.4.2
        1.2.5 top node modules, tags: leading npm modules and packages

            1.2.5.1 express framework , tags:express framework 


                1.2.5.1.1 blog https://appdividend.com/2022/03/05/node-js-express-tutorial-for-beginners/, tags: express tutorial
root dir: /Users/i500695/work/code/nodejs/tutorial/express

                    1.2.5.1.1.1 first steps


a. create expressdemo dir and run npm init
[i500695@WYLQRXL9LQ:2022-08-18 18:19:33:~/work/code/nodejs/tutorial/express/expressdemo:]2020$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sensible defaults.

See `npm help init` for definitive documentation on these fields
and exactly what they do.

Use `npm install <pkg>` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
package name: (expressdemo) 
version: (1.0.0) 
description: express demo
entry point: (index.js) 
test command: test
git repository: 
keywords: 
author: yosi izaq
license: (ISC) 
About to write to /Users/i500695/work/code/nodejs/tutorial/express/expressdemo/package.json:

{
  "name": "expressdemo",
  "version": "1.0.0",
  "description": "express demo",
  "main": "index.js",
  "scripts": {
    "test": "test"
  },
  "author": "yosi izaq",
  "license": "ISC"
}


Is this OK? (yes) y

b. install Express 
$ npm i express --save

c.  Create a server.js file in the root.
Create our Node.js server through the following code.

// server.js

const express = require('express');
const app = express();
const port = 3000;
app.listen(port, function(){
  console.log('Node js Express js Tutorial');
});
We use the require() function to include the “express module.”

Before we can start using the express module, we need to make an object.

Here we are creating a callback function. This function will be called whenever anybody browses to the root of our web application which is http://localhost:3000.

The callback function will send the string ‘Node js Express js Tutorial’ to the web page.

In the callback function, we log the string ‘Node js Express js Tutorial’ back to the client.

We then use the listen to function to make our server application listen to client requests on port no 3000. You can specify any available port over here.

my example:
[i500695@WYLQRXL9LQ:2022-08-18 18:24:16:~/work/code/nodejs/tutorial/express/expressdemo:]2023$ cat !$
cat server.js
const express = require('express');
const app = express();
const port=3030;
app.listen(port, () => {
    console.log('Welcome to express demo');
});

d. nodemon
If we do not want to restart the server manually, we can use a node package called nodemon. It resets the server every time we change the file.

npm install nodemon --save-dev
Change the package.json file and add the following line in the “scripts” object.

"scripts": {
    "start": "nodemon server.js"
},
When you type in terminal “npm start,” it will bootstrap the server, and when we change the files, it will automatically restart.


                    1.2.5.1.1.2 ejs templating engine
what is a templating engine. see: https://appdividend.com/2018/11/24/how-to-use-template-engines-with-express/
e.  Install the EJS templating engine.
To include the CSS and js files in the express, first, we will create a static directory called the public, and in that, we will put our CSS and JS files.
[i500695@WYLQRXL9LQ:2022-08-18 18:26:35:~/work/code/nodejs/tutorial/express/expressdemo:]2027$ mkdir public
[i500695@WYLQRXL9LQ:2022-08-18 18:36:55:~/work/code/nodejs/tutorial/express/expressdemo:]2028$ ls
node_modules/		package-lock.json	package.json		public/			server.js

add to // server.js

app.use(express.static('public'));
We will use “ejs” as a templating engine, so first, we need to download that through NPM.

// server.js

npm install --save ejs
Now we need to update our server.js file to set the view engine.

// server.js

app.set('view engine', 'ejs');
We need to create one folder inside our root called views. Then, in that folder, make one file called index.ejs.

<!-- index.ejs -->

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>EJS Engine</title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
      <div class="jumbotron">
        Node js Express js Tutorial
      </div>
    </div>
  </body>
</html>

[i500695@WYLQRXL9LQ:2022-08-18 18:46:03:~/work/code/nodejs/tutorial/express/expressdemo:]2033$ mkdir views
[i500695@WYLQRXL9LQ:2022-08-18 18:47:28:~/work/code/nodejs/tutorial/express/expressdemo:]2034$ cd !$
cd views
[i500695@WYLQRXL9LQ:2022-08-18 18:47:31:~/work/code/nodejs/tutorial/express/expressdemo/views:]2035$ ed index.ejs
index.js: No such file or directory
a
<!-- index.ejs -->

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>EJS Engine</title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
      <div class="jumbotron">
        Node js Express js Tutorial
      </div>
    </div>
  </body>
</html>

.
w
323
q

f. To display this route, we need to add the following code to the server.js file.
app.get('/', function (req, res) {
   res.sendFile(path.join(__dirname,'public', 'index.html'));
});
Our index.html file inside the public folder looks like this.

<!DOCTYPE html>
<html lang="en">
<head>
   <meta charset="UTF-8">
   <meta name="viewport" content="width=He, initial-scale=1.0">
   <meta http-equiv="X-UA-Compatible" content="ie=edge">
   <title>Node js tutorial</title>
</head>
<body>
   Node js tutorial
</body>
</html>

open browser at http://localhost:3030/

                    1.2.5.1.1.3 handle routes 
Before we deep dive into routes, let’s understand the basics of routes in the Express web framework.

What are Routes
Routing determines how an application responds to a client request to a particular endpoint.

For example, a client can make a GET, POST, PUT or DELETE http request for various URLs such as the ones shown below;

http://localhost:3000/coins
http://localhost:3000/coins/post
In the above example,

If a GET request is made for the first URL, the response should ideally be a list of coins.
If the POST request is made for the second URL, we will save the data.
So based on the URL which is accessed, a different functionality on the web server will be invoked, and accordingly, the response will be sent to the client. This is the concept of routing.
Each route can have one or more handler functions executed when the route is matched.

Set up the routes for our application. So use the Router module provided by Express js. First, create a folder inside root called routes. Then, in that folder, make one file called CoinRouter.js.

const express = require('express');
const app = express();
const CoinRouter = express.Router();

CoinRouter.route('/').get(function (req, res) {
  res.render('index');
});
module.exports = CoinRouter;

here's mine:
[i500695@WYLQRXL9LQ:2022-08-23 14:55:45:~/work/code/nodejs/tutorial/express/expressdemo:]2041$ cat routes/CoinRouter.js 
const express = require('express');
const app = express();
const CoinRouter = express.Router();

CoinRouter.route('/').get( (req, res) => {
    res.render('index');
});
module.exports = CoinRouter;

now wire it to server.js 
// server.js

const CoinRouter = require('./routes/CoinRouter');

app.use('/coins', CoinRouter);
Please switch to the browser URL: http://localhost:3000/coins/. It will display an index view.

The next step will be to create a bootstrap interface to add the coin name and price.

(I used port 3030, so http://localhost:3030/coins/)

                    1.2.5.1.1.4 Create a form for adding coins
In the views, the folder makes one file called to create.ejs file.

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>EJS Engine generated coins form </title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
        <h1>Add Coin</h1>
        <form method="post" action="/coins/post">
          <div class="form-group">
            <label for="item">Coin Name</label>
            <input type="text" class="form-control" id="name" name="name">
          </div>
          <div class="form-group">
            <label for="item">Coin Price</label>
            <input type="text" class="form-control" id="price" name="price">
          </div>
          <button type="submit" class="btn btn-default">Submit Coin</button>
        </form>
    </div>
  </body>
</html>

The next step is to create a route in the CoinRouter.js file, so put the following code.

// CoinRouter.js

CoinRouter.route('/create').get(function (req, res) {
   res.render('create');
 });

Navigate to form, http://localhost:3030/coins/create

                    1.2.5.1.1.5 Install Mongoose Library.
First get mongo container running. See: <url:/Users/i500695/work/KB/containers_kb#r=run_MongoDB_with_docker_>
verify mongo running:
$ docker ps -a | grep mongo
44fc8960722e   mongo:latest   "docker-entrypoint.s…"   2 days ago     Up 2 days                 0.0.0.0:27017->27017/tcp   test-mongo

We will use MongoDB for the database, so we set up a MongoDB database, so we need to download a package called Mongoose in our project.

npm install --save mongoose
Now, configure the database for our Node js application.

// server.js

const mongoose = require('mongoose');

mongoose.Promise = global.Promise; // only required for mongoose ver < 5. see https://stackoverflow.com/questions/51862570/mongoose-why-we-make-mongoose-promise-global-promise-when-setting-a-mongoo
mongoose.connect('mongodb://localhost/expressdemo');

                    1.2.5.1.1.6 Install the body-parser module.
We are sending the form data to the Node js server, so we need to install the body-parser module to parse our posted data and insert that data into the MongoDB database.

npm install --save body-parser
Now, include this module in our server.js file.
// server.js

const bodyParser = require('body-parser');

app.use(bodyParser.urlencoded({extended: true}));
app.use(bodyParser.json());

                    1.2.5.1.1.7 create a model
Next is to create a model for our database. So create one folder in the root called models. In that folder, create one file called Coin.model.js.

// Coin.model.js

const mongoose = require('mongoose');
const Schema = mongoose.Schema;

const Coin = new Schema({
  name: {
    type: String
  },
  price: {
     type: Number
  }
},{
    collection: 'coins'
});

module.exports = mongoose.model('Coin', Coin);

                    1.2.5.1.1.8 add coin post route 
Now, create a  post route in the CoinRouter.js put the following code.

// CoinRouter.js

const Coin = require('../models/Coin.model');

CoinRouter.route('/post').post(function (req, res) {
   const coin = new Coin(req.body);
   console.log(coin);
   coin.save()
     .then(coin => {
     res.redirect('/coins');
     })
     .catch(err => {
     res.status(400).send("unable to save to database");
     });
 });
Each route can have one or more handler functions executed when the route is matched.

The general syntax for a route is shown below.

app.METHOD(PATH, HANDLER)
Wherein,

1) app is an instance of the express module

2) METHOD is an HTTP request method (GET, POST, PUT or DELETE)

3) PATH is a path on the server.

4) HANDLER is the function executed when the route is matched.

                    1.2.5.1.1.9 server.js 
Our server.js file looks like this.

// server.js

const express = require('express');
const app = express();
const port = 3000;
const path = require('path');
const mongoose = require('mongoose');
const bodyParser = require('body-parser');

mongoose.Promise = global.Promise;
mongoose.connect('mongodb://localhost/expressdemo');

const CoinRouter = require('./routes/CoinRouter');

app.use(express.static('public'));
app.set('view engine', 'ejs');

app.use(bodyParser.urlencoded({extended: true}));
app.use(bodyParser.json());

app.use('/coins', CoinRouter);

app.get('/', function (req, res) {
   res.sendFile(path.join(__dirname,'public', 'index.html'));
});

app.listen(port, function(){
  console.log('Node js Express js Tutorial at port', port);
});
Here we define a route if the URL http://localhost:3000/coins is selected in the browser. In addition, we are attaching a callback function to the route that will be called when we browse to the coins listing URL.

When the URL contains /coins URI, it will execute CoinRouter, which includes many subroutes for Get, Post, Patch, and Delete requests.

Try to submit the Coin, and yes, it will successfully add to the MongoDB database.

                    1.2.5.1.1.10 display coins list 
We need to get the data from the database, so you need to put the following code in the CoinRouter.js file.

// CoinRouter.js

CoinRouter.route('/').get(function (req, res) {
   Coin.find(function (err, coins){
      if(err){
        console.log(err);
      }
      else {
        res.render('index', {coins: coins});
      }
    });
});

Also, we need to modify that index.ejs view to show the data.

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Node js Express Tutorial. EJS generated index for coins example </title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
      <table class="table table-striped">
        <thead>
          <tr>
            <td><b>Coin Name</b></td>
            <td><b>Coin Price</b></td>
            <td colspan="2"><b>Action</b></td>
          </tr>
        </thead>
        <tbody>
          <% for(var i=0; i < coins.length; i++) { %>
          <tr>
            <td><%= coins[i].name %></td>
            <td><%= coins[i].price %></td>
            <td><a href="" class="btn btn-primary">Edit</a></td>
            <td><a href="" class="btn btn-danger">Delete</a></td>
          </tr>
          <% } %>
        </tbody>
      </table>
    </div>
  </body>
</html>

                    1.2.5.1.1.11 Make edit view and route.
In the views folder, make one called edit.ejs. Also, we need to pass the data from the database by its id.
In MongoDB, the primary key is _id. So we need to fetch the collection of data by its id. So write the following code into the CoinRouter.js file.

// CoinRouter.js

CoinRouter.route('/edit/:id').get(function (req, res) {
   const id = req.params.id;
   Coin.findById(id, function (err, coin){
       res.render('edit', {coin: coin});
   });
 });

Create an edit.ejs file in the views directory.

<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Edit Coin</title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
        <h1>Edit Coin</h1>
        <form method="post" action="/coins/update/<%= coin._id %>">
          <div class="form-group">
            <label for="item">Coin Name</label>
            <input type="text" class="form-control" id="name" name="name" value="<%= coin.name %>">
          </div>
          <div class="form-group">
            <label for="item">Coin Price</label>
            <input type="text" class="form-control" id="price" name="price" value="<%= coin.price %>">
          </div>
          <button type="submit" class="btn btn-default">Update</button>
        </form>
    </div>
  </body>
</html>

Now, code the update function to update the values in the database.

                    1.2.5.1.1.12 Delete the data.
Now, delete functionality remains, which we will do and call it a day.

// CoinRouter.js

CoinRouter.route('/delete/:id').get(function (req, res) {
  Coin.findByIdAndRemove({_id: req.params.id},
       function(err, coin){
        if(err) res.json(err);
        else res.redirect('/coins');
    });
});

                    1.2.5.1.1.13 Full code
[i500695@WYLQRXL9LQ:2022-09-04 18:24:35:~/work/code/nodejs/tutorial/express/expressdemo:]2010$ ls
models/			node_modules/		package-lock.json	package.json		public/			routes/			server.js		views/

                        1.2.5.1.1.13.1 root level


[i500695@WYLQRXL9LQ:2022-09-04 18:24:59:~/work/code/nodejs/tutorial/express/expressdemo:]2011$ cat package.json 
{
  "name": "expressdemo",
  "version": "1.0.0",
  "description": "express demo",
  "main": "index.js",
  "scripts": {
    "start": "nodemon server.js",
    "test": "test"
  },
  "author": "yosi izaq",
  "license": "ISC",
  "dependencies": {
    "body-parser": "^1.20.0",
    "ejs": "^3.1.8",
    "express": "^4.18.1",
    "mongoose": "^6.5.2"
  },
  "devDependencies": {
    "nodemon": "^2.0.19"
  }
}
[i500695@WYLQRXL9LQ:2022-09-04 18:25:08:~/work/code/nodejs/tutorial/express/expressdemo:]2012$ cat server.js 
const express = require('express');
const app = express();
const CoinRouter = require('./routes/CoinRouter.js');
const mongoose = require('mongoose');
const bodyParser = require('body-parser');
const path = require('path');

app.use(express.static('public'));
app.use(bodyParser.urlencoded({extended: true}));
app.use(bodyParser.json());
app.set('view engine', 'ejs');

const port=3030;
mongoose.connect('mongodb://localhost/expressdemo');

app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'index.html'));
});
app.use('/coins', CoinRouter);

app.listen(port, () => {
    console.log('Welcome to express demo');
});


                        1.2.5.1.1.13.2 models 
[i500695@WYLQRXL9LQ:2022-09-04 18:25:41:~/work/code/nodejs/tutorial/express/expressdemo:]2014$ ls models/
Coin.model.js
[i500695@WYLQRXL9LQ:2022-09-04 18:25:47:~/work/code/nodejs/tutorial/express/expressdemo:]2015$ cat models/Coin.model.js 
const mongoose = require('mongoose');
const Schema = mongoose.Schema;

const CoinSchema = new Schema({
    name: {type: String},
    price: {type: Number}
},
    {collection: 'coins'}
);

module.exports = mongoose.model('Coin', CoinSchema);


                        1.2.5.1.1.13.3 static 
[i500695@WYLQRXL9LQ:2022-09-04 18:26:12:~/work/code/nodejs/tutorial/express/expressdemo:]2017$ ls public/
index.html
[i500695@WYLQRXL9LQ:2022-09-04 18:26:18:~/work/code/nodejs/tutorial/express/expressdemo:]2018$ cat public/index.html 
<!DOCTYPE html>
<html lang="en">
<head>
   <meta charset="UTF-8">
   <meta name="viewport" content="width=He, initial-scale=1.0">
   <meta http-equiv="X-UA-Compatible" content="ie=edge">
   <title>Node js tutorial</title>
</head>
<body>
   Node js tutorial
</body>
</html>


                        1.2.5.1.1.13.4 routes
[i500695@WYLQRXL9LQ:2022-09-04 18:26:25:~/work/code/nodejs/tutorial/express/expressdemo:]2019$ ls routes/
CoinRouter.js
[i500695@WYLQRXL9LQ:2022-09-04 18:26:54:~/work/code/nodejs/tutorial/express/expressdemo:]2020$ cat routes/CoinRouter.js 
const Coin = require('../models/Coin.model');
const express = require('express');
// const app = express();
const CoinRouter = express.Router();

CoinRouter.route('/create').get( (req, res) => {
    res.render('create');
});

CoinRouter.route('/').get( (req, res) => {
    // 1st step return index.html
    // res.render('index');

    // 2nd step, after mongo and model are ready return coins list 
    Coin.find(  (errs, coins) => {
        if (errs) {
            console.log(`error producing coins list: ${errs}`);
        }
        else {
        }
        res.render('index', {coins: coins}); //note, that index.ejs will display the coins
    }
    );
});

CoinRouter.route('/edit/:id').get( (req, res) => {
    const id = req.params.id; // extract query (path) param id.
    Coin.findById(id, (err, coin) => {
        res.render('edit', {coin: coin});
    });
});

CoinRouter.route('/').post( (req, res) => {
    Coin.find( (err, coins) => {
        if (err) {
            console.log(err);
        } else {
            res.render('index', {coins: coins});
        }
    }
    );
});

CoinRouter.route('/post').post( (req, res) => {
    console.log('/post got body ', JSON.stringify(req.body, null, 4));
    const coin = new Coin(req.body);
    console.log('/post got coin ', JSON.stringify(coin, null, 4));
    coin.save().then( coin => {
        res.redirect('/coins');
    }).catch( err => {
        const msg = `Failed to save coin to DB due to error: ${err}`
        res.status(400).send(msg);
    });
});

CoinRouter.route('/update/:id').post( (req, res) => {
    console.log('Trying to update coin with id', req.params.id);
    Coin.findById(req.params.id, (err, coin) => {
        if (!coin) {
            // return next(new Error('Failed to find coin for update'));
            res.status(403).send('Failed to find coin for update');
        }
        else {
            coin.name = req.body.name;
            coin.price = req.body.price;
            coin.save().then( coin => {
                res.redirect('/coins');
            }).catch( err => {
                res.status(400).send(`Failed to update DB for coin ${coin.name}`);
            });;
        }

    });
});

CoinRouter.route('/delete/:id').get(function (req, res) {
  Coin.findByIdAndRemove({_id: req.params.id},
       function(err, coin){
        if(err) res.json(err);
        else res.redirect('/coins');
    });
});

module.exports = CoinRouter;


                        1.2.5.1.1.13.5 views
[i500695@WYLQRXL9LQ:2022-09-04 18:29:11:~/work/code/nodejs/tutorial/express/expressdemo:]2031$ for f in $(ls views/); do echo "$f"; cat "views/$f"; done
create.ejs
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>EJS Engine generated coins form </title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
        <h1>Add Coin</h1>
        <form method="post" action="/coins/post">
          <div class="form-group">
            <label for="item">Coin Name</label>
            <input type="text" class="form-control" id="name" name="name">
          </div>
          <div class="form-group">
            <label for="item">Coin Price</label>
            <input type="text" class="form-control" id="price" name="price">
          </div>
          <button type="submit" class="btn btn-default">Submit Coin</button>
        </form>
    </div>
  </body>
</html>

edit.ejs
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Edit Coin</title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
        <h1>Edit Coin</h1>
        <form method="post" action="/coins/update/<%= coin._id %>">
          <div class="form-group">
            <label for="item">Coin Name</label>
            <input type="text" class="form-control" id="name" name="name" value="<%= coin.name %>">
          </div>
          <div class="form-group">
            <label for="item">Coin Price</label>
            <input type="text" class="form-control" id="price" name="price" value="<%= coin.price %>">
          </div>
          <button type="submit" class="btn btn-default">Update</button>
        </form>
    </div>
  </body>
</html>

index.ejs
<!-- index.ejs -->
<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Node js Express Tutorial. EJS generated index for coins example </title>
    <link rel="stylesheet" href="/css/bootstrap.min.css">
  </head>
  <body>
    <div class="container">
      <table class="table table-striped">
        <thead>
          <tr>
            <td><b>Coin Name</b></td>
            <td><b>Coin Price</b></td>
            <td colspan="2"><b>Action</b></td>
          </tr>
        </thead>
        <tbody>
          <% for(var i=0; i < coins.length; i++) { %>
          <tr>
            <td><%= coins[i].name %></td>
            <td><%= coins[i].price %></td>
            <td><a href="coins/edit/<%= coins[i]._id %>" class="btn btn-primary">Edit</a></td>
            <td><a href="coins/delete/<%= coins[i]._id %>" class="btn btn-danger">Delete</a></td>
          </tr>
          <% } %>
        </tbody>
      </table>
    </div>
  </body>
</html>
                    1.2.5.1.1.14 Run instructions
a. mongo Container should be running:
e.g.
[i500695@WYLQRXL9LQ:2022-09-04 18:17:25:~:]2003$ docker ps -a
CONTAINER ID   IMAGE          COMMAND                  CREATED        STATUS          PORTS                      NAMES
44fc8960722e   mongo:latest   "docker-entrypoint.s…"   12 days ago    Up 55 minutes   0.0.0.0:27017->27017/tcp   test-mongo

b. start web server
$cd /Users/i500695/work/code/nodejs/tutorial/express/expressdemo
[i500695@WYLQRXL9LQ:2022-09-04 18:18:41:~/work/code/nodejs/tutorial/express/expressdemo:]2008$ npm run start

> expressdemo@1.0.0 start
> nodemon server.js

[nodemon] 2.0.19
[nodemon] to restart at any time, enter `rs`
[nodemon] watching path(s): *.*
[nodemon] watching extensions: js,mjs,json
[nodemon] starting `node server.js`
Welcome to express demo

c. browse to root http://localhost:3030/coins
cmd+alt+i for dev Tools

d. create a few coins 
http://localhost:3030/coins/create
use the form the create a few coins 

ex: 
Welcome to express demo
/post got body  {
    "name": "bitcoin",
    "price": "100"
}
/post got coin  {
    "name": "bitcoin",
    "price": 100,
    "_id": "6314c28eac5ecec51ada56bb"
}

e. delete coins by clicking delete 

f. update coins by clicking update 
Trying to update coin with id 6314c28eac5ecec51ada56bb

                    1.2.5.1.1.15
                1.2.5.1.2 


                1.2.5.1.3

            1.2.5.2
<url:#r=__express__>

            1.2.5.2 koa.js  framework
Koa works wonders creating different web services, aka APIs. With Koa, building these APIs becomes super fun and easy since it can efficiently deal with HTTP middleware with a stack-like method.

Further, it normalizes Node flaws constructively. You can maintain various forms of the content represented to the users with the same URL like translating a page, personalizing content in eCommerce websites, having different formats for images, and much more with this framework. 

Another perk of using Koa is that it’s quite similar to Express. You can still enjoy the flexibility of Express with more freedom and fewer complexities while writing code. This minimizes the scope of errors across the entire stack of the application. 

Features:

Is a Customizable & Futuristic framework- is referred to as a lightweight version of Express
Handles errors exceptionally 
Has cascading middleware (Personalizing user experience)
Normalises node inconsistencies clean and helps in maintaining code 
Cleans cache, supports proxy and content negotiation
Has more options for Customisation; allows building apps from scratch
When to use Koa.js 

When performance is a critical demand from your web application, Koa is what you need. Especially for a big project, the framework can build extensive apps with large and experienced development teams. Under certain circumstances, Koa has proven to be a faster framework than Express.

However, it may seem to be a difficult choice for beginners because it’s still in the growth stages with the community and is less popular as a result. 

            1.2.5.3 meteor framework
If you are looking for a framework that is specific to Javascript and uses only one language, Meteor.js is the ideal pick.  

Officially launched in 2012, startup software, Meteor, developed Meteor.js — an open-source, isomorphic, Javascript web framework. It propagates automatic data changes to clients without developer’s efforts. Most importantly, it’s comfortable with variants of device-operating systems including Android, iOS for mobile devices and desktop applications all wrapped in one language- Javascript. 

Meteor has comprehensive libraries and testing features to keep up with the client-server communication. The framework is known for its smooth running of data between client and server, which most applications of high-streaming, real-time functionalities require. 

Meteor is a perfect Node.js framework to build simple, efficient, and modern web applications. 

Features:

Writing of code in modern JavaScript, Isomorphic framework
Cross-platform framework, building rapid prototyping with CLI
Extensive community support, open-source framework 
Full-stack solution 
Superfast interactions – fast results 
Easy integration with other frameworks
When to use Meteor.js

If your development team is good to go with Javascript, Meteor.js is a splendid choice. It is very easy to learn and super fun to program in. You can use it to build apps in no time since the framework allows you to use the same code written for a web app or mobile app. With Meteor, you can also deploy live updates even on the installed apps without disrupting an on-going user session. 

Also, did I mention? The framework builds real-time applications with its built-in core. Without a doubt, it’s a perfect solution for collaboration with real-time app projects, short deadlines, and cross-platform
            1.2.5.4 socket.io for chat apps
Socket.io is a Javascript library used in building real-time apps and establishing bidirectional communication between web clients and servers. With this library framework, you can develop applications with requirements for websocket development. For example, chat applications like Whatsapp continuously run for live updates and refresh the background process for updates or messages. It also offers real-time analytics in fewer lines of code.

More than a thousand companies, including Bepro, Barogo, and Patreon, use Socket.io.

Features:

Binary support (with a client-side library and a server-side library)
Multiplexing support
Reliability
Auto-reconnection support
Error detection & auto-correction
Similar APIs for a client and server-side development
When to use Socket.io

Socket.io develops real-time applications like chat room applications, video conferencing apps, multiplayer games, and others, where servers are required to push the data without being requested from the client side. For example, live video calling apps like Zoom need to communicate real-time bidirectional data to several participants and Socket could come in handy with similar apps.
            1.2.5.5 nestjs 
see <url:/Users/i500695/work/KB/nestjs_kb>

            1.2.5.6 fastify

            1.2.5.7 lodash , tags: lodash
Lodash is a popular utility library for JavaScript that provides a wide range of functions for working with arrays, objects, strings, and other types of data. Here are some useful Lodash functions that you might find helpful:

_.map(): Returns a new array with the results of calling a function on each element in the original array.
const arr = [1, 2, 3];
const doubled = _.map(arr, n => n * 2);
console.log(doubled); // [2, 4, 6]

_.filter(): Returns a new array with all elements from the original array that pass a test function.
const arr = [1, 2, 3];
const even = _.filter(arr, n => n % 2 === 0);
console.log(even); // [2]

_.reduce(): Reduces an array to a single value by calling a function on each element and accumulating the result.
const arr = [1, 2, 3];
const sum = _.reduce(arr, (acc, n) => acc + n, 0);
console.log(sum); // 6

_.groupBy(): Groups elements in an array by a given key.
const arr = [
  { id: 1, name: 'Alice' },
  { id: 2, name: 'Bob' },
  { id: 3, name: 'Charlie' },
  { id: 4, name: 'Alice' }
];
const byName = _.groupBy(arr, 'name');
console.log(byName);
/*
{
  Alice: [
    { id: 1, name: 'Alice' },
    { id: 4, name: 'Alice' }
  ],
  Bob: [
    { id: 2, name: 'Bob' }
  ],
  Charlie: [
    { id: 3, name: 'Charlie' }
  ]
}
*/

_.sortBy(): Returns a new array with the elements from the original array sorted by a given key.
const arr = [
  { name: 'Charlie', age: 30 },
  { name: 'Alice', age: 25 },
  { name: 'Bob', age: 35 }
];
const byAge = _.sortBy(arr, 'age');
console.log(byAge);
/*
[
  { name: 'Alice', age: 25 },
  { name: 'Charlie', age: 30 },
  { name: 'Bob', age: 35 }
]
*/

_.isEqual(): Returns true if two values are deeply equal, meaning they have the same properties and values (for objects) or the same elements (for arrays).
const a = { x: [1, 2], y: 'hello' };
const b = { x: [1, 2], y: 'hello' };
console.log(_.isEqual(a, b)); // true
These are just a few examples of the many useful Lodash functions available. You can find more information and examples in the Lodash documentation.

_.cloneDeep(): Creates a deep copy of an object or array, including nested objects and arrays.
const obj = { a: { b: [1, 2] } };
const copy = _.cloneDeep(obj);
console.log(copy); // { a: { b: [1, 2] } }
console.log(copy === obj); // false
console.log(copy.a === obj.a); // false
console.log(copy.a.b === obj.a.b); // false

_.debounce(): Creates a debounced function that delays invoking a function until after a certain amount of time has elapsed since the last time it was called.
function saveChanges() {
  console.log('Changes saved!');
}

const debouncedSaveChanges = _.debounce(saveChanges, 1000);

debouncedSaveChanges();
debouncedSaveChanges();
debouncedSaveChanges();

// Only one "Changes saved!" message is logged, after one second has elapsed.

_.throttle(): Creates a throttled function that limits the rate at which a function can be called.
function logMessage() {
  console.log('Hello!');
}

const throttledLogMessage = _.throttle(logMessage, 1000);

setInterval(throttledLogMessage, 500);
// "Hello!" is logged every second, not every 500 milliseconds

_.chunk(): Creates an array of elements split into groups of a given size.
const arr = [1, 2, 3, 4, 5, 6];
const chunks = _.chunk(arr, 2);
console.log(chunks); // [[1, 2], [3, 4], [5, 6]]

_.zip(): Creates an array of grouped elements, the first of which contains the first elements of the given arrays, the second of which contains the second elements, and so on.
const a = [1, 2, 3];
const b = ['a', 'b', 'c'];
const zipped = _.zip(a, b);
console.log(zipped); // [[1, 'a'], [2, 'b'], [3, 'c']]

_.uniqBy(): Returns a new array with unique elements based on a given key.
const arr = [
  { id: 1, name: 'Alice' },
  { id: 2, name: 'Bob' },
  { id: 3, name: 'Charlie' },
  { id: 4, name: 'Alice' }
];
const uniqueByName = _.uniqBy(arr, 'name');
console.log(uniqueByName); // [{ id: 1, name: 'Alice' }, { id: 2, name: 'Bob' }, { id: 3, name: 'Charlie' }]
I hope these additional examples are helpful! Lodash provides many other useful functions as well, so it's worth exploring the documentation to see what else it can do.

_.omit(): Returns a new object with all properties of the original object except for the ones specified.
const obj = { a: 1, b: 2, c: 3 };
const withoutB = _.omit(obj, 'b');
console.log(withoutB); // { a: 1, c: 3 }

_.pick(): Returns a new object with only the properties of the original object specified.
const obj = { a: 1, b: 2, c: 3 };
const onlyBAndC = _.pick(obj, ['b', 'c']);
console.log(onlyBAndC); // { b: 2, c: 3 }

_.get(): Gets the value at the specified path in an object, or returns a default value if the path is not found.
const obj = { a: { b: { c: 1 } } };
console.log(_.get(obj, 'a.b.c')); // 1
console.log(_.get(obj, 'x.y.z', 'default')); // 'default'

_.set(): Sets the value at the specified path in an object.
const obj = { a: { b: { c: 1 } } };
_.set(obj, 'a.b.c', 2);
console.log(obj); // { a: { b: { c: 2 } } }

_.isEmpty(): Checks if a given value is empty (i.e. has no enumerable properties).
console.log(_.isEmpty({})); // true
console.log(_.isEmpty([])); // true
console.log(_.isEmpty('')); // true
console.log(_.isEmpty(null)); // true
console.log(_.isEmpty(undefined)); // true
console.log(_.isEmpty({ a: 1 })); // false
console.log(_.isEmpty([1])); // false
console.log(_.isEmpty('a')); // false
console.log(_.isEmpty(0)); // true (because 0 has no enumerable properties)

_.isEqual(): Compares two values to see if they are equivalent.
console.log(_.isEqual({ a: [1, 2] }, { a: [1, 2] })); // true
console.log(_.isEqual({ a: [1, 2] }, { a: [2, 1] })); // false
console.log(_.isEqual(1, '1')); // false

_.capitalize(): Capitalizes the first letter of a string.
console.log(_.capitalize('hello world')); // 'Hello world'
console.log(_.capitalize('42')); // '42'
console.log(_.capitalize('')); // ''

_.times(): Invokes a function a specified number of times, passing in the index of each iteration.
_.times(3, console.log);
// 0
// 1
// 2

const arr = _.times(3, n => n ** 2);
console.log(arr); // [0, 1, 4]
I hope these additional examples are helpful as well! Lodash is a very powerful library with many useful functions for manipulating data.P

                1.2.5.7.1 getting-started 

tutorial: https://www.tutorialspoint.com/lodash/lodash_environment.htm 


                1.2.5.7.2 unionWith
[i500695@WYLQRXL9LQ:2023-04-20 18:18:23:~/work/code/nodejs/lodash:]2044$ cat unions.js 

const _ = require('lodash');

let arr1 = [ 1,2, [1,2]];
let arr2 = [ 1,3, 4];
let arr3 = _.union(arr1,arr2);
console.log('demo union of array ', arr1,' and array ', arr2, 'union: ', arr3);

let arrays = [ arr1, arr2, arr3];
let arr4 = _.unionWith(...arrays, (a,b) => {return a===b;});
console.log('demo union of array of arrays ', arrays, 'lodash union: ', arr4);
let arr5 = Array.from(new Set(...arrays));
let set1 = new Set(...arrays);
console.log('demo union of array of arrays ', arrays, 'Set from arrays: ', set1, ' ES6 union: ', arr5);
[i500695@WYLQRXL9LQ:2023-04-20 18:18:27:~/work/code/nodejs/lodash:]2045$ node unions.js 
node:internal/modules/cjs/loader:1093
  throw err;
  ^

Error: Cannot find module 'lodash'
[i500695@WYLQRXL9LQ:2023-04-20 18:19:15:~/work/code/nodejs/lodash:]2046$ npm i lodash
[i500695@WYLQRXL9LQ:2023-04-20 18:19:26:~/work/code/nodejs/lodash:]2047$ node unions.js 
demo union of array  [ 1, 2, [ 1, 2 ] ]  and array  [ 1, 3, 4 ] union:  [ 1, 2, [ 1, 2 ], 3, 4 ]
demo union of array of arrays  [ [ 1, 2, [ 1, 2 ] ], [ 1, 3, 4 ], [ 1, 2, [ 1, 2 ], 3, 4 ] ] lodash union:  [ 1, 2, [ 1, 2 ], 3, 4 ]
demo union of array of arrays  [ [ 1, 2, [ 1, 2 ] ], [ 1, 3, 4 ], [ 1, 2, [ 1, 2 ], 3, 4 ] ] Set from arrays:  Set(3) { 1, 2, [ 1, 2 ] }  ES6 union:  [ 1, 2, [ 1, 2 ] ]

                1.2.5.7.3 nested json paths

                    1.2.5.7.3.1 is there a lodash utility function that returns a list of nested paths of JSON object 
Yes, Lodash has a utility function called _.toPath() that can be used to convert a string representation of a nested property path to an array of property names.

For example, given a JSON object like this:

const obj = {
  foo: {
    bar: {
      baz: 42
    }
  }
};

You can use _.toPath() to convert the string 'foo.bar.baz' to an array ['foo', 'bar', 'baz']:

const path = _.toPath('foo.bar.baz');
console.log(path); // ['foo', 'bar', 'baz']
To get a list of all possible nested paths of a JSON object, you can use a combination of Lodash's _.flatMapDeep() and _.toPath() functions.

Here's an example implementation:

const getAllNestedPaths = (obj, prefix = []) => {
  return _.flatMapDeep(obj, (value, key) => {
    const path = [...prefix, key];
    return _.isObject(value) ? getAllNestedPaths(value, path) : path;
  });
};

// Example usage:
const obj = {
  foo: {
    bar: {
      baz: 42
    },
    qux: [1, 2, 3]
  },
  fizz: 'buzz'
};

const paths = getAllNestedPaths(obj);
console.log(paths); // [['foo', 'bar', 'baz'], ['foo', 'qux'], ['fizz']]
The getAllNestedPaths() function takes a JSON object and an optional prefix array parameter (defaulted to an empty array), which is used to build up the path as we recursively traverse the object.

The function uses _.flatMapDeep() to iterate over each property of the object and return either an array of nested paths (if the property is an object), or a single path (if the property is not an object).

For object properties, we recursively call getAllNestedPaths() with the current property and the updated path, and flatten the resulting array using _.flatMapDeep(). For non-object properties, we simply return the current path.

Finally, we get a flat array of all nested paths by calling getAllNestedPaths() with the top-level object, and log the result to the console.

[i500695@WYLQRXL9LQ:2023-04-20 18:31:30:~/work/code/nodejs/lodash/nested_paths:]2058$ cat !$
cat get_all_nested_paths_simple.js
const _ = require('lodash');
const getAllNestedPaths = (obj, prefix = []) => {
  return _.flatMapDeep(obj, (value, key) => {
    const path = [...prefix, key];
    return _.isObject(value) ? getAllNestedPaths(value, path) : path;
  });
};

// Example usage:
const obj = {
  foo: {
    bar: {
      baz: 42
    },
    qux: [1, 2, 3]
  },
  fizz: 'buzz'
};

const paths = getAllNestedPaths(obj);
console.log("Getting all paths of", obj); 
console.log(paths); // [['foo', 'bar', 'baz'], ['foo', 'qux'], ['fizz']]

[i500695@WYLQRXL9LQ:2023-04-20 18:32:41:~/work/code/nodejs/lodash/nested_paths:]2059$ node get_all_nested_paths_simple.js
Getting all paths of { foo: { bar: { baz: 42 }, qux: [ 1, 2, 3 ] }, fizz: 'buzz' }
[
  'foo',  'bar', 'baz',
  'foo',  'qux', 0,
  'foo',  'qux', 1,
  'foo',  'qux', 2,
  'fizz'
]
                    1.2.5.7.3.2 modify to get a nested list of key values of the paths
To modify the previous implementation to get a nested list of key-value pairs for each path, we can simply modify the base case of the recursion to return an object with the current path and value, instead of just the path.

Here's the modified implementation:

const getAllNestedPaths = (obj, prefix = []) => {
  return _.flatMapDeep(obj, (value, key) => {
    const path = [...prefix, key];
    return _.isObject(value)
      ? getAllNestedPaths(value, path)
      : { path, value };
  });
};

// Example usage:
const obj = {
  foo: {
    bar: {
      baz: 42
    },
    qux: [1, 2, 3]
  },
  fizz: 'buzz'
};

const paths = getAllNestedPaths(obj);
console.log(paths);
The getAllNestedPaths() function is almost the same as before, but now we return an object with both the current path and value when we reach a non-object property.

We then use _.flatMapDeep() to recursively iterate over all properties, and return either a nested array of key-value pairs (if the property is an object), or a single key-value pair (if the property is not an object).

Finally, we get a flat array of all nested key-value pairs by calling getAllNestedPaths() with the top-level object, and log the result to the console.

This will output:

[
  { path: ['foo', 'bar', 'baz'], value: 42 },
  { path: ['foo', 'qux', '0'], value: 1 },
  { path: ['foo', 'qux', '1'], value: 2 },
  { path: ['foo', 'qux', '2'], value: 3 },
  { path: ['fizz'], value: 'buzz' }
]
As you can see, we now have a flat list of key-value pairs for each path in the original object.

[i500695@WYLQRXL9LQ:2023-04-20 18:40:05:~/work/code/nodejs/lodash/nested_paths:]2071$ cat !$
cat get_all_nested_paths_and_values.js
const _ = require('lodash');
const getAllNestedPaths = (obj, prefix = []) => {
  return _.flatMapDeep(obj, (value, key) => {
    const path = [...prefix, key];
    console.log(path);
    return _.isObject(value)
      ? getAllNestedPaths(value, path)
      : { path, value };
  });
};

// Example usage:
const obj = {
  foo: {
    bar: {
      baz: 42
    },
    qux: [1, 2, 3]
  },
  fizz: 'buzz'
};

const paths = getAllNestedPaths(obj);
console.log(paths);

[i500695@WYLQRXL9LQ:2023-04-20 18:40:16:~/work/code/nodejs/lodash/nested_paths:]2072$ node !$
node get_all_nested_paths_and_values.js
[ 'foo' ]
[ 'foo', 'bar' ]
[ 'foo', 'bar', 'baz' ]
[ 'foo', 'qux' ]
[ 'foo', 'qux', 0 ]
[ 'foo', 'qux', 1 ]
[ 'foo', 'qux', 2 ]
[ 'fizz' ]
[
  { path: [ 'foo', 'bar', 'baz' ], value: 42 },
  { path: [ 'foo', 'qux', 0 ], value: 1 },
  { path: [ 'foo', 'qux', 1 ], value: 2 },
  { path: [ 'foo', 'qux', 2 ], value: 3 },
  { path: [ 'fizz' ], value: 'buzz' }
]
                    1.2.5.7.3.3 modify to get path of specific property recurring in nested objects. say an id property
[i500695@WYLQRXL9LQ:2023-04-20 18:44:39:~/work/code/nodejs/lodash/nested_paths:]2081$ cat !$
cat get_all_nested_paths_and_values_for_property.js
const _ = require('lodash');
const getPathsForProperty = (obj, propName, prefix = []) => {
  return _.flatMapDeep(obj, (value, key) => {
    const path = [...prefix, key];
    if (_.isObject(value)) {
      return getPathsForProperty(value, propName, path);
    } else if (key === propName) {
      return {path, value};
    } else {
      return [];
    }
  });
};

// Example usage:
const obj = {
  foo: {
    id: 'fooId',
    bar: {
      id: 'barId',
      baz: {
        id: 'bazId'
      }
    }
  },
  fizz: {
    buzz: {
      id: 'buzzId'
    }
  }
};

console.log("getting all nested ids of", JSON.stringify(obj, null,4));
const paths = getPathsForProperty(obj, 'id');
console.log(paths);

[i500695@WYLQRXL9LQ:2023-04-20 18:45:20:~/work/code/nodejs/lodash/nested_paths:]2082$ node !$
node get_all_nested_paths_and_values_for_property.js
getting all nested ids of {
    "foo": {
        "id": "fooId",
        "bar": {
            "id": "barId",
            "baz": {
                "id": "bazId"
            }
        }
    },
    "fizz": {
        "buzz": {
            "id": "buzzId"
        }
    }
}
[
  { path: [ 'foo', 'id' ], value: 'fooId' },
  { path: [ 'foo', 'bar', 'id' ], value: 'barId' },
  { path: [ 'foo', 'bar', 'baz', 'id' ], value: 'bazId' },
  { path: [ 'fizz', 'buzz', 'id' ], value: 'buzzId' }
]
                    1.2.5.7.3.4
                1.2.5.7.4
            1.2.5.8 axios 
Axios is an HTTP client API framework that allows developers to make promises while making a request. Requests communicate with the server, and Axios responds with a promise as to whether your request was fulfilled or refused.

Among many developers, Axios is gaining a lot of traction, thanks to Axios-fetch, Axios-debug-log, Axios-mock-adapter, Axios-API-versioning, Axios-VCR, and other powerful third-party additions.

Axios can handle GET, POST, DELETE, and PUT requests.

Features of Axios
Allows developers to make simultaneous requests.
Axios supports promised base requests.
Transforms responses and requests to JSON data.
Requests and responses to interceptions.
Support HTTP requests for Node js apps
Supports HTTP requests from the browsers.


            1.2.5.9 karma 
Node js developers must test their applications to ensure they are stable, dependable, and perform well. This job requires a Karma package. Karma’s primary goal is to provide a productive testing environment to developers.

Features of Karma
Tests code in real browsers.
Tests code in multiple browsers (mobile phones, tablets, and desktops).
Controls the whole testing workflow from command or IDE.
Executes tests after every save.
Executes tests locally during development.
Executes tests on a continuous integration server.


            1.2.5.10 grunt 
With a task runner, Grunt developers can reduce the number of tasks required to maintain a project, automate minifications, compile jobs, testing, code linting, and other duties. 

Features of Grunt
Grunt has a plethora of plugins that can automate even the most monotonous jobs.
Grunt allows developers to publish Grunt-specific plugins through NPM.

            1.2.5.11 PM2
For most Node js users, process management is a top concern. 

PM2 includes process management for production applications and a load balancer to assist with performance adjustments. 

PM2 allows developers to keep their applications online indefinitely. This step allows developers to reload applications without experiencing any downtime. 

Features of PM2
Behavior configuration
Container Integration
Watch & Reload
Log management
Monitoring
Max memory reload

            1.2.5.12 Mocha is a feature-rich JS test framework that runs on Node js and the browser, making asynchronous testing simple and enjoyable. 

Mocha tests are executed sequentially, allowing flexible and precise reporting while mapping uncaught exceptions to the appropriate test cases.

Features of Mocha
Multiple browser support.
Simple async support, including promises.
Test coverage reporting.
String diff support.
JavaScript API for running tests.
Auto-detects and disables coloring for non-TTYs.
Async test timeout support.

            1.2.5.13 jsonwebtoken
Jsonwebtoken is a library to sign, verify and decode JSON Web Tokens.

const jwt = require('jsonwebtoken');
const token = jwt.sign({ foo: 'bar' }, 'shhhhh');

            1.2.5.14 bcrypt
Bcrypt is a library to hash and verify passwords with sync, callbacks, and promise interface.

const bcrypt = require('bcrypt');
const saltRounds = 10;
const myPlaintextPassword = 's0/\/\P4$$w0rD';
bcrypt.hash(myPlaintextPassword, saltRounds, function(err, hash) {
    // Store hash in your password DB.
});

            1.2.5.15 uuid
UUID is a library to create RFC4122 universally unique identifiers.

const { v4: uuidv4 } = require('uuid');
uuidv4(); // => '1a68a438-b077-468b-b1e8-dcdd976a0f5b'

            1.2.5.16 passport
Passport is Express-compatible authentication middleware for Node.js with 480+ strategies.

passport.use(new LocalStrategy(
  function(username, password, done) {
    User.findOne({ username: username }, function (err, user) {
      if (err) { return done(err); }
      if (!user) { return done(null, false); }
      if (!user.verifyPassword(password)) { return done(null, false); }
      return done(null, user);
    });
  }
));

            1.2.5.17 multer , tags: multer

                1.2.5.17.1 blog: https://blog.logrocket.com/multer-nodejs-express-upload-file , tags: multer express upload tutorial

                    1.2.5.17.1.1 forms
Web applications receive all different types of input from users, including text, graphical controls like checkboxes or radio buttons, and files, like images, videos, and other media.

In forms, each of these inputs are submitted to a server that processes the inputs, uses them in some way, perhaps saving them somewhere else, then gives the frontend a success or failed response.

When submitting forms that contain text inputs, the server, Node.js in our case, has less work to do. Using Express, you can easily grab all the inputs entered in the req.body object. However, submitting forms with files is a bit more complex because they require more processing, which is where Multer comes in.

                1.2.5.17.2

            1.2.5.18 https://www.npmjs.com/package/npkill
`npkill` is a Node.js command-line utility that can be used to find and remove node_modules folders that are no longer being used by your project. 

Here's how you can use `npkill`:

| 1. Install `npkill` globally using the following command:
| 
| ```
| npm install -g npkill
| ```
| 
| 2. Navigate to the root directory of your project.
| 
| 3. Run `npkill` by typing `npkill` in the terminal and pressing Enter.
| 
| 4. `npkill` will display a list of all the `node_modules` folders in your project directory and its subdirectories, along with the disk space they are consuming.
| 
| 5. You can navigate through the list using the arrow keys and select the `node_modules` folders you want to remove using the spacebar.
| 
| 6. After selecting the folders you want to remove, press the Enter key to delete them.

Note that `npkill` will permanently delete the selected `node_modules` folders from your system, so be sure to double-check that you have selected the correct folders before confirming the deletion.

Also, make sure to run `npm install` after deleting the `node_modules` folders to re-install the dependencies needed for your project to run.

            1.2.5.19 nodejs unzipper module. description, use cases and code examples, tags: nodejs unzipper module. description use cases and code examples
Absolutely! Let's dive into the `unzipper` module for Node.js:

**Description**

* **Purpose:** The `unzipper` module is designed for parsing and extracting `.zip` files in Node.js applications. It offers a convenient, stream-based API to handle large ZIP archives without loading them entirely into memory.
* **Core Features:**
    * Reads zip files as streams.
    * Extracts specific files based on filename patterns.
    * Supports events for entry opening, extraction, and closing.
    * Can handle various file types within zip archives.
    * No native module dependencies, relying on Node.js's built-in `zlib` module for decompression. 
* **Installation:**
   ```bash
   npm install unzipper
   ```

**Use Cases**

|1. **File Extraction:** Extract individual files or all files from a zip archive.
|2. **Filtering:** Extract only the files that match specific patterns (e.g., only `.txt` files).
|3. **Stream Processing:**  Process extracted files as they are being unzipped, ideal for large archives.
|4. **Custom Logic:** Execute custom actions for each entry in the archive (e.g., rename, move, validate files). 

**Code Examples**

**Example 1: Extracting All Files**

```javascript
const fs = require('fs');
const unzipper = require('unzipper');

fs.createReadStream('my_archive.zip')
  .pipe(unzipper.Extract({ path: 'output_directory' }))
  .on('close', () => console.log('Extraction complete!'));
```

**Example 2: Extracting Specific Files**

```javascript
const fs = require('fs');
const unzipper = require('unzipper');

fs.createReadStream('my_archive.zip')
  .pipe(unzipper.Parse()) // Parse the archive
  .on('entry', (entry) => {
    const fileName = entry.path;
    const type = entry.type; // 'Directory' or 'File'

    if (fileName.endsWith('.txt')) { 
      // Only extract text files
      entry.pipe(fs.createWriteStream('output_directory/' + fileName));
    } else {
      entry.autodrain(); // Discard non-text files
    }
  })
  .on('close', () => console.log('Extraction complete!'));
```

**Example 3: Extracting and Handling a Specific File**

```javascript
const fs = require('fs');
const unzipper = require('unzipper');

fs.createReadStream('my_archive.zip')
    .pipe(unzipper.ParseOne(/specific_file\.txt/)) // Extract this file only
    .pipe(fs.createWriteStream('specific_file.txt'))
    .on('error', (error) => console.error(error))
    .on('finish', () => console.log('File extraction complete!'));

```


**Explanation:**

|1. **Create a readable stream:** `fs.createReadStream` opens the ZIP file in streaming mode.
|2. **Pipe to `unzipper.Extract` or `unzipper.Parse`:**
|   * `unzipper.Extract` is used to directly extract all files to a specified directory.
|   * `unzipper.Parse` is for handling individual entries within the archive using the `entry` event.
|3. **`entry` Event:**  Emitted for each file or directory within the zip. You can examine the `entry.path` and `entry.type` to decide what to do with each entry.
|4. **`pipe` for Extraction:** To extract a file, pipe its contents to a writable stream (`fs.createWriteStream`).
|5. **`autodrain`:** Discard the contents of entries you don't want to extract.
|6. **`close` Event:** Indicates that the entire archive has been processed.


            1.2.5.20
        1.2.6
    1.3 nodejs Event Loop

        1.3.1  basics 

Node.js is a single-threaded application, but it can support concurrency via the concept of event and callbacks. Every API of Node.js is asynchronous and being single-threaded, they use async function calls to maintain concurrency. Node uses observer pattern. Node thread keeps an event loop and whenever a task gets completed, it fires the corresponding event which signals the event-listener function to execute.

Event-Driven Programming
Node.js uses events heavily and it is also one of the reasons why Node.js is pretty fast compared to other similar technologies. As soon as Node starts its server, it simply initiates its variables, declares functions and then simply waits for the event to occur.

In an event-driven application, there is generally a main loop that listens for events, and then triggers a callback function when one of those events is detected.

Event Loop
Although events look quite similar to callbacks, the difference lies in the fact that callback functions are called when an asynchronous function returns its result, whereas event handling works on the observer pattern. The functions that listen to events act as Observers. Whenever an event gets fired, its listener function starts executing. Node.js has multiple in-built events available through events module and EventEmitter class which are used to bind events and event-listeners as follows −

// Import events module
var events = require('events');

// Create an eventEmitter object
var eventEmitter = new events.EventEmitter();
Following is the syntax to bind an event handler with an event −

// Bind event and event  handler as follows
eventEmitter.on('eventName', eventHandler);
We can fire an event programmatically as follows −

// Fire an event 
eventEmitter.emit('eventName');
Example
Create a js file named main.js with the following code −

// Import events module
var events = require('events');


// Create an eventEmitter object
var eventEmitter = new events.EventEmitter();

// Create an event handler as follows
var connectHandler = function connected() {
   console.log('connection succesful.');
  
   // Fire the data_received event 
   eventEmitter.emit('data_received');
}

// Bind the connection event with the handler
eventEmitter.on('connection', connectHandler);
 
// Bind the data_received event with the anonymous function
eventEmitter.on('data_received', function(){
   console.log('data received succesfully.');
});

// Fire the connection event 
eventEmitter.emit('connection');

console.log("Program Ended.");
Now let's try to run the above program and check its output −

$ node main.js
IT should produce the following result −

connection successful.
data received successfully.
Program Ended.
How Node Applications Work?
In Node Application, any async function accepts a callback as the last parameter and a callback function accepts an error as the first parameter. Let's revisit the previous example again. Create a text file named input.txt with the following content.

Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!
Create a js file named main.js having the following code −

var fs = require("fs");

fs.readFile('input.txt', function (err, data) {
   if (err){
      console.log(err.stack);
      return;
   }
   console.log(data.toString());
});
console.log("Program Ended");
Here fs.readFile() is a async function whose purpose is to read a file. If an error occurs during the read operation, then the err object will contain the corresponding error, else data will contain the contents of the file. readFile passes err and data to the callback function after the read operation is complete, which finally prints the content.

Program Ended
Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!

        1.3.2 nodejs event-loop timers and nexttick

            1.3.2.1 background


https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/#:~:text=setImmediate()%20and%20setTimeout(),threshold%20in%20ms%20has%20elapsed.
What is the Event Loop?
The event loop is what allows Node.js to perform non-blocking I/O operations — despite the fact that JavaScript is single-threaded — by offloading operations to the system kernel whenever possible.

Since most modern kernels are multi-threaded, they can handle multiple operations executing in the background. When one of these operations completes, the kernel tells Node.js so that the appropriate callback may be added to the poll queue to eventually be executed. We'll explain this in further detail later in this topic.

Event Loop Explained
When Node.js starts, it initializes the event loop, processes the provided input script (or drops into the REPL, which is not covered in this document) which may make async API calls, schedule timers, or call process.nextTick(), then begins processing the event loop.

The following diagram shows a simplified overview of the event loop's order of operations.

   ┌───────────────────────────┐
┌─>│           timers          │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │     pending callbacks     │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │       idle, prepare       │
│  └─────────────┬─────────────┘      ┌───────────────┐
│  ┌─────────────┴─────────────┐      │   incoming:   │
│  │           poll            │<─────┤  connections, │
│  └─────────────┬─────────────┘      │   data, etc.  │
│  ┌─────────────┴─────────────┐      └───────────────┘
│  │           check           │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
└──┤      close callbacks      │
   └───────────────────────────┘

Each box will be referred to as a "phase" of the event loop.

Each phase has a FIFO queue of callbacks to execute. While each phase is special in its own way, generally, when the event loop enters a given phase, it will perform any operations specific to that phase, then execute callbacks in that phase's queue until the queue has been exhausted or the maximum number of callbacks has executed. When the queue has been exhausted or the callback limit is reached, the event loop will move to the next phase, and so on.

Since any of these operations may schedule more operations and new events processed in the poll phase are queued by the kernel, poll events can be queued while polling events are being processed. As a result, long running callbacks can allow the poll phase to run much longer than a timer's threshold. See the timers and poll sections for more details.

There is a slight discrepancy between the Windows and the Unix/Linux implementation, but that's not important for this demonstration. The most important parts are here. There are actually seven or eight steps, but the ones we care about — ones that Node.js actually uses - are those above.


id=_nodejs_eventloop_timers_and_nexttick
            1.3.2.2 Phases Overview
timers: this phase executes callbacks scheduled by setTimeout() and setInterval().
pending callbacks: executes I/O callbacks deferred to the next loop iteration.
idle, prepare: only used internally.
poll: retrieve new I/O events; execute I/O related callbacks (almost all with the exception of close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate.
check: setImmediate() callbacks are invoked here.
close callbacks: some close callbacks, e.g. socket.on('close', ...).
Between each run of the event loop, Node.js checks if it is waiting for any asynchronous I/O or timers and shuts down cleanly if there are not any.

            1.3.2.3 Phases in Detail

                1.3.2.3.1 timers
A timer specifies the threshold after which a provided callback may be executed rather than the exact time a person wants it to be executed. Timers callbacks will run as early as they can be scheduled after the specified amount of time has passed; however, Operating System scheduling or the running of other callbacks may delay them.

Technically, the poll phase controls when timers are executed.

For example, say you schedule a timeout to execute after a 100 ms threshold, then your script starts asynchronously reading a file which takes 95 ms:

const fs = require('fs');

function someAsyncOperation(callback) {
  // Assume this takes 95ms to complete
  fs.readFile('/path/to/file', callback);
}

const timeoutScheduled = Date.now();

setTimeout(() => {
  const delay = Date.now() - timeoutScheduled;

  console.log(`${delay}ms have passed since I was scheduled`);
}, 100);

// do someAsyncOperation which takes 95 ms to complete
someAsyncOperation(() => {
  const startCallback = Date.now();

  // do something that will take 10ms...
  while (Date.now() - startCallback < 10) {
    // do nothing
  }
});
When the event loop enters the poll phase, it has an empty queue (fs.readFile() has not completed), so it will wait for the number of ms remaining until the soonest timer's threshold is reached. While it is waiting 95 ms pass, fs.readFile() finishes reading the file and its callback which takes 10 ms to complete is added to the poll queue and executed. When the callback finishes, there are no more callbacks in the queue, so the event loop will see that the threshold of the soonest timer has been reached then wrap back to the timers phase to execute the timer's callback. In this example, you will see that the total delay between the timer being scheduled and its callback being executed will be 105ms.

To prevent the poll phase from starving the event loop, libuv (the C library that implements the Node.js event loop and all of the asynchronous behaviors of the platform) also has a hard maximum (system dependent) before it stops polling for more events.

pending callbacks
This phase executes callbacks for some system operations such as types of TCP errors. For example if a TCP socket receives ECONNREFUSED when attempting to connect, some *nix systems want to wait to report the error. This will be queued to execute in the pending callbacks phase.

poll
The poll phase has two main functions:

Calculating how long it should block and poll for I/O, then
Processing events in the poll queue.
When the event loop enters the poll phase and there are no timers scheduled, one of two things will happen:

If the poll queue is not empty, the event loop will iterate through its queue of callbacks executing them synchronously until either the queue has been exhausted, or the system-dependent hard limit is reached.

If the poll queue is empty, one of two more things will happen:

If scripts have been scheduled by setImmediate(), the event loop will end the poll phase and continue to the check phase to execute those scheduled scripts.

If scripts have not been scheduled by setImmediate(), the event loop will wait for callbacks to be added to the queue, then execute them immediately.

Once the poll queue is empty the event loop will check for timers whose time thresholds have been reached. If one or more timers are ready, the event loop will wrap back to the timers phase to execute those timers' callbacks.

check
This phase allows a person to execute callbacks immediately after the poll phase has completed. If the poll phase becomes idle and scripts have been queued with setImmediate(), the event loop may continue to the check phase rather than waiting.

setImmediate() is actually a special timer that runs in a separate phase of the event loop. It uses a libuv API that schedules callbacks to execute after the poll phase has completed.

Generally, as the code is executed, the event loop will eventually hit the poll phase where it will wait for an incoming connection, request, etc. However, if a callback has been scheduled with setImmediate() and the poll phase becomes idle, it will end and continue to the check phase rather than waiting for poll events.

close callbacks
If a socket or handle is closed abruptly (e.g. socket.destroy()), the 'close' event will be emitted in this phase. Otherwise it will be emitted via process.nextTick().

setImmediate() vs setTimeout()
setImmediate() and setTimeout() are similar, but behave in different ways depending on when they are called.

setImmediate() is designed to execute a script once the current poll phase completes.
setTimeout() schedules a script to be run after a minimum threshold in ms has elapsed.
The order in which the timers are executed will vary depending on the context in which they are called. If both are called from within the main module, then timing will be bound by the performance of the process (which can be impacted by other applications running on the machine).

For example, if we run the following script which is not within an I/O cycle (i.e. the main module), the order in which the two timers are executed is non-deterministic, as it is bound by the performance of the process:

// timeout_vs_immediate.js
setTimeout(() => {
  console.log('timeout');
}, 0);

setImmediate(() => {
  console.log('immediate');
});
$ node timeout_vs_immediate.js
timeout
immediate

$ node timeout_vs_immediate.js
immediate
timeout
However, if you move the two calls within an I/O cycle, the immediate callback is always executed first:

// timeout_vs_immediate.js
const fs = require('fs');

fs.readFile(__filename, () => {
  setTimeout(() => {
    console.log('timeout');
  }, 0);
  setImmediate(() => {
    console.log('immediate');
  });
});
$ node timeout_vs_immediate.js
immediate
timeout

$ node timeout_vs_immediate.js
immediate
timeout
The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed before any timers if scheduled within an I/O cycle, independently of how many timers are present.

process.nextTick()
Understanding process.nextTick()
You may have noticed that process.nextTick() was not displayed in the diagram, even though it's a part of the asynchronous API. This is because process.nextTick() is not technically part of the event loop. Instead, the nextTickQueue will be processed after the current operation is completed, regardless of the current phase of the event loop. Here, an operation is defined as a transition from the underlying C/C++ handler, and handling the JavaScript that needs to be executed.

Looking back at our diagram, any time you call process.nextTick() in a given phase, all callbacks passed to process.nextTick() will be resolved before the event loop continues. This can create some bad situations because it allows you to "starve" your I/O by making recursive process.nextTick() calls, which prevents the event loop from reaching the poll phase.

Why would that be allowed?
Why would something like this be included in Node.js? Part of it is a design philosophy where an API should always be asynchronous even where it doesn't have to be. Take this code snippet for example:

function apiCall(arg, callback) {
  if (typeof arg !== 'string')
    return process.nextTick(
      callback,
      new TypeError('argument should be string')
    );
}
The snippet does an argument check and if it's not correct, it will pass the error to the callback. The API updated fairly recently to allow passing arguments to process.nextTick() allowing it to take any arguments passed after the callback to be propagated as the arguments to the callback so you don't have to nest functions.

What we're doing is passing an error back to the user but only after we have allowed the rest of the user's code to execute. By using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed. To achieve this, the JS call stack is allowed to unwind then immediately execute the provided callback which allows a person to make recursive calls to process.nextTick() without reaching a RangeError: Maximum call stack size exceeded from v8.

This philosophy can lead to some potentially problematic situations. Take this snippet for example:

let bar;

// this has an asynchronous signature, but calls callback synchronously
function someAsyncApiCall(callback) {
  callback();
}

// the callback is called before `someAsyncApiCall` completes.
someAsyncApiCall(() => {
  // since someAsyncApiCall hasn't completed, bar hasn't been assigned any value
  console.log('bar', bar); // undefined
});

bar = 1;
The user defines someAsyncApiCall() to have an asynchronous signature, but it actually operates synchronously. When it is called, the callback provided to someAsyncApiCall() is called in the same phase of the event loop because someAsyncApiCall() doesn't actually do anything asynchronously. As a result, the callback tries to reference bar even though it may not have that variable in scope yet, because the script has not been able to run to completion.

By placing the callback in a process.nextTick(), the script still has the ability to run to completion, allowing all the variables, functions, etc., to be initialized prior to the callback being called. It also has the advantage of not allowing the event loop to continue. It may be useful for the user to be alerted to an error before the event loop is allowed to continue. Here is the previous example using process.nextTick():

let bar;

function someAsyncApiCall(callback) {
  process.nextTick(callback);
}

someAsyncApiCall(() => {
  console.log('bar', bar); // 1
});

bar = 1;
Here's another real world example:

const server = net.createServer(() => {}).listen(8080);

server.on('listening', () => {});
When only a port is passed, the port is bound immediately. So, the 'listening' callback could be called immediately. The problem is that the .on('listening') callback will not have been set by that time.

To get around this, the 'listening' event is queued in a nextTick() to allow the script to run to completion. This allows the user to set any event handlers they want.

process.nextTick() vs setImmediate()
We have two calls that are similar as far as users are concerned, but their names are confusing.

process.nextTick() fires immediately on the same phase
setImmediate() fires on the following iteration or 'tick' of the event loop
In essence, the names should be swapped. process.nextTick() fires more immediately than setImmediate(), but this is an artifact of the past which is unlikely to change. Making this switch would break a large percentage of the packages on npm. Every day more new modules are being added, which means every day we wait, more potential breakages occur. While they are confusing, the names themselves won't change.

We recommend developers use setImmediate() in all cases because it's easier to reason about.

Why use process.nextTick()?
There are two main reasons:

Allow users to handle errors, cleanup any then unneeded resources, or perhaps try the request again before the event loop continues.

At times it's necessary to allow a callback to run after the call stack has unwound but before the event loop continues.

One example is to match the user's expectations. Simple example:

const server = net.createServer();
server.on('connection', (conn) => {});

server.listen(8080);
server.on('listening', () => {});
Say that listen() is run at the beginning of the event loop, but the listening callback is placed in a setImmediate(). Unless a hostname is passed, binding to the port will happen immediately. For the event loop to proceed, it must hit the poll phase, which means there is a non-zero chance that a connection could have been received allowing the connection event to be fired before the listening event.

Another example is inheriting from EventEmitter and emitting an event from within the constructor:

const EventEmitter = require('events');

class MyEmitter extends EventEmitter {
  constructor() {
    super();
    this.emit('event');
  }
}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
You can't emit an event from the constructor immediately because the script will not have processed to the point where the user assigns a callback to that event. So, within the constructor itself, you can use process.nextTick() to set a callback to emit the event after the constructor has finished, which provides the expected results:

const EventEmitter = require('events');

class MyEmitter extends EventEmitter {
  constructor() {
    super();

    // use nextTick to emit the event once a handler is assigned
    process.nextTick(() => {
      this.emit('event');
    });
  }
}

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});


            1.3.2.4
        1.3.3
    1.4 buffers

nodejs buffers


Pure JavaScript is Unicode friendly, but it is not so for binary data. While dealing with TCP streams or the file system, it's necessary to handle octet streams. Node provides Buffer class which provides instances to store raw data similar to an array of integers but corresponds to a raw memory allocation outside the V8 heap.
Buffer class is a global class that can be accessed in an application without importing the buffer module.
Creating Buffers
Node Buffer can be constructed in a variety of ways.
Method 1
Following is the syntax to create an uninitiated Buffer of 10 octets −
var buf = new Buffer(10);
Method 2
Following is the syntax to create a Buffer from a given array −
var buf = new Buffer([10, 20, 30, 40, 50]);
Method 3
Following is the syntax to create a Buffer from a given string and optionally encoding type −
var buf = new Buffer("Simply Easy Learning", "utf-8");
Though "utf8" is the default encoding, you can use any of the following encodings "ascii", "utf8", "utf16le", "ucs2", "base64" or "hex".
Writing to Buffers
Syntax
Following is the syntax of the method to write into a Node Buffer −
buf.write(string[, offset][, length][, encoding])
Parameters
Here is the description of the parameters used −
* string − This is the string data to be written to buffer.
* offset − This is the index of the buffer to start writing at. Default value is 0.
* length − This is the number of bytes to write. Defaults to buffer.length.
* encoding − Encoding to use. 'utf8' is the default encoding.
Return Value
This method returns the number of octets written. If there is not enough space in the buffer to fit the entire string, it will write a part of the string.
Example
buf = new Buffer(256);
len = buf.write("Simply Easy Learning");

console.log("Octets written : "+  len);
When the above program is executed, it produces the following result −
Octets written : 20
Reading from Buffers
Syntax
Following is the syntax of the method to read data from a Node Buffer −
buf.toString([encoding][, start][, end])
Parameters
Here is the description of the parameters used −
* encoding − Encoding to use. 'utf8' is the default encoding.
* start − Beginning index to start reading, defaults to 0.
* end − End index to end reading, defaults is complete buffer.
Return Value
This method decodes and returns a string from buffer data encoded using the specified character set encoding.
Example
buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
  buf[i] = i + 97;
}

console.log( buf.toString('ascii'));       // outputs: abcdefghijklmnopqrstuvwxyz
console.log( buf.toString('ascii',0,5));   // outputs: abcde
console.log( buf.toString('utf8',0,5));    // outputs: abcde
console.log( buf.toString(undefined,0,5)); // encoding defaults to 'utf8', outputs abcde
When the above program is executed, it produces the following result −
abcdefghijklmnopqrstuvwxyz
abcde
abcde
abcde
Convert Buffer to JSON
Syntax
Following is the syntax of the method to convert a Node Buffer into JSON object −
buf.toJSON()
Return Value
This method returns a JSON-representation of the Buffer instance.
Example
var buf = new Buffer('Simply Easy Learning');
var json = buf.toJSON(buf);

console.log(json);
When the above program is executed, it produces the following result −
[ 83, 105, 109, 112, 108, 121, 32, 69, 97, 115, 121, 32, 76, 101, 97, 114, 110, 105, 110,
   103 ]
Concatenate Buffers
Syntax
Following is the syntax of the method to concatenate Node buffers to a single Node Buffer −
Buffer.concat(list[, totalLength])
Parameters
Here is the description of the parameters used −
* list − Array List of Buffer objects to be concatenated.
* totalLength − This is the total length of the buffers when concatenated.
Return Value
This method returns a Buffer instance.
Example
var buffer1 = new Buffer('TutorialsPoint ');
var buffer2 = new Buffer('Simply Easy Learning');
var buffer3 = Buffer.concat([buffer1,buffer2]);
console.log("buffer3 content: " + buffer3.toString());
When the above program is executed, it produces the following result −
buffer3 content: TutorialsPoint Simply Easy Learning
Compare Buffers
Syntax
Following is the syntax of the method to compare two Node buffers −
buf.compare(otherBuffer);
Parameters
Here is the description of the parameters used −
* otherBuffer − This is the other buffer which will be compared with buf
Return Value
Returns a number indicating whether it comes before or after or is the same as the otherBuffer in sort order.
Example
var buffer1 = new Buffer('ABC');
var buffer2 = new Buffer('ABCD');
var result = buffer1.compare(buffer2);

if(result < 0) {
   console.log(buffer1 +" comes before " + buffer2);
}else if(result == 0){
   console.log(buffer1 +" is same as " + buffer2);
}else {
   console.log(buffer1 +" comes after " + buffer2);
}
When the above program is executed, it produces the following result −
ABC comes before ABCD
Copy Buffer
Syntax
Following is the syntax of the method to copy a node buffer −
buf.copy(targetBuffer[, targetStart][, sourceStart][, sourceEnd])
Parameters
Here is the description of the parameters used −
* targetBuffer − Buffer object where buffer will be copied.
* targetStart − Number, Optional, Default: 0
* sourceStart − Number, Optional, Default: 0
* sourceEnd − Number, Optional, Default: buffer.length
Return Value
No return value. Copies data from a region of this buffer to a region in the target buffer even if the target memory region overlaps with the source. If undefined, the targetStart and sourceStart parameters default to 0, while sourceEnd defaults to buffer.length.
Example
var buffer1 = new Buffer('ABC');

//copy a buffer
var buffer2 = new Buffer(3);
buffer1.copy(buffer2);
console.log("buffer2 content: " + buffer2.toString());
When the above program is executed, it produces the following result −
buffer2 content: ABC
Slice Buffer
Syntax
Following is the syntax of the method to get a sub-buffer of a node buffer −
buf.slice([start][, end])
Parameters
Here is the description of the parameters used −
* start − Number, Optional, Default: 0
* end − Number, Optional, Default: buffer.length
Return Value
Returns a new buffer which references the same memory as the old one, but offset and cropped by the start (defaults to 0) and end (defaults to buffer.length) indexes. Negative indexes start from the end of the buffer.
Example
var buffer1 = new Buffer('TutorialsPoint');

//slicing a buffer
var buffer2 = buffer1.slice(0,9);
console.log("buffer2 content: " + buffer2.toString());
When the above program is executed, it produces the following result −
buffer2 content: Tutorials
Buffer Length
Syntax
Following is the syntax of the method to get a size of a node buffer in bytes −
buf.length;
Return Value
Returns the size of a buffer in bytes.
Example
var buffer = new Buffer('TutorialsPoint');

//length of the buffer
console.log("buffer length: " + buffer.length);
When the above program is executed, it produces following result −
buffer length: 14
Methods Reference
Following is a reference of Buffers module available in Node.js. For more detail, you can refer to the official documentation.
Class Methods
S.No.	Method & Description
1	Buffer.isEncoding(encoding)
Returns true if the encoding is a valid encoding argument, false otherwise.
2	Buffer.isBuffer(obj)
Tests if obj is a Buffer.
3	Buffer.byteLength(string[, encoding])
Gives the actual byte length of a string. encoding defaults to 'utf8'. It is not the same as String.prototype.length, since String.prototype.length returns the number of characters in a string.
4	Buffer.concat(list[, totalLength])
Returns a buffer which is the result of concatenating all the buffers in the list together.
5	Buffer.compare(buf1, buf2)
The same as buf1.compare(buf2). Useful for sorting an array of buffers.


Code example
var buf = new Buffer(10); 
console.log("buf= ",buf);


var buf1 = new Buffer([1,2,3,4]); 
console.log("buf1= ",buf1);

var buf2 = new Buffer(256); 
wlen = buf2.write("writing to buffer");
console.log("wrote "+wlen+" bytes to buf2. content(hex)= ",buf2);
console.log("readable content= "+buf2.toString('utf8',0, wlen));

buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
  buf[i] = i + 97;
}

console.log( buf.toString('ascii'));       // outputs: abcdefghijklmnopqrstuvwxyz
console.log( buf.toString('ascii',0,5));   // outputs: abcde
console.log( buf.toString('utf8',0,5));    // outputs: abcde
console.log( buf.toString(undefined,0,5)); // encoding defaults to 'utf8', outputs abcde




var buf = new Buffer('Simply Easy Learning');
var json = buf.toJSON(buf);

console.log(json);


var buffer1 = new Buffer('TutorialsPoint ');
var buffer2 = new Buffer('Simply Easy Learning');
var buffer3 = Buffer.concat([buffer1,buffer2]);
console.log("buffer3 content: " + buffer3.toString());

var buffera = new Buffer('ABC');
var bufferb = new Buffer('ABCD');
var result = buffera.compare(buffer2);

if(result < 0) {
   console.log(buffera +" comes before " + bufferb);
}else if(result == 0){
   console.log(buffera +" is same as " + bufferb);
}else {
   console.log(buffera +" comes after " + bufferb);
}

var bufferc = new Buffer('ABC');

//copy a buffer
var bufferd = new Buffer(3);
bufferc.copy(bufferd);
console.log("bufferd content: " + bufferd.toString());

var buffere = new Buffer('TutorialsPoint');

//slicing a buffer
var bufferf = bufferd.slice(0,9);
console.log("bufferf content: " + bufferf.toString());


var bufferg = new Buffer('TutorialsPoint');

//length of the buffer
console.log("buffer length: " + bufferg.length);





Test:
[i500695@C02X632CJGH6:2018-10-18 11:17:11:~/Desktop/work/code/nodejs/tutorial:]505$ node buffers.js 
buf=  <Buffer 00 00 00 00 00 00 00 00 00 00>
buf1=  <Buffer 01 02 03 04>
wrote 17 bytes to buf2. content(hex)=  <Buffer 77 72 69 74 69 6e 67 20 74 6f 20 62 75 66 66 65 72 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ... >
readable content= writing to buffer
abcdefghijklmnopqrstuvwxyz
abcde
abcde
abcde
{ type: 'Buffer',
  data: 
   [ 83,
     105,
     109,
     112,
     108,
     121,
     32,
     69,
     97,
     115,
     121,
     32,
     76,
     101,
     97,
     114,
     110,
     105,
     110,
     103 ] }
buffer3 content: TutorialsPoint Simply Easy Learning
ABC comes before ABCD
bufferd content: ABC
bufferf content: ABC
buffer length: 14

    1.5 streams

nodejs Streams

Streams are objects that let you read data from a source or write data to a destination in continuous fashion. In Node.js, there are four types of streams −
* Readable − Stream which is used for read operation.
* Writable − Stream which is used for write operation.
* Duplex − Stream which can be used for both read and write operation.
* Transform − A type of duplex stream where the output is computed based on input.
Each type of Stream is an EventEmitter instance and throws several events at different instance of times. For example, some of the commonly used events are −
* data − This event is fired when there is data is available to read.
* end − This event is fired when there is no more data to read.
* error − This event is fired when there is any error receiving or writing data.
* finish − This event is fired when all the data has been flushed to underlying system.
This tutorial provides a basic understanding of the commonly used operations on Streams.


Piping is a mechanism where we provide the output of one stream as the input to another stream. It is normally used to get data from one stream and to pass the output of that stream to another stream. There is no limit on piping operations. Now we'll show a piping example for reading from one file and writing it to another file.


Chaining the Streams
Chaining is a mechanism to connect the output of one stream to another stream and create a chain of multiple stream operations. It is normally used with piping operations. Now we'll use piping and chaining to first compress a file and then decompress the same.


Code:
var fs = require("fs");
var data = '';

console.log("demo read stream. node streams emit data,end,error,finish events...");
// Create a readable stream
var readerStream = fs.createReadStream('input.txt');

// Set the encoding to be utf8. 
readerStream.setEncoding('UTF8');

console.log("reader register on data CB");
// Handle stream events --> data, end, and error
readerStream.on('data', function(chunk) {
   console.log("reader on data CB got chunk: ", chunk);
   data += chunk;
});

readerStream.on('end',function(){
   console.log("on end CB ");
   console.log(data);
});

readerStream.on('error', function(err){
   console.log("on error CB ");
   console.log(err.stack);
});


console.log("demo write stream.");
//var data1="sample data";

var writeStream = fs.createWriteStream('output.txt');

writeStream.write(data,'UTF8');
writeStream.end();

writeStream.on('finish', function () {
   console.log("writer got finish event");
});


writeStream.on('error', function (err) {
   console.log("writer got error event: ", err.stack);
});

console.log("Demo piping streams"); 
var readerStream1 = fs.createReadStream('input.txt');
var writeStream1 = fs.createWriteStream('piped_output.txt');
readerStream1.pipe(writeStream1);

console.log("check piped output..."); 
fs.readFile('piped_output.txt', function (err,data) {
    if (err) return console.error(err);
    console.log("Printing piped_output.txt from CB: ", data.toString());
});

console.log("Demo chaining streams"); 
console.log("Demo chaining streams. Compressing"); 
var zlib = require('zlib');


var readerStream2 = fs.createReadStream('input.txt');
readerStream2.
        pipe(zlib.createGzip()).
        pipe(fs.createWriteStream('input.txt.gz'));


readerStream2.on('end' , function (){
console.log("input.txt.gz created"); 

console.log("Demo chaining streams. Decompressing"); 
var readerStream3 = fs.createReadStream('input.txt.gz');
        readerStream3.
        pipe(zlib.createGunzip()).
        pipe(fs.createWriteStream('input1.txt'));

        readerStream3.on('end', function () {
            console.log("input.txt.gz decompressed to input1.txt"); 
            
        });
});

console.log("Program Ended");


Test:
[i500695@C02X632CJGH6:2018-10-18 13:06:57:~/Desktop/work/code/nodejs/tutorial:]522$ node streamsDemo.js 
demo read stream. node streams emit data,end,error,finish events...
reader register on data CB
demo write stream.
Demo piping streams
check piped output...
Demo chaining streams
Demo chaining streams. Compressing
Program Ended
reader on data CB got chunk:  kkkalkslks
lasklk
asaa

writer got finish event
on end CB 
kkkalkslks
lasklk
asaa

input.txt.gz created
Demo chaining streams. Decompressing
Printing piped_output.txt from CB:  kkkalkslks
lasklk
asaa

input.txt.gz decompressed to input1.txt

    1.6 filesystem
Nodejs filesystem

Node implements File I/O using simple wrappers around standard POSIX functions. The Node File System (fs) module can be imported using the following syntax −
var fs = require("fs")
Synchronous vs Asynchronous
Every method in the fs module has synchronous as well as asynchronous forms. Asynchronous methods take the last parameter as the completion function callback and the first parameter of the callback function as error. It is better to use an asynchronous method instead of a synchronous method, as the former never blocks a program during its execution, whereas the second one does.
Example
Create a text file named input.txt with the following content −
Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!
Let us create a js file named main.js with the following code −
var fs = require("fs");

// Asynchronous read
fs.readFile('input.txt', function (err, data) {
   if (err) {
      return console.error(err);
   }
   console.log("Asynchronous read: " + data.toString());
});

// Synchronous read
var data = fs.readFileSync('input.txt');
console.log("Synchronous read: " + data.toString());

console.log("Program Ended");
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Synchronous read: Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!

Program Ended
Asynchronous read: Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!
The following sections in this chapter provide a set of good examples on major File I/O methods.
Open a File
Syntax
Following is the syntax of the method to open a file in asynchronous mode −
fs.open(path, flags[, mode], callback)
Parameters
Here is the description of the parameters used −
* path − This is the string having file name including path.
* flags − Flags indicate the behavior of the file to be opened. All possible values have been mentioned below.
* mode − It sets the file mode (permission and sticky bits), but only if the file was created. It defaults to 0666, readable and writeable.
* callback − This is the callback function which gets two arguments (err, fd).
Flags
Flags for read/write operations are −
Sr.No.	Flag & Description
1	r
Open file for reading. An exception occurs if the file does not exist.
2	r+
Open file for reading and writing. An exception occurs if the file does not exist.
3	rs
Open file for reading in synchronous mode.
4	rs+
Open file for reading and writing, asking the OS to open it synchronously. See notes for 'rs' about using this with caution.
5	w
Open file for writing. The file is created (if it does not exist) or truncated (if it exists).
6	wx
Like 'w' but fails if the path exists.
7	w+
Open file for reading and writing. The file is created (if it does not exist) or truncated (if it exists).
8	wx+
Like 'w+' but fails if path exists.
9	a
Open file for appending. The file is created if it does not exist.
10	ax
Like 'a' but fails if the path exists.
11	a+
Open file for reading and appending. The file is created if it does not exist.
12	ax+
Like 'a+' but fails if the the path exists.
Example
Let us create a js file named main.js having the following code to open a file input.txt for reading and writing.
var fs = require("fs");

// Asynchronous - Opening File
console.log("Going to open file!");
fs.open('input.txt', 'r+', function(err, fd) {
   if (err) {
      return console.error(err);
   }
   console.log("File opened successfully!");     
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to open file!
File opened successfully!
Get File Information
Syntax
Following is the syntax of the method to get the information about a file −
fs.stat(path, callback)
Parameters
Here is the description of the parameters used −
* path − This is the string having file name including path.
* callback − This is the callback function which gets two arguments (err, stats) where stats is an object of fs.Stats type which is printed below in the example.
Apart from the important attributes which are printed below in the example, there are several useful methods available in fs.Stats class which can be used to check file type. These methods are given in the following table.
Sr.No.	Method & Description
1	stats.isFile()
Returns true if file type of a simple file.
2	stats.isDirectory()
Returns true if file type of a directory.
3	stats.isBlockDevice()
Returns true if file type of a block device.
4	stats.isCharacterDevice()
Returns true if file type of a character device.
5	stats.isSymbolicLink()
Returns true if file type of a symbolic link.
6	stats.isFIFO()
Returns true if file type of a FIFO.
7	stats.isSocket()
Returns true if file type of asocket.
Example
Let us create a js file named main.js with the following code −
var fs = require("fs");

console.log("Going to get file info!");
fs.stat('input.txt', function (err, stats) {
   if (err) {
      return console.error(err);
   }
   console.log(stats);
   console.log("Got file info successfully!");
   
   // Check file type
   console.log("isFile ? " + stats.isFile());
   console.log("isDirectory ? " + stats.isDirectory());    
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to get file info!
{ 
   dev: 1792,
   mode: 33188,
   nlink: 1,
   uid: 48,
   gid: 48,
   rdev: 0,
   blksize: 4096,
   ino: 4318127,
   size: 97,
   blocks: 8,
   atime: Sun Mar 22 2015 13:40:00 GMT-0500 (CDT),
   mtime: Sun Mar 22 2015 13:40:57 GMT-0500 (CDT),
   ctime: Sun Mar 22 2015 13:40:57 GMT-0500 (CDT) 
}
Got file info successfully!
isFile ? true
isDirectory ? false
Writing a File
Syntax
Following is the syntax of one of the methods to write into a file −
fs.writeFile(filename, data[, options], callback)
This method will over-write the file if the file already exists. If you want to write into an existing file then you should use another method available.
Parameters
Here is the description of the parameters used −
* path − This is the string having the file name including path.
* data − This is the String or Buffer to be written into the file.
* options − The third parameter is an object which will hold {encoding, mode, flag}. By default. encoding is utf8, mode is octal value 0666. and flag is 'w'
* callback − This is the callback function which gets a single parameter err that returns an error in case of any writing error.
Example
Let us create a js file named main.js having the following code −
Live Demo
var fs = require("fs");

console.log("Going to write into existing file");
fs.writeFile('input.txt', 'Simply Easy Learning!', function(err) {
   if (err) {
      return console.error(err);
   }
   
   console.log("Data written successfully!");
   console.log("Let's read newly written data");
   
   fs.readFile('input.txt', function (err, data) {
      if (err) {
         return console.error(err);
      }
      console.log("Asynchronous read: " + data.toString());
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to write into existing file
Data written successfully!
Let's read newly written data
Asynchronous read: Simply Easy Learning!
Reading a File
Syntax
Following is the syntax of one of the methods to read from a file −
fs.read(fd, buffer, offset, length, position, callback)
This method will use file descriptor to read the file. If you want to read the file directly using the file name, then you should use another method available.
Parameters
Here is the description of the parameters used −
* fd − This is the file descriptor returned by fs.open().
* buffer − This is the buffer that the data will be written to.
* offset − This is the offset in the buffer to start writing at.
* length − This is an integer specifying the number of bytes to read.
* position − This is an integer specifying where to begin reading from in the file. If position is null, data will be read from the current file position.
* callback − This is the callback function which gets the three arguments, (err, bytesRead, buffer).
Example
Let us create a js file named main.js with the following code −
var fs = require("fs");
var buf = new Buffer(1024);

console.log("Going to open an existing file");
fs.open('input.txt', 'r+', function(err, fd) {
   if (err) {
      return console.error(err);
   }
   console.log("File opened successfully!");
   console.log("Going to read the file");
   
   fs.read(fd, buf, 0, buf.length, 0, function(err, bytes){
      if (err){
         console.log(err);
      }
      console.log(bytes + " bytes read");
      
      // Print only read bytes to avoid junk.
      if(bytes > 0){
         console.log(buf.slice(0, bytes).toString());
      }
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to open an existing file
File opened successfully!
Going to read the file
97 bytes read
Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!
Closing a File
Syntax
Following is the syntax to close an opened file −
fs.close(fd, callback)
Parameters
Here is the description of the parameters used −
* fd − This is the file descriptor returned by file fs.open() method.
* callback − This is the callback function No arguments other than a possible exception are given to the completion callback.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");
var buf = new Buffer(1024);

console.log("Going to open an existing file");
fs.open('input.txt', 'r+', function(err, fd) {
   if (err) {
      return console.error(err);
   }
   console.log("File opened successfully!");
   console.log("Going to read the file");
   
   fs.read(fd, buf, 0, buf.length, 0, function(err, bytes) {
      if (err) {
         console.log(err);
      }

      // Print only read bytes to avoid junk.
      if(bytes > 0) {
         console.log(buf.slice(0, bytes).toString());
      }

      // Close the opened file.
      fs.close(fd, function(err) {
         if (err) {
            console.log(err);
         } 
         console.log("File closed successfully.");
      });
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to open an existing file
File opened successfully!
Going to read the file
Tutorials Point is giving self learning content
to teach the world in simple and easy way!!!!!

File closed successfully.
Truncate a File
Syntax
Following is the syntax of the method to truncate an opened file −
fs.ftruncate(fd, len, callback)
Parameters
Here is the description of the parameters used −
* fd − This is the file descriptor returned by fs.open().
* len − This is the length of the file after which the file will be truncated.
* callback − This is the callback function No arguments other than a possible exception are given to the completion callback.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");
var buf = new Buffer(1024);

console.log("Going to open an existing file");
fs.open('input.txt', 'r+', function(err, fd) {
   if (err) {
      return console.error(err);
   }
   console.log("File opened successfully!");
   console.log("Going to truncate the file after 10 bytes");
   
   // Truncate the opened file.
   fs.ftruncate(fd, 10, function(err) {
      if (err) {
         console.log(err);
      } 
      console.log("File truncated successfully.");
      console.log("Going to read the same file"); 
      
      fs.read(fd, buf, 0, buf.length, 0, function(err, bytes){
         if (err) {
            console.log(err);
         }

         // Print only read bytes to avoid junk.
         if(bytes > 0) {
            console.log(buf.slice(0, bytes).toString());
         }

         // Close the opened file.
         fs.close(fd, function(err) {
            if (err) {
               console.log(err);
            } 
            console.log("File closed successfully.");
         });
      });
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to open an existing file
File opened successfully!
Going to truncate the file after 10 bytes
File truncated successfully.
Going to read the same file
Tutorials 
File closed successfully.
Delete a File
Syntax
Following is the syntax of the method to delete a file −
fs.unlink(path, callback)
Parameters
Here is the description of the parameters used −
* path − This is the file name including path.
* callback − This is the callback function No arguments other than a possible exception are given to the completion callback.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");

console.log("Going to delete an existing file");
fs.unlink('input.txt', function(err) {
   if (err) {
      return console.error(err);
   }
   console.log("File deleted successfully!");
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to delete an existing file
File deleted successfully!
Create a Directory
Syntax
Following is the syntax of the method to create a directory −
fs.mkdir(path[, mode], callback)
Parameters
Here is the description of the parameters used −
* path − This is the directory name including path.
* mode − This is the directory permission to be set. Defaults to 0777.
* callback − This is the callback function No arguments other than a possible exception are given to the completion callback.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");

console.log("Going to create directory /tmp/test");
fs.mkdir('/tmp/test',function(err) {
   if (err) {
      return console.error(err);
   }
   console.log("Directory created successfully!");
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to create directory /tmp/test
Directory created successfully!
Read a Directory
Syntax
Following is the syntax of the method to read a directory −
fs.readdir(path, callback)
Parameters
Here is the description of the parameters used −
* path − This is the directory name including path.
* callback − This is the callback function which gets two arguments (err, files) where files is an array of the names of the files in the directory excluding '.' and '..'.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");

console.log("Going to read directory /tmp");
fs.readdir("/tmp/",function(err, files) {
   if (err) {
      return console.error(err);
   }
   files.forEach( function (file) {
      console.log( file );
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to read directory /tmp
ccmzx99o.out
ccyCSbkF.out
employee.ser
hsperfdata_apache
test
test.txt
Remove a Directory
Syntax
Following is the syntax of the method to remove a directory −
fs.rmdir(path, callback)
Parameters
Here is the description of the parameters used −
* path − This is the directory name including path.
* callback − This is the callback function No arguments other than a possible exception are given to the completion callback.
Example
Let us create a js file named main.js having the following code −
var fs = require("fs");

console.log("Going to delete directory /tmp/test");
fs.rmdir("/tmp/test",function(err) {
   if (err) {
      return console.error(err);
   }
   console.log("Going to read directory /tmp");
   
   fs.readdir("/tmp/",function(err, files) {
      if (err) {
         return console.error(err);
      }
      files.forEach( function (file) {
         console.log( file );
      });
   });
});
Now run the main.js to see the result −
$ node main.js
Verify the Output.
Going to read directory /tmp
ccmzx99o.out
ccyCSbkF.out
employee.ser
hsperfdata_apache
test.txt
Methods Reference
Following is a reference of File System module available in Node.js. For more detail you can refer to the official documentation.


    1.7 globals
nodejs globals

Node.js global objects are global in nature and they are available in all modules. We do not need to include these objects in our application, rather we can use them directly. These objects are modules, functions, strings and object itself as explained below.
__filename
The __filename represents the filename of the code being executed. This is the resolved absolute path of this code file. For a main program, this is not necessarily the same filename used in the command line. The value inside a module is the path to that module file.
Example
Create a js file named main.js with the following code −
// Let's try to print the value of __filename

console.log( __filename );
Now run the main.js to see the result −
$ node main.js
Based on the location of your program, it will print the main file name as follows −
/web/com/1427091028_21099/main.js
__dirname
The __dirname represents the name of the directory that the currently executing script resides in.
Example
Create a js file named main.js with the following code −
// Let's try to print the value of __dirname

console.log( __dirname );
Now run the main.js to see the result −
$ node main.js
Based on the location of your program, it will print current directory name as follows −
/web/com/1427091028_21099
setTimeout(cb, ms)
The setTimeout(cb, ms) global function is used to run callback cb after at least ms milliseconds. The actual delay depends on external factors like OS timer granularity and system load. A timer cannot span more than 24.8 days.
This function returns an opaque value that represents the timer which can be used to clear the timer.
Example
Create a js file named main.js with the following code −
function printHello(){
   console.log( "Hello, World!");
}
// Now call above function after 2 seconds
setTimeout(printHello, 2000);
Now run the main.js to see the result −
$ node main.js
Verify the output is printed after a little delay.
Hello, World!
clearTimeout(t)
The clearTimeout(t) global function is used to stop a timer that was previously created with setTimeout(). Here t is the timer returned by the setTimeout() function.
Example
Create a js file named main.js with the following code −
function printHello(){
   console.log( "Hello, World!");
}

// Now call above function after 2 seconds
var t = setTimeout(printHello, 2000);

// Now clear the timer
clearTimeout(t);
Now run the main.js to see the result −
$ node main.js
Verify the output where you will not find anything printed.
setInterval(cb, ms)
The setInterval(cb, ms) global function is used to run callback cb repeatedly after at least ms milliseconds. The actual delay depends on external factors like OS timer granularity and system load. A timer cannot span more than 24.8 days.
This function returns an opaque value that represents the timer which can be used to clear the timer using the function clearInterval(t).
Example
Create a js file named main.js with the following code −
function printHello(){
   console.log( "Hello, World!");
}
// Now call above function after 2 seconds
setInterval(printHello, 2000);
Now run the main.js to see the result −
$ node main.js
The above program will execute printHello() after every 2 second. Due to system limitation, this program can not be executed with Try it option so you can check it in your machine locally.
Global Objects
The following table provides a list of other objects which we use frequently in our applications. For a more detail, you can refer to the official documentation.
S.No.	Module Name & Description
1	Console
Used to print information on stdout and stderr.
2	Process
Used to get information on current process. Provides multiple events related to process activities.

My example 
console.log("Demo of nodejs globals");

console.log(" __filename = ", __filename);
console.log(" __dirname = ", __dirname);
console.log(" platform+arch = ", process.platform, process.arch);
console.log(" pid = ", process.pid);
console.log(" title = ", process.title);


console.log("setTimeout(cb,ms) triggers cb after ms...");

function echoMsg (argument) {
    console.log(argument.toString());
}

var to = setTimeout(echoMsg, 2000, "printed after 2 seconds");
var to1 = setTimeout(echoMsg, 2000, "printed after 2 seconds");

clearTimeout(to1);

setInterval(echoMsg, 1000, "Print after one second");


Test:
[i500695@C02X632CJGH6:2018-10-18 13:41:29:~/Desktop/work/code/nodejs/tutorial:]523$ node globalsDemo.js 
Demo of nodejs globals
 __filename =  /Users/i500695/Desktop/work/code/nodejs/tutorial/globalsDemo.js
 __dirname =  /Users/i500695/Desktop/work/code/nodejs/tutorial
 platform+arch =  darwin x64
 pid =  3115
 title =  node
setTimeout(cb,ms) triggers cb after ms...
Print after one second
printed after 2 seconds
Print after one second
Print after one second
Print after one second
Print after one second
Print after one second
Print after one second

    1.8 utility Modules
Nodes utility modules

a	OS Module Provides basic operating-system related utility functions.
b	Path Module Provides utilities for handling and transforming file paths.
c	Net Module Provides both servers and clients as streams. Acts as a network wrapper.
d	DNS Module Provides functions to do actual DNS lookup as well as to use underlying operating system name resolution functionalities.
e	Domain Module Provides ways to handle multiple different I/O operations as a single group.

    1.9 web
Nodejs web

What is a Web Server?
A Web Server is a software application which handles HTTP requests sent by the HTTP client, like web browsers, and returns web pages in response to the clients. Web servers usually deliver html documents along with images, style sheets, and scripts.
Most of the web servers support server-side scripts, using scripting languages or redirecting the task to an application server which retrieves data from a database and performs complex logic and then sends a result to the HTTP client through the Web server.
Apache web server is one of the most commonly used web servers. It is an open source project.
Web Application Architecture
A Web application is usually divided into four layers −
￼
* Client − This layer consists of web browsers, mobile browsers or applications which can make HTTP requests to the web server.
* Server − This layer has the Web server which can intercept the requests made by the clients and pass them the response.
* Business − This layer contains the application server which is utilized by the web server to do the required processing. This layer interacts with the data layer via the database or some external programs.
* Data − This layer contains the databases or any other source of data.
Creating a Web Server using Node
Node.js provides an http module which can be used to create an HTTP client of a server. Following is the bare minimum structure of the HTTP server which listens at 8081 port.
Create a js file named server.js −
File: server.js
var http = require('http');
var fs = require('fs');
var url = require('url');

// Create a server
http.createServer( function (request, response) {  
   // Parse the request containing file name
   var pathname = url.parse(request.url).pathname;
   
   // Print the name of the file for which request is made.
   console.log("Request for " + pathname + " received.");
   
   // Read the requested file content from file system
   fs.readFile(pathname.substr(1), function (err, data) {
      if (err) {
         console.log(err);
         // HTTP Status: 404 : NOT FOUND
         // Content Type: text/plain
         response.writeHead(404, {'Content-Type': 'text/html'});
      }else {	
         //Page found	  
         // HTTP Status: 200 : OK
         // Content Type: text/plain
         response.writeHead(200, {'Content-Type': 'text/html'});	
         
         // Write the content of the file to response body
         response.write(data.toString());		
      }
      // Send the response body 
      response.end();
   });   
}).listen(8081);

// Console will print the message
console.log('Server running at http://127.0.0.1:8081/');
Next let's create the following html file named index.htm in the same directory where you created server.js.
File: index.htm
<html>
   <head>
      <title>Sample Page</title>
   </head>
   
   <body>
      Hello World!
   </body>
</html>
Now let us run the server.js to see the result −
$ node server.js
Verify the Output.
Server running at http://127.0.0.1:8081/
Make a request to Node.js server
Open http://127.0.0.1:8081/index.htm in any browser to see the following result.
￼
Verify the Output at server end.
Server running at http://127.0.0.1:8081/
Request for /index.htm received.
Creating Web client using Node
A web client can be created using http module. Let's check the following example.
Create a js file named client.js −
File: client.js
var http = require('http');

// Options to be used by request 
var options = {
   host: 'localhost',
   port: '8081',
   path: '/index.htm'  
};

// Callback function is used to deal with response
var callback = function(response){
   // Continuously update stream with data
   var body = '';
   response.on('data', function(data) {
      body += data;
   });
   
   response.on('end', function() {
      // Data received completely.
      console.log(body);
   });
}
// Make a request to the server
var req = http.request(options, callback);
req.end();
Now run the client.js from a different command terminal other than server.js to see the result −
$ node client.js
Verify the Output.
<html>
   <head>
      <title>Sample Page</title>
   </head>
   
   <body>
      Hello World!
   </body>
</html>
Verify the Output at server end.
Server running at http://127.0.0.1:8081/
Request for /index.htm received.


My example:

Code:
Client:

[i500695@C02X632CJGH6:2018-10-18 17:07:01:~/Desktop/work/code/nodejs:]518$ cat tutorial/client.js 
var http = require('http');

// Options to be used by request 
var options = {
   host: 'localhost',
   port: '8081',
   path: '/index.htm'  
};

// Callback function is used to deal with response
var callback = function(response){
   // Continuously update stream with data
   var body = '';
   response.on('data', function(data) {
      body += data;
   });
   
   response.on('end', function() {
      // Data received completely.
      console.log(body);
   });
}
// Make a request to the server
var req = http.request(options, callback);
req.end();

// Options to be used by request 
var options1 = {
   host: 'localhost',
   port: '8081',
   path: '/client.js'
};

;
var req1 = http.request(options1, callback);
req1.end();
[i500695@C02X632CJGH6:2018-10-18 17:07:01:~/Desktop/work/code/nodejs:]518$ cat tutorial/client.js 
var http = require('http');

// Options to be used by request 
var options = {
   host: 'localhost',
   port: '8081',
   path: '/index.htm'  
};

// Callback function is used to deal with response
var callback = function(response){
   // Continuously update stream with data
   var body = '';
   response.on('data', function(data) {
      body += data;
   });
   
   response.on('end', function() {
      // Data received completely.
      console.log(body);
   });
}
// Make a request to the server
var req = http.request(options, callback);
req.end();

// Options to be used by request 
var options1 = {
   host: 'localhost',
   port: '8081',
   path: '/client.js'
};

;
var req1 = http.request(options1, callback);
req1.end();



Server:
var http = require('http');
var fs = require('fs');
var url = require('url');

// Create a server
http.createServer( function (request, response) {  
   // Parse the request containing file name
   var pathname = url.parse(request.url).pathname;
   
   // Print the name of the file for which request is made.
   console.log("Request for " + pathname + " received.");
   
   // Read the requested file content from file system
   fs.readFile(pathname.substr(1), function (err, data) {
      if (err) {
         console.log(err);
         // HTTP Status: 404 : NOT FOUND
         // Content Type: text/plain
         response.writeHead(404, {'Content-Type': 'text/html'});
      }else {	
         //Page found	  
         // HTTP Status: 200 : OK
         // Content Type: text/plain
         response.writeHead(200, {'Content-Type': 'text/html'});	
         
         // Write the content of the file to response body
         response.write(data.toString());		
      }
      // Send the response body 
      response.end();
   });   
}).listen(8081);

// Console will print the message
console.log('Server running at http://127.0.0.1:8081/');


Tests:
Client:
[i500695@C02X632CJGH6:2018-10-18 17:07:11:~/Desktop/work/code/nodejs/tutorial:]507$ node client.js 
var http = require('http');

// Options to be used by request 
var options = {
   host: 'localhost',
   port: '8081',
   path: '/index.htm'  
};

// Callback function is used to deal with response
var callback = function(response){
   // Continuously update stream with data
   var body = '';
   response.on('data', function(data) {
      body += data;
   });
   
   response.on('end', function() {
      // Data received completely.
      console.log(body);
   });
}
// Make a request to the server
var req = http.request(options, callback);
req.end();

// Options to be used by request 
var options1 = {
   host: 'localhost',
   port: '8081',
   path: '/client.js'
};

;
var req1 = http.request(options1, callback);
req1.end();

<html>
   <head>
      <title>Sample Page</title>
   </head>
   
   <body>
      Hello World!
   </body>
</html>


Server:
[i500695@C02X632CJGH6:2018-10-18 17:06:52:~/Desktop/work/code/nodejs/tutorial:]528$ node server.js 
Server running at http://127.0.0.1:8081/
Request for /index.htm received.
Request for /client.js received.

id=__express__
    1.10 Express, tags: Express framework


        1.10.0  intro
Express.js, aka Express, tops the list of best Node.js frameworks. It has a minimalistic approach and seems to be a classic and straightforward framework for coding architecture. Officially launched in 2010, it has been called the de facto standard for Node.js under the MIT license. 

It does not require you to go steeper in the learning curve; instead, just a basic understanding of Node.js environment and programming skills suffice. Its fast, robust, and asynchronous architecture jives well with Node.

Express aligns with high-speed I/O operations and single-threaded nature of Node making it a default requirement for apps built with Node.js platform.

A more robust Application User Interface(API) means a more streamlined form of client-to-server requests and visible user interactions. Using Express, these software engineering principles are well executed.

Improving communication between client and server provides a thoroughly enjoyable experience to a web or mobile user. Companies like Twitter, Uber, Accenture, and other tech giants like IBM deploy applications built with Express. 

Express offers some powerful features that take backend development to the next level. 

Features:

Rapid server-side programming packages- the framework has many Node.js features as functions and speeds up the process with few code lines. 
High performance- multiple operations are executed independently of each other using asynchronous programming
Super-high test coverage helps build applications with maximum testability. 
A myriad of HTTP helpers- they make programs more intelligible, reusable.
Better content negotiation- this helps in better communication between the client and server by providing HTTP headers to URLs, which fetch the exact information for the users/client-side. 
MVC Architectural pattern

You can develop web apps faster with the framework since it has almost readily available grounds for API generation. You can use it for any enterprise-grade or browser-based app because of its robust routing, templating, security features, and error handling provisions. 
        1.10.1  Install
[i500695@C02X632CJGH6:2018-10-18 17:25:58:~/Desktop/work/code/nodejs/tutorial:]526$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sensible defaults.

See `npm help json` for definitive documentation on these fields
and exactly what they do.

Use `npm install <pkg>` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
package name: (tutorial) 
version: (1.0.0) 
description: yosi izaq node.js tutorial
entry point: (buffers.js) server.js
test command: server.js
git repository: 
keywords: 
author: yosi izaq
license: (ISC) 
About to write to /Users/i500695/Desktop/work/code/nodejs/tutorial/package.json:

{
  "name": "tutorial",
  "version": "1.0.0",
  "description": "yosi izaq node.js tutorial",
  "main": "server.js",
  "dependencies": {
    "express": "^4.16.4"
  },
  "devDependencies": {},
  "scripts": {
    "test": "server.js",
    "start": "node server.js"
  },
  "author": "yosi izaq",
  "license": "ISC"
}


Is this OK? (yes) 
[i500695@C02X632CJGH6:2018-10-18 17:34:56:~/Desktop/work/code/nodejs/tutorial:]527$ sudo npm install express --save
Password:
npm WARN tutorial@1.0.0 No repository field.

+ express@4.16.4
updated 1 package and audited 121 packages in 2.273s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-18 17:35:08:~/Desktop/work/code/nodejs/tutorial:]528$ cat package.json 
{
  "name": "tutorial",
  "version": "1.0.0",
  "description": "yosi izaq node.js tutorial",
  "main": "server.js",
  "dependencies": {
    "express": "^4.16.4"
  },
  "devDependencies": {},
  "scripts": {
    "test": "server.js",
    "start": "node server.js"
  },
  "author": "yosi izaq",
  "license": "ISC"
}


[i500695@C02X632CJGH6:2018-10-18 18:00:48:~/Desktop/work/code/nodejs/tutorial:]542$ sudo npm install body-parser --save
Password:
npm WARN tutorial@1.0.0 No repository field.

+ body-parser@1.18.3
updated 1 package and audited 151 packages in 2.729s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-18 18:01:14:~/Desktop/work/code/nodejs/tutorial:]543$ sudo npm install cookie-parser --save
npm WARN tutorial@1.0.0 No repository field.

+ cookie-parser@1.4.3
added 1 package from 2 contributors and audited 154 packages in 2.5s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-18 18:01:22:~/Desktop/work/code/nodejs/tutorial:]544$ sudo npm install multer --save
npm WARN tutorial@1.0.0 No repository field.

+ multer@1.4.1
added 21 packages from 13 contributors and audited 192 packages in 2.033s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-18 18:05:43:~/Desktop/work/code/nodejs/tutorial:]545$ cat package.json 
{
  "name": "tutorial",
  "version": "1.0.0",
  "description": "yosi izaq node.js tutorial",
  "main": "server.js",
  "dependencies": {
    "body-parser": "^1.18.3",
    "cookie-parser": "^1.4.3",
    "express": "^4.16.4",
    "multer": "^1.4.1"
  },
  "devDependencies": {},
  "scripts": {
    "test": "server.js",
    "start": "node server.js"
  },
  "author": "yosi izaq",
  "license": "ISC"
}

        1.10.2 Express and supertest

            1.10.2.1 https://www.codementor.io/knownasilya/testing-express-apis-with-supertest-du107mcv2
Testing Express APIs with Supertest
Published Feb 22, 2015Last updated Feb 15, 2017
Introduction

Hello, I'm Ilya, a full-stack developer who uses Node.js on the server and Ember.js on the client. Lately I've been having lots of fun testing my Express APIs, and I just wanted to show-off how fun and simple it can be. Hope you enjoy this as much as I enjoyed writing it!
Getting Started

For this tutorial we'll start with a simple Express API, and we will set up a test environment and do some integration tests on our API using supertest and tape. Supertest is a library made specifically for testing nodejs http servers, and tape is an assertion library that we'll use to setup our testing structure.

I've created a repository on Github, where you will find a fully working application with the API and the tests. This is the code that I will be referencing throughout this tutorial.

Let's begin! We'll start by installing all of our dependencies:

npm install --save express
npm install --save-dev supertest tape

Now we'll create our project structure, something like:

my-project/
  |_ package.json
  |_ index.js
  |_ server/
  | |_index.js 
  |_ test/
     |_ index.js

This is my standard project structure when building Express apps. Now let's write that app!
Our API

Let us start with server/index.js where we will write a super simple API, which will work with some user data.

'use strict';

var express = require('express');
var app = express();
var users = ['John', 'Betty', 'Hal'];

app.get('/api/users', function (req, res) {
  res.json(users);
});

module.exports = app;

Note: Usually you'd make a call to a database, but for the sake of this tutorial, I'll use a simple fixture.

Now, if you notice, I'm not calling app.listen(..) anywhere, that is because supertest takes an app object, and doesn't need your app to be listening on a port. For our app to run we will add some code to our index.js file, which will be the main file that is called when invoking npm start.

'use strict';

var server = require('./server');
var port = process.env.PORT || 3000;

server.listen(port, function () {
  console.log('Server running on port %d', port);
});

Now we require our app from above, and we listen on it there. This gives us the ability to require our server and pass it to supertest. So now if we ran npm start we should see something like this:

Server running on port 3000

**
Note: ** If npm start doesn't do anything, add a start script to your package.json, see here.

Now that's wonderful and exciting, but how do we know that our app works? Well, we could visit localhost:3000/api/users and we'll see the resulting users. Maybe go ahead and try that now, I'll wait 😃
Are We Satisfied?

I hope your API worked, but do we really want to do that every time we make a change? No, because we have problems to solve and apps to build that will solve those problems.

This is where supertest comes into play, but before we can do that, let's setup our first dummy test, we'll do this in test/index.js.

'use strict';

var test = require('tape');

test('First test!', function (t) {
  t.end();
});

Now this is the most simple of tests, because it doesn't do anything! Here we are using tape to create a test, and we are letting it know that the test has finished. The API for tape is very simple, and should be relatively easy to grasp.

We can run this test if we modify our test script in package.json to node test, which will run test/index.js with node. So now if we run npm test, we'll see something like:

TAP version 13
# First test!

|1..0
# tests 0
# pass  0

# ok

This looks about right, and our test passed, but it's kind of ugly and unreadable. We can spice it up with npm install --save-dev tap-spec and by modifying our test script to node test | tap-spec.
Test It

Now that we can run a test, let's setup out API test. We do this by adding supertest and importing our app.

var request = require('supertest');
var app = require('../server');

That is all the setup that we need before we write our test.

test('Correct users returned', function (t) {
  request(app)
    .get('/api/users')
    .expect('Content-Type', /json/)
    .expect(200)
    .end(function (err, res) {
      t.end();
    });
}); 

If we run this test as it is, we should have a passing result (although you'll see that it's 0 out of 0 tests, since we didn't assert anything with tape), and that is good because just from this code we know that our request was successful due to the 200 status code, and we are getting json back, just as expected since we used res.json.

Let's see if our result is as expected. For this we'll assert if our users are the correct users. We'll do this from inside the callback that we passed to end, which will return as an error or our response.

'use strict';

var test = require('tape');
var request = require('supertest');
var app = require('../server');

test('Correct users returned', function (t) {
  request(app)
    .get('/api/users')
    .expect('Content-Type', /json/)
    .expect(200)
    .end(function (err, res) {
      var expectedUsers = ['John', 'Betty', 'Hal'];

      t.error(err, 'No error');
      t.same(res.body, expectedUsers, 'Users as expected');
      t.end();
    });
});

Now we're getting somewhere!

We now have two assertions of the result that we have. First of all we test that there isn't an error by using t.error(). We follow by confirming that our users are indeed correct; for this we use t.same(), and we compare the result, which is stored in res.body, as expected.

We should now see the following when we run npm test:

Correct users returned

    ✓ No error
    ✓ Users as expected



  total:     2
  passing:   2
  duration:  135ms

  All tests pass!

Congratulations, you wrote your first API test!

From here you can get creative, and test express routers and middleware (with a little bootstrapping), and remember to visit the superagent documentation, because you can use those methods with supertest (supertest is based on superagent).

The full code is located in the testing-express-api repository.

            1.10.2.2

        1.10.3 passport, authentication library

            1.10.3.1  web tutorials


                1.10.3.1.1  https://scotch.io/tutorials/easy-node-authentication-setup-and-local

                1.10.3.1.2 http://www.passportjs.org/docs/
Overview

Passport is authentication middleware for Node. It is designed to serve a singular purpose: authenticate requests. When writing modules, encapsulation is a virtue, so Passport delegates all other functionality to the application. This separation of concerns keeps code clean and maintainable, and makes Passport extremely easy to integrate into an application.

In modern web applications, authentication can take a variety of forms. Traditionally, users log in by providing a username and password. With the rise of social networking, single sign-on using an OAuth provider such as Facebook or Twitter has become a popular authentication method. Services that expose an API often require token-based credentials to protect access.

Passport recognizes that each application has unique authentication requirements. Authentication mechanisms, known as strategies, are packaged as individual modules. Applications can choose which strategies to employ, without creating unnecessary dependencies.

Despite the complexities involved in authentication, code does not have to be complicated.

app.post('/login', passport.authenticate('local', { successRedirect: '/',
                                                    failureRedirect: '/login' }));

Install

$ npm install passport

Authenticate

Authenticating requests is as simple as calling passport.authenticate() and specifying which strategy to employ. authenticate()'s function signature is standard Connect middleware, which makes it convenient to use as route middleware in Express applications.

app.post('/login',
  passport.authenticate('local'),
  function(req, res) {
    // If this function gets called, authentication was successful.
    // `req.user` contains the authenticated user.
    res.redirect('/users/' + req.user.username);
  });

By default, if authentication fails, Passport will respond with a 401 Unauthorized status, and any additional route handlers will not be invoked. If authentication succeeds, the next handler will be invoked and the req.user property will be set to the authenticated user.

Note: Strategies must be configured prior to using them in a route. Continue reading the chapter on configuration for details.
Redirects

A redirect is commonly issued after authenticating a request.

app.post('/login',
  passport.authenticate('local', { successRedirect: '/',
                                   failureRedirect: '/login' }));

In this case, the redirect options override the default behavior. Upon successful authentication, the user will be redirected to the home page. If authentication fails, the user will be redirected back to the login page for another attempt.
Flash Messages

Redirects are often combined with flash messages in order to display status information to the user.

app.post('/login',
  passport.authenticate('local', { successRedirect: '/',
                                   failureRedirect: '/login',
                                   failureFlash: true })
);

Setting the failureFlash option to true instructs Passport to flash an error message using the message given by the strategy's verify callback, if any. This is often the best approach, because the verify callback can make the most accurate determination of why authentication failed.

Alternatively, the flash message can be set specifically.

passport.authenticate('local', { failureFlash: 'Invalid username or password.' });

A successFlash option is available which flashes a success message when authentication succeeds.

passport.authenticate('local', { successFlash: 'Welcome!' });

Note: Using flash messages requires a req.flash() function. Express 2.x provided this functionality, however it was removed from Express 3.x. Use of connect-flash middleware is recommended to provide this functionality when using Express 3.x.
Disable Sessions

After successful authentication, Passport will establish a persistent login session. This is useful for the common scenario of users accessing a web application via a browser. However, in some cases, session support is not necessary. For example, API servers typically require credentials to be supplied with each request. When this is the case, session support can be safely disabled by setting the session option to false.

app.get('/api/users/me',
  passport.authenticate('basic', { session: false }),
  function(req, res) {
    res.json({ id: req.user.id, username: req.user.username });
  });

Custom Callback

If the built-in options are not sufficient for handling an authentication request, a custom callback can be provided to allow the application to handle success or failure.

app.get('/login', function(req, res, next) {
  passport.authenticate('local', function(err, user, info) {
    if (err) { return next(err); }
    if (!user) { return res.redirect('/login'); }
    req.logIn(user, function(err) {
      if (err) { return next(err); }
      return res.redirect('/users/' + user.username);
    });
  })(req, res, next);
});

In this example, note that authenticate() is called from within the route handler, rather than being used as route middleware. This gives the callback access to the req and res objects through closure.

If authentication failed, user will be set to false. If an exception occurred, err will be set. An optional info argument will be passed, containing additional details provided by the strategy's verify callback.

The callback can use the arguments supplied to handle the authentication result as desired. Note that when using a custom callback, it becomes the application's responsibility to establish a session (by calling req.login()) and send a response.
Configure

Three pieces need to be configured to use Passport for authentication:

    Authentication strategies
    Application middleware
    Sessions (optional)

Strategies

Passport uses what are termed strategies to authenticate requests. Strategies range from verifying a username and password, delegated authentication using OAuth or federated authentication using OpenID.

Before asking Passport to authenticate a request, the strategy (or strategies) used by an application must be configured.

Strategies, and their configuration, are supplied via the use() function. For example, the following uses the LocalStrategy for username/password authentication.

var passport = require('passport')
  , LocalStrategy = require('passport-local').Strategy;

passport.use(new LocalStrategy(
  function(username, password, done) {
    User.findOne({ username: username }, function (err, user) {
      if (err) { return done(err); }
      if (!user) {
        return done(null, false, { message: 'Incorrect username.' });
      }
      if (!user.validPassword(password)) {
        return done(null, false, { message: 'Incorrect password.' });
      }
      return done(null, user);
    });
  }
));

Verify Callback

This example introduces an important concept. Strategies require what is known as a verify callback. The purpose of a verify callback is to find the user that possesses a set of credentials.

When Passport authenticates a request, it parses the credentials contained in the request. It then invokes the verify callback with those credentials as arguments, in this case username and password. If the credentials are valid, the verify callback invokes done to supply Passport with the user that authenticated.

return done(null, user);

If the credentials are not valid (for example, if the password is incorrect), done should be invoked with false instead of a user to indicate an authentication failure.

return done(null, false);

An additional info message can be supplied to indicate the reason for the failure. This is useful for displaying a flash message prompting the user to try again.

return done(null, false, { message: 'Incorrect password.' });

Finally, if an exception occurred while verifying the credentials (for example, if the database is not available), done should be invoked with an error, in conventional Node style.

return done(err);

Note that it is important to distinguish the two failure cases that can occur. The latter is a server exception, in which err is set to a non-null value. Authentication failures are natural conditions, in which the server is operating normally. Ensure that err remains null, and use the final argument to pass additional details.

By delegating in this manner, the verify callback keeps Passport database agnostic. Applications are free to choose how user information is stored, without any assumptions imposed by the authentication layer.
Middleware

In a Connect or Express-based application, passport.initialize() middleware is required to initialize Passport. If your application uses persistent login sessions, passport.session() middleware must also be used.

app.configure(function() {
  app.use(express.static('public'));
  app.use(express.cookieParser());
  app.use(express.bodyParser());
  app.use(express.session({ secret: 'keyboard cat' }));
  app.use(passport.initialize());
  app.use(passport.session());
  app.use(app.router);
});

Note that enabling session support is entirely optional, though it is recommended for most applications. If enabled, be sure to use session() before passport.session() to ensure that the login session is restored in the correct order.

In Express 4.x, the Connect middleware is no longer included in the Express core, and the app.configure() method has been removed. The same middleware can be found in their npm module equivalents.

var session = require("express-session"),
    bodyParser = require("body-parser");

app.use(express.static("public"));
app.use(session({ secret: "cats" }));
app.use(bodyParser.urlencoded({ extended: false }));
app.use(passport.initialize());
app.use(passport.session());

Sessions

In a typical web application, the credentials used to authenticate a user will only be transmitted during the login request. If authentication succeeds, a session will be established and maintained via a cookie set in the user's browser.

Each subsequent request will not contain credentials, but rather the unique cookie that identifies the session. In order to support login sessions, Passport will serialize and deserialize user instances to and from the session.

passport.serializeUser(function(user, done) {
  done(null, user.id);
});

passport.deserializeUser(function(id, done) {
  User.findById(id, function(err, user) {
    done(err, user);
  });
});

In this example, only the user ID is serialized to the session, keeping the amount of data stored within the session small. When subsequent requests are received, this ID is used to find the user, which will be restored to req.user.

The serialization and deserialization logic is supplied by the application, allowing the application to choose an appropriate database and/or object mapper, without imposition by the authentication layer.
Username & Password

The most widely used way for websites to authenticate users is via a username and password. Support for this mechanism is provided by the passport-local module.
Install

$ npm install passport-local

Configuration

var passport = require('passport')
  , LocalStrategy = require('passport-local').Strategy;

passport.use(new LocalStrategy(
  function(username, password, done) {
    User.findOne({ username: username }, function(err, user) {
      if (err) { return done(err); }
      if (!user) {
        return done(null, false, { message: 'Incorrect username.' });
      }
      if (!user.validPassword(password)) {
        return done(null, false, { message: 'Incorrect password.' });
      }
      return done(null, user);
    });
  }
));

The verify callback for local authentication accepts username and password arguments, which are submitted to the application via a login form.
Form

A form is placed on a web page, allowing the user to enter their credentials and log in.

<form action="/login" method="post">
    <div>
        <label>Username:</label>
        <input type="text" name="username"/>
    </div>
    <div>
        <label>Password:</label>
        <input type="password" name="password"/>
    </div>
    <div>
        <input type="submit" value="Log In"/>
    </div>
</form>

Route

The login form is submitted to the server via the POST method. Using authenticate() with the local strategy will handle the login request.

app.post('/login',
  passport.authenticate('local', { successRedirect: '/',
                                   failureRedirect: '/login',
                                   failureFlash: true })
);

Setting the failureFlash option to true instructs Passport to flash an error message using the message option set by the verify callback above. This is helpful when prompting the user to try again.
Parameters

By default, LocalStrategy expects to find credentials in parameters named username and password. If your site prefers to name these fields differently, options are available to change the defaults.

passport.use(new LocalStrategy({
    usernameField: 'email',
    passwordField: 'passwd'
  },
  function(username, password, done) {
    // ...
  }
));

OpenID

OpenID is an open standard for federated authentication. When visiting a website, users present their OpenID to sign in. The user then authenticates with their chosen OpenID provider, which issues an assertion to confirm the user's identity. The website verifies this assertion in order to sign the user in.

Support for OpenID is provided by the passport-openid module.
Install

$ npm install passport-openid

Configuration

When using OpenID, a return URL and realm must be specified. The returnURL is the URL to which the user will be redirected after authenticating with their OpenID provider. realm indicates the part of URL-space for which authentication is valid. Typically this will be the root URL of the website.

var passport = require('passport')
  , OpenIDStrategy = require('passport-openid').Strategy;

passport.use(new OpenIDStrategy({
    returnURL: 'http://www.example.com/auth/openid/return',
    realm: 'http://www.example.com/'
  },
  function(identifier, done) {
    User.findOrCreate({ openId: identifier }, function(err, user) {
      done(err, user);
    });
  }
));

The verify callback for OpenID authentication accepts an identifier argument containing the user's claimed identifier.
Form

A form is placed on a web page, allowing the user to enter their OpenID and sign in.

<form action="/auth/openid" method="post">
    <div>
        <label>OpenID:</label>
        <input type="text" name="openid_identifier"/><br/>
    </div>
    <div>
        <input type="submit" value="Sign In"/>
    </div>
</form>

Routes

Two routes are required for OpenID authentication. The first route accepts the form submission containing an OpenID identifier. During authentication, the user will be redirected to their OpenID provider. The second route is the URL to which the user will be returned after authenticating with their OpenID provider.

// Accept the OpenID identifier and redirect the user to their OpenID
// provider for authentication.  When complete, the provider will redirect
// the user back to the application at:
//     /auth/openid/return
app.post('/auth/openid', passport.authenticate('openid'));

// The OpenID provider has redirected the user back to the application.
// Finish the authentication process by verifying the assertion.  If valid,
// the user will be logged in.  Otherwise, authentication has failed.
app.get('/auth/openid/return',
  passport.authenticate('openid', { successRedirect: '/',
                                    failureRedirect: '/login' }));

Profile Exchange

OpenID can optionally be configured to retrieve profile information about the user being authenticated. Profile exchange is enabled by setting the profile option to true.

passport.use(new OpenIDStrategy({
    returnURL: 'http://www.example.com/auth/openid/return',
    realm: 'http://www.example.com/',
    profile: true
  },
  function(identifier, profile, done) {
    // ...
  }
));

When profile exchange is enabled, the function signature of the verify callback accepts an additional profile argument containing user profile information provided by the OpenID provider; refer to User Profile for further information.
OAuth

OAuth is a standard protocol that allows users to authorize API access to web and desktop or mobile applications. Once access has been granted, the authorized application can utilize the API on behalf of the user. OAuth has also emerged as a popular mechanism for delegated authentication.

OAuth comes in two primary flavors, both of which are widely deployed.

The initial version of OAuth was developed as an open standard by a loosely organized collective of web developers. Their work resulted in OAuth 1.0, which was superseded by OAuth 1.0a. This work has now been standardized by the IETF as RFC 5849.

Recent efforts undertaken by the Web Authorization Protocol Working Group have focused on defining OAuth 2.0. Due to the lengthy standardization effort, providers have proceeded to deploy implementations conforming to various drafts, each with slightly different semantics.

Thankfully, Passport shields an application from the complexities of dealing with OAuth variants. In many cases, a provider-specific strategy can be used instead of the generic OAuth strategies described below. This cuts down on the necessary configuration, and accommodates any provider-specific quirks. See Facebook, Twitter or the list of providers for preferred usage.

Support for OAuth is provided by the passport-oauth module.
Install

$ npm install passport-oauth

OAuth 1.0

OAuth 1.0 is a delegated authentication strategy that involves multiple steps. First, a request token must be obtained. Next, the user is redirected to the service provider to authorize access. Finally, after authorization has been granted, the user is redirected back to the application and the request token can be exchanged for an access token. The application requesting access, known as a consumer, is identified by a consumer key and consumer secret.
Configuration

When using the generic OAuth strategy, the key, secret, and endpoints are specified as options.

var passport = require('passport')
  , OAuthStrategy = require('passport-oauth').OAuthStrategy;

passport.use('provider', new OAuthStrategy({
    requestTokenURL: 'https://www.provider.com/oauth/request_token',
    accessTokenURL: 'https://www.provider.com/oauth/access_token',
    userAuthorizationURL: 'https://www.provider.com/oauth/authorize',
    consumerKey: '123-456-789',
    consumerSecret: 'shhh-its-a-secret'
    callbackURL: 'https://www.example.com/auth/provider/callback'
  },
  function(token, tokenSecret, profile, done) {
    User.findOrCreate(..., function(err, user) {
      done(err, user);
    });
  }
));

The verify callback for OAuth-based strategies accepts token, tokenSecret, and profile arguments. token is the access token and tokenSecret is its corresponding secret. profile will contain user profile information provided by the service provider; refer to User Profile for additional information.
Routes

Two routes are required for OAuth authentication. The first route initiates an OAuth transaction and redirects the user to the service provider. The second route is the URL to which the user will be redirected after authenticating with the provider.

// Redirect the user to the OAuth provider for authentication.  When
// complete, the provider will redirect the user back to the application at
//     /auth/provider/callback
app.get('/auth/provider', passport.authenticate('provider'));

// The OAuth provider has redirected the user back to the application.
// Finish the authentication process by attempting to obtain an access
// token.  If authorization was granted, the user will be logged in.
// Otherwise, authentication has failed.
app.get('/auth/provider/callback',
  passport.authenticate('provider', { successRedirect: '/',
                                      failureRedirect: '/login' }));

Link

A link or button can be placed on a web page, which will start the authentication process when clicked.

<a href="/auth/provider">Log In with OAuth Provider</a>

OAuth 2.0

OAuth 2.0 is the successor to OAuth 1.0, and is designed to overcome perceived shortcomings in the earlier version. The authentication flow is essentially the same. The user is first redirected to the service provider to authorize access. After authorization has been granted, the user is redirected back to the application with a code that can be exchanged for an access token. The application requesting access, known as a client, is identified by an ID and secret.
Configuration

When using the generic OAuth 2.0 strategy, the client ID, client secret, and endpoints are specified as options.

var passport = require('passport')
  , OAuth2Strategy = require('passport-oauth').OAuth2Strategy;

passport.use('provider', new OAuth2Strategy({
    authorizationURL: 'https://www.provider.com/oauth2/authorize',
    tokenURL: 'https://www.provider.com/oauth2/token',
    clientID: '123-456-789',
    clientSecret: 'shhh-its-a-secret'
    callbackURL: 'https://www.example.com/auth/provider/callback'
  },
  function(accessToken, refreshToken, profile, done) {
    User.findOrCreate(..., function(err, user) {
      done(err, user);
    });
  }
));

The verify callback for OAuth 2.0-based strategies accepts accessToken, refreshToken, and profile arguments. refreshToken can be used to obtain new access tokens, and may be undefined if the provider does not issue refresh tokens. profile will contain user profile information provided by the service provider; refer to User Profile for additional information.
Routes

Two routes are required for OAuth 2.0 authentication. The first route redirects the user to the service provider. The second route is the URL to which the user will be redirected after authenticating with the provider.

// Redirect the user to the OAuth 2.0 provider for authentication.  When
// complete, the provider will redirect the user back to the application at
//     /auth/provider/callback
app.get('/auth/provider', passport.authenticate('provider'));

// The OAuth 2.0 provider has redirected the user back to the application.
// Finish the authentication process by attempting to obtain an access
// token.  If authorization was granted, the user will be logged in.
// Otherwise, authentication has failed.
app.get('/auth/provider/callback',
  passport.authenticate('provider', { successRedirect: '/',
                                      failureRedirect: '/login' }));

Scope

When requesting access using OAuth 2.0, the scope of access is controlled by the scope option.

app.get('/auth/provider',
  passport.authenticate('provider', { scope: 'email' })
);

Multiple scopes can be specified as an array.

app.get('/auth/provider',
  passport.authenticate('provider', { scope: ['email', 'sms'] })
);

Values for the scope option are provider-specific. Consult the provider's documentation for details regarding supported scopes.
Link

A link or button can be placed on a web page, which will start the authentication process when clicked.

<a href="/auth/provider">Log In with OAuth 2.0 Provider</a>

User Profile

When authenticating using a third-party service such as Facebook or Twitter, user profile information will often be available. Each service tends to have a different way of encoding this information. To make integration easier, Passport normalizes profile information to the extent possible.

Normalized profile information conforms to the contact schema established by [Joseph Smarr][schema-author]. The common fields available are outlined in the following table.

provider {String}
    The provider with which the user authenticated (facebook, twitter, etc.).
id {String}
    A unique identifier for the user, as generated by the service provider.
displayName {String}
    The name of this user, suitable for display.
name {Object}

    familyName {String}
        The family name of this user, or "last name" in most Western languages.
    givenName {String}
        The given name of this user, or "first name" in most Western languages.
    middleName {String}
        The middle name of this user.

emails {Array} [n]

    value {String}
        The actual email address.
    type {String}
        The type of email address (home, work, etc.).

photos {Array} [n]

    value {String}
        The URL of the image.

Note that not all of the above fields are available from every service provider. Some providers may contain additional information not described here. Consult the provider-specific documentation for further details.
Facebook

The Facebook strategy allows users to log in to a web application using their Facebook account. Internally, Facebook authentication works using OAuth 2.0.

Support for Facebook is implemented by the passport-facebook module.
Install

$ npm install passport-facebook

Configuration

In order to use Facebook authentication, you must first create an app at Facebook Developers. When created, an app is assigned an App ID and App Secret. Your application must also implement a redirect URL, to which Facebook will redirect users after they have approved access for your application.

var passport = require('passport')
  , FacebookStrategy = require('passport-facebook').Strategy;

passport.use(new FacebookStrategy({
    clientID: FACEBOOK_APP_ID,
    clientSecret: FACEBOOK_APP_SECRET,
    callbackURL: "http://www.example.com/auth/facebook/callback"
  },
  function(accessToken, refreshToken, profile, done) {
    User.findOrCreate(..., function(err, user) {
      if (err) { return done(err); }
      done(null, user);
    });
  }
));

The verify callback for Facebook authentication accepts accessToken, refreshToken, and profile arguments. profile will contain user profile information provided by Facebook; refer to User Profile for additional information.

Note: For security reasons, the redirection URL must reside on the same host that is registered with Facebook.
Routes

Two routes are required for Facebook authentication. The first route redirects the user to Facebook. The second route is the URL to which Facebook will redirect the user after they have logged in.

// Redirect the user to Facebook for authentication.  When complete,
// Facebook will redirect the user back to the application at
//     /auth/facebook/callback
app.get('/auth/facebook', passport.authenticate('facebook'));

// Facebook will redirect the user to this URL after approval.  Finish the
// authentication process by attempting to obtain an access token.  If
// access was granted, the user will be logged in.  Otherwise,
// authentication has failed.
app.get('/auth/facebook/callback',
  passport.authenticate('facebook', { successRedirect: '/',
                                      failureRedirect: '/login' }));

Note that the URL of the callback route matches that of the callbackURL option specified when configuring the strategy.
Permissions

If your application needs extended permissions, they can be requested by setting the scope option.

app.get('/auth/facebook',
  passport.authenticate('facebook', { scope: 'read_stream' })
);

Multiple permissions can be specified as an array.

app.get('/auth/facebook',
  passport.authenticate('facebook', { scope: ['read_stream', 'publish_actions'] })
);

Link

A link or button can be placed on a web page, allowing one-click login with Facebook.

<a href="/auth/facebook">Login with Facebook</a>

Twitter

The Twitter strategy allows users to sign in to a web application using their Twitter account. Internally, Twitter authentication works using OAuth 1.0a.

Support for Twitter is implemented by the passport-twitter module.
Install

$ npm install passport-twitter

Configuration

In order to use Twitter authentication, you must first create an application at Twitter Developers. When created, an application is assigned a consumer key and consumer secret. Your application must also implement a callback URL, to which Twitter will redirect users after they have approved access for your application.

var passport = require('passport')
  , TwitterStrategy = require('passport-twitter').Strategy;

passport.use(new TwitterStrategy({
    consumerKey: TWITTER_CONSUMER_KEY,
    consumerSecret: TWITTER_CONSUMER_SECRET,
    callbackURL: "http://www.example.com/auth/twitter/callback"
  },
  function(token, tokenSecret, profile, done) {
    User.findOrCreate(..., function(err, user) {
      if (err) { return done(err); }
      done(null, user);
    });
  }
));

The verify callback for Twitter authentication accepts token, tokenSecret, and profile arguments. profile will contain user profile information provided by Twitter; refer to User Profile for additional information.
Routes

Two routes are required for Twitter authentication. The first route initiates an OAuth transaction and redirects the user to Twitter. The second route is the URL to which Twitter will redirect the user after they have signed in.

// Redirect the user to Twitter for authentication.  When complete, Twitter
// will redirect the user back to the application at
//   /auth/twitter/callback
app.get('/auth/twitter', passport.authenticate('twitter'));

// Twitter will redirect the user to this URL after approval.  Finish the
// authentication process by attempting to obtain an access token.  If
// access was granted, the user will be logged in.  Otherwise,
// authentication has failed.
app.get('/auth/twitter/callback',
  passport.authenticate('twitter', { successRedirect: '/',
                                     failureRedirect: '/login' }));

Note that the URL of the callback route matches that of the callbackURL option specified when configuring the strategy.
Link

A link or button can be placed on a web page, allowing one-click sign in with Twitter.

<a href="/auth/twitter">Sign in with Twitter</a>

Google

The Google strategy allows users to sign in to a web application using their Google account. Google used to support OpenID internally, but it now works based on OpenID Connect and supports oAuth 1.0 and oAuth 2.0.

Support for Google is implemented by the passport-google-oauth module.
Install

$ npm install passport-google-oauth

Configuration

The Client Id and Client Secret needed to authenticate with Google can be set up from the Google Developers Console. You may also need to enable Google+ API in the developer console, otherwise user profile data may not be fetched. Google supports authentication with both oAuth 1.0 and oAuth 2.0.
oAuth 1.0

The Google OAuth 1.0 authentication strategy authenticates users using a Google account and OAuth tokens. The strategy requires a verify callback, which accepts these credentials and calls done providing a user, as well as options specifying a consumer key, consumer secret, and callback URL.
Configuration

var passport = require('passport');
var GoogleStrategy = require('passport-google-oauth').OAuthStrategy;

// Use the GoogleStrategy within Passport.
//   Strategies in passport require a `verify` function, which accept
//   credentials (in this case, a token, tokenSecret, and Google profile), and
//   invoke a callback with a user object.
passport.use(new GoogleStrategy({
    consumerKey: GOOGLE_CONSUMER_KEY,
    consumerSecret: GOOGLE_CONSUMER_SECRET,
    callbackURL: "http://www.example.com/auth/google/callback"
  },
  function(token, tokenSecret, profile, done) {
      User.findOrCreate({ googleId: profile.id }, function (err, user) {
        return done(err, user);
      });
  }
));

Routes

Use passport.authenticate(), specifying the 'google' strategy, to authenticate requests. Authentication with Google requires an extra scope parameter. For information, go here.

// GET /auth/google
//   Use passport.authenticate() as route middleware to authenticate the
//   request.  The first step in Google authentication will involve redirecting
//   the user to google.com.  After authorization, Google will redirect the user
//   back to this application at /auth/google/callback
app.get('/auth/google',
  passport.authenticate('google', { scope: 'https://www.google.com/m8/feeds' });

// GET /auth/google/callback
//   Use passport.authenticate() as route middleware to authenticate the
//   request.  If authentication fails, the user will be redirected back to the
//   login page.  Otherwise, the primary route function function will be called,
//   which, in this example, will redirect the user to the home page.
app.get('/auth/google/callback', 
  passport.authenticate('google', { failureRedirect: '/login' }),
  function(req, res) {
    res.redirect('/');
  });

oAuth 2.0

The Google OAuth 2.0 authentication strategy authenticates users using a Google account and OAuth 2.0 tokens. The strategy requires a verify callback, which accepts these credentials and calls done providing a user, as well as options specifying a client ID, client secret, and callback URL.
Configuration

var passport = require('passport');
var GoogleStrategy = require('passport-google-oauth').OAuth2Strategy;

// Use the GoogleStrategy within Passport.
//   Strategies in Passport require a `verify` function, which accept
//   credentials (in this case, an accessToken, refreshToken, and Google
//   profile), and invoke a callback with a user object.
passport.use(new GoogleStrategy({
    clientID: GOOGLE_CLIENT_ID,
    clientSecret: GOOGLE_CLIENT_SECRET,
    callbackURL: "http://www.example.com/auth/google/callback"
  },
  function(accessToken, refreshToken, profile, done) {
       User.findOrCreate({ googleId: profile.id }, function (err, user) {
         return done(err, user);
       });
  }
));

Routes

Use passport.authenticate(), specifying the 'google' strategy, to authenticate requests. Authentication with Google requires an extra scope parameter. For information, go here.

// GET /auth/google
//   Use passport.authenticate() as route middleware to authenticate the
//   request.  The first step in Google authentication will involve
//   redirecting the user to google.com.  After authorization, Google
//   will redirect the user back to this application at /auth/google/callback
app.get('/auth/google',
  passport.authenticate('google', { scope: ['https://www.googleapis.com/auth/plus.login'] }));

// GET /auth/google/callback
//   Use passport.authenticate() as route middleware to authenticate the
//   request.  If authentication fails, the user will be redirected back to the
//   login page.  Otherwise, the primary route function function will be called,
//   which, in this example, will redirect the user to the home page.
app.get('/auth/google/callback', 
  passport.authenticate('google', { failureRedirect: '/login' }),
  function(req, res) {
    res.redirect('/');
  });

Link

A link or button can be placed on a web page, allowing one-click sign in with Google.

<a href="/auth/google">Sign In with Google</a>

Basic & Digest

Along with defining HTTP's authentication framework, RFC 2617 also defined the Basic and Digest authentications schemes. These two schemes both use usernames and passwords as credentials to authenticate users, and are often used to protect API endpoints.

It should be noted that relying on username and password creditials can have adverse security impacts, especially in scenarios where there is not a high degree of trust between the server and client. In these situations, it is recommended to use an authorization framework such as OAuth 2.0.

Support for Basic and Digest schemes is provided by the passport-http module.
Install

$ npm install passport-http

Basic

The Basic scheme uses a username and password to authenticate a user. These credentials are transported in plain text, so it is advised to use HTTPS when implementing this scheme.
Configuration

passport.use(new BasicStrategy(
  function(username, password, done) {
    User.findOne({ username: username }, function (err, user) {
      if (err) { return done(err); }
      if (!user) { return done(null, false); }
      if (!user.validPassword(password)) { return done(null, false); }
      return done(null, user);
    });
  }
));

The verify callback for Basic authentication accepts username and password arguments.
Protect Endpoints

app.get('/api/me',
  passport.authenticate('basic', { session: false }),
  function(req, res) {
    res.json(req.user);
  });

Specify passport.authenticate() with the basic strategy to protect API endpoints. Sessions are not typically needed by APIs, so they can be disabled.
Digest

The Digest scheme uses a username and password to authenticate a user. Its primary benefit over Basic is that it uses a challenge-response paradigm to avoid sending the password in the clear.
Configuration

passport.use(new DigestStrategy({ qop: 'auth' },
  function(username, done) {
    User.findOne({ username: username }, function (err, user) {
      if (err) { return done(err); }
      if (!user) { return done(null, false); }
      return done(null, user, user.password);
    });
  },
  function(params, done) {
    // validate nonces as necessary
    done(null, true)
  }
));

The Digest strategy utilizes two callbacks, the second of which is optional.

The first callback, known as the "secret callback" accepts the username and calls done supplying a user and the corresponding secret password. The password is used to compute a hash, and authentication fails if it does not match that contained in the request.

The second "validate callback" accepts nonce related params, which can be checked to avoid replay attacks.
Protect Endpoints

app.get('/api/me',
  passport.authenticate('digest', { session: false }),
  function(req, res) {
    res.json(req.user);
  });

Specify passport.authenticate() with the digest strategy to protect API endpoints. Sessions are not typically needed by APIs, so they can be disabled.
OAuth

OAuth (formally specified by RFC 5849) provides a means for users to grant third-party applications access to their data without exposing their password to those applications.

The protocol greatly improves the security of web applications, in particular, and OAuth has been important in bringing attention to the potential dangers of exposing passwords to external services.

While OAuth 1.0 is still widely used, it has been superseded by OAuth 2.0. It is recommended to base new implementations on OAuth 2.0.

When using OAuth to protect API endpoints, there are three distinct steps that that must be performed:

    The application requests permission from the user for access to protected resources.
    A token is issued to the application, if permission is granted by the user.
    The application authenticates using the token to access protected resources.

Issuing Tokens

OAuthorize, a sibling project to Passport, provides a toolkit for implementing OAuth service providers.

The authorization process is a complex sequence that involves authenticating both the requesting application and the user, as well as prompting the user for permission, ensuring that enough detail is provided for the user to make an informed decision.

Additionally, it is up to the implementor to determine what limits can be placed on the application regarding scope of access, as well as subsequently enforcing those limits.

As a toolkit, OAuthorize does not attempt to make implementation decisions. This guide does not cover these issues, but does highly recommend that services deploying OAuth have a complete understanding of the security considerations involved.
Authenticating Tokens

Once issued, OAuth tokens can be authenticated using the passport-http-oauth module.
Install

$ npm install passport-http-oauth

Configuration

passport.use('token', new TokenStrategy(
  function(consumerKey, done) {
    Consumer.findOne({ key: consumerKey }, function (err, consumer) {
      if (err) { return done(err); }
      if (!consumer) { return done(null, false); }
      return done(null, consumer, consumer.secret);
    });
  },
  function(accessToken, done) {
    AccessToken.findOne({ token: accessToken }, function (err, token) {
      if (err) { return done(err); }
      if (!token) { return done(null, false); }
      Users.findById(token.userId, function(err, user) {
        if (err) { return done(err); }
        if (!user) { return done(null, false); }
        // fourth argument is optional info.  typically used to pass
        // details needed to authorize the request (ex: `scope`)
        return done(null, user, token.secret, { scope: token.scope });
      });
    });
  },
  function(timestamp, nonce, done) {
    // validate the timestamp and nonce as necessary
    done(null, true)
  }
));

In contrast to other strategies, there are two callbacks required by OAuth. In OAuth, both an identifier for the requesting application and the user-specific token are encoded as credentials.

The first callback is known as the "consumer callback", and is used to find the application making the request, including the secret assigned to it. The second callback is the "token callback", which is used to indentify the user as well as the token's corresponding secret. The secrets supplied by the consumer and token callbacks are used to compute a signature, and authentication fails if it does not match the request signature.

A final "validate callback" is optional, which can be used to prevent replay attacks by checking the timestamp and nonce used in the request.
Protect Endpoints

app.get('/api/me',
  passport.authenticate('token', { session: false }),
  function(req, res) {
    res.json(req.user);
  });

Specify passport.authenticate() with the token strategy to protect API endpoints. Sessions are not typically needed by APIs, so they can be disabled.
OAuth 2.0

OAuth 2.0 (formally specified by RFC 6749) provides an authorization framework which allows users to authorize access to third-party applications. When authorized, the application is issued a token to use as an authentication credential. This has two primary security benefits:

    The application does not need to store the user's username and password.
    The token can have a restricted scope (for example: read-only access).

These benefits are particularly important for ensuring the security of web applications, making OAuth 2.0 the predominant standard for API authentication.

When using OAuth 2.0 to protect API endpoints, there are three distinct steps that must be performed:

    The application requests permission from the user for access to protected resources.
    A token is issued to the application, if permission is granted by the user.
    The application authenticates using the token to access protected resources.

Issuing Tokens

OAuth2orize, a sibling project to Passport, provides a toolkit for implementing OAuth 2.0 authorization servers.

The authorization process is a complex sequence that involves authenticating both the requesting application and the user, as well as prompting the user for permission, ensuring that enough detail is provided for the user to make an informed decision.

Additionally, it is up to the implementor to determine what limits can be placed on the application regarding scope of access, as well as subsequently enforcing those limits.

As a toolkit, OAuth2orize does not attempt to make implementation decisions. This guide does not cover these issues, but does highly recommend that services deploying OAuth 2.0 have a complete understanding of the security considerations involved.
Authenticating Tokens

OAuth 2.0 provides a framework, in which an arbitrarily extensible set of token types can be issued. In practice, only specific token types have gained widespread use.
Bearer Tokens

Bearer tokens are the most widely issued type of token in OAuth 2.0. So much so, in fact, that many implementations assume that bearer tokens are the only type of token issued.

Bearer tokens can be authenticated using the passport-http-bearer module.
Install

$ npm install passport-http-bearer

Configuration

passport.use(new BearerStrategy(
  function(token, done) {
    User.findOne({ token: token }, function (err, user) {
      if (err) { return done(err); }
      if (!user) { return done(null, false); }
      return done(null, user, { scope: 'read' });
    });
  }
));

The verify callback for bearer tokens accepts the token as an argument. When invoking done, optional info can be passed, which will be set by Passport at req.authInfo. This is typically used to convey the scope of the token, and can be used when making access control checks.
Protect Endpoints

app.get('/api/me',
  passport.authenticate('bearer', { session: false }),
  function(req, res) {
    res.json(req.user);
  });

Specify passport.authenticate() with the bearer strategy to protect API endpoints. Sessions are not typically needed by APIs, so they can be disabled.
API Schemes

The following is a list of strategies that implement authentication schemes used when protecting API endpoints.
Scheme 	Specification 	Developer
Anonymous 	N/A 	Jared Hanson
Bearer 	RFC 6750 	Jared Hanson
Basic 	RFC 2617 	Jared Hanson
Digest 	RFC 2617 	Jared Hanson
Hash 	N/A 	Yuri Karadzhov
Hawk 	hueniverse/hawk 	José F. Romaniello
Local API Key 	N/A 	Sudhakar Mani
OAuth 	RFC 5849 	Jared Hanson
OAuth 2.0 Client Password 	RFC 6749 	Jared Hanson
OAuth 2.0 JWT Client Assertion 	draft-jones-oauth-jwt-bearer 	xTuple
OAuth 2.0 Public Client 	RFC 6749 	Tim Shadel
Log In

Passport exposes a login() function on req (also aliased as logIn()) that can be used to establish a login session.

req.login(user, function(err) {
  if (err) { return next(err); }
  return res.redirect('/users/' + req.user.username);
});

When the login operation completes, user will be assigned to req.user.

Note: passport.authenticate() middleware invokes req.login() automatically. This function is primarily used when users sign up, during which req.login() can be invoked to automatically log in the newly registered user.
Log Out

Passport exposes a logout() function on req (also aliased as logOut()) that can be called from any route handler which needs to terminate a login session. Invoking logout() will remove the req.user property and clear the login session (if any).

app.get('/logout', function(req, res){
  req.logout();
  res.redirect('/');
});

Authorize

An application may need to incorporate information from multiple third-party services. In this case, the application will request the user to "connect", for example, both their Facebook and Twitter accounts.

When this occurs, a user will already be authenticated with the application, and any subsequent third-party accounts merely need to be authorized and associated with the user. Because authentication and authorization in this situation are similar, Passport provides a means to accommodate both.

Authorization is performed by calling passport.authorize(). If authorization is granted, the result provided by the strategy's verify callback will be assigned to req.account. The existing login session and req.user will be unaffected.

app.get('/connect/twitter',
  passport.authorize('twitter-authz', { failureRedirect: '/account' })
);

app.get('/connect/twitter/callback',
  passport.authorize('twitter-authz', { failureRedirect: '/account' }),
  function(req, res) {
    var user = req.user;
    var account = req.account;

    // Associate the Twitter account with the logged-in user.
    account.userId = user.id;
    account.save(function(err) {
      if (err) { return self.error(err); }
      self.redirect('/');
    });
  }
);

In the callback route, you can see the use of both req.user and req.account. The newly connected account is associated with the logged-in user and saved to the database.
Configuration

Strategies used for authorization are the same as those used for authentication. However, an application may want to offer both authentication and authorization with the same third-party service. In this case, a named strategy can be used, by overriding the strategy's default name in the call to use().

passport.use('twitter-authz', new TwitterStrategy({
    consumerKey: TWITTER_CONSUMER_KEY,
    consumerSecret: TWITTER_CONSUMER_SECRET,
    callbackURL: "http://www.example.com/connect/twitter/callback"
  },
  function(token, tokenSecret, profile, done) {
    Account.findOne({ domain: 'twitter.com', uid: profile.id }, function(err, account) {
      if (err) { return done(err); }
      if (account) { return done(null, account); }

      var account = new Account();
      account.domain = 'twitter.com';
      account.uid = profile.id;
      var t = { kind: 'oauth', token: token, attributes: { tokenSecret: tokenSecret } };
      account.tokens.push(t);
      return done(null, account);
    });
  }
));

In the above example, you can see that the twitter-authz strategy is finding or creating an Account instance to store Twitter account information. The result will be assigned to req.account, allowing the route handler to associate the account with the authenticated user.
Association in Verify Callback

One downside to the approach described above is that it requires two instances of the same strategy and supporting routes.

To avoid this, set the strategy's passReqToCallback option to true. With this option enabled, req will be passed as the first argument to the verify callback.

passport.use(new TwitterStrategy({
    consumerKey: TWITTER_CONSUMER_KEY,
    consumerSecret: TWITTER_CONSUMER_SECRET,
    callbackURL: "http://www.example.com/auth/twitter/callback",
    passReqToCallback: true
  },
  function(req, token, tokenSecret, profile, done) {
    if (!req.user) {
      // Not logged-in. Authenticate based on Twitter account.
    } else {
      // Logged in. Associate Twitter account with user.  Preserve the login
      // state by supplying the existing user after association.
      // return done(null, req.user);
    }
  }
));

With req passed as an argument, the verify callback can use the state of the request to tailor the authentication process, handling both authentication and authorization using a single strategy instance and set of routes. For example, if a user is already logged in, the newly "connected" account can be associated. Any additional application-specific properties set on req, including req.session, can be used as well.

                1.10.3.1.3
            1.10.3.2

        1.10.4 Schema validations

            1.10.4.1 swagger validation , Schema validations

                1.10.4.1.1 https://www.npmjs.com/package/express-openapi-validate
index.js

const fs = require("fs");
const express = require("express");
const { OpenApiValidator } = require("express-openapi-validate");
const jsYaml = require("js-yaml");
 
const app = express();
app.use(express.json());
 
const openApiDocument = jsYaml.safeLoad(
  fs.readFileSync("openapi.yaml", "utf-8")
);
const validator = new OpenApiValidator(openApiDocument);
 
app.post("/echo", validator.validate("post", "/echo"), (req, res, next) => {
  res.json({ output: req.body.input });
});
 
app.use((err, req, res, next) => {
  const statusCode = err.statusCode || 500;
  res.status(statusCode).json({
    error: {
      name: err.name,
      message: err.message,
      data: err.data,
    },
  });
});
 
const server = app.listen(3000, () => {
  console.log("Listening on", server.address());
});
openapi.yaml

openapi: 3.0.1
info:
  title: Example API with a single echo endpoint
  version: 1.0.0
components:
  schemas:
    Error:
      type: object
      properties:
        error:
          type: object
          properties:
            name:
              type: string
            message:
              type: string
            data:
              type: array
              items:
                type: object
          required:
            - name
            - message
      required:
        - error
  responses:
    error:
      description: Default error response with error object
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Error"
paths:
  /echo:
    post:
      description: Echo input back
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                input:
                  type: string
              required:
                - input
      responses:
        "200":
          description: Echoed input
          content:
            application/json:
              schema:
                type: object
                properties:
                  output:
                    type: string
        default:
          $ref: "#/components/responses/error"

                1.10.4.1.2 usage in semantic
src/swagger folder contains .json resources for swagger usage.
validation jsons are in src/swagger/schemas
[i500695@C02X632CJGH6:2018-11-14 18:04:57:~/Desktop/work/SAP/CF_LocAL/portal-cf-site-semantic-service:]579$ ls -R src/swagger/
app/		batch/		examples/	index.js	read/		schemas/	site/		swagger.json

src/swagger//app:
app-id.json	app.json

src/swagger//batch:
batch.json

src/swagger//examples:
app-list.json		entity-list.json	single-app.json		single-entity.json	single-site.json	site-list.json

src/swagger//read:
entity-type-id.json	entity-type.json

src/swagger//schemas:
batch-request.json	cdm.json		entity-list.json	id.json			single-entity.json

src/swagger//site:
site-id.json	site.json

[i500695@C02X632CJGH6:2018-11-14 18:05:03:~/Desktop/work/SAP/CF_LocAL/portal-cf-site-semantic-service:]580$ cat src/swagger//schemas/id.json 
{
    "type": "string",
    "pattern": "^[\\w-:@+~./]+$",
    "minLength": 1,
    "maxLength": 70
}

The json schema are stored in 
    swaggerDoc.components.schemas = {
        'BatchRequest': require('./schemas/batch-request.json'),
        'EntityList': require('./schemas/entity-list.json'),
        'SingleEntity': require('./schemas/single-entity.json'),
        'CDM': require('./schemas/cdm.json'),
        'ID': require('./schemas/id.json')
    };
in swagger/index.js

note that the .json files use $ref to include the schemas. ex from app.json:
   "get": {
        "tags": [
            "App"
        ],
        "summary": "Read all apps, optionally filter by specific catalog/group, or a specific app, optionally with related entities",
        "parameters": [
            {
                "name": "contextId",
                "description": "The context id",
                "in": "query",
                "schema": {
                    "$ref": "#/components/schemas/ID"
                },

Actual validation:
        ex: sites.js:
        const requestValidator = new OpenApiValidator(swaggerDoc());

    const validateRequest = (req, res, next) => {
        requestValidator.validate(req.method.toLowerCase(), req.baseUrl + (req.params.id ? "/{id}" : ""))(req, res, next);
    };


                1.10.4.1.3
            1.10.4.2


        1.10.5 express FAQ
        
            1.10.5.1 get request params and query params 
Express 4.x

To get a URL parameter's value, use req.params

app.get('/p/:tagId', function(req, res) {
  res.send("tagId is set to " + req.params.tagId);
});

// GET /p/5
// tagId is set to 5
If you want to get a query parameter ?tagId=5, then use req.query

app.get('/p', function(req, res) {
  res.send("tagId is set to " + req.query.tagId);
});

// GET /p?tagId=5
// tagId is set to 5

            1.10.5.2
        1.10.6 X509 authentication

resources:
https://smallstep.com/hello-mtls/doc/combined/express/nodejs
https://intown.biz/2016/11/22/node-client-auth/

            1.10.6.1 https://medium.com/@sevcsik/authentication-using-https-client-certificates-3c9d270e8326 
Authentication using HTTPS client certificates

We hear a lot about how passwords are insecure, and should not be used alone for authentication. They are hard to remember, so users are tempted to come up with weak passwords, and reuse them across multiple websites. Even if the password is strong, it’s still just a short string the users know.
Image for post
Image from betanews.com
There are numerous ways to mitigate this, such as HMAC or time-based one-time passwords or more recently universal 2nd-factor hardware tokens. They all based on something the user has, rather than something they know. What they have is a secret key, which they can use to generate a password or sign messages.
What seems to be forgotten in the consumer world is that every browser has had a feature built-in since TLS was introduced, called mutual authentication, which allows the user to present a certificate as well as the server. This means the user can authenticate with something they have and — if the certificate is protected by a passphrase — something they know.
In this post, we implement a simple Node.js example which uses client certificates to authenticate the user.
We only one need external dependency, express, otherwise, we just depend on the standard Node.js HTTPS server. We also need fs to read the certificates/keys to configure HTTPS.
const express = require('express')
const fs = require('fs')
const https = require('https')

Setting up the private key and the certificate
First of all, we need to generate our keys and certificates. We use the openssl command-line tool. On Linux, it’s likely already installed – if not, install the openssl package of your distribution. On Windows it’s a bit trickier, see this tutorial;
Like with every regular HTTPS server, we need to generate a server certificate. For the sake of brevity, we use a self-signed certificate here — in real life, you probably want to use a well-known certificate authority, such as Let’s Encrypt.
To generate a self-signed certificate (in our case, without encryption):
$ openssl req -x509 -newkey rsa:4096 -keyout server_key.pem -out server_cert.pem -nodes -days 365 -subj "/CN=localhost/O=Client\ Certificate\ Demo"
This is actually a three-step process combined into one command:
Create a new 4096bit RSA key and save it to server_key.pem, without DES encryption (-newkey, -keyout and -nodes)
Create a Certificate Signing Request for a given subject, valid for 365 days (-days, -subj)
Sign the CSR using the server key, and save it to server_cert.pem as an X.509 certificate (-x509, -out)
We could have also done this with tree commands, openssl genrsa, openssl req and openssl x509. We used the PEM format (the default setting), which is a base64-encoded text file with a ----- BEGIN/END CERTIFICATE/PRIVATE KEY ----- header and footer. Another option would be the DER format, which uses binary encoding. There is a bit of a confusion what the file extension should refer to: it’s also common to use .key or .crt, referring to the contents of the file rather than the encoding (in which case they can contain both DER- and PEM-encoded data).

Configuring the Node.js HTTP server
Let’s add our server key and certificate to the options object, which we pass to the HTTPS server later:
const opts = { key: fs.readFileSync('server_key.pem')
             , cert: fs.readFileSync('server_cert.pem')
Next, we instruct the HTTPS server to request a client certificate from the user
, requestCert: true
Then we tell it to accept requests with no valid certificate. We need this to handle invalid connections as well (for example to display an error message), otherwise, they would just get a cryptic HTTPS error message from the browser (ERR_BAD_SSL_CLIENT_AUTH_CERT to be precise)
, rejectUnauthorized: false

Finally, we supply a list of CA certificates that we consider valid. For now, we sign client certificates with our own server key, so it will be the same as our server certificate.
, ca: [ fs.readFileSync('server_cert.pem') ]
             }
Then we create our app. We use express only for routeing here — we could use the passport middleware as well, with a strategy for client certificates, but for now, we keep things simple.
const app = express()
We add our “landing page” first. This is unprotected, so everyone will see it whether they present a client cert or not.
app.get('/', (req, res) => {
	res.send('<a href="authenticate">Log in using client certificate</a>')
})

Then we add our protected endpoint: it just displays information about the user and the validity of their certificate. We can get the certificate information from the HTTPS connection handle:
app.get('/authenticate', (req, res) => {
	const cert = req.connection.getPeerCertificate()
The req.client.authorized flag will be true if the certificate is valid and was issued by a CA we white-listed earlier in opts.ca. We display the name of our user (CN = Common Name) and the name of the issuer, which is localhost.
if (req.client.authorized) {
		res.send(`Hello ${cert.subject.CN}, your certificate was issued by ${cert.issuer.CN}!`)

They can still provide a certificate which is not accepted by us. Unfortunately, the cert object will be an empty object instead of null if there is no certificate at all, so we have to check for a known field rather than truthiness.
} else if (cert.subject) {
		res.status(403)
		   .send(`Sorry ${cert.subject.CN}, certificates from ${cert.issuer.CN} are not welcome here.`)
And last, they can come to us with no certificate at all:
} else {
		res.status(401)
		   .send(`Sorry, but you need to provide a client certificate to continue.`)
	}
})

Let’s create our HTTPS server and we’re ready to go.
https.createServer(opts, app).listen(9999)
Then we can start our server with npm i && node server.js.

Setting up client certificates
If we try to “log in” to our site now, we get a 401 response, because we don’t have any client certificates yet. To test our setup, we create two certificates for our two users, Alice and Bob. Alice is nice as she has a valid certificate issued by us, while Bob is nasty and tries to log in using a self-signed certificate.
To create a key and a Certificate Signing Request for Alice and Bob we can use the following command:
$ openssl req -newkey rsa:4096 -keyout alice_key.pem -out alice_csr.pem -nodes -days 365 -subj "/CN=Alice"
$ openssl req -newkey rsa:4096 -keyout bob_key.pem -out bob_csr.pem -nodes -days 365 -subj "/CN=Bob"
We sign Alice’s CSR with our key and save it as a certificate. Here, we act as a Certificate Authority, so we supply our certificate and key via the -CA parameters:
$ openssl x509 -req -in alice_csr.pem -CA server_cert.pem -CAkey server_key.pem -out alice_cert.pem -set_serial 01 -days 365
Bob doesn’t believe in authority, so he just signs his certificate on his own:
$ openssl x509 -req -in bob_csr.pem -signkey bob_key.pem -out bob_cert.pem -days 365

Trying to get in
To use these certificates in our browser, we need to bundle them in PKCS#12 format. That will contain both the private key and the certificate, thus the browser can use it for encryption. For Alice, we add the -clcerts option, which excludes the CA certificate from the bundle. Since we issued the certificate, we already have the certificate: we don’t need to include it in Alice’s certificate as well. You can also password-protect the certificate.
$ openssl pkcs12 -export -clcerts -in alice_cert.pem -inkey alice_key.pem -out alice.p12
$ openssl pkcs12 -export -in bob_cert.pem -inkey bob_key.pem -out bob.p12
We can import these private keys to the browser. In Firefox, go to Preferences -> Advanced -> View Certificates -> Import, and choose both files.
If you open https://localhost:9999 in the browser now, a dialog will come up to choose a certificate. Note that only Alice’s certificate is in the list: that’s because the browser already knows that only certs issued by us will be accepted (because we advertise it using the opts.ca list). If you continue, you’ll see our success message with the details of Alice.

This is only a browser limitation, you can still try to get in with Bob’s cert using cURL:
$ curl --insecure --cert bob.p12 --cert-type p12 https://localhost:9999/authenticate
And see that Bob’s not welcome here!
Of course this solution isn’t practical in real life: we don’t want to genereate keys for our users via the command line and have them installing them into their browsers manually. In the next article, we’ll see how we can generate new client certificates dynamically and install them seamlessly to the users’ browser.
To try this server, there clone this post’s github repo, where you can also find the keys and certificates.

            1.10.6.2 https://intown.biz/2016/11/22/node-client-auth/
USE SSL CLIENT AUTHENTICATION WITH NODE.JS AND EXPRESS
repo: https://github.com/mmendelson222/https-demo

step by step:
Create a signing key (CA)
Everything starts with a signing key, which can be created with a command similar to this:

$ openssl req -new -x509 -days 365 -keyout ca-key.pem -out ca-crt.pem
The resulting cert and key can then be used to sign other certificates. Creating a self signed cert is similar.

Create a signed certificate
Creating a signed certificate is a multi-step process. First you’ll need a signing key, as generated above.

export CERT=server
export CA_NAME=ca
#generating private key for server
openssl genrsa -out $CERT-key.pem 4096
#generate a signing request
openssl req -new -sha256 -config $CERT.cnf -key $CERT-key.pem -out $CERT-csr.pem
#perform the signing
openssl x509 -req -days 365 -in $CERT-csr.pem -CA $CA_NAME-crt.pem -CAkey $CA_NAME-key.pem -CAcreateserial -out $CERT-crt.pem
The initial command (genrsa) generates public and private keys. The third command’s final product, server-crt.pem, is used along with the private key to run ssh in express.

Set up https
To start, your express app must be running https, so you’ll need to have (or generate) a public and private key for that. Here is an example of how to set that up:



var express = require('express');
var fs = require('fs');
var https = require('https');
var app = express();
var options = {
    key: fs.readFileSync('certs/server-key.pem'),
    cert: fs.readFileSync('certs/server-crt.pem'),
};
app.use(function (req, res, next) {
    res.writeHead(200);
    res.end("hello world\n");
    next();
});
var listener = https.createServer(options, app).listen(4433, function () {
    console.log('Express HTTPS server listening on port ' + listener.address().port);
});
Test https

$ node app
Express HTTPS server listening on port 4433
Test using curl in another window. Note that we use -k to bypass certificate validation.

$ curl https://127.0.0.1:4433 -k
hello world
Set up client authentication
Once you have ssh cooperating, you can add client auth. requestCert will require the client (e.g. curl, browser) to send a cert. rejectUnauthorized=false allows us to handle validation ourselves.

If you’re using a browser,

You’ll notice that now we have the client auth certificate. If this was created as a CA, then ANY certificate which is signed by this one will validate.

var options = {
    key: fs.readFileSync('certs/server-key.pem'),
    cert: fs.readFileSync('certs/server-crt.pem'),
    ca: fs.readFileSync('certs/ca.pem'), #client auth ca OR cert
    requestCert: true,                   #new
    rejectUnauthorized: false            #new
};
Here’s how we handle the validation:

app.use(function (req, res, next) {
   if (!req.client.authorized) {
       return res.status(401).send('User is not authorized');
   }
   #examine the cert itself, and even validate based on that!
   var cert = req.socket.getPeerCertificate();
   if (cert.subject) {
       console.log(cert.subject.CN);
   }
   next();
});
Test client authentication
# Access the site using the client certificate created above.
curl -v -s -k --key certs/client1-key.pem --cert certs/client1-crt.pem https://localhost:4433
Test client authentication with a browser
Add the client pfx file to your certificate store. If you’re using a newly created CA, you might need to add its pfx as well. If you’re not presented with a dialog box in step 3, this is likely the problem.
Browse to https://localhost:4433.
You should be presented with a dialog box. Choose the client certificate.
Note that if you change the certificate, you will need to completely close Chrome (and possibly need to kill the task) in order to see the dialog again.

id=__nodejs_client_certificate_authentication__
            1.10.6.3 My example
/Users/i500695/work/code/nodejs/net/x509server

id=__prepare_x509_certs_node__
                1.10.6.3.1 Prepare certificates
All passwords. 1234
- server side

    -- server ca pvk+certificate 
    openssl req -new -x509 -days 365 -keyout server-ca-key.pem -out server-ca-crt.pem

    -- instead of answering prompts can use cnf. ex
    $ cat server.cnf 
[ req ]
default_bits           = 4096
days                   = 9999
distinguished_name     = req_distinguished_name
attributes             = req_attributes
prompt                 = no
x509_extensions        = v3_ca

[ req_distinguished_name ]
C                      = US
ST                     = VA
L                      = Herndon
O                      = Mycorp Inc
OU                     = devops
CN                     = localhost
emailAddress           = administrator@mycorp.com

[ req_attributes ]
challengePassword      = password

[ v3_ca ]
authorityInfoAccess = @issuer_info

[ issuer_info ]
OCSP;URI.0 = http://ocsp.example.com/
caIssuers;URI.0 = http://example.com/ca.cert


    -- create a signed server certificate
export CERT=server
export CA_NAME=server-ca
#generating private key for server
openssl genrsa -out $CERT-key.pem 4096
#generate a signing request
openssl req -new -sha256 -config $CERT.cnf -key $CERT-key.pem -out $CERT-csr.pem
#perform the signing
openssl x509 -req -days 365 -in $CERT-csr.pem -CA $CA_NAME-crt.pem -CAkey $CA_NAME-key.pem -CAcreateserial -out $CERT-crt.pem

    -- 
-client side
    -- client ca pvk+certificate 
    openssl req -new -x509 -days 365 -keyout client-ca-key.pem -out client-ca-crt.pem

    -- instead of answering prompts can use cnf. ex
    $ cat client.cnf 
[ req ]
default_bits           = 4096
days                   = 9999
distinguished_name     = req_distinguished_name
attributes             = req_attributes
prompt                 = no
x509_extensions        = v3_ca

[ req_distinguished_name ]
C                      = US
ST                     = VA
L                      = Yosi
O                      = SAP
OU                     = dev
CN                     = localhost
emailAddress           = yosi.izaq@sap.com

[ req_attributes ]
challengePassword      = 1234

[ v3_ca ]
authorityInfoAccess = @issuer_info

[ issuer_info ]
OCSP;URI.0 = http://ocsp.example.com/
caIssuers;URI.0 = http://example.com/ca.cert


    -- create a signed client certificate
export CERT=client
export CA_NAME=client-ca
#generating private key for client
openssl genrsa -out $CERT-key.pem 4096
#generate a signing request
openssl req -new -sha256 -config $CERT.cnf -key $CERT-key.pem -out $CERT-csr.pem
#perform the signing
openssl x509 -req -days 365 -in $CERT-csr.pem -CA $CA_NAME-crt.pem -CAkey $CA_NAME-key.pem -CAcreateserial -out $CERT-crt.pem

package to pfx
openssl pkcs12 -export -in client-crt.pem -inkey client-key.pem -out client-crt.pfx
                1.10.6.3.2 setup node server app

-- w/o client cert atn
$ cat app.js 
const express = require('express');
const fs = require('fs');
const https = require('https');
const app = express();
const options = {
    key: fs.readFileSync('x509/server-key.pem'),
    cert: fs.readFileSync('x509/server-crt.pem'),
};
app.use(function (req, res, next) {
    res.writeHead(200);
    res.end("hello world\n");
    next();
});
var listener = https.createServer(options, app).listen(4433, function () {
    console.log('Express HTTPS server listening on port ' + listener.address().port);
});
-- $ node app.js 
Express HTTPS server listening on port 4433

-- $ curl https://127.0.0.1:4433 -k
hello world

-- Now add certificate authentication
$ cat app.js 
const express = require('express');
const fs = require('fs');
const https = require('https');
const app = express();
const options = {
    key: fs.readFileSync('x509/server-key.pem'),
    cert: fs.readFileSync('x509/server-crt.pem'),
    ca: fs.readFileSync('x509/client-ca-crt.pem'),
    requestCert: true,
    rejectUnauthorized: false,
};
app.use(function (req, res, next) {
    if (! req.client.authorized) {
        return res.status(401).send('User is not authorized');
    }
    const cert = req.socket.getPeerCertificate();
    if (cert.subject) {
        console.log('cert subject', cert.subject.CN);
        console.log(JSON.stringify(cert, null, 4));
    }
    res.writeHead(200);
    res.end("hello world\n");
    next();
});
var listener = https.createServer(options, app).listen(4433, function () {
    console.log('Express HTTPS server listening on port ' + listener.address().port);
});

$ node app.js 
Express HTTPS server listening on port 4433
cert subject localhost




                1.10.6.3.3 client

                    1.10.6.3.3.1 curl x509 client


-- $ curl -v -s -k --key x509/client-key.pem --cert x509/client-crt.pem https://localhost:4433
*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 4433 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* successfully set certificate verify locations:
*   CAfile: /etc/ssl/cert.pem
  CApath: none
* TLSv1.2 (OUT), TLS handshake, Client hello (1):
* TLSv1.2 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Request CERT (13):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Certificate (11):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS handshake, CERT verify (15):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256
* ALPN, server accepted to use http/1.1
* Server certificate:
*  subject: C=US; ST=VA; L=Herndon; O=Mycorp Inc; OU=devops; CN=localhost; emailAddress=administrator@mycorp.com
*  start date: Jan 26 15:53:42 2021 GMT
*  expire date: Jan 26 15:53:42 2022 GMT
*  issuer: C=IL; ST=Some-State; L=Hadera; O=SAP; CN=server ca; emailAddress=yosi.izaq@sap.com
*  SSL certificate verify result: unable to get local issuer certificate (20), continuing anyway.
> GET / HTTP/1.1
> Host: localhost:4433
> User-Agent: curl/7.64.1
> Accept: */*
> 
< HTTP/1.1 200 OK
< X-Powered-By: Express
< Date: Wed, 27 Jan 2021 09:35:01 GMT
< Connection: keep-alive
< Keep-Alive: timeout=5
< Transfer-Encoding: chunked
< 
hello world
* Connection #0 to host localhost left intact
* Closing connection 0

                    1.10.6.3.3.2 ssl x509 client (only connect, no http request)
openssl s_client -CAfile x509/server-ca-crt.pem -cert x509/client-crt.pem -key x509/client-key.pem -connect localhost:4433 < /dev/null

                    1.10.6.3.3.3  axios x509 client
[i500695@C02X632CJGH6:2021-02-01 17:15:05:~/work/code/nodejs/net/x509server:]2007$ cat axio_client.js | pbcopy
const fs = require('fs');
const https = require('https');
const axios = require('axios');

// https://nodejs.org/api/https.html#https_https_request_options_callback...
const httpsAgent = new https.Agent({
    cert: fs.readFileSync(__dirname + '/x509/client-crt.pem'),
    key: fs.readFileSync(__dirname + '/x509/client-key.pem'),
    rejectUnauthorized: false, // required to prevent UNABLE_TO_VERIFY_LEAF_SIGNATURE error
    passphrase: '1234',
    // pfx: fs.readFileSync(__dirname + '/x509/client-crt.pfx'),
    // ca: [fs.readFileSync(__dirname + '/x509/server-ca-crt.pem')],
    // maxVersion: 'TLSv1.3',
    // minVersion: 'TLSv1.3',
     ca: fs.readFileSync('x509/server-ca-crt.pem'),
});
axios.get('https://localhost:4433', { httpsAgent }).then((response) => {
    console.log(response.data);
}, (error) => {
    console.log(error.code);
});

node axio_client.js
hello world
                    1.10.6.3.3.4 request x509 client
$ cat client.js | pbcopy
'use strict';

const request = require('request');
const fs = require('fs');

var options = {
    // rejectUnauthorized: false, // required to prevent UNABLE_TO_VERIFY_LEAF_SIGNATURE error, if the server CA is ok it is not required
    method: "GET",
    url: 'https://localhost:4433',
    headers: {
        "content-type": "application/json",
    },
    agentOptions: {
        // either client cert+pvk or pfx...
        cert: fs.readFileSync(__dirname + '/x509/client-crt.pem'),
        key: fs.readFileSync(__dirname + '/x509/client-key.pem'),
        // pfx: fs.readFileSync(__dirname + '/x509/client-crt.pfx'),

        passphrase: '1234',
        ca: [fs.readFileSync(__dirname + '/x509/server-ca-crt.pem')],
    }
};

request.get(options, (error, response, body) => {
    // console.log(error);
    // console.log(response);
    console.log(body);
});

$ node client.js
hello world

  

                    1.10.6.3.3.5 capture 
$ tcpdump -i lo0 -s 0 -w x509.pcap
open pcap:

                    1.10.6.3.3.6
                1.10.6.3.4 Troubelshooting guide
https://levelup.gitconnected.com/how-to-resolve-certificate-errors-in-nodejs-app-involving-ssl-calls-781ce48daded

                1.10.6.3.5


            1.10.6.4 Client side certificate based authentication

                1.10.6.4.1  axios, Client side certificate based authentication
https://stackoverflow.com/questions/46894187/nodejs-request-to-a-web-service-with-p12-certificate
https://smallstep.com/hello-mtls/doc/client/axios

                    1.10.6.4.1.1   Examples
a. send cert+key+ca separately
const fs = require('fs');
const https = require('https');
const axios = require('axios');

// https://nodejs.org/api/https.html#https_https_request_options_callback...
const httpsAgent = new https.Agent({
  cert: fs.readFileSync('client.crt'),
  key: fs.readFileSync('client.key'),
  ca: fs.readFileSync('ca.crt'),
});

const result = await axios.get('https://myserver.internal.net:443', { httpsAgent });
// do something with the result

b.  send cert+key+ca as pkcs pfx
'use strict';

const request = require('request');
const fs = require('fs');

var options = {
    url: 'https://some-url/api',
    headers: {
        "content-type": "application/json",
    },
    agentOptions: {
        pfx: fs.readFileSync(__dirname + '/certs/myCert.p12'),
        passphrase: ''
    }
};

request.get(options, (error, response, body) => {
    console.log(error);
    console.log(response);
    console.log(body);
});

c.

                    1.10.6.4.1.2


                1.10.6.4.2 https agent
https://nodejs.org/api/https.html#https_https_request_options_callback

looks like pfx is supported. see
- server side
const https = require('https');
const fs = require('fs');

const options = {
  pfx: fs.readFileSync('test/fixtures/test_cert.pfx'),
  passphrase: 'sample'
};

https.createServer(options, (req, res) => {
  res.writeHead(200);
  res.end('hello world\n');
}).listen(8000);

- client side

-
                1.10.6.4.3

            1.10.6.5 DER files

                1.10.6.5.1 read, write, compare DER certificate files
[i500695@C02X632CJGH6:2021-02-16 16:01:30:~/work/code/nodejs/net/x509server:]2035$ cat DER_read_write.js 
const fs = require('fs');

const derBinary = fs.readFileSync(__dirname + '/x509/server-ca-crt.der');
console.log('Read DER in binary format. lenght', derBinary.length);

fs.writeFileSync(__dirname + '/x509/server-ca-crt2.der', derBinary);
const der2Binary = fs.readFileSync(__dirname + '/x509/server-ca-crt2.der');

function compare_buffers(b1, b2) {
    if (b1.length !== b2.length) {
        return false;
    }

    for (let index = 0; index < b1.length; index++) {
        if (b1[index] !== b2[index]) {
            return false;
        } 
    }
    return true 
}

const same = compare_buffers(der2Binary, derBinary);
console.log(`It is ${same} that input and output DER files are equal`);



[i500695@C02X632CJGH6:2021-02-16 16:01:39:~/work/code/nodejs/net/x509server:]2036$ node DER_read_write.js 
Read DER in binary format. lenght 979
It is true that input and output DER files are equal
                1.10.6.5.2

            1.10.6.6
        1.10.7


    1.11 Express
Express Overview
Express is a minimal and flexible Node.js web application framework that provides a robust set of features to develop web and mobile applications. It facilitates the rapid development of Node based Web applications. Following are some of the core features of Express framework −

Allows to set up middlewares to respond to HTTP Requests.

Defines a routing table which is used to perform different actions based on HTTP Method and URL.

Allows to dynamically render HTML Pages based on passing arguments to templates.

Installing Express
Firstly, install the Express framework globally using NPM so that it can be used to create a web application using node terminal.

$ npm install express --save
The above command saves the installation locally in the node_modules directory and creates a directory express inside node_modules. You should install the following important modules along with express −

body-parser − This is a node.js middleware for handling JSON, Raw, Text and URL encoded form data.

cookie-parser − Parse Cookie header and populate req.cookies with an object keyed by the cookie names.

multer − This is a node.js middleware for handling multipart/form-data.

$ npm install body-parser --save
$ npm install cookie-parser --save
$ npm install multer --save
one command:
$ npm install body-parser --save && npm install cookie-parser --save && npm install multer --save

Hello world Example
Following is a very basic Express app which starts a server and listens on port 8081 for connection. This app responds with Hello World! for requests to the homepage. For every other path, it will respond with a 404 Not Found.

var express = require('express');
var app = express();

app.get('/', function (req, res) {
   res.send('Hello World');
})

var server = app.listen(8081, function () {
   var host = server.address().address
   var port = server.address().port
   
   console.log("Example app listening at http://%s:%s", host, port)
})
Save the above code in a file named server.js and run it with the following command.

$ node server.js
You will see the following output −

Example app listening at http://0.0.0.0:8081
Open http://127.0.0.1:8081/ in any browser to see the following result.

First Application
Request & Response
Express application uses a callback function whose parameters are request and response objects.

app.get('/', function (req, res) {
   // --
})
Request Object − The request object represents the HTTP request and has properties for the request query string, parameters, body, HTTP headers, and so on.

Response Object − The response object represents the HTTP response that an Express app sends when it gets an HTTP request.

You can print req and res objects which provide a lot of information related to HTTP request and response including cookies, sessions, URL, etc.

Basic Routing
We have seen a basic application which serves HTTP request for the homepage. Routing refers to determining how an application responds to a client request to a particular endpoint, which is a URI (or path) and a specific HTTP request method (GET, POST, and so on).

We will extend our Hello World program to handle more types of HTTP requests.

var express = require('express');
var app = express();

// This responds with "Hello World" on the homepage
app.get('/', function (req, res) {
   console.log("Got a GET request for the homepage");
   res.send('Hello GET');
})

// This responds a POST request for the homepage
app.post('/', function (req, res) {
   console.log("Got a POST request for the homepage");
   res.send('Hello POST');
})

// This responds a DELETE request for the /del_user page.
app.delete('/del_user', function (req, res) {
   console.log("Got a DELETE request for /del_user");
   res.send('Hello DELETE');
})

// This responds a GET request for the /list_user page.
app.get('/list_user', function (req, res) {
   console.log("Got a GET request for /list_user");
   res.send('Page Listing');
})

// This responds a GET request for abcd, abxcd, ab123cd, and so on
app.get('/ab*cd', function(req, res) {   
   console.log("Got a GET request for /ab*cd");
   res.send('Page Pattern Match');
})

var server = app.listen(8081, function () {

   var host = server.address().address
   var port = server.address().port

   console.log("Example app listening at http://%s:%s", host, port)
})
Save the above code in a file named server.js and run it with the following command.

$ node server.js
You will see the following output −

Example app listening at http://0.0.0.0:8081
Now you can try different requests at http://127.0.0.1:8081 to see the output generated by server.js. Following are a few screens shots showing different responses for different URLs.

Screen showing again http://127.0.0.1:8081/list_user

Second Application
Screen showing again http://127.0.0.1:8081/abcd

Third Application
Screen showing again http://127.0.0.1:8081/abcdefg

Fourth Application
Serving Static Files
Express provides a built-in middleware express.static to serve static files, such as images, CSS, JavaScript, etc.

You simply need to pass the name of the directory where you keep your static assets, to the express.static middleware to start serving the files directly. For example, if you keep your images, CSS, and JavaScript files in a directory named public, you can do this −

app.use(express.static('public'));
We will keep a few images in public/images sub-directory as follows −

node_modules
server.js
public/
public/images
public/images/logo.png
Let's modify "Hello Word" app to add the functionality to handle static files.

var express = require('express');
var app = express();

app.use(express.static('public'));

app.get('/', function (req, res) {
   res.send('Hello World');
})

var server = app.listen(8081, function () {
   var host = server.address().address
   var port = server.address().port

   console.log("Example app listening at http://%s:%s", host, port)

})
Save the above code in a file named server.js and run it with the following command.

$ node server.js
Now open http://127.0.0.1:8081/images/logo.png in any browser and see observe following result.

Fifth Application
GET Method
Here is a simple example which passes two values using HTML FORM GET method. We are going to use process_get router inside server.js to handle this input.

<html>
   <body>
      
      <form action = "http://127.0.0.1:8081/process_get" method = "GET">
         First Name: <input type = "text" name = "first_name">  <br>
         Last Name: <input type = "text" name = "last_name">
         <input type = "submit" value = "Submit">
      </form>
      
   </body>
</html>
Let's save above code in index.htm and modify server.js to handle home page requests as well as the input sent by the HTML form.

var express = require('express');
var app = express();

app.use(express.static('public'));
app.get('/index.htm', function (req, res) {
   res.sendFile( __dirname + "/" + "index.html" );
})

app.get('/process_get', function (req, res) {
   // Prepare output in JSON format
   response = {
      first_name:req.query.first_name,
      last_name:req.query.last_name
   };
   console.log(response);
   res.end(JSON.stringify(response));
})

var server = app.listen(8081, function () {
   var host = server.address().address
   var port = server.address().port
   console.log("Example app listening at http://%s:%s", host, port)

})
Accessing the HTML document using http://127.0.0.1:8081/index.htm will generate the following form −


First Name:	
Last Name:	



Now you can enter the First and Last Name and then click submit button to see the result and it should return the following result −

{"first_name":"John","last_name":"Paul"}
POST Method
Here is a simple example which passes two values using HTML FORM POST method. We are going to use process_get router inside server.js to handle this input.

<html>
   <body>
      
      <form action = "http://127.0.0.1:8081/process_post" method = "POST">
         First Name: <input type = "text" name = "first_name"> <br>
         Last Name: <input type = "text" name = "last_name">
         <input type = "submit" value = "Submit">
      </form>
      
   </body>
</html>
Let's save the above code in index.htm and modify server.js to handle home page requests as well as the input sent by the HTML form.

var express = require('express');
var app = express();
var bodyParser = require('body-parser');

// Create application/x-www-form-urlencoded parser
var urlencodedParser = bodyParser.urlencoded({ extended: false })

app.use(express.static('public'));
app.get('/index.htm', function (req, res) {
   res.sendFile( __dirname + "/" + "index.htm" );
})

app.post('/process_post', urlencodedParser, function (req, res) {
   // Prepare output in JSON format
   response = {
      first_name:req.body.first_name,
      last_name:req.body.last_name
   };
   console.log(response);
   res.end(JSON.stringify(response));
})

var server = app.listen(8081, function () {
   var host = server.address().address
   var port = server.address().port
   
   console.log("Example app listening at http://%s:%s", host, port)

})
Accessing the HTML document using http://127.0.0.1:8081/index.htm will generate the following form −


First Name:	
Last Name:	



Now you can enter the First and Last Name and then click the submit button to see the following result −

{"first_name":"John","last_name":"Paul"}
File Upload
The following HTML code creates a file uploader form. This form has method attribute set to POST and enctype attribute is set to multipart/form-data

<html>
   <head>
      <title>File Uploading Form</title>
   </head>

   <body>
      <h3>File Upload:</h3>
      Select a file to upload: <br />
      
      <form action = "http://127.0.0.1:8081/file_upload" method = "POST" 
         enctype = "multipart/form-data">
         <input type="file" name="file" size="50" />
         <br />
         <input type = "submit" value = "Upload File" />
      </form>
      
   </body>
</html>
Let's save above code in index.htm and modify server.js to handle home page requests as well as file upload.

var express = require('express');
var app = express();
var fs = require("fs");

var bodyParser = require('body-parser');
var multer  = require('multer');

app.use(express.static('public'));
app.use(bodyParser.urlencoded({ extended: false }));
app.use(multer({ dest: '/tmp/'}));

app.get('/index.htm', function (req, res) {
   res.sendFile( __dirname + "/" + "index.htm" );
})

app.post('/file_upload', function (req, res) {
   console.log(req.files.file.name);
   console.log(req.files.file.path);
   console.log(req.files.file.type);
   var file = __dirname + "/" + req.files.file.name;
   
   fs.readFile( req.files.file.path, function (err, data) {
      fs.writeFile(file, data, function (err) {
         if( err ){
            console.log( err );
            }else{
               response = {
                  message:'File uploaded successfully',
                  filename:req.files.file.name
               };
            }
         console.log( response );
         res.end( JSON.stringify( response ) );
      });
   });
})

var server = app.listen(8081, function () {
   var host = server.address().address
   var port = server.address().port
   
   console.log("Example app listening at http://%s:%s", host, port)
})
Accessing the HTML document using http://127.0.0.1:8081/index.htm will generate the following form −

File Upload:
Select a file to upload: 





NOTE: This is just dummy form and would not work, but it must work at your server.
Cookies Management
You can send cookies to a Node.js server which can handle the same using the following middleware option. Following is a simple example to print all the cookies sent by the client.

var express      = require('express')
var cookieParser = require('cookie-parser')

var app = express()
app.use(cookieParser())

app.get('/', function(req, res) {
   console.log("Cookies: ", req.cookies)
})
app.listen(8081)

    1.12 RESTful API



What is REST architecture?
REST stands for REpresentational State Transfer. REST is web standards based architecture and uses HTTP Protocol. It revolves around resource where every component is a resource and a resource is accessed by a common interface using HTTP standard methods. REST was first introduced by Roy Fielding in 2000.

A REST Server simply provides access to resources and REST client accesses and modifies the resources using HTTP protocol. Here each resource is identified by URIs/ global IDs. REST uses various representation to represent a resource like text, JSON, XML but JSON is the most popular one.

HTTP methods
Following four HTTP methods are commonly used in REST based architecture.

GET - This is used to provide a read only access to a resource.

PUT - This is used to create a new resource.

DELETE - This is used to remove a resource.

POST - This is used to update a existing resource or create a new resource.

RESTful Web Services
A web service is a collection of open protocols and standards used for exchanging data between applications or systems. Software applications written in various programming languages and running on various platforms can use web services to exchange data over computer networks like the Internet in a manner similar to inter-process communication on a single computer. This interoperability (e.g., communication between Java and Python, or Windows and Linux applications) is due to the use of open standards.

Web services based on REST Architecture are known as RESTful web services. These webservices uses HTTP methods to implement the concept of REST architecture. A RESTful web service usually defines a URI, Uniform Resource Identifier a service, which provides resource representation such as JSON and set of HTTP Methods.

Creating RESTful for A Library
Consider we have a JSON based database of users having the following users in a file users.json:

{
   "user1" : {
      "name" : "mahesh",
	  "password" : "password1",
	  "profession" : "teacher",
	  "id": 1
   },
   "user2" : {
      "name" : "suresh",
	  "password" : "password2",
	  "profession" : "librarian",
	  "id": 2
   },
   "user3" : {
      "name" : "ramesh",
	  "password" : "password3",
	  "profession" : "clerk",
	  "id": 3
   }
}
Based on this information we are going to provide following RESTful APIs.

S. N.	URI	HTTP Method	POST body	Result
1	listUsers	GET	empty	Show list of all the users.
2	addUser	POST	JSON String	Add details of new user.
3	deleteUser	DELETE	JSON String	Delete an existing user.
4	:id	GET	empty	Show details of a user.
I'm keeping most of the part of all the examples in the form of hard coding assuming you already know how to pass values from front end using Ajax or simple form data and how to process them using express Request object.

List Users
Let's implement our first RESTful API listUsers using the following code in a server.js file:

server.js
var express = require('express');
var app = express();
var fs = require("fs");

app.get('/listUsers', function (req, res) {
   fs.readFile( __dirname + "/" + "users.json", 'utf8', function (err, data) {
       console.log( data );
       res.end( data );
   });
})

var server = app.listen(8081, function () {

  var host = server.address().address
  var port = server.address().port

  console.log("Example app listening at http://%s:%s", host, port)

})
Now try to access defined API using URL: http://127.0.0.1:8081/listUsers and HTTP Method : GET on local machine using any REST client. This should produce following result:

You can change given IP address when you will put the solution in production environment.

{
   "user1" : {
      "name" : "mahesh",
      "password" : "password1",
      "profession" : "teacher",
      "id": 1
   },
   "user2" : {
      "name" : "suresh",
      "password" : "password2",
      "profession" : "librarian",
      "id": 2
   },
   "user3" : {
      "name" : "ramesh",
      "password" : "password3",
      "profession" : "clerk",
      "id": 3
   }
}
Add User
Following API will show you how to add new user in the list. Following is the detail of the new user:

user = {
   "user4" : {
      "name" : "mohit",
      "password" : "password4",
      "profession" : "teacher",
      "id": 4
   }
}
You can accept the same input in the form of JSON using Ajax call but for teaching point of view, we are making it hard coded here. Following is the addUser API to a new user in the database:

server.js
var express = require('express');
var app = express();
var fs = require("fs");

var user = {
   "user4" : {
      "name" : "mohit",
      "password" : "password4",
      "profession" : "teacher",
      "id": 4
   }
}

app.post('/addUser', function (req, res) {
   // First read existing users.
   fs.readFile( __dirname + "/" + "users.json", 'utf8', function (err, data) {
       data = JSON.parse( data );
       data["user4"] = user["user4"];
       console.log( data );
       res.end( JSON.stringify(data));
   });
})

var server = app.listen(8081, function () {

  var host = server.address().address
  var port = server.address().port
  console.log("Example app listening at http://%s:%s", host, port)

})
Now try to access defined API using URL: http://127.0.0.1:8081/addUser and HTTP Method : POST on local machine using any REST client. This should produce following result:

{
"user1":{"name":"mahesh","password":"password1","profession":"teacher","id":1},
"user2":{"name":"suresh","password":"password2","profession":"librarian","id":2},
"user3":{"name":"ramesh","password":"password3","profession":"clerk","id":3},
"user4":{"name":"mohit","password":"password4","profession":"teacher","id":4}
}
Show Detail
Now we will implement an API which will be called using user ID and it will display the detail of the corresponding user.

server.js
var express = require('express');
var app = express();
var fs = require("fs");

app.get('/:id', function (req, res) {
   // First read existing users.
   fs.readFile( __dirname + "/" + "users.json", 'utf8', function (err, data) {
      var users = JSON.parse( data );
      var user = users["user" + req.params.id] 
      console.log( user );
      res.end( JSON.stringify(user));
   });
})

var server = app.listen(8081, function () {

   var host = server.address().address
   var port = server.address().port
   console.log("Example app listening at http://%s:%s", host, port)

})
Now try to access defined API using URL: http://127.0.0.1:8081/2 and HTTP Method : GET on local machine using any REST client. This should produce following result:

{"name":"suresh","password":"password2","profession":"librarian","id":2}
Delete User
This API is very similar to addUser API where we receive input data through req.body and then based on user ID we delete that user from the database. To keep our program simple we assume we are going to delete user with ID 2.

server.js
var express = require('express');
var app = express();
var fs = require("fs");

var id = 2;

app.delete('/deleteUser', function (req, res) {

   // First read existing users.
   fs.readFile( __dirname + "/" + "users.json", 'utf8', function (err, data) {
       data = JSON.parse( data );
       delete data["user" + 2];
       
       console.log( data );
       res.end( JSON.stringify(data));
   });
})

var server = app.listen(8081, function () {

  var host = server.address().address
  var port = server.address().port
  console.log("Example app listening at http://%s:%s", host, port)

})
Now try to access defined API using URL: http://127.0.0.1:8081/deleteUser and HTTP Method : DELETE on local machine using any REST client. This should produce following result:

{"user1":{"name":"mahesh","password":"password1","profession":"teacher","id":1},
"user3":{"name":"ramesh","password":"password3","profession":"clerk","id":3}}


    1.13 Spawning processes
Node.js runs in a single-thread mode, but it uses an event-driven paradigm to handle concurrency. It also facilitates creation of child processes to leverage parallel processing on multi-core CPU based systems.

Child processes always have three streams child.stdin, child.stdout, and child.stderr which may be shared with the stdio streams of the parent process.

Node provides child_process module which has the following three major ways to create a child process.

exec − child_process.exec method runs a command in a shell/console and buffers the output.

spawn − child_process.spawn launches a new process with a given command.

fork − The child_process.fork method is a special case of the spawn() to create child processes.

The exec() method
child_process.exec method runs a command in a shell and buffers the output. It has the following signature −

child_process.exec(command[, options], callback)
Parameters
Here is the description of the parameters used −

command (String) The command to run, with space-separated arguments

options (Object) may comprise one or more of the following options −

cwd (String) Current working directory of the child process

env (Object) Environment key-value pairs

encoding (String) (Default: 'utf8')

shell (String) Shell to execute the command with (Default: '/bin/sh' on UNIX, 'cmd.exe' on Windows, The shell should understand the -c switch on UNIX or /s /c on Windows. On Windows, command line parsing should be compatible with cmd.exe.)

timeout (Number) (Default: 0)

maxBuffer (Number) (Default: 200*1024)

killSignal (String) (Default: 'SIGTERM')

uid (Number) Sets the user identity of the process.

gid (Number) Sets the group identity of the process.

callback The function gets three arguments error, stdout, and stderr which are called with the output when the process terminates.

The exec() method returns a buffer with a max size and waits for the process to end and tries to return all the buffered data at once.

Example
Let us create two js files named support.js and master.js −

File: support.js

console.log("Child Process " + process.argv[2] + " executed." );
File: master.js

const fs = require('fs');
const child_process = require('child_process');

for(var i=0; i<3; i++) {
   var workerProcess = child_process.exec('node support.js '+i,function 
      (error, stdout, stderr) {
      
      if (error) {
         console.log(error.stack);
         console.log('Error code: '+error.code);
         console.log('Signal received: '+error.signal);
      }
      console.log('stdout: ' + stdout);
      console.log('stderr: ' + stderr);
   });

   workerProcess.on('exit', function (code) {
      console.log('Child process exited with exit code '+code);
   });
}
Now run the master.js to see the result −

$ node master.js
Verify the Output. Server has started.

Child process exited with exit code 0
stdout: Child Process 1 executed.

stderr:
Child process exited with exit code 0
stdout: Child Process 0 executed.

stderr:
Child process exited with exit code 0
stdout: Child Process 2 executed.
The spawn() Method
child_process.spawn method launches a new process with a given command. It has the following signature −

child_process.spawn(command[, args][, options])
Parameters
Here is the description of the parameters used −

command (String) The command to run

args (Array) List of string arguments

options (Object) may comprise one or more of the following options −

cwd (String) Current working directory of the child process.

env (Object) Environment key-value pairs.

stdio (Array) String Child's stdio configuration.

customFds (Array) Deprecated File descriptors for the child to use for stdio.

detached (Boolean) The child will be a process group leader.

uid (Number) Sets the user identity of the process.

gid (Number) Sets the group identity of the process.

The spawn() method returns streams (stdout &stderr) and it should be used when the process returns a volume amount of data. spawn() starts receiving the response as soon as the process starts executing.

Example
Create two js files named support.js and master.js −

File: support.js

console.log("Child Process " + process.argv[2] + " executed." );
File: master.js

const fs = require('fs');
const child_process = require('child_process');
 
for(var i = 0; i<3; i++) {
   var workerProcess = child_process.spawn('node', ['support.js', i]);

   workerProcess.stdout.on('data', function (data) {
      console.log('stdout: ' + data);
   });

   workerProcess.stderr.on('data', function (data) {
      console.log('stderr: ' + data);
   });

   workerProcess.on('close', function (code) {
      console.log('child process exited with code ' + code);
   });
}
Now run the master.js to see the result −

$ node master.js
Verify the Output. Server has started

stdout: Child Process 0 executed.

child process exited with code 0
stdout: Child Process 1 executed.

stdout: Child Process 2 executed.

child process exited with code 0
child process exited with code 0
The fork() Method
child_process.fork method is a special case of spawn() to create Node processes. It has the following signature −

child_process.fork(modulePath[, args][, options])
Parameters
Here is the description of the parameters used −

modulePath (String) The module to run in the child.

args (Array) List of string arguments

options (Object) may comprise one or more of the following options −

cwd (String) Current working directory of the child process.

env (Object) Environment key-value pairs.

execPath (String) Executable used to create the child process.

execArgv (Array) List of string arguments passed to the executable (Default: process.execArgv).

silent (Boolean) If true, stdin, stdout, and stderr of the child will be piped to the parent, otherwise they will be inherited from the parent, see the "pipe" and "inherit" options for spawn()'s stdio for more details (default is false).

uid (Number) Sets the user identity of the process.

gid (Number) Sets the group identity of the process.

The fork method returns an object with a built-in communication channel in addition to having all the methods in a normal ChildProcess instance.

Example
Create two js files named support.js and master.js −

File: support.js

console.log("Child Process " + process.argv[2] + " executed." );
File: master.js

const fs = require('fs');
const child_process = require('child_process');
 
for(var i=0; i<3; i++) {
   var worker_process = child_process.fork("support.js", [i]);	

   worker_process.on('close', function (code) {
      console.log('child process exited with code ' + code);
   });
}
Now run the master.js to see the result −

$ node master.js
Verify the Output. Server has started.

Child Process 0 executed.
Child Process 1 executed.
Child Process 2 executed.
child process exited with code 0
child process exited with code 0
child process exited with code 0


    1.14 nodejs packaging, JXcore
JXcore, which is an open source project, introduces a unique feature for packaging and encryption of source files and other assets into JX packages.

Consider you have a large project consisting of many files. JXcore can pack them all into a single file to simplify the distribution. This chapter provides a quick overview of the whole process starting from installing JXcore.

JXcore Installation
Installing JXcore is quite simple. Here we have provided step-by-step instructions on how to install JXcore on your system. Follow the steps given below −

Step 1
Download the JXcore package from https://github.com/jxcore/jxcore, as per your operating system and machine architecture. We downloaded a package for Cenots running on 64-bit machine.

$ wget https://s3.amazonaws.com/nodejx/jx_rh64.zip
Step 2
Unpack the downloaded file jx_rh64.zipand copy the jx binary into /usr/bin or may be in any other directory based on your system setup.

$ unzip jx_rh64.zip
$ cp jx_rh64/jx /usr/bin
Step 3
Set your PATH variable appropriately to run jx from anywhere you like.

$ export PATH=$PATH:/usr/bin
Step 4
You can verify your installation by issuing a simple command as shown below. You should find it working and printing its version number as follows −

$ jx --version
v0.10.32
Packaging the Code
Consider you have a project with the following directories where you kept all your files including Node.js, main file, index.js, and all the modules installed locally.

drwxr-xr-x  2 root root  4096 Nov 13 12:42 images
-rwxr-xr-x  1 root root 30457 Mar  6 12:19 index.htm
-rwxr-xr-x  1 root root 30452 Mar  1 12:54 index.js
drwxr-xr-x 23 root root  4096 Jan 15 03:48 node_modules
drwxr-xr-x  2 root root  4096 Mar 21 06:10 scripts
drwxr-xr-x  2 root root  4096 Feb 15 11:56 style
To package the above project, you simply need to go inside this directory and issue the following jx command. Assuming index.js is the entry file for your Node.js project −

$ jx package index.js index
Here you could have used any other package name instead of index. We have used index because we wanted to keep our main file name as index.jx. However, the above command will pack everything and will create the following two files −

index.jxp This is an intermediate file which contains the complete project detail needed to compile the project.

index.jx This is the binary file having the complete package that is ready to be shipped to your client or to your production environment.

Launching JX File
Consider your original Node.js project was running as follows −

$ node index.js command_line_arguments
After compiling your package using JXcore, it can be started as follows −

$ jx index.jx command_line_arguments
To know more on JXcore, you can check its official website.



    1.15 promise

        1.15.1 promises basics 

https://www.promisejs.org/
https://developer.ibm.com/node/2016/08/24/promises-in-node-js-an-alternative-to-callbacks/

check my tutorial code:
<url:/Users/i500695/work/code/nodejs/tutorial/promiseDemo.js>
console.log("Starting promise demo");

const fs = require('fs');
const util = require('util');

function readJSONSync(filename){
let fs=require("fs");
        return JSON.parse(fs.readFileSync(filename, 'utf8'));
}

jsonData = readJSONSync("jsonFile");

console.log("Read data synchrounsly, %s ", JSON.stringify(jsonData));

function readJSONCB(filename, cb){
let fs=require("fs");
        fs.readFile(filename, 'utf8', function (err, res){
                if (err) return cb(err);
                cb(null, JSON.parse(res)) ;
        });
}

function printJSON(param1, json){
    console.log("Read data callback, %s ", JSON.stringify(json));
}

readJSONCB("jsonFile", printJSON);

//creating a promise
function readFilePromise(filename, encoding){

        console.log("readFilePromise called for file %s",filename);
        return new Promise( function(fulfill, reject){
                let fs = require("fs");
                fs.readFile(filename, encoding, function(err,res){
                        ////throw error commented code
                        //const errorMsg = new Error("Test error message");
                        //reject(errorMsg);
                        if (err) {

                                reject(err);
                        }
                        else {
                                fulfill(res);
                        }
                });
        });
}

//consuming a Promise
function readFileUsingPromise(filename){
        console.log("readFileUsingPromise called for file %s",filename);
        return readFilePromise(filename,  'utf8').then(function(res){
                console.log("readFileUsingPromise, read: %s", JSON.stringify(JSON.parse(res)));
                return JSON.parse(res);
        })
        .catch(function(err){
                console.log("Caught error %s",err.message);
        })
        ;
}

readFileUsingPromise("jsonFile");


//Manual tests. when lines 33-35 are active
// [i500695@C02X632CJGH6:2018-12-11 10:51:15:~/Desktop/work/code/nodejs/tutorial:]597$ node promiseDemo.js 
// Starting promise demo
// Read data synchrounsly, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise called for file jsonFile
// readFilePromise called for file jsonFile
// Read data callback, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise, read: {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"}
// [i500695@C02X632CJGH6:2018-12-11 10:51:23:~/Desktop/work/code/nodejs/tutorial:]598$ node promiseDemo.js 
// Starting promise demo
// Read data synchrounsly, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise called for file jsonFile
// readFilePromise called for file jsonFile
// Read data callback, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// Caught error Test error message
//
//
let getDateTimeFunc = function getDateTime() {

    var date = new Date();

    var hour = date.getHours();
    hour = (hour < 10 ? "0" : "") + hour;

    var min  = date.getMinutes();
    min = (min < 10 ? "0" : "") + min;

    var sec  = date.getSeconds();
    sec = (sec < 10 ? "0" : "") + sec;

    var year = date.getFullYear();

    var month = date.getMonth() + 1;
    month = (month < 10 ? "0" : "") + month;

    var day  = date.getDate();
    day = (day < 10 ? "0" : "") + day;

    return year + ":" + month + ":" + day + ":" + hour + ":" + min + ":" + sec;

}

console.log("Promise chaining demo");

//let toggle = false; //toggle for resolve / reject
let toggle = true; //toggle for resolve / reject
//1st promise.
let buyPhonePromise = new Promise( function(resove, reject){
        if (toggle){
                let phone = {
                        brand: 'apple',
                        color: 'black',
                        model: 'iphone xr'
                };
                resove(phone);
        } else{
                let error= new Error('too expensive lol');
                reject(error);
        }
});

//2nd promise, note takes 1st promise resolve as argument
let configurePhonePromise = function(phone){
        let message = 'successfully bought and configured new ' + phone.brand + ' phone, ' + phone.color + ' '+   phone.model;
        return Promise.resolve(message);
};

//3rd message, add date to message
let addDatePromise = function(message){
        let rmessage = getDateTimeFunc+' '+message;
        return Promise.resolve(message);
};

//chain promises for consumption
let simBuy = function(){

        buyPhonePromise
        .then(configurePhonePromise)
        .then(addDatePromise)
        .then(function(resolved){
                console.log(resolved);
        })
        .catch(function(reject){
                console.log(reject.message);
        });
};

simBuy();

console.log("Promise chaining demo using ES7 async await");


const buyPhonePromiseAA = new Promise( 
        (resolve, reject) => {
        if (toggle){
                console.log("buying phone...");
                const phone = {
                        brand: 'apple',
                        color: 'black',
                        model: 'iphone xr'
                };
                console.log("resolve phone %o",phone);
                resolve(phone);
        } else{
                console.log("not buying phone...");
                let error= new Error('too expensive lol');
                reject(error);
        }
});

//2nd promise, note takes 1st promise resolve as argument
async function  configurePhonePromiseAA (phone){
        return new Promise(
                (res,rej) => {
        let message = 'Async/Await successfully bought and configured new ' + phone.brand + ' phone, ' + phone.color + ' '+   phone.model;
        res(message);
                }
        );
};

//3rd message, add date to message
async function addDatePromiseAA (message){
        return new Promise(
                (res,jeg) => {
        let rmessage = getDateTimeFunc+' '+message;
        res(message);
                }
        )
};

async function simBuyAA(){

        try{
                console.log("Staring async calls...");
                let phone = await buyPhonePromiseAA;  
                console.log("bought phone %s",phone);
                let message = await configurePhonePromiseAA(phone);
                let rmessage = await addDatePromiseAA(message);
                console.log(rmessage);
                console.log("After async calls...");

        }
        catch (err){
                console.log(err);
        }
};

( async () => {
        await simBuyAA();
})();

console.log('async await syntax (syntactic sugar for promises)');

async function readFileAsync(filename, encoding){
        let fs = require("fs");
        //return fs.readFile(filename, encoding); //-> exception, since core
    //API doesn't support promise syntax. must promisify
        return util.promisify(fs.readFile)(filename, encoding);
}

async function readFileUsingAsyncPromise(filename){
        console.log("readFileUsingAsyncPromise called for file %s",filename);
        let result;
        try {
            result = await readFileAsync(filename, 'utf8');
        } catch (err){
            console.log('readFileUsingAsyncPromise error ', err);
        }
        console.log('file %s content is: %s', filename, result);
        return result;
}

readFileUsingAsyncPromise("jsonFile").then( (content) => {
    console.log('readFileUsingAsyncPromise read ',content);   
});



console.log('async await syntax. promisify wrapper for core api (like fs)');
const readFileAW = util.promisify(fs.readFile);
async function readFileUsingAsyncPromise2(filename){
    return await readFileAW(filename);
}
readFileUsingAsyncPromise2("jsonFile").then( (content) => {
    console.log('readFileUsingAsyncPromise2 read ',content);   
});

console.log('fire multiple promises in paralel and return which have failed');
async function promise1(delayms, msg){
    return new Promise( (res, rej) => { setTimeout( (res,msg) => {console.log(msg); res(msg);} , delayms); } );
}

promise1();

        1.15.2 promise all 

        1.15.3
    1.16 authentication & authorization

        1.16.1  Json Web Token, JWT

            1.16.1.1  web tutorials

                1.16.1.1.1  https://stormpath.com/blog/nodejs-jwt-create-verify
JWT, access token, token, OAuth token.. what does it all mean??

Properly known as “JSON Web Tokens”, JWTs are a fairly new player in the authentication space. Being the cool new thing, everyone is hip to start using them. But are you doing it securely? In this article we’ll discuss user authentication best practices in Node.js using JWTs, while showing you how to use the nJwt library for creating and verifying JWTs in your Node.js application.

What is a JSON Web Token (JWT)?

In a nutshell, a JWT is an object that can tell you things about a user and what they’re allowed to do. JWTs are meant to be issued by a trusted authority and given to a user. Typically this means your server is creating the JWT and sending it to your user’s web browser or mobile device for safe keeping.

JWTs can be digitally signed with a secret key. Doing so allows you to assert that a token was issued by your server and was not maliciously modified.

When the token is signed, it is “stateless”: this means you don’t need any extra information, other than the secret key, to verify that the information in the token is “true”. This great feature allows you to remove that pesky session table in your database.
When Should I Use Them?

JWTs are typically used to replace session identifiers. For example: if you’re using a session system which stores an opaque ID on the client in a cookie while also maintaining session in a database for hat ID. With JWTs you can replace both the session data and the opaque ID.

You’ll still use a cookie to store the access token, but you need to make sure you secure your JWT cookies. For more information on that topic I’ll refer you to my other post, Build Secure User Interfaces Using JSON Web Tokens (JWTs).

With the token stored in a secure cookie, the user’s client will supply the token on every subsequent request to your server. This allows the server to authenticate the request, without having to ask for credentials a second time (until the token expires, that is).
How to Create a JWT

There are a few things you’ll need in order to create a JWT for a user, we’ll walk through each of these steps in detail:

    Generate the secret signing key
    Authenticate the user
    Prepare the claims
    Generate the token
    Send the token to the client

                    1.16.1.1.1.1  Generate the Secret Signing Key

To be secure, we want to sign our tokens with a secret signing key. This key should be kept confidential and only accessible to your server. It should be highly random and not guessable. In our example, we’ll use the node-uuid library to create a random key for us:

var secretKey = uuid.v4();
	
var secretKey = uuid.v4();

                    1.16.1.1.1.2 Authenticate the User

Before we can make claims about the user, we need to know who the user is. So the user needs to make an initial authentication request, typically by logging into your system by presenting a username and password in a form. It could also mean that they’ve presented an API key and secret to your API service, using something like the Authorization: Basic scheme.

In either situation, your server should verity the user’s credentials. After you’ve done this and obtained the user data from your system, you want to create a JWT which will “remember” the information about the user. We’ll put this information into the claims of the token.

                    1.16.1.1.1.3 Prepare The Claims

Now that we have the user data, we want to build the “claims” of the JWT. That will look like this:

var claims = {
  sub: 'user9876',
  iss: 'https://mytrustyapp.com',
  permissions: 'upload-photos'
}
	
var claims = {
  sub: 'user9876',
  iss: 'https://mytrustyapp.com',
  permissions: 'upload-photos'
}

Let’s discuss each of these fields. Technically speaking, you can create a JWT without any claims. But these three fields are the most common:

    sub – This is the “subject” of the token, the person whom it identifies. For this field you should use the opaque user ID from your user management system. Don’t use personally identifiable information, like an email address.

    iss – This is the “issuer” field, and it lets other parties know who created this token. This could be the URL of your website, or something more specific if your website has multiple applications with different user databases.

    permissions – Sometimes you’ll see this as scope if the JWT is being used as an OAuth Bearer Token. This is simply a comma-seperated list of things that the user has access to do.

                    1.16.1.1.1.4 Generate the Token

Now that we have the claims and the signing key, we can create our JWT object:

var jwt = nJwt.create(claims,secretKey);

This will be our internal representation of the token, before we send it to the user. Let’s take a look at what’s inside of it:

console.log(jwt)

You will see an object structure which describes the header and the claims body of the token:

{
  header: {
    typ: 'JWT',
    alg: 'HS256'
  },
  body: {
    jti: '3ee9364e-8aca-4e39-8ba2-74e654c7e083',
    iat: 1434695471,
    exp: 1434699071,
    sub: 'user9876',
    iss: 'https://mytrustyapp.com',
    permissions: 'upload-photos'
  }
}

You’ll see the claims that you specified earlier, and many other properties. These are the secure defaults that our library is setting for you, let’s visit each one in detail:

    alg – This declares how we’ve signed our token, in this case using the Hmac algorithm with a strength of 256 bits. If you want more security, you can bump this up to HS512

    exp – This is the time that the token will expire, as a unix timestamp offset in seconds. By default our library sets this to 1 hour in the future. If you need to change this value, call jwt.setExpiration() and pass a Date object that represents the desired expiration time.

    iat – This is the time that the token was created, as a unix timestamp offset in seconds.

    jti – This is simply a random value, that is created for every JWT. We provide this in case you want to create a database of tokens that were issued. You may do this if you want to implement a token blacklist for tokens that you know have been compromised (i.e. a user tells you their account has been hacked into).

                    1.16.1.1.1.5 Send the Token to the Client

Now that we have the JWT object, we can “compact” it to get the actual token, which will be a Base64 URL-Safe string that can be passed down to the client.

Simply call compact, and then take a look at the result:

var token = jwt.compact();
console.log(token);

What you see will look like this:

eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJqdGkiOiIyYWIzOWRhYS03ZGJhLTQxYTAtODhiYS00NGE2YmIyYjk3YWMiLCJpYXQiOjE0MzQ2OTY4MDEsImV4cCI6MTQzNDcwMDQwMX0.qRe18XcmNXB2Ily-U9dwF_8j9DuZOi35HJGppK4lpBw

This is the compact JWT, it’s a three-part string (separated by periods). It contains the encoded header, body, and signature.

How you send the token to the client will depend on the type of application you are working with. The most common use case is a login form on a traditional website. In that situation you will store the cookie in an HttpOnly cookie, so you can simply set the cookie on the POST response.

For example, if you’re using the cookies library for Express:

new Cookies(req,res).set('access_token',token,{
  httpOnly: true,
  secure: true      // for your production environment
});

Once the client has the token, it can use it for authentication. For example, if you’re building a single-page-app, the app will be making XHR requests of your server. When it does so, it will supply the cookie for authentication.
How to Verify JWTs

When a client has a token it will use it to authenticate the user. The token can be sent to your server in a cookie or an HTTP header, such as the Authorization: Bearer header.

For example, if it comes in as a cookie and you’re using the cookies library with your Express app, you could pull the token from the cookie like this:

var token = new Cookies(req,res).get('access_token');

Regardless of how the token comes in, it will be that same compacted string that you sent to the client. To verify the string, you simply need to pass it to the verify method in the library, along with the secret key that was used to sign the token:

var verifiedJwt = nJwt.verify(token,secretKey);

If the token is valid, you can log it to the console and see the same information that you put into it!

{
  header: {
    typ: 'JWT',
    alg: 'HS256'
  },
  body: {
    jti: '3ee9364e-8aca-4e39-8ba2-74e654c7e083',
    iat: 1434695471,
    exp: 1434699071,
    sub: 'user9876',
    iss: 'https://mytrustyapp.com',
    permissions: 'upload-photos'
  }
}

If the token is invalid, the verify method will throw an error which describes the problem:

JwtParseError: Jwt is expired

If you don’t want to throw errors you can use the verify function asynchronously:

nJwt.verify(token,secretKey,function(err,token){
  if(err){
    // respond to request with error
  }else{
    // continue with the request
  }
});

JWTs Made Easy!

That’s it! Creating and verifying JWTs is incredibly simple, especially with the API that nJwt gives you. No go forth and JWT all the services!

But remember: do it securely. While our nJwt library does all the security for the JWT, you also need to ensure that you application is using cookies securely. Please see my other article for an in-depth walkthrough of the security concerns:

Build Secure User Interfaces Using JSON Web Tokens (JWTs)

Happy verifying!

                1.16.1.1.2 https://medium.freecodecamp.org/securing-node-js-restful-apis-with-json-web-tokens-9f811a92bb52

Securing Node.js RESTful APIs with JSON Web Tokens

Have you ever wondered how authentication works? What’s behind all the complexity and abstractions. Actually, nothing special. It’s a way of encrypting a value, in turn creating a unique token that users use as an identifier. This token verifies your identity. It can authenticate who you are, and authorize various resources you have access to. If you by any chance don’t know any of these keywords, be patient, I’ll explain everything below.

This will be a step by step tutorial of how to add token based authentication to an existing REST API. The authentication strategy in question is JWT (JSON Web Token). If that doesn’t tell you much, it’s fine. It was just as strange for me when I first heard the term.

What does JWT actually mean in a down to earth point of view? Let’s break down what the official definition states:

    JSON Web Token (JWT) is a compact, URL-safe means of representing claims to be transferred between two parties. The claims in a JWT are encoded as a JSON object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or integrity protected with a Message Authentication Code (MAC) and/or encrypted.
    - Internet Engineering Task Force (IETF)

That was a mouthful. Let’s translate that to English. A JWT is an encoded string of characters which is safe to send between two computers if they both have HTTPS. The token represents a value that is accessible only by the computer that has access to the secret key with which it was encrypted. Simple enough, right?

What does this look like in real life? Let’s say a user wants to sign in to their account. They send a request with the required credentials such as email and password to the server. The server checks to see if the credentials are valid. If they are, the server creates a token using the desired payload and a secret key. This string of characters that results from the encryption is called a token. Then the server sends it back to the client. The client, in turn, saves the token to use it in every other request the user will send. The practice of adding a token to the request headers is as way of authorizing the user to access resources. This is a practical example of how JWT works.

Okay, that’s enough talk! The rest of this tutorial will be coding, and I’d love if you would follow along and code alongside me, as we progress. Every snippet of code will be followed by an explanation. I believe the best way of understanding it correctly will be to code it yourself along the way.

Before I begin, there are some things you need to know about Node.js and some EcmaScript standards I’ll be using. I will not be using ES6, as it is not as beginner friendly as traditional JavaScript. But, I will expect you already know how to build a RESTful API with Node.js. If not, you can take a detour and check this out before proceeding.

Also, the whole demo is on GitHub if you wish to see it in its entirety.
Let’s start writing some code, shall we?

Well, not yet actually. We need to set up the environment first. The code will have to wait at least a couple more minutes. This part is boring so to get up and running quick we’ll clone the repository from the tutorial above. Open up a terminal window or command line prompt and run this command:

git clone https://github.com/adnanrahic/nodejs-restful-api.git

You’ll see a folder appear, open it up. Let’s take a look at the folder structure.

> user
  - User.js
  - UserController.js
- db.js
- server.js
- app.js
- package.json

We have a user folder with a model and a controller, and basic CRUD already implemented. Our app.js contains the basic configuration. The db.js makes sure the application connects to the database. The server.js makes sure our server spins up.

Go ahead and install all required Node modules. Switch back to your terminal window. Make sure you’re in the folder named ‘nodejs-restful-api’ and run npm install. Wait a second or two for the modules to install. Now you need to add a database connection string in db.js.

Jump over to mLab, create an account if you do not already have one, and open up your database dashboard. Create a new database, name it as you wish and proceed to its configuration page. Add a database user to your database and copy the connection string from the dashboard to your code.

All you need to do now is to change the placeholder values for <dbuser> and <dbpassword>. Replace them with the username and password of the user you created for the database. A detailed step by step explanation of this process can be found in the tutorial linked above.

Let’s say the user I created for the database is named wally with a password of theflashisawesome. Having that in mind, the db.js file should now look something like this:

var mongoose = require('mongoose');
mongoose.connect('mongodb://wally:theflashisawesome@ds147072.mlab.com:47072/securing-rest-apis-with-jwt', { useMongoClient: true });

Go ahead and spin up the server, back in your terminal window type node server.js. You should see Express server listening on port 3000 get logged to the terminal.
Finally, some code.

Let’s start out by brainstorming about what we want to build. First of all we want to add user authentication. Meaning, implementing a system for registering and logging users in.

Secondly, we want to add authorization. The act of granting users the permission to access certain resources on our REST API.

Start out by adding a new file in the root directory of the project. Give it a name of config.js. Here you’ll put configuration settings for the application. Everything we need at the moment is just to define a secret key for our JSON Web Token.

Disclaimer: Have in mind, under no circumstances should you ever, (EVER!) have your secret key publicly visible like this. Always put all of your keys in environment variables! I’m only writing it like this for demo purposes.

// config.js
module.exports = {
  'secret': 'supersecret'
};

With this added you’re ready to start adding the authentication logic. Create a folder named auth and start out by adding a file named AuthController.js. This controller will be home for our authentication logic.

Add this piece of code to the top of the AuthController.js.

// AuthController.js

var express = require('express');
var router = express.Router();
var bodyParser = require('body-parser');
router.use(bodyParser.urlencoded({ extended: false }));
router.use(bodyParser.json());
var User = require('../user/User');

Now you’re ready to add the modules for using JSON Web Tokens and encrypting passwords. Paste this code into the AuthController.js:

var jwt = require('jsonwebtoken');
var bcrypt = require('bcryptjs');
var config = require('../config');

Open up a terminal window in your project folder and install the following modules:

npm install jsonwebtoken --save
npm install bcryptjs --save

That’s all the modules we need to implement our desired authentication. Now you’re ready to create a /register endpoint. Add this piece of code to your AuthController.js:

router.post('/register', function(req, res) {
  
  var hashedPassword = bcrypt.hashSync(req.body.password, 8);
  
  User.create({
    name : req.body.name,
    email : req.body.email,
    password : hashedPassword
  },
  function (err, user) {
    if (err) return res.status(500).send("There was a problem registering the user.")

    // create a token
    var token = jwt.sign({ id: user._id }, config.secret, {
      expiresIn: 86400 // expires in 24 hours
    });

    res.status(200).send({ auth: true, token: token });
  }); 
});

Here we’re expecting the user to send us three values, a name, an email and a password. We’re immediately going to take the password and encrypt it with Bcrypt’s hashing method. Then take the hashed password, include name and email and create a new user. After the user has been successfully created, we’re at ease to create a token for that user.

The jwt.sign() method takes a payload and the secret key defined in config.js as parameters. It creates a unique string of characters representing the payload. In our case, the payload is an object containing only the id of the user. Let’s write a piece of code to get the user id based on the token we got back from the register endpoint.

router.get('/me', function(req, res) {

  var token = req.headers['x-access-token'];
  if (!token) return res.status(401).send({ auth: false, message: 'No token provided.' });
  
  jwt.verify(token, config.secret, function(err, decoded) {
    if (err) return res.status(500).send({ auth: false, message: 'Failed to authenticate token.' });
    
    res.status(200).send(decoded);
  });
});

Here we’re expecting the token be sent along with the request in the headers. The default name for a token in the headers of an HTTP request is x-access-token. If there is no token provided with the request the server sends back an error. To be more precise, an 401 unauthorized status with a response message of ‘No token provided’. If the token exists, the jwt.verify() method will be called. This method decodes the token making it possible to view the original payload. We’ll handle errors if there are any and if there are not, send back the decoded value as the response.

Finally we need to add the route to the AuthController.js in our main app.js file. First export the router from AuthController.js:

// add this to the bottom of AuthController.js
module.exports = router;

Then add a reference to the controller in the main app, right above where you exported the app.

// app.js
var AuthController = require('./auth/AuthController');
app.use('/api/auth', AuthController);

module.exports = app;

Let’s test this out. Why not?

Open up your REST API testing tool of choice, I use Postman or Insomnia, but any will do.

Go back to your terminal and run node server.js. If it is running, stop it, save all changes to you files, and run node server.js again.

Open up Postman and hit the register endpoint (/api/auth/register). Make sure to pick the POST method and x-www-form-url-encoded. Now, add some values. My user’s name is Mike and his password is ‘thisisasecretpassword’. That’s not the best password I’ve ever seen, to be honest, but it’ll do. Hit send!
/register

See the response? The token is a long jumbled string. To try out the /api/auth/me endpoint, first copy the token. Change the URL to /me instead of /register, and the method to GET. Now you can add the token to the request header.
/me

Voilà! The token has been decoded into an object with an id field. Want to make sure that the id really belongs to Mike, the user we just created? Sure you do. Jump back into your code editor.

// in AuthController.js change this line
res.status(200).send(decoded);

// to
User.findById(decoded.id, function (err, user) {
  if (err) return res.status(500).send("There was a problem finding the user.");
  if (!user) return res.status(404).send("No user found.");
  
  res.status(200).send(user);
});

Now when you send a request to the /me endpoint you’ll see:

The response now contains the whole user object! Cool! But, not good. The password should never be returned with the other data about the user. Let’s fix this. We can add a projection to the query and omit the password. Like this:

User.findById(decoded.id, 
  { password: 0 }, // projection
  function (err, user) {
    if (err) return res.status(500).send("There was a problem finding the user.");
    if (!user) return res.status(404).send("No user found.");

    res.status(200).send(user);
});

That’s better, now we can see all values except the password. Mike’s looking good.
Did someone say login?

After implementing the registration, we should create a way for existing users to log in. Let’s think about it for a second. The register endpoint required us to create a user, hash a password, and issue a token. What will the login endpoint need us to implement? It should check if a user with the given email exists at all. But also check if the provided password matches the hashed password in the database. Only then will we want to issue a token. Add this to your AuthController.js.

router.post('/login', function(req, res) {

  User.findOne({ email: req.body.email }, function (err, user) {
    if (err) return res.status(500).send('Error on the server.');
    if (!user) return res.status(404).send('No user found.');

    var passwordIsValid = bcrypt.compareSync(req.body.password, user.password);
    if (!passwordIsValid) return res.status(401).send({ auth: false, token: null });

    var token = jwt.sign({ id: user._id }, config.secret, {
      expiresIn: 86400 // expires in 24 hours
    });

    res.status(200).send({ auth: true, token: token });
  });

});

First of all we check if the user exists. Then using Bcrypt’s .compareSync() method we compare the password sent with the request to the password in the database. If they match we .sign() a token. That’s pretty much it. Let’s try it out.

Cool it works! What if we get the password wrong?

Great, when the password is wrong the server sends a response status of 401 unauthorized. Just what we wanted!

To finish off this part of the tutorial, let’s add a simple logout endpoint to nullify the token.

// AuthController.js
router.get('/logout', function(req, res) {
  res.status(200).send({ auth: false, token: null });
});

Disclaimer: The logout endpoint is not needed. The act of logging out can solely be done through the client side. A token is usually kept in a cookie or the browser’s localstorage. Logging out is as simple as destroying the token on the client. This /logout endpoint is created to logically depict what happens when you log out. The token gets set to null.

With this we’ve finished the authentication part of the tutorial. Want to move on to the authorization? I bet you do.
Do you have permission to be here?

To comprehend the logic behind an authorization strategy we need to wrap our head around something called middleware. Its name is self explanatory, to some extent, isn’t it? Middleware is a piece of code, a function in Node.js, that acts as a bridge between some parts of your code.

When a request reaches an endpoint, the router has an option to pass the request on to the next middleware function in line. Emphasis on the word next! Because that’s exactly what the name of the function is! Let’s see an example. Comment out the line where you send back the user as a response. Add a next(user) right underneath.

router.get('/me', function(req, res, next) {

  var token = req.headers['x-access-token'];
  if (!token) return res.status(401).send({ auth: false, message: 'No token provided.' });
  
  jwt.verify(token, config.secret, function(err, decoded) {
    if (err) return res.status(500).send({ auth: false, message: 'Failed to authenticate token.' });
    
    User.findById(decoded.id, 
    { password: 0 }, // projection
    function (err, user) {
      if (err) return res.status(500).send("There was a problem finding the user.");
      if (!user) return res.status(404).send("No user found.");

      // res.status(200).send(user); Comment this out!
      next(user); // add this line
    });
  });
});

// add the middleware function
router.use(function (user, req, res, next) {
  res.status(200).send(user);
});

    Middleware functions are functions that have access to the request object (req), the response object (res), and the next function in the application’s request-response cycle. The next function is a function in the Express router which, when invoked, executes the middleware succeeding the current middleware.
    - Using middleware, expressjs.com

Jump back to postman and check out what happens when you hit the /api/auth/me endpoint. Does it surprise you that the outcome is exactly the same? It should be!

Disclaimer: Go ahead and delete this sample before we continue as it is only used for demonstrating the logic of using next().

Let’s take this same logic and apply it to create a middleware function to check the validity of tokens. Create a new file in the auth folder and name it VerifyToken.js. Paste this snippet of code in there.

var jwt = require('jsonwebtoken');
var config = require('../config');

function verifyToken(req, res, next) {
  var token = req.headers['x-access-token'];
  if (!token)
    return res.status(403).send({ auth: false, message: 'No token provided.' });

  jwt.verify(token, config.secret, function(err, decoded) {
    if (err)
    return res.status(500).send({ auth: false, message: 'Failed to authenticate token.' });

    // if everything good, save to request for use in other routes
    req.userId = decoded.id;
    next();
  });
}

module.exports = verifyToken;

Let’s break it down. We’re going to use this function as a custom middleware to check if a token exists and whether it is valid. After validating it, we add the decoded.id value to the request (req) variable. We now have access to it in the next function in line in the request-response cycle. Calling next() will make sure flow will continue to the next function waiting in line. In the end, we export the function.

Now, open up the AuthController.js once again. Add a reference to VerifyToken.js at the top of the file and edit the /me endpoint. It should now look like this:

// AuthController.js

var VerifyToken = require('./VerifyToken');

// ...

router.get('/me', VerifyToken, function(req, res, next) {

  User.findById(req.userId, { password: 0 }, function (err, user) {
    if (err) return res.status(500).send("There was a problem finding the user.");
    if (!user) return res.status(404).send("No user found.");
    
    res.status(200).send(user);
  });

});

// ...

See how we added VerifyToken in the chain of functions? We now handle all the authorization in the middleware. This frees up all the space in the callback to only handle the logic we need. This is an awesome example of how to write DRY code. Now, every time you need to authorize a user you can add this middleware function to the chain. Test it in Postman again, to make sure it still works like it should.

Feel free to mess with the token and try the endpoint again. With an invalid token, you’ll see the desired error message, and be sure the code you wrote works the way you want.

Why is this so powerful? You can now add the VerifyToken middleware to any chain of functions and be sure the endpoints are secured. Only users with verified tokens can access the resources!
Wrapping your head around everything.

Don’t feel bad if you did not grasp everything at once. Some of these concepts are hard to understand. It’s fine to take a step back and rest your brain before trying again. That’s why I recommend you go through the code by yourself and try your best to get it to work.

Again, here’s the GitHub repository. You can catch up on any things you may have missed, or just get a better look at the code if you get stuck.

                1.16.1.1.3 

            1.16.1.2


        1.16.2


    1.17 regex
    
        1.17.1 https://www.w3schools.com/js/js_regexp.asp
What Is a Regular Expression?
A regular expression is a sequence of characters that forms a search pattern.

When you search for data in a text, you can use this search pattern to describe what you are searching for.

A regular expression can be a single character, or a more complicated pattern.

Regular expressions can be used to perform all types of text search and text replace operations.

Syntax
/pattern/modifiers;
Example
var patt = /w3schools/i;
Example explained:

/w3schools/i  is a regular expression.

w3schools  is a pattern (to be used in a search).

i  is a modifier (modifies the search to be case-insensitive).

Using String Methods
In JavaScript, regular expressions are often used with the two string methods: search() and replace().

The search() method uses an expression to search for a match, and returns the position of the match.

The replace() method returns a modified string where the pattern is replaced.

Using String search() With a String
The search() method searches a string for a specified value and returns the position of the match:

Example
Use a string to do a search for "W3schools" in a string:

var str = "Visit W3Schools!";
var n = str.search("W3Schools");
Try it Yourself »
Using String search() With a Regular Expression
Example
Use a regular expression to do a case-insensitive search for "w3schools" in a string:

var str = "Visit W3Schools";
var n = str.search(/w3schools/i);
The result in n will be:

6
Try it Yourself »

Using String replace() With a String
The replace() method replaces a specified value with another value in a string:

var str = "Visit Microsoft!";
var res = str.replace("Microsoft", "W3Schools");
Try it Yourself »
Use String replace() With a Regular Expression
Example
Use a case insensitive regular expression to replace Microsoft with W3Schools in a string:

var str = "Visit Microsoft!";
var res = str.replace(/microsoft/i, "W3Schools");
The result in res will be:

Visit W3Schools!
Try it Yourself »
Did You Notice?
Regular expression arguments (instead of string arguments) can be used in the methods above.
Regular expressions can make your search much more powerful (case insensitive for example).

Regular Expression Modifiers
Modifiers can be used to perform case-insensitive more global searches:

Modifier	Description	Try it
i	Perform case-insensitive matching	Try it »
g	Perform a global match (find all matches rather than stopping after the first match)	Try it »
m	Perform multiline matching	Try it »
Regular Expression Patterns
Brackets are used to find a range of characters:

Expression	Description	Try it
[abc]	Find any of the characters between the brackets	Try it »
[0-9]	Find any of the digits between the brackets	Try it »
(x|y)	Find any of the alternatives separated with |	Try it »
Metacharacters are characters with a special meaning:

Metacharacter	Description	Try it
\d	Find a digit	Try it »
\s	Find a whitespace character	Try it »
\b	Find a match at the beginning or at the end of a word	Try it »
\uxxxx	Find the Unicode character specified by the hexadecimal number xxxx	Try it »
Quantifiers define quantities:

Quantifier	Description	Try it
n+	Matches any string that contains at least one nTry it »
n*	Matches any string that contains zero or more occurrences of nTry it »
n?	Matches any string that contains zero or one occurrences of nTry it »
Using the RegExp Object
In JavaScript, the RegExp object is a regular expression object with predefined properties and methods.

Using test()
The test() method is a RegExp expression method.

It searches a string for a pattern, and returns true or false, depending on the result.

The following example searches a string for the character "e":

Example
var patt = /e/;
patt.test("The best things in life are free!");
Since there is an "e" in the string, the output of the code above will be:

true
Try it Yourself »
You don't have to put the regular expression in a variable first. The two lines above can be shortened to one:

/e/.test("The best things in life are free!");
Using exec()
The exec() method is a RegExp expression method.

It searches a string for a specified pattern, and returns the found text as an object.

If no match is found, it returns an empty (null) object.

The following example searches a string for the character "e":

Example 1
/e/.exec("The best things in life are free!");

        1.17.2 My examples
node
> var re2 = new RegExp("^[\\w/]+$");
> > re2.test('hello\\')
false
> re2.test('hello/')
true
> re2.test('hello')
true
        1.17.3
    1.18 JSON validation


        1.18.1 https://json-schema.org/learn/getting-started-step-by-step.html

    1.19 falsy values and tests

        1.19.1 demo test falsy values and ternary ?: operator
[i500695@C02X632CJGH6:2021-04-01 16:36:53:~/work/SAP/git/portal-cf-transport-service:]2023$ ts-node 
> const nu=null;
undefined
> const undef=undefined;
undefined
> const emp:string='';
undefined
> emp
''
> undef
undefined
> nu
null
> const t1 = emp? 'not falsy' : 'falsy';
undefined
> t1
'falsy'
> const t2 = undef? 'not falsy' : 'falsy';
undefined
> t2
'falsy'
> const t3 = nu? 'not falsy' : 'falsy';
undefined
> t3
'falsy'
> const t4 = nu != null? 'not falsy' : 'falsy';
undefined
> t4
'falsy'
> const t5 = undef != null? 'not falsy' : 'falsy';
undefined
> t5
'falsy'
> const t6 = emp != null? 'not falsy' : 'falsy';
undefined
> t6
'not falsy'

note t6 fails test..., conclusion use (var)? to test for all possible falsy values
        1.19.2 Nullish coalescing operator ?? Operator

https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing_operator


Using the nullish coalescing operator
In this example, we will provide default values but keep values other than null or undefined.
const nullValue = null;
const emptyText = ""; // falsy
const someNumber = 42;

const valA = nullValue ?? "default for A";
const valB = emptyText ?? "default for B";
const valC = someNumber ?? 0;

console.log(valA); // "default for A"
console.log(valB); // "" (as the empty string is not null or undefined)
console.log(valC); // 42

Assigning a default value to a variable
Earlier, when one wanted to assign a default value to a variable, a common pattern was to use the logical OR operator (||):
let foo;

//  foo is never assigned any value so it is still undefined
let someDummyText = foo || 'Hello!';


However, due to || being a boolean logical operator, the left hand-side operand was coerced to a boolean for the evaluation and any falsy value (0, '', NaN, null, undefined) was not returned. This behavior may cause unexpected consequences if you consider 0, '', or NaN as valid values.
let count = 0;
let text = "";

let qty = count || 42;
let message = text || "hi!";
console.log(qty);     // 42 and not 0
console.log(message); // "hi!" and not ""


The nullish coalescing operator avoids this pitfall by only returning the second operand when the first one evaluates to either null or undefined (but no other falsy values):
let myText = ''; // An empty string (which is also a falsy value)

let notFalsyText = myText || 'Hello world';
console.log(notFalsyText); // Hello world

let preservingFalsy = myText ?? 'Hi neighborhood';
console.log(preservingFalsy); // '' (as myText is neither undefined nor null)

Short-circuiting
Like the OR and AND logical operators, the right-hand side expression is not evaluated if the left-hand side proves to be neither null nor undefined.
function A() { console.log('A was called'); return undefined;}
function B() { console.log('B was called'); return false;}
function C() { console.log('C was called'); return "foo";}

console.log( A() ?? C() );
// logs "A was called" then "C was called" and then "foo"
// as A() returned undefined so both expressions are evaluated

console.log( B() ?? C() );
// logs "B was called" then "false"
// as B() returned false (and not null or undefined), the right
// hand side expression was not evaluated


No chaining with AND or OR operators
It is not possible to combine both the AND (&&) and OR operators (||) directly with ??. A SyntaxError will be thrown in such cases.
null || undefined ?? "foo"; // raises a SyntaxError
true || undefined ?? "foo"; // raises a SyntaxError


However, providing parenthesis to explicitly indicate precedence is correct:
(null || undefined) ?? "foo"; // returns "foo"

Relationship with the optional chaining operator (?.)
The nullish coalescing operator treats undefined and null as specific values and so does the optional chaining operator (?.) which is useful to access a property of an object which may be null or undefined.
let foo = { someFooProp: "hi" };

console.log(foo.someFooProp?.toUpperCase());  // "HI"
console.log(foo.someBarProp?.toUpperCase()); // undefined

        1.19.3

    1.20

2. Debugging
https://nodejs.org/en/docs/guides/debugging-getting-started/
Enable Inspector

When started with the --inspect switch, a Node.js process listens via WebSockets for diagnostic commands as defined by the Inspector Protocol, by default at host and port 127.0.0.1:9229. Each process is also assigned a unique UUID (e.g. 0f2c936f-b1cd-4ac9-aab3-f63b0f33d55e).

Inspector clients must know and specify host address, port, and UUID to connect to the WebSocket interface. The full URL is ws://127.0.0.1:9229/0f2c936f-b1cd-4ac9-aab3-f63b0f33d55e, of course dependent on actual host and port and with the correct UUID for the instance.

Inspector also includes an HTTP endpoint to serve metadata about the debuggee, including its WebSocket URL, UUID, and Chrome DevTools URL. Get this metadata by sending an HTTP request to http://[host:port]/json/list. This returns a JSON object like the following; use the webSocketDebuggerUrl property as the URL to connect directly to Inspector.
    2.1 Running and Debugging Node.js with intellij 
https://www.jetbrains.com/help/idea/running-and-debugging-node-js.html

Edit debug configurations (upper right side near green hammer icon)
add nodejs 

For CF, add environment variables
PORT,
MODE

set nodejs script to bin/web

    2.2 CLI debugger

[i500695@C02X632CJGH6:2018-10-23 11:51:13:~/Desktop/work/SAP/CF_LocAL/portal-cf-site-semantic-service:]566$ node inspect bin/web 
< Debugger listening on ws://127.0.0.1:9229/863a2450-46a7-4113-b9d0-d6d7d2165511
< For help see https://nodejs.org/en/docs/inspector
< Debugger attached.
Break on start in bin/web:1
> 1 (function (exports, require, module, __filename, __dirname) { 
  2 'use strict';
  3 

        2.2.1 commands: https://nodejs.org/api/debugger.html
Node.js includes an out-of-process debugging utility accessible via a V8 Inspector and built-in debugging client. To use it, start Node.js with the inspect argument followed by the path to the script to debug; a prompt will be displayed indicating successful launch of the debugger:

$ node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/80e7a814-7cd3-49fb-921a-2e02228cd5ba
< For help, see: https://nodejs.org/en/docs/inspector
< Debugger attached.
Break on start in myscript.js:1
> 1 (function (exports, require, module, __filename, __dirname) { global.x = 5;
  2 setTimeout(() => {
  3   console.log('world');
debug>

Node.js's debugger client is not a full-featured debugger, but simple step and inspection are possible.

Inserting the statement debugger; into the source code of a script will enable a breakpoint at that position in the code:

// myscript.js
global.x = 5;
setTimeout(() => {
  debugger;
  console.log('world');
}, 1000);
console.log('hello');

Once the debugger is run, a breakpoint will occur at line 3:

$ node inspect myscript.js
< Debugger listening on ws://127.0.0.1:9229/80e7a814-7cd3-49fb-921a-2e02228cd5ba
< For help, see: https://nodejs.org/en/docs/inspector
< Debugger attached.
Break on start in myscript.js:1
> 1 (function (exports, require, module, __filename, __dirname) { global.x = 5;
  2 setTimeout(() => {
  3   debugger;
debug> cont
< hello
break in myscript.js:3
  1 (function (exports, require, module, __filename, __dirname) { global.x = 5;
  2 setTimeout(() => {
> 3   debugger;
  4   console.log('world');
  5 }, 1000);
debug> next
break in myscript.js:4
  2 setTimeout(() => {
  3   debugger;
> 4   console.log('world');
  5 }, 1000);
  6 console.log('hello');
debug> repl
Press Ctrl + C to leave debug repl
> x
5
> 2 + 2
4
debug> next
< world
break in myscript.js:5
  3   debugger;
  4   console.log('world');
> 5 }, 1000);
  6 console.log('hello');
  7
debug> .exit

The repl command allows code to be evaluated remotely. The next command steps to the next line. Type help to see what other commands are available.

Pressing enter without typing a command will repeat the previous debugger command.
Watchers
#

It is possible to watch expression and variable values while debugging. On every breakpoint, each expression from the watchers list will be evaluated in the current context and displayed immediately before the breakpoint's source code listing.

To begin watching an expression, type watch('my_expression'). The command watchers will print the active watchers. To remove a watcher, type unwatch('my_expression').
Command reference
#
Stepping
#

    cont, c - Continue execution
    next, n - Step next
    step, s - Step in
    out, o - Step out
    pause - Pause running code (like pause button in Developer Tools)

Breakpoints
#

    setBreakpoint(), sb() - Set breakpoint on current line
    setBreakpoint(line), sb(line) - Set breakpoint on specific line
    setBreakpoint('fn()'), sb(...) - Set breakpoint on a first statement in functions body
    setBreakpoint('script.js', 1), sb(...) - Set breakpoint on first line of script.js
    clearBreakpoint('script.js', 1), cb(...) - Clear breakpoint in script.js on line 1

It is also possible to set a breakpoint in a file (module) that is not loaded yet:

$ node inspect main.js
< Debugger listening on ws://127.0.0.1:9229/4e3db158-9791-4274-8909-914f7facf3bd
< For help, see: https://nodejs.org/en/docs/inspector
< Debugger attached.
Break on start in main.js:1
> 1 (function (exports, require, module, __filename, __dirname) { const mod = require('./mod.js');
  2 mod.hello();
  3 mod.hello();
debug> setBreakpoint('mod.js', 22)
Warning: script 'mod.js' was not loaded yet.
debug> c
break in mod.js:22
 20 // USE OR OTHER DEALINGS IN THE SOFTWARE.
 21
>22 exports.hello = function() {
 23   return 'hello from module';
 24 };
debug>

Information
#

    backtrace, bt - Print backtrace of current execution frame
    list(5) - List scripts source code with 5 line context (5 lines before and after)
    watch(expr) - Add expression to watch list
    unwatch(expr) - Remove expression from watch list
    watchers - List all watchers and their values (automatically listed on each breakpoint)
    repl - Open debugger's repl for evaluation in debugging script's context
    exec expr - Execute an expression in debugging script's context

Execution control
#

    run - Run script (automatically runs on debugger's start)
    restart - Restart script
    kill - Kill script

Various
#

    scripts - List all loaded scripts
    version - Display V8's version

Advanced Usage
#
V8 Inspector Integration for Node.js
#

V8 Inspector integration allows attaching Chrome DevTools to Node.js instances for debugging and profiling. It uses the Chrome DevTools Protocol.

V8 Inspector can be enabled by passing the --inspect flag when starting a Node.js application. It is also possible to supply a custom port with that flag, e.g. --inspect=9222 will accept DevTools connections on port 9222.

To break on the first line of the application code, pass the --inspect-brk flag instead of --inspect.

$ node --inspect index.js
Debugger listening on 127.0.0.1:9229.
To start debugging, open the following URL in Chrome:
    chrome-devtools://devtools/bundled/js_app.html?experiments=true&v8only=true&ws=127.0.0.1:9229/dc9010dd-f8b8-4ac5-a510-c1a114ec7d29

        2.2.2

    2.3
3. Testing frameworks. tags: grunt, Mocha, sinon, chai, mockito, ts-mockito



    3.1 grunt

        3.1.1 https://gruntjs.com/getting-started
Getting started

Grunt and Grunt plugins are installed and managed via npm, the Node.js package manager. Grunt 0.4.x requires stable Node.js versions >= 0.8.0.

Before setting up Grunt ensure that your npm is up-to-date by running npm update -g npm (this might require sudo on certain systems).

If you already have installed Grunt and are now searching for some quick reference, please checkout our Gruntfile example and how to configure a task.

Installing the CLI
Using Grunt 0.3? Please see Grunt 0.3 Notes

In order to get started, you'll want to install Grunt's command line interface (CLI) globally. You may need to use sudo (for OSX, *nix, BSD etc) or run your command shell as Administrator (for Windows) to do this.

npm install -g grunt-cli
This will put the grunt command in your system path, allowing it to be run from any directory.

Note that installing grunt-cli does not install the Grunt task runner! The job of the Grunt CLI is simple: run the version of Grunt which has been installed next to a Gruntfile. This allows multiple versions of Grunt to be installed on the same machine simultaneously.

How the CLI works
Each time grunt is run, it looks for a locally installed Grunt using node's require() system. Because of this, you can run grunt from any subfolder in your project.

If a locally installed Grunt is found, the CLI loads the local installation of the Grunt library, applies the configuration from your Gruntfile, and executes any tasks you've requested for it to run. To really understand what is happening, read the code.

Working with an existing Grunt project
Assuming that the Grunt CLI has been installed and that the project has already been configured with a package.json and a Gruntfile, it's very easy to start working with Grunt:

Change to the project's root directory.
Install project dependencies with npm install.
Run Grunt with grunt.
That's really all there is to it. Installed Grunt tasks can be listed by running grunt --help but it's usually a good idea to start with the project's documentation.

Preparing a new Grunt project
A typical setup will involve adding two files to your project: package.json and the Gruntfile.

package.json: This file is used by npm to store metadata for projects published as npm modules. You will list grunt and the Grunt plugins your project needs as devDependencies in this file.

Gruntfile: This file is named Gruntfile.js or Gruntfile.coffee and is used to configure or define tasks and load Grunt plugins. When this documentation mentions a Gruntfile it is talking about a file, which is either a Gruntfile.js or a Gruntfile.coffee.

package.json
The package.json file belongs in the root directory of your project, next to the Gruntfile, and should be committed with your project source. Running npm install in the same folder as a package.json file will install the correct version of each dependency listed therein.

There are a few ways to create a package.json file for your project:

Most grunt-init templates will automatically create a project-specific package.json file.
The npm init command will create a basic package.json file.
Start with the example below, and expand as needed, following this specification.
{
  "name": "my-project-name",
  "version": "0.1.0",
  "devDependencies": {
    "grunt": "~0.4.5",
    "grunt-contrib-jshint": "~0.10.0",
    "grunt-contrib-nodeunit": "~0.4.1",
    "grunt-contrib-uglify": "~0.5.0"
  }
}
Installing Grunt and gruntplugins

The easiest way to add Grunt and gruntplugins to an existing package.json is with the command npm install <module> --save-dev. Not only will this install <module> locally, but it will automatically be added to the devDependencies section, using a tilde version range.

For example, this will install the latest version of Grunt in your project folder, adding it to your devDependencies:

npm install grunt --save-dev
The same can be done for gruntplugins and other node modules. As seen in the following example installing the JSHint task module:

npm install grunt-contrib-jshint --save-dev
Checkout the current available gruntplugins to be installed and used on your project at the plugins page.

Be sure to commit the updated package.json file with your project when you're done!

The Gruntfile
The Gruntfile.js or Gruntfile.coffee file is a valid JavaScript or CoffeeScript file that belongs in the root directory of your project, next to the package.json file, and should be committed with your project source.

A Gruntfile is comprised of the following parts:

The "wrapper" function
Project and task configuration
Loading Grunt plugins and tasks
Custom tasks
An example Gruntfile

In the following Gruntfile, project metadata is imported into the Grunt config from the project's package.json file and the grunt-contrib-uglify plugin's uglify task is configured to minify a source file and generate a banner comment dynamically using that metadata. When grunt is run on the command line, the uglify task will be run by default.

module.exports = function(grunt) {

  // Project configuration.
  grunt.initConfig({
    pkg: grunt.file.readJSON('package.json'),
    uglify: {
      options: {
        banner: '/*! <%= pkg.name %> <%= grunt.template.today("yyyy-mm-dd") %> */\n'
      },
      build: {
        src: 'src/<%= pkg.name %>.js',
        dest: 'build/<%= pkg.name %>.min.js'
      }
    }
  });

  // Load the plugin that provides the "uglify" task.
  grunt.loadNpmTasks('grunt-contrib-uglify');

  // Default task(s).
  grunt.registerTask('default', ['uglify']);

};
Now that you've seen the whole Gruntfile, let's look at its component parts.

The "wrapper" function

Every Gruntfile (and gruntplugin) uses this basic format, and all of your Grunt code must be specified inside this function:

module.exports = function(grunt) {
  // Do grunt-related things in here
};
Project and task configuration

Most Grunt tasks rely on configuration data defined in an object passed to the grunt.initConfig method.

In this example, grunt.file.readJSON('package.json') imports the JSON metadata stored in package.json into the grunt config. Because <% %> template strings may reference any config properties, configuration data like filepaths and file lists may be specified this way to reduce repetition.

You may store any arbitrary data inside of the configuration object, and as long as it doesn't conflict with properties your tasks require, it will be otherwise ignored. Also, because this is JavaScript, you're not limited to JSON; you may use any valid JS here. You can even programmatically generate the configuration if necessary.

Like most tasks, the grunt-contrib-uglify plugin's uglify task expects its configuration to be specified in a property of the same name. Here, the banner option is specified, along with a single uglify target named build that minifies a single source file to a single destination file.

// Project configuration.
grunt.initConfig({
  pkg: grunt.file.readJSON('package.json'),
  uglify: {
    options: {
      banner: '/*! <%= pkg.name %> <%= grunt.template.today("yyyy-mm-dd") %> */\n'
    },
    build: {
      src: 'src/<%= pkg.name %>.js',
      dest: 'build/<%= pkg.name %>.min.js'
    }
  }
});
Loading Grunt plugins and tasks

Many commonly used tasks like concatenation, minification and linting are available as grunt plugins. As long as a plugin is specified in package.json as a dependency, and has been installed via npm install, it may be enabled inside your Gruntfile with a simple command:

// Load the plugin that provides the "uglify" task.
grunt.loadNpmTasks('grunt-contrib-uglify');
Note: the grunt --help command will list all available tasks.

Custom tasks

You can configure Grunt to run one or more tasks by default by defining a default task. In the following example, running grunt at the command line without specifying a task will run the uglify task. This is functionally the same as explicitly running grunt uglify or even grunt default. Any number of tasks (with or without arguments) may be specified in the array.

// Default task(s).
grunt.registerTask('default', ['uglify']);
If your project requires tasks not provided by a Grunt plugin, you may define custom tasks right inside the Gruntfile. For example, this Gruntfile defines a completely custom default task that doesn't even utilize task configuration:

module.exports = function(grunt) {

  // A very basic default task.
  grunt.registerTask('default', 'Log some stuff.', function() {
    grunt.log.write('Logging some stuff...').ok();
  });

};
Custom project-specific tasks don't need to be defined in the Gruntfile; they may be defined in external .js files and loaded via the grunt.loadTasks method.

        3.1.2 https://fairwaytech.com/2014/01/understanding-grunt-part-1-installation-linting-concatenation-and-minification/

            3.1.2.1 Understanding Grunt – Part 1: Installation, Linting, Concatenation, and Minification

Grunt has become the go-to build tool for the node.js environment. This multi-part tutorial will demonstrate how to configure Grunt to perform common tasks required on Node.js projects. The first part of the tutorial will provide a whirlwind tour of Grunt basics as we configure Grunt to:

    Lint our source code with JSHint

    Concatenate our source code into a single file for distribution

    Provide a minified version of our concatenated file

The second part will go more in depth on several topics as we configure Grunt to run a suite of automated tests using the Mocha test framework.

After you finish this tutorial you should understand Grunt well enough to setup the basic tasks that will be required on most projects. You should also have a base of knowledge for exploring solutions to more complex scenarios.

This guide will be using Grunt 0.4.2 and assumes you have already installed Node.js >=0.8.0.
Installing the Grunt CLI

Grunt is comprised of two components; The Grunt runner, and the Grunt CLI. The Grunt CLI should be installed as a global npm module, whereas the Grunt runner should be installed as a local npm module in your project. We’ll come back to the Grunt runner later, so for now, just install the Grunt CLI by running the following as a command line if you haven’t already done so:

npm install -g grunt-cli

If you encounter errors, you may need to sudo or run your console as an admin on Windows systems.
Demo Project

This tutorial was written so that you can follow along as we build a demo project.

As of now, it consists of only a few source files, math.js and string.js, both of which contain a few functions. These files have been placed inside of a src folder.

module.exports = {
	add: function (a, b) {
		return a + b;
	},

	subtract: function (a, b) {
		return a - b;
	}
};

src/math.js

module.exports = {
	add: function (a, b) {
		return a + b;
	},

	subtract: function (a, b) {
		return a - b;
	}
};

src/string.js

Also included in the project are the configuration files package.json, and gruntfile.js. These two files are central to the usage of Grunt.

View the step01 branch on Github.

Note: Each step in this tutorial is contained within a separate branch on the Github repository. If something isn’t working for you locally at any step in the tutorial, it may be helpful to compare your code against the code in the associated branch on Github.
package.json

Let’s take a closer look at package.json. It serves as the source of meta information for a Node.js project. If you’re not already familiar with package.json, now would be a good time to get to know what it’s all about.

The original intent of the package.json file was to describe a module being deployed via the npm system. Its usage has since been appropriated for a wide number of other purposes. It is used by many tools in the Node.js ecosystem including “Platform as a Service” deployments, cloud-based continuous integration tools, and build systems like Grunt. As such, it’s become, arguably, the most important file in any Node.js project. If you haven’t been keeping a well maintained package.json file in your Node.js projects, you should start doing so now.

The package.json file shown below provides information such as the name of the project, the version number, where the git repo is located, and much more. Visit package.json.nodejitsu.com to see an interactive list of many standard package.json options.

{
  "name": "GruntTutorial",
  "version": "0.1.0",
  "author": "Craig Maslowski <craig@craigmaslowski.com>",
  "description": "The demo project that accompanies my 'Understanding Grunt' tutorial",
  "contributors": [
    {
      "name": "Craig Maslowski",
      "email": "craig@craigmaslowski.com"
    }
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/craigmaslowski/Grunt-Tutorial.git"
  },
  "devDependencies": {
  }
}

package.json
gruntfile.js

The gruntfile.js file is where all configuration for Grunt occurs. This is where we will configure and register tasks, register plugins, and otherwise tell Grunt we want it what to do.

module.exports = function(grunt) {
	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
	});
};

gruntfile.js

The gruntfile.js is pretty bare so far. All we’ve done is tell Grunt to read our package.json file into a property named pkg. This is actually more powerful than it appears, as we now have access to all that meta information and can use it inside Grunt Templates. Grunt Templates let’s us do things like automatically build a banner comment in our concatenated and minified js files.

Let’s get ready for that now, by adding a banner variable to gruntfile.js. Later, we’ll configure the concat and uglify plugins to insert this variable into the top of the files they build.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
	});
};

gruntfile.js

The variable we’ve added defines a Grunt Template which prints the name of our project, the version number, the url of our git repo, and the date the build was performed. Grunt Templates are a powerful part of the Grunt system and we’ll come back to them more than once as we go through the tutorial.

Particularly astute readers might be asking whether it’s possible to automatically bump the version number in package.json when Grunt runs a build. The answer is, of course, yes. The grunt-bump plugin does just this.
Installing Grunt In The Project

There’s one last thing we need to do before we get going. We need to install the Grunt runner in our project. This is done using npm at the command line.

npm install grunt --save-dev

By passing the --save-dev flag, we also told npm to update the devDependencies array in our package.json file. This is useful because it can be used later to install the correct versions of our development dependencies when the source code is used on another system.

{
  "name": "GruntTutorial",
  "version": "0.1.0",
  "author": "Craig Maslowski <craig@craigmaslowski.com>",
  "description": "The demo project that accompanies my 'Understanding Grunt' tutorial",
  "contributors": [
    {
      "name": "Craig Maslowski",
      "email": "craig@craigmaslowski.com"
    }
  ],
  "repository": {
    "type": "git",
    "url": "https://github.com/craigmaslowski/Grunt-Tutorial.git"
  },
  "devDependencies": {
    "grunt": "~0.4.2"
  }
}

package.json

View the step02 branch on Github.

See the differences between step01 and step02.
Grunt Plugins

I’ve talked an awful lot about Grunt plugins so far, but we haven’t seen any yet. That’s about to change. From here on out, most of what we’ll be doing is installing and configuring various different plugins. It’s time to actually make Grunt do something.
JSHint

Let’s get started by making sure that our code adheres to good JavaScript practices by linting our files. We’ll use the JSHint plugin to do so.

The first thing we need to do is install it. We do this using npm at the command line, again passing the --save-dev flag so it updates the devDependencies array in package.json. The npm package we’ll be installing is grunt-contrib-jshint.

npm install grunt-contrib-jshint --save-dev

Next, we’ll tell Grunt to load this plugin by updating gruntfile.js with a call to grunt.loadNpmTasks.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
};

gruntfile.js

Finally, we’ll tell JSHint which files we want it to check, and set some linting options.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			files: ['gruntfile.js', 'src/*.js'],
			options: {
				maxlen: 80,
				quotmark: 'single'
			}
		}
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
};

gruntfile.js

This last change needs a bit of an explanation. We’ve added a jshint property to the object we pass to grunt.initConfig. This jshint object is a Grunt plugin configuration task. A plugin task is where we set the configuration for a task that Grunt will carry out.

Inside of the jshint task we set two properties. The first tells JSHint which files we want it to process. In this case, that’s the gruntfile.js itself and every js file in our src folder.

We’ve also added an options object which will be passed along to JSHint. These are the same JSHint options that are available outside of Grunt. Check out the JSHint docs to see the full list of options.

What we’ve done here is a common pattern that we’ll be using with most Grunt plugins. Install the npm module with the --save-dev flag, tell Grunt, to load the plugin, and configure a task by telling the plugin which files to operate on and passing it some options.
Registering Tasks

Now we’re almost ready to run Grunt. The last thing we need to do is register our default Alias Task. Registering Alias Tasks allows us to handle several different scenarios such as running linting and tests tasks during development, and provide a separate configuration for release building that includes concatenation and minification.

This may seem confusing, as we called our JSHint object a Task in the last section, and I’ll admit that it is. Grunt provides multiple ways to configure Tasks. This will become more clear in the part 2 of this tutorial when we cover Tasks in greater detail. In the meantime, I’ll do my best to be clear about a task relating to plugin task versus a task related to Grunt Alias Task.

In this case, we want to create a default Alias Task to tell Grunt which plugin tasks to run when we run the grunt command without passing it any parameters. We do this by modifying gruntfile.js with a call to grunt.registerTask. The first parameter is the name of the Alias Task, and the second is an array of plugins tasks to process. Note that the jshint string we pass matches the name of the property we passed to the grunt.initConfig call.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			files: ['gruntfile.js', 'src/*.js'],
			options: {
				maxlen: 80,
				quotmark: 'single'
			}
		}
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');

	grunt.registerTask('default', ['jshint']);
};

gruntfile.js

Finally we can run Grunt and get some results. Executing grunt at the command line, provides us with our first linting error telling us our banner line in gruntfile.js is longer than the 80 character limit we specified.

Running "jshint:files" (jshint) task
Linting gruntfile.js ...ERROR
[L2:C168] W101: Line is too long.
  var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

We’ll fix that by breaking up the string into multiple lines.

var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

gruntfile.js (changes only)

Now when we run grunt at the command line, our code is given a clean bill of health by JSHint.

Running "jshint:files" (jshint) task
>> 3 files lint free.

Done, without errors.

View the step03 branch on Github.

See the differences between step02 and step03.
Concatenation

Next we’ll move onto concatenation. Again our first step is to install the plugin with npm at the command line using the --save-dev flag.

npm install grunt-contrib-concat --save-dev

We update gruntfile.js by telling Grunt to load the plugin and configure the concat task. Finally, we update our default Grunt Alias task to include our concat plugin task.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
	banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
	banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			files: ['gruntfile.js', 'src/*.js'],
			options: {
				maxlen: 80,
				quotmark: 'single'
			}
		},
		concat: {
			options: {
				separator: ';n',
				banner: banner
			},
			build: {
				files: [{
					src: ['src/*.js'], 
					dest: 'build/<%= pkg.name %>.js'
				}]
			}
		},
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
	grunt.loadNpmTasks('grunt-contrib-concat');

	grunt.registerTask('default', ['jshint', 'concat']);
};

gruntfile.js

Our concat task is confgured with two options. separator tells the concat plugin to include a semi-colon and the newline character after the contents of each file. banner is a string that the concat plugin will prepend to the file it generates. In this case, we are using the banner variable we defined earlier.

Also provided in our concat configuration is a build Target telling Grunt which files to process and where to place the concatenated file.

Targets are another important, and powerful, part of Grunt. Targets allow us to create MultiTasks, a fancy name for the ability to provide multiple configurations of the same plugin task. We’ll see more use of these in part two of this tutorial when we add testing.

It’s important to note that the property name build is arbitrary. We could have called it rootBeer and achieved the same result.

One other thing that’s worth mentioning is the usage of another template in the dest property of the files object. Here we are using a Template to specify the name of the concatenated file by using the value of the name property from package.json. In this case, our concatenated file will be created in build/GruntTutorial.js.

Now when we run grunt at the command line, we see the following output:

Running "jshint:files" (jshint) task

>> 3 files lint free.

Running "concat:build" (concat) task
File "build/GruntTutorial.js" created.

Done, without errors.

We also see that Grunt has concatenated our math.js and string.js file into build/GruntTutorial.js with our dynamically generated banner included at the top.

/*

GruntTutorial 0.1.0- The demo project that accompanies my 'Understanding Grunt' tutorial
https://github.com/craigmaslowski/Grunt-Tutorial.git
Built on 2014-01-06
*/
module.exports = {
	add: function (a, b) {
		return a + b;
	},

	subtract: function (a, b) {
		return a - b;
	}
};
;
module.exports = {
	capitalize: function (a) {
		var arr = a.split('');
		arr[0] = arr[0].toUpperCase();
		return arr.join('');
	},

	reverse: function (a) {
		return a.split('').reverse().join('');
	}
};

build/GruntTutorial.js

View the step04 branch on Github.

See the differences between step03 and step04.

Minification

The last step we’ll do in this part is minify our concatenated file. The pattern will be the same as before.

Install the plugin via npm.

npm install grunt-contrib-uglify --save-dev

Update gruntfile.js to load the plugin, configure an uglify plugin task, and add the uglify task to the default Alias Task.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
	banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
	banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			files: ['gruntfile.js', 'src/*.js'],
			options: {
				maxlen: 80,
				quotmark: 'single'
			}
		},
		concat: {
			options: {
				separator: ';n',
				banner: banner
			},
			build: {
				files: [{
					src: ['src/*.js'], 
					dest: 'build/<%= pkg.name %>.js'
				}]
			},
		},
		uglify: {
			options: {
				banner: banner,
			},
			build: {
				files: { 
					'build/<%= pkg.name %>.min.js': 
						['build/<%= pkg.name %>.js'],
				}
			}
		},
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
	grunt.loadNpmTasks('grunt-contrib-concat');
	grunt.loadNpmTasks('grunt-contrib-uglify');

	grunt.registerTask('default', ['jshint', 'concat', 'uglify']);
};

gruntfile.js

Once again, we’ve set the banner option to the banner variable we declared earlier so that Grunt will prepend this information in the minified file it creates.

Running grunt at the command line now yields the output.

Running “jshint:files” (jshint) task

>> 3 files lint free.

Running "concat:build" (concat) task
File "build/GruntTutorial.js" created.

Running "uglify:build" (uglify) task
File "build/GruntTutorial.min.js" created.

Done, without errors.

Looking inside the build folder we see our minified GruntTutorial.min.js file.

View the step05 branch on Github.

See the differences between step04 and step05.
Conclusion

We covered a lot of ground in this part of the tutorial, but many of the topics were only given minimal treatment. In the next part of this tutorial, we’ll go more in depth on several topics as we add test coverage to our demo project using the Mocha testing framework.

            3.1.2.2
        3.1.3
    3.2 Mocha

        3.2.1 Mocha tutorial
was in: https://fairwaytech.com/2014/01/understanding-grunt-part-2-automated-testing-with-mocha/

We’ll be using the Mocha test framework as we go through this portion of the tutorial. The plugin we’ll be using to get tests running is the grunt-simple-mocha plugin. We’ll be adding two test files. One to test the code in our math.js file, and one to test our string.js file.

var expect = require('chai').expect,
	math = require('../src/math');

describe('add', function () {
	it('should return 3 when passed the params (1, 2)', function () {
		expect(math.add(1, 2)).to.equal(3);
	});
});

describe('subtract', function () {
	it('should return -1 when passed the params (1, 2)', function () {
		expect(math.subtract(1, 2)).to.equal(-1);
	});
});

tests/math.tests.js

var expect = require('chai').expect,
	string = require('../src/string');

describe('capitalize', function () {
	it('should return "Foo" when passed the param ("foo")', function () {
		expect(string.capitalize('foo')).to.equal('Foo');
	});
});

describe('reverse', function () {
	it('should return "oof" when passed the param ("foo")', function () {
		expect(string.reverse('foo')).to.equal('oof');
	});
});

/tests/string.tests.js

To demonstrate that the tests pass without Grunt, I’ve installed Mocha globally. The grunt-simple-mocha plugin will install the Mocha framework as a local dependency. It isn’t necessary for you to install Mocha globally, but if you want to follow along, run the following in a terminal.

npm install -g mocha

Now when we run the following in a terminal:

mocha tests

I receive the following output showing that my tests pass.

․․․․

4 passing (4ms)

Simple Mocha

Let’s configure Grunt to run these tests for us automatically. We’ll begin by installing the grunt-simple-mocha plugin using the --save-dev flag to keep package.json up to date.

npm install grunt-simple-mocha --save-dev

Next we’ll modify gruntfile.js to load the plugin and configure it.

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
	banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
	banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			files: ['gruntfile.js', 'src/*.js'],
			options: {
				maxlen: 80,
				quotmark: 'single'
			}
		},
		concat: {
			options: {
				separator: ';n',
				banner: banner
			},
			build: {
				files: [{
					src: ['src/*.js'], 
					dest: 'build/<%= pkg.name %>.js'
				}]
			},
		},
		uglify: {
			options: {
				banner: banner,
			},
			build: {
				files: { 
					'build/<%= pkg.name %>.min.js': 
						['build/<%= pkg.name %>.js'],
				}
			}
		},
		simplemocha: {
			options: {
				globals: ['expect'],
				timeout: 3000,
				ignoreLeaks: false,
				ui: 'bdd',
				reporter: 'tap'
			},
			all: { src: ['tests/*.js'] }
		}
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
	grunt.loadNpmTasks('grunt-contrib-concat');
	grunt.loadNpmTasks('grunt-contrib-uglify');
	grunt.loadNpmTasks('grunt-simple-mocha');

	grunt.registerTask('default', 
		['jshint', 'simplemocha', 'concat', 'uglify']);
};

gruntfile.js 

Again, we see the same pattern identified in part one of the tutorial. We set some options to pass to Mocha, and tell Grunt which files to process. In this case though, we see a file pattern we haven’t yet encountered. The ** in the file pattern tests/**/*.js instructs Grunt to process all *.js files in the tests folder, as well as *.js inside of any subfolders.

Lastly, we’ve added simplemocha to our default task. It’s important to note that it was added between the jshint and concat tasks. Grunt will run the plugin tasks in the order they are provided, and will stop processing when any task fails. We don’t want to concatenate or minify if the tests fail. Placing the simplemocha task before the others ensures Grunt will stop processing if any test fails. 

Now, when I run grunt from the command line, I see that all of my tests pass. 

Running "jshint:files" (jshint) task
>> 3 files lint free.

Running "simplemocha:all" (simplemocha) task
|1..4
ok 1 add should return 3 when passed the params (1, 2)
ok 2 subtract should return -1 when passed the params (1, 2)
ok 3 capitalize should return "Foo" when passed the param ("foo")
ok 4 reverse should return "oof" when passed the param ("foo")
# tests 4
# pass 4
# fail 0

Running "concat:build" (concat) task
File "build/GruntTutorial.js" created.

Running "uglify:build" (uglify) task
File "build/GruntTutorial.min.js" created.

Done, without errors..

View the step06 branch on Github. 

See the differences between step05 and step06.
Grunt Tasks

In the last tutorial, I highlighted some potential confusion about what actually comprises a Task in the Grunt system. Tasks can be defined in many ways in Grunt. To help understand how tasks work, let’s dive into the command line a bit more.

Up to this point, we’ve just been running grunt at the command line. This instructs Grunt to look for a default task in gruntfile.js and execute it.

Grunt also lets us specify which Task(s) to run from the command line. If we only wanted to lint our code, we could do so by running the following command

grunt jshint

That would produce the following output showing that only the task executed was jshint.

Running "jshint:files" (jshint) task
>> 3 files lint free.

Done, without errors.

We can also pass multiple tasks at the command line.

grunt jshint simplemocha

Grunt will execute these tasks in the order in which they are passed.

Running "jshint:files" (jshint) task
>> 3 files lint free.

Running "simplemocha:all" (simplemocha) task
|1..4
ok 1 add should return 3 when passed the params (1, 2)
ok 2 subtract should return -1 when passed the params (1, 2)
ok 3 capitalize should return "Foo" when passed the param ("foo")
ok 4 reverse should return "oof" when passed the param ("foo")
# tests 4
# pass 4
# fail 0

Done, without errors.

As we’ve already seen with our default task, we can define Alias Tasks inside of gruntfile.js to run multiple tasks at the same time. Let’s add a development Alias Task to gruntfile.js which only runs the jshint and simplemocha tasks since we probably don’t want to concatenate and minify everytime we run Grunt during development.

grunt.registerTask('development', ['jshint', 'simplemocha']);

gruntfile.js (changes only)

Now we can run this alias task from the command line.

grunt development

Which produces the same output as when we specified both tasks individually at the command line.

Running "jshint:files" (jshint) task
>> 3 files lint free.

Running "simplemocha:all" (simplemocha) task
|1..4
ok 1 add should return 3 when passed the params (1, 2)
ok 2 subtract should return -1 when passed the params (1, 2)
ok 3 capitalize should return "Foo" when passed the param ("foo")
ok 4 reverse should return "oof" when passed the param ("foo")
# tests 4
# pass 4
# fail 0

Done, without errors.

Grunt has one more trick up its sleeve regarding defining and running Tasks. When we created the concat task in the last part of the tutorial, I mentioned that the build property in the configuration was arbitrarily named and I called it a Target. Targets also identified as a Task in Grunt.

Let’s modify the jshint configuration and split the files we’re linting into two separate Targets to see how they work.

jshint: {
	options: {
		maxlen: 80,
		quotmark: 'single'
	},
	dev: ['gruntfile.js', 'tests/*.js'],
	app:  ['src/**/*.js']
},

gruntfile.js (changes only) 

We now have two Targets in our jshint configuration, dev and app. The dev task will lint gruntfile.js and all of our tests. The app task will lint only the app source code.

These Targets can now be run individually from the command line. The Target to execute is specified as follows:

grunt jshint:dev 

Which produces the following output. 

Running "jshint:dev" (jshint) task
>> 3 files lint free.

Done, without errors.

We can also tell Grunt to execute only the app Target.

grunt jshint:app

Which produces the following output.

Running "jshint:app" (jshint) task
>> 2 files lint free.

Done, without errors.

Also interesting to note is that when we run grunt jshint from the command line now, Grunt will run both tasks.

Running "jshint:dev" (jshint) task
>> 3 files lint free.

Running "jshint:app" (jshint) task
>> 2 files lint free.

Done, without errors.

View the step07 branch on Github. 

See the differences between step06 and step07.
Watching Files For Changes

Now that we understand tasks in Grunt, let’s see how we can make it more useful for development. Earlier in the tutorial, we added the development alias task so we could lint and test while working on code without concatenating and minifying. Let’s make Grunt automatically run the development task by installing the grunt-contrib-watch plugin.

npm install grunt-contrib-watch --save-dev A_new_bli

    |1..4.1
general


    |1..4.2 links
general
    |1..4.3 Design

    |1..4.4 Code



|1..5
ok 1

Next we’ll need to tell Grunt to load the plugin and configure it by indicating which files it should monitor for changes and which tasks to run when it detects a change in the file. 

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
	banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
	banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			options: {
				maxlen: 80,
				quotmark: 'single'
			},
			dev: ['gruntfile.js', 'tests/*.js'],
			app:  ['src/**/*.js']
		},
		concat: {
			options: {
				separator: ';n',
				banner: banner
			},
			build: {
				files: [{
					src: ['src/*.js'], 
					dest: 'build/<%= pkg.name %>.js'
				}]
			},
		},
		uglify: {
			options: {
				banner: banner,
			},
			build: {
				files: { 
					'build/<%= pkg.name %>.min.js': 
						['build/<%= pkg.name %>.js'],
				}
			}
		},
		simplemocha: {
			options: {
				globals: ['expect'],
				timeout: 3000,
				ignoreLeaks: false,
				ui: 'bdd',
				reporter: 'tap'
			},
			all: { src: ['tests/**/*.js'] }
		},
		watch: {
			scripts: {
				files: ['gruntfile.js', 'src/*.js', 'tests/**/*.js'],
				tasks: ['development']
			}
		}
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
	grunt.loadNpmTasks('grunt-contrib-concat');
	grunt.loadNpmTasks('grunt-contrib-uglify');
	grunt.loadNpmTasks('grunt-simple-mocha');
	grunt.loadNpmTasks('grunt-contrib-watch');

	grunt.registerTask('development', ['jshint', 'simplemocha']);
	grunt.registerTask('default', 
		['jshint', 'simplemocha', 'concat', 'uglify']);
};

In this case, we’ve told Grunt to monitor gruntfile.js, our app code, and our tests. We start grunt in watch mode by running the following at the command line.

grunt watch

When it detects a change in any file, it will run the development task. Here’s the output after I made a change to string.js

Running "watch" task
Waiting...OK
>> File "src/string.js" changed.

Running "jshint:dev" (jshint) task
>> 3
|1..5
ok 1

Next we’ll need to tell Grunt to load the plugin and configure it by indicating which files it should monitor for changes and which tasks to run when it detects a change in the file. 

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %>';
	banner += '- <%= pkg.description %>n<%= pkg.repository.url %>n';
	banner += 'Built on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
		jshint: {
			options: {
				maxlen: 80,
				quotmark: 'single'
			},
			dev: ['gruntfile.js', 'tests/*.js'],
			app:  ['src/**/*.js']
		},
		concat: {
			options: {
				separator: ';n',
				banner: banner
			},
			build: {
				files: [{
					src: ['src/*.js'], 
					dest: 'build/<%= pkg.name %>.js'
				}]
			},
		},
		uglify: {
			options: {
				banner: banner,
			},
			build: {
				files: { 
					'build/<%= pkg.name %>.min.js': 
						['build/<%= pkg.name %>.js'],
				}
			}
		},
		simplemocha: {
			options: {
				globals: ['expect'],
				timeout: 3000,
				ignoreLeaks: false,
				ui: 'bdd',
				reporter: 'tap'
			},
			all: { src: ['tests/**/*.js'] }
		},
		watch: {
			scripts: {
				files: ['gruntfile.js', 'src/*.js', 'tests/**/*.js'],
				tasks: ['development']
			}
		}
	});

	grunt.loadNpmTasks('grunt-contrib-jshint');
	grunt.loadNpmTasks('grunt-contrib-concat');
	grunt.loadNpmTasks('grunt-contrib-uglify');
	grunt.loadNpmTasks('grunt-simple-mocha');
	grunt.loadNpmTasks('grunt-contrib-watch');

	grunt.registerTask('development', ['jshint', 'simplemocha']);
	grunt.registerTask('default', 
		['jshint', 'simplemocha', 'concat', 'uglify']);
};

In this case, we’ve told Grunt to monitor gruntfile.js, our app code, and our tests. We start grunt in watch mode by running the following at the command line.

grunt watch

When it detects a change in any file, it will run the development task. Here’s the output after I made a change to string.js

Running "watch" task
Waiting...OK
>> File "src/string.js" changed.

Running "jshint:dev" (jshint) task
>> 3 files lint free.

Running "jshint:app" (jshint) task
>> 2 files lint free.

Running "simplemocha:all" (simplemocha) task
|1..4
ok 1 add should return 3 when passed the params (1, 2)
ok 2 subtract should return -1 when passed the params (1, 2)
ok 3 capitalize should return "Foo" when passed the param ("foo")
ok 4 reverse should return "oof" when passed the param ("foo")
# tests 4
# pass 4
# fail 0

Done, without errors.
Completed in 0.632s at Wed Jan 08 2014 15:14:44 GMT-0800 (PST) - Waiting...

View the step08 branch on Github.

See the changes between step07 and step08.
Epilogue: Gulp…Is Grunt Already Old News?

As I was about halfway through writing part two of this tutorial, a colleague of mine told me about a new task runner that looks like it may unseat Grunt as the go-to tool for Node.js projects.

Gulp bills itself as “the streaming build system.” It makes heavy use of Node.js streams, eliminating the need to write temporary files to disk as it’s running tasks. Gulp’s API makes creating build tasks a much more clear process. Without going into detail, here’s a gulpfile.js that gets us as close to the same configuration as possible using Gulp.

var fs = require('fs'),
	path = require('path'),
	gulp = require('gulp'),
	jshint = require('gulp-jshint'),
	concat = require('gulp-concat'),
	uglify = require('gulp-uglify'),
	mocha = require('gulp-mocha');

var pkg = JSON.parse(
	fs.readFileSync(path.resolve(__dirname, './package.json'))
);

gulp.task('jshint:dev', function () {
	gulp.src(['gulpfile.js', 'tests/**/*.js'])
		.pipe(jshint({
				maxlen: 80,
				quotmark: 'single'
			}))
		.pipe(jshint.reporter('default'));
});

gulp.task('jshint:app', function () {
	gulp.src(['src/*.js'])
		.pipe(jshint({
				maxlen: 80,
				quotmark: 'single'
			}))
		.pipe(jshint.reporter('default'));
});

gulp.task('test', function () {
	gulp.src(['tests/**/*.js'])
		.pipe(mocha());
});

gulp.task('concat', function () {
	gulp.src(['src/*.js'])
		.pipe(concat(pkg.name + '.js'))
		.pipe(gulp.dest('./build/'));
});

gulp.task('minify', function () {
	gulp.src(['./build/' + pkg.name + '.js'])
		.pipe(uglify())
		.pipe(gulp.dest('./build/min/'));
});


gulp.task('development', function () {
	gulp.watch(['gruntfile.js', 'src/*.js', 'tests/**/*.js'], function () {
		gulp.run('jshint:dev', 'jshint:app', 'test');
	});
});

gulp.task('default', function () {
	gulp.run('jshint:dev', 'jshint:app', 'test', 'concat', 'minify');
});

gulpfile.js 

The major differences in functionality are that we can’t put a banner in the concatenated file, and we can’t put a banner or specify the name of the minified file. This is lack of functionality is in the plugins as opposed to Gulp itself though.

    
        3.2.2 another tutorial, tags: mocha tutorial

            3.2.2.1 INSTALLATION
Install with npm globally:

$ npm install --global mocha
or as a development dependency for your project:

$ npm install --save-dev mocha

            3.2.2.2 setup project
[i500695@WYLQRXL9LQ:2022-03-01 15:48:25:~/work/code/nodejs/tutorial/test/mocha:]2079$ npm init
This utility will walk you through creating a package.json file.
It only covers the most common items, and tries to guess sensible defaults.

See `npm help init` for definitive documentation on these fields
and exactly what they do.

Use `npm install <pkg>` afterwards to install a package and
save it as a dependency in the package.json file.

Press ^C at any time to quit.
package name: (mocha) mocha
version: (1.0.0) 
description: mocha demo
entry point: (index.js) 
test command: test
git repository: 
keywords: mocha demo tutorial
author: yosi izaq
license: (ISC) 
About to write to /Users/i500695/work/code/nodejs/tutorial/test/mocha/package.json:

{
  "name": "mocha",
  "version": "1.0.0",
  "description": "mocha demo",
  "main": "index.js",
  "scripts": {
    "test": "test"
  },
  "keywords": [
    "mocha",
    "demo",
    "tutorial"
  ],
  "author": "yosi izaq",
  "license": "ISC"
}


Is this OK? (yes) y
[i500695@WYLQRXL9LQ:2022-03-01 15:49:12:~/work/code/nodejs/tutorial/test/mocha:]2080$ ls
package.json
[i500695@WYLQRXL9LQ:2022-03-01 15:49:15:~/work/code/nodejs/tutorial/test/mocha:]2081$ cat package.json 
{
  "name": "mocha",
  "version": "1.0.0",
  "description": "mocha demo",
  "main": "index.js",
  "scripts": {
    "test": "test"
  },
  "keywords": [
    "mocha",
    "demo",
    "tutorial"
  ],
  "author": "yosi izaq",
  "license": "ISC"
}
[i500695@WYLQRXL9LQ:2022-03-01 15:49:18:~/work/code/nodejs/tutorial/test/mocha:]2082$ npm install --save-dev mocha

added 80 packages, and audited 81 packages in 959ms

20 packages are looking for funding
  run `npm fund` for details

found 0 vulnerabilities
[i500695@WYLQRXL9LQ:2022-03-01 15:49:31:~/work/code/nodejs/tutorial/test/mocha:]2083$ cat package.json 
{
  "name": "mocha",
  "version": "1.0.0",
  "description": "mocha demo",
  "main": "index.js",
  "scripts": {
    "test": "test"
  },
  "keywords": [
    "mocha",
    "demo",
    "tutorial"
  ],
  "author": "yosi izaq",
  "license": "ISC",
  "devDependencies": {
    "mocha": "^9.2.1"
  }
}
[i500695@WYLQRXL9LQ:2022-03-01 15:49:56:~/work/code/nodejs/tutorial/test/mocha:]2084$ npm i mocha

up to date, audited 81 packages in 818ms

20 packages are looking for funding
  run `npm fund` for details

found 0 vulnerabilities
[i500695@WYLQRXL9LQ:2022-03-01 15:50:00:~/work/code/nodejs/tutorial/test/mocha:]2085$ mkdir test
[i500695@WYLQRXL9LQ:2022-03-01 15:50:14:~/work/code/nodejs/tutorial/test/mocha:]2086$ cd !$
cd test
[i500695@WYLQRXL9LQ:2022-03-01 15:50:15:~/work/code/nodejs/tutorial/test/mocha/test:]2087$ vi test.js

            3.2.2.3 run test 
[i500695@WYLQRXL9LQ:2022-03-01 15:52:44:~/work/code/nodejs/tutorial/test/mocha:]2090$ cat test/test.js 
const assert = require('assert');
describe('Array', function () {
  describe('#indexOf()', function () {
    it('should return -1 when the value is not present', function () {
      assert.equal([1, 2, 3].indexOf(4), -1);
    });
  });
});
[i500695@WYLQRXL9LQ:2022-03-01 15:52:54:~/work/code/nodejs/tutorial/test/mocha:]2091$ ./node_modules/mocha/bin/mocha 


  Array
    #indexOf()
      ✔ should return -1 when the value is not present


  1 passing (2ms)

Set up a test script in package.json:

"scripts": {
  "test": "mocha"
}
Then run tests with:

$ npm test
            3.2.2.4 RUN CYCLE OVERVIEW
Updated for v8.0.0.

The following is a mid-level outline of Mocha’s “flow of execution” when run in Node.js; the “less important” details have been omitted.

In a browser, test files are loaded by <script> tags, and calling mocha.run() begins at step 9 below.

                3.2.2.4.1 SERIAL MODE
User (that’s you) executes mocha
Loads options from config files, if present
Mocha processes any command-line options provided (see section on configuration merging for details)
If known flags for the node executable are found:
Mocha will spawn node in a child process, executing itself with these flags
Otherwise, Mocha does not spawn a child process
Mocha loads modules specified by --require
If a file loaded this way contains known Mocha-specific exports (e.g., root hook plugins), Mocha “registers” these
If not, Mocha ignores any exports of a --require’d module
Mocha validates any custom reporters or interfaces which were loaded via --require or otherwise
Mocha discovers test files; when given no files or directories, it finds files with extensions .js, .mjs or .cjs in the test directory (but not its children), relative to the current working directory
The (default) bdd interface loads the test files in no particular order, which are given an interface-specific global context (this is how, e.g., describe() ends up as a global in a test file)
When a test file is loaded, Mocha executes all of its suites and finds–but does not execute–any hooks and tests therein.
Top-level hooks, tests and suites are all made members of an “invisible” root suite; there is only one root suite for the entire process
Mocha runs global setup fixtures, if any
Starting with the “root” suite, Mocha executes:
Any “before all” hooks (for the root suite, this only happens once; see root hook plugins)
For each test, Mocha executes:
Any “before each” hooks
The test (and reports the result)
Any “after each” hooks
If the current suite has a child suite, repeat the steps in 10. for each child suite; each child suite inherits any “before each” and “after each” hooks defined in its parent
Any “after all” hooks (for the root suite, this only happens once; see root hook plugins)
Mocha prints a final summary/epilog, if applicable
Mocha runs global teardown fixtures, if any

                3.2.2.4.2 #PARALLEL MODE
Repeat steps 1 through 6 from Serial Mode above, skipping reporter validation
All test files found are put into a queue (they are not loaded by the main process)
Mocha runs global setup fixtures, if any
Mocha creates a pool of subprocesses (“workers”)
Immediately before a worker runs the first test it receives, the worker “bootstraps” itself by:
Loading all --require’d modules
Registering any root hook plugins
Ignoring global fixtures and custom reporters
Asserting the built-in or custom interface is valid
When a worker receives a test file to run, the worker creates a new Mocha instance for the single test file, and:
The worker repeats step 8 from above
The worker repeats step 10 from above, with the caveat that the worker does not report test results directly; it holds them in a memory buffer
When the worker completes the test file, buffered results are returned to the main process, which then gives them to the user-specified reporter (spec by default)
The worker makes itself available to the pool; the pool gives the worker another test file to run, if any remain
Mocha prints a final summary/epilog, if applicable
Mocha runs global teardown fixtures, if any
#

                3.2.2.4.3 

            3.2.2.5 DETECTS MULTIPLE CALLS TO DONE()
If you use callback-based async tests, Mocha will throw an error if done() is called multiple times. This is handy for catching accidental double callbacks.
[i500695@WYLQRXL9LQ:2022-03-01 15:59:55:~/work/code/nodejs/tutorial/test/mocha:]2096$ cat test/test.js 
const assert = require('assert');
describe('Array', function () {
  describe('#indexOf()', function () {
      it('should return -1 when the value is not present', function () {
          assert.equal([1, 2, 3].indexOf(4), -1);
      });

      it('double done', function (done) {
          // Calling `done()` twice is an error
          setImmediate(done);
          setImmediate(done);
      });
  });
});
[i500695@WYLQRXL9LQ:2022-03-01 16:00:02:~/work/code/nodejs/tutorial/test/mocha:]2097$ npm test

> mocha@1.0.0 test
> mocha



  Array
    #indexOf()
      ✔ should return -1 when the value is not present
      ✔ double done
      1) double done


  2 passing (3ms)
  1 failing

  1) Array
       #indexOf()
         double done:
     Error: done() called multiple times in test <Array #indexOf() double done> of file /Users/i500695/work/code/nodejs/tutorial/test/mocha/test/test.js
      at processImmediate (node:internal/timers:466:21)

            3.2.2.6 ASSERTIONS
Mocha allows you to use any assertion library you wish. In the above example, we’re using Node.js’ built-in assert module — but generally, if it throws an Error, it will work! This means you can use libraries such as:

should.js - BDD style shown throughout these docs
expect.js - expect() style assertions
chai - expect(), assert() and should-style assertions
better-assert - C-style self-documenting assert()
unexpected - “the extensible BDD assertion toolkit”

            3.2.2.7 ASYNCHRONOUS CODE
By adding an argument (usually named done) to it() to a test callback, Mocha will know that it should wait for this function to be called to complete the test. This callback accepts both an Error instance (or subclass thereof) or a falsy value; anything else is invalid usage and throws an error (usually causing a failed test).

describe('User', function () {
  describe('#save()', function () {
    it('should save without error', function (done) {
      var user = new User('Luna');
      user.save(function (err) {
        if (err) done(err);
        else done();
      });
    });
  });
});
Alternatively, use the done() callback directly (which will handle an error argument, if it exists):

describe('User', function () {
  describe('#save()', function () {
    it('should save without error', function (done) {
      var user = new User('Luna');
      user.save(done);
    });
  });
});


                3.2.2.7.1  working with promises
Alternately, instead of using the done() callback, you may return a Promise. This is useful if the APIs you are testing return promises instead of taking callbacks:

beforeEach(function () {
  return db.clear().then(function () {
    return db.save([tobi, loki, jane]);
  });
});

describe('#find()', function () {
  it('respond with matching records', function () {
    return db.find({type: 'User'}).should.eventually.have.length(3);
  });
});
The latter example uses Chai as Promised for fluent promise assertions.

In Mocha v3.0.0 and newer, returning a Promise and calling done() will result in an exception, as this is generally a mistake:

const assert = require('assert');

// antipattern
it('should complete this test', function (done) {
  return new Promise(function (resolve) {
    assert.ok(true);
    resolve();
  }).then(done);
});
The above test will fail with Error: Resolution method is overspecified. Specify a callback *or* return a Promise; not both.. In versions older than v3.0.0, the call to done() is effectively ignored.

                3.2.2.7.2 USING ASYNC / AWAIT
If your JS environment supports async / await, you can also write asynchronous tests like this:

beforeEach(async function () {
  await db.clear();
  await db.save([tobi, loki, jane]);
});

describe('#find()', function () {
  it('responds with matching records', async function () {
    const users = await db.find({type: 'User'});
    users.should.have.length(3);
  });
});

                3.2.2.7.3 SYNCHRONOUS CODE
When testing synchronous code, omit the callback and Mocha will automatically continue on to the next test.

describe('Array', function () {
  describe('#indexOf()', function () {
    it('should return -1 when the value is not present', function () {
      [1, 2, 3].indexOf(5).should.equal(-1);
      [1, 2, 3].indexOf(0).should.equal(-1);
    });
  });
});


                3.2.2.7.4 ARROW FUNCTIONS
Passing arrow functions (aka “lambdas”) to Mocha is discouraged. Lambdas lexically bind this and cannot access the Mocha context. For example, the following code will fail:

describe('my suite', () => {
  it('my test', () => {
    // should set the timeout of this test to 1000 ms; instead will fail
    this.timeout(1000);
    assert.ok(true);
  });
});
If you do not need to use Mocha’s context, lambdas should work. Be aware that using lambdas will be more painful to refactor if the need eventually arises!

                3.2.2.7.5 
            3.2.2.8 HOOKS
With its default “BDD”-style interface, Mocha provides the hooks before(), after(), beforeEach(), and afterEach(). These should be used to set up preconditions and clean up after your tests.

describe('hooks', function () {
  before(function () {
    // runs once before the first test in this block
  });

  after(function () {
    // runs once after the last test in this block
  });

  beforeEach(function () {
    // runs before each test in this block
  });

  afterEach(function () {
    // runs after each test in this block
  });

  // test cases
});
Tests can appear before, after, or interspersed with your hooks. Hooks will run in the order they are defined, as appropriate; all before() hooks run (once), then any beforeEach() hooks, tests, any afterEach() hooks, and finally after() hooks (once).

#DESCRIBING HOOKS
Any hook can be invoked with an optional description, making it easier to pinpoint errors in your tests. If a hook is given a named function, that name will be used if no description is supplied.

beforeEach(function () {
  // beforeEach hook
});

beforeEach(function namedFun() {
  // beforeEach:namedFun
});

beforeEach('some description', function () {
  // beforeEach:some description
});
#ASYNCHRONOUS HOOKS
All hooks (before(), after(), beforeEach(), afterEach()) may be sync or async as well, behaving much like a regular test-case. For example, you may wish to populate database with dummy content before each test:

describe('Connection', function () {
  var db = new Connection(),
    tobi = new User('tobi'),
    loki = new User('loki'),
    jane = new User('jane');

  beforeEach(function (done) {
    db.clear(function (err) {
      if (err) return done(err);
      db.save([tobi, loki, jane], done);
    });
  });

  describe('#find()', function () {
    it('respond with matching records', function (done) {
      db.find({type: 'User'}, function (err, res) {
        if (err) return done(err);
        res.should.have.length(3);
        done();
      });
    });
  });
});

            3.2.2.9 ROOT-LEVEL HOOKS
A hook defined at the top scope of a test file (outside of a suite) is a root hook.

As of v8.0.0, Root Hook Plugins are the preferred mechanism for setting root hooks.

#DELAYED ROOT SUITE
WARNING: Delayed root suites are incompatible with parallel mode.

If you need to perform asynchronous operations before any of your suites are run (e.g. for dynamically generating tests), you may delay the root suite. Run mocha with the --delay flag. This will attach a special callback function, run(), to the global context:

const assert = require('assert');

const fn = async x => {
  return new Promise(resolve => {
    setTimeout(resolve, 3000, 2 * x);
  });
};

// instead of an IIFE, you can use 'setImmediate' or 'nextTick' or 'setTimeout'
(async function () {
  const z = await fn(3);

  describe('my suite', function () {
    it(`expected value ${z}`, function () {
      assert.strictEqual(z, 6);
    });
  });

  run();
})();


            3.2.2.10 #ROOT-LEVEL HOOKS
A hook defined at the top scope of a test file (outside of a suite) is a root hook.

As of v8.0.0, Root Hook Plugins are the preferred mechanism for setting root hooks.

            3.2.2.11 #DELAYED ROOT SUITE
WARNING: Delayed root suites are incompatible with parallel mode.

If you need to perform asynchronous operations before any of your suites are run (e.g. for dynamically generating tests), you may delay the root suite. Run mocha with the --delay flag. This will attach a special callback function, run(), to the global context:

const assert = require('assert');

const fn = async x => {
  return new Promise(resolve => {
    setTimeout(resolve, 3000, 2 * x);
  });
};

// instead of an IIFE, you can use 'setImmediate' or 'nextTick' or 'setTimeout'
(async function () {
  const z = await fn(3);

  describe('my suite', function () {
    it(`expected value ${z}`, function () {
      assert.strictEqual(z, 6);
    });
  });

  run();
})();

            3.2.2.12 #PENDING TESTS
“Pending” — as in “someone should write these test cases eventually” — test-cases are those without a callback:

describe('Array', function () {
  describe('#indexOf()', function () {
    // pending test below
    it('should return -1 when the value is not present');
  });
});
Pending tests will be included in the test results, and marked as pending. A pending test is not considered a failed test.

Read the inclusive tests section for an example of conditionally marking a test as pending via this.skip().

            3.2.2.13 #EXCLUSIVE TESTS
WARNING: Exclusive tests are incompatible with parallel mode.

The exclusivity feature allows you to run only the specified suite or test-case by appending .only() to the function. Here’s an example of executing only a particular suite:

describe('Array', function () {
  describe.only('#indexOf()', function () {
    // ...
  });
});
Note: All nested suites will still be executed.

Here’s an example of executing an individual test case:

describe('Array', function () {
  describe('#indexOf()', function () {
    it.only('should return -1 unless present', function () {
      // ...
    });

    it('should return the index when present', function () {
      // ...
    });
  });
});
Previous to v3.0.0, .only() used string matching to decide which tests to execute; this is no longer the case. In v3.0.0 or newer, .only() can be used multiple times to define a subset of tests to run:

describe('Array', function () {
  describe('#indexOf()', function () {
    it.only('should return -1 unless present', function () {
      // this test will be run
    });

    it.only('should return the index when present', function () {
      // this test will also be run
    });

    it('should return -1 if called with a non-Array context', function () {
      // this test will not be run
    });
  });
});
You may also choose multiple suites:

describe('Array', function () {
  describe.only('#indexOf()', function () {
    it('should return -1 unless present', function () {
      // this test will be run
    });

    it('should return the index when present', function () {
      // this test will also be run
    });
  });

  describe.only('#concat()', function () {
    it('should return a new Array', function () {
      // this test will also be run
    });
  });

  describe('#slice()', function () {
    it('should return a new Array', function () {
      // this test will not be run
    });
  });
});
But tests will have precedence:

describe('Array', function () {
  describe.only('#indexOf()', function () {
    it.only('should return -1 unless present', function () {
      // this test will be run
    });

    it('should return the index when present', function () {
      // this test will not be run
    });
  });
});
Note: Hooks, if present, will still be executed.

Be mindful not to commit usages of .only() to version control, unless you really mean it! To do so one can run mocha with the option --forbid-only in the continuous integration test command (or in a git precommit hook).

            3.2.2.14 #INCLUSIVE TESTS
This feature is the inverse of .only(). By appending .skip(), you may tell Mocha to ignore test case(s). Anything skipped will be marked as pending, and reported as such. Here’s an example of skipping an individual test:

describe('Array', function () {
  describe('#indexOf()', function () {
    it.skip('should return -1 unless present', function () {
      // this test will not be run
    });

    it('should return the index when present', function () {
      // this test will be run
    });
  });
});
You can also put .skip() on an entire suite. This is equivalent to appending .skip() onto all tests in the suite. Hooks in the suite are also skipped.

describe('Array', function () {
  describe.skip('#indexOf()', function () {
    it('should return -1 unless present', function () {
      // this test will not be run
    });
  });
});
Note: Code in skipped suites, that is placed outside of hooks or tests is still executed, as mocha will still invoke the suite function to build up the suite structure for visualization.

Best practice: Use .skip() instead of commenting tests out.

You may also skip at runtime using this.skip(). If a test needs an environment or configuration which cannot be detected beforehand, a runtime skip is appropriate. For example:

it('should only test in the correct environment', function() {
  if (/* check test environment */) {
    // make assertions
  } else {
    this.skip();
  }
});
The above test will be reported as pending. It’s also important to note that calling this.skip() will effectively abort the test.

Best practice: To avoid confusion, do not execute further instructions in a test or hook after calling this.skip().

Contrast the above test with the following code:

it('should only test in the correct environment', function() {
  if (/* check test environment */) {
    // make assertions
  } else {
    // do nothing
  }
});
Because this test does nothing, it will be reported as passing.

Best practice: Don’t do nothing! A test should make an assertion or use this.skip().

To skip multiple tests in this manner, use this.skip() in a “before all” hook:

before(function() {
  if (/* check test environment */) {
    // setup code
  } else {
    this.skip();
  }
});
This will skip all it, beforeEach/afterEach, and describe blocks within the suite. before/after hooks are skipped unless they are defined at the same level as the hook containing this.skip().

describe('outer', function () {
  before(function () {
    this.skip();
  });

  after(function () {
    // will be executed
  });

  describe('inner', function () {
    before(function () {
      // will be skipped
    });

    after(function () {
      // will be skipped
    });
  });
});
Updated in v7.0.0: skipping a test within an “after all” hook is disallowed and will throw an exception. Use a return statement or other means to abort hook execution.

Before Mocha v3.0.0, this.skip() was not supported in asynchronous tests and hooks.

            3.2.2.15 #RETRY TESTS
You can choose to retry failed tests up to a certain number of times. This feature is designed to handle end-to-end tests (functional tests/Selenium…) where resources cannot be easily mocked/stubbed. It’s not recommended to use this feature for unit tests.

This feature does re-run a failed test and its corresponding beforeEach/afterEach hooks, but not before/after hooks. this.retries() has no effect on failing hooks.

NOTE: Example below was written using Selenium webdriver (which overwrites global Mocha hooks for Promise chain).

describe('retries', function () {
  // Retry all tests in this suite up to 4 times
  this.retries(4);

  beforeEach(function () {
    browser.get('http://www.yahoo.com');
  });

  it('should succeed on the 3rd try', function () {
    // Specify this test to only retry up to 2 times
    this.retries(2);
    expect($('.foo').isDisplayed()).to.eventually.be.true;
  });
});

            3.2.2.16 DYNAMICALLY GENERATING TESTS , todo: write demo
- my demo:
[i500695@WYLQRXL9LQ:2022-03-02 14:08:06:~/work/code/nodejs/tutorial/test/mocha:]2106$ cat test/test.js 
const assert = require('assert');
describe('Array', function () {
  describe('#indexOf()', function () {
      it('should return -1 when the value is not present', function () {
          assert.equal([1, 2, 3].indexOf(4), -1);
      });

      it('double done', function (done) {
          // Calling `done()` twice is an error
          setImmediate(done);
          setImmediate(done);
      });
  });
});

function mult(args) {
    return args.reduce(( prv, cur) => prv*cur, 1);
}

describe('test mult function', function() {
    const test_inputs_outputs = [
        {args: [1,2,3], expected: 6},
        {args: [], expected: 1},
        {args: [-1,2,3], expected: -6},
        {args: [3], expected: 3},
        {args: [1,2,3,4,5,6], expected: 720},
        {args: [1,2,3,4], expected: 24}
    ];

    test_inputs_outputs.forEach(({args, expected}) => {
        it(`test multiplication of ${args}, should be ${expected}`, function() {
            const result = mult(args);
            assert.strictEqual(result, expected);
        });
    });
});
[i500695@WYLQRXL9LQ:2022-03-02 14:08:11:~/work/code/nodejs/tutorial/test/mocha:]2107$ npm test

> mocha@1.0.0 test
> mocha



  Array
    #indexOf()
      ✔ should return -1 when the value is not present
      ✔ double done
      1) double done

  test mult function
    ✔ test multiplication of 1,2,3, should be 6
    ✔ test multiplication of , should be 1
    ✔ test multiplication of -1,2,3, should be -6
    ✔ test multiplication of 3, should be 3
    ✔ test multiplication of 1,2,3,4,5,6, should be 720
    ✔ test multiplication of 1,2,3,4, should be 24


  8 passing (4ms)
  1 failing

  1) Array
       #indexOf()
         double done:
     Error: done() called multiple times in test <Array #indexOf() double done> of file /Users/i500695/work/code/nodejs/tutorial/test/mocha/test/test.js
      at processImmediate (node:internal/timers:466:21)


- explanation
Given Mocha’s use of function expressions to define suites and test cases, it’s straightforward to generate your tests dynamically. No special syntax is required — plain ol’ JavaScript can be used to achieve functionality similar to “parameterized” tests, which you may have seen in other frameworks.

Take the following example:

const assert = require('assert');

function add(args) {
  return args.reduce((prev, curr) => prev + curr, 0);
}

describe('add()', function () {
  const tests = [
    {args: [1, 2], expected: 3},
    {args: [1, 2, 3], expected: 6},
    {args: [1, 2, 3, 4], expected: 10}
  ];

  tests.forEach(({args, expected}) => {
    it(`correctly adds ${args.length} args`, function () {
      const res = add(args);
      assert.strictEqual(res, expected);
    });
  });
});
The above code will produce a suite with three specs:

$ mocha

  add()
    ✓ correctly adds 2 args
    ✓ correctly adds 3 args
    ✓ correctly adds 4 args
Tests added inside a .forEach handler often don’t play well with editor plugins, especially with “right-click run” features. Another way to parameterize tests is to generate them with a closure. This following example is equivalent to the one above:

describe('add()', function () {
  const testAdd = ({args, expected}) =>
    function () {
      const res = add(args);
      assert.strictEqual(res, expected);
    };

  it('correctly adds 2 args', testAdd({args: [1, 2], expected: 3}));
  it('correctly adds 3 args', testAdd({args: [1, 2, 3], expected: 6}));
  it('correctly adds 4 args', testAdd({args: [1, 2, 3, 4], expected: 10}));
});
With top-level await you can collect your test data in a dynamic and asynchronous way while the test file is being loaded.
See also --delay for CommonJS modules without top-level await.

// testfile.mjs
import assert from 'assert';

// top-level await: Node >= v14.8.0 with ESM test file
const tests = await new Promise(resolve => {
  setTimeout(resolve, 5000, [
    {args: [1, 2], expected: 3},
    {args: [1, 2, 3], expected: 6},
    {args: [1, 2, 3, 4], expected: 10}
  ]);
});

// in suites ASYNCHRONOUS callbacks are NOT supported
describe('add()', function () {
  tests.forEach(({args, expected}) => {
    it(`correctly adds ${args.length} args`, function () {
      const res = args.reduce((sum, curr) => sum + curr, 0);
      assert.strictEqual(res, expected);
    });
  });
});

            3.2.2.17 TEST DURATION
Many reporters will display test duration and flag tests that are slow (default: 75ms), as shown here with the SPEC reporter:

test duration

There are three levels of test duration (depicted in the following image):

FAST: Tests that run within half of the “slow” threshold will show the duration in green (if at all).
NORMAL: Tests that run exceeding half of the threshold (but still within it) will show the duration in yellow.
SLOW: Tests that run exceeding the threshold will show the duration in red.
test duration range

To tweak what’s considered “slow”, you can use the slow() method:

describe('something slow', function () {
  this.slow(300000); // five minutes

  it('should take long enough for me to go make a sandwich', function () {
    // ...
  });
});

my demo:

            3.2.2.18 TIMEOUTS
#SUITE-LEVEL
Suite-level timeouts may be applied to entire test “suites”, or disabled via this.timeout(0). This will be inherited by all nested suites and test-cases that do not override the value.

describe('a suite of tests', function () {
  this.timeout(500);

  it('should take less than 500ms', function (done) {
    setTimeout(done, 300);
  });

  it('should take less than 500ms as well', function (done) {
    setTimeout(done, 250);
  });
});
#TEST-LEVEL
Test-specific timeouts may also be applied, or the use of this.timeout(0) to disable timeouts all together:

it('should take less than 500ms', function (done) {
  this.timeout(500);
  setTimeout(done, 300);
});
#HOOK-LEVEL
Hook-level timeouts may also be applied:

describe('a suite of tests', function () {
  beforeEach(function (done) {
    this.timeout(3000); // A very long environment setup.
    setTimeout(done, 2500);
  });
});
Again, use this.timeout(0) to disable the timeout for a hook.

In v3.0.0 or newer, a parameter passed to this.timeout() greater than the maximum delay value will cause the timeout to be disabled. In v8.0.0 or newer, this.enableTimeouts() has been removed. Warning: With async tests if you disable timeouts via this.timeout(0) and then do not call done(), your test will exit silently.

- demo 
    -- run 
[i500695@WYLQRXL9LQ:2022-03-02 17:32:59:~/work/code/nodejs/tutorial/test/mocha:]2146$ npm test

> mocha@1.0.0 test
> mocha --inline-diffs



  Array
    #indexOf()
      ✔ should return -1 when the value is not present
      ✔ double done
      1) double done

  test mult function
    ✔ test multiplication of 1,2,3, should be 6
    ✔ test multiplication of , should be 1
    ✔ test multiplication of -1,2,3, should be -6
    ✔ test multiplication of 3, should be 3
    ✔ test multiplication of 1,2,3,4,5,6, should be 720
    ✔ test multiplication of 1,2,3,4, should be 24

  test slow function
    ✔ fast test < 30sec
normal test will give error:  Error: Resolution method is overspecified. Specify a callback *or* return a Promise; not both. Reason async function returns promise and done() is another promise
fast action
    2) normal test 60> test time > 30sec
    ✔ slow test > 60sec


  10 passing (35s)
  2 failing

  1) Array
       #indexOf()
         double done:
     Error: done() called multiple times in test <Array #indexOf() double done> of file /Users/i500695/work/code/nodejs/tutorial/test/mocha/test/test.js
      at processImmediate (node:internal/timers:466:21)

  2) test slow function
       normal test 60> test time > 30sec:
     Error: Resolution method is overspecified. Specify a callback *or* return a Promise; not both.
      at Context.<anonymous> (test/test.js:49:9)


    -- code
[i500695@WYLQRXL9LQ:2022-03-02 17:32:56:~/work/code/nodejs/tutorial/test/mocha:]2145$ cat !$
cat test/test.js
const assert = require('assert');
describe('Array', function () {
  describe('#indexOf()', function () {
      it('should return -1 when the value is not present', function () {
          assert.equal([1, 2, 3].indexOf(4), -1);
      });

      it('double done', function (done) {
          // Calling `done()` twice is an error
          setImmediate(done);
          setImmediate(done);
      });
  });
});

function mult(args) {
    return args.reduce(( prv, cur) => prv*cur, 1);
}

describe('test mult function', function() {
    const test_inputs_outputs = [
        {args: [1,2,3], expected: 6},
        {args: [], expected: 1},
        {args: [-1,2,3], expected: -6},
        {args: [3], expected: 3},
        {args: [1,2,3,4,5,6], expected: 720},
        {args: [1,2,3,4], expected: 24}
    ];

    test_inputs_outputs.forEach(({args, expected}) => {
        it(`test multiplication of ${args}, should be ${expected}`, function() {
            const result = mult(args);
            assert.strictEqual(result, expected);
        });
    });
});

describe('test slow function', async function() {
    this.slow(60000); // 1 minute. so >1 slow, 30-60 seconds normal, <30 fast 
   
    it('fast test < 30sec', async function() {
        setTimeout(() => {console.log('fast action');}, 5000);
        //await new Promise(res => setTimeout(res, 5000));
        //done()
    }).timeout(70000);
    it('normal test 60> test time > 30sec', async function(done) {
        console.log('normal test will give error:  Error: Resolution method is overspecified. Specify a callback *or* return a Promise; not both. Reason async function returns promise and done() is another promise');
        await new Promise(res => setTimeout(res, 35000));
        done()
     }).timeout(70000);
    it('slow test > 60sec', async function() {
        setTimeout(() => {console.log('fast action');}, 61000);
    }).timeout(70000);
});

            3.2.2.19 inline-diffs
code:
describe('inline-diff demo', function() {
    it('test inline-diff', function() {
        const expected = {
            name: 'yosi',
            surname: 'izaq'
        };
        assert.strictEqual(expected, {
            name: 'yosii',
            surname: 'itzak'
        });
    });
});

run:
[i500695@WYLQRXL9LQ:2022-03-02 17:42:36:~/work/code/nodejs/tutorial/test/mocha:]2153$ grep test package.json 
    "test": "mocha --inline-diffs"

demo:
  2) inline-diff demo
       test inline-diff:

      AssertionError [ERR_ASSERTION]: Expected "actual" to be reference-equal to "expected":
+ actual - expected

  {
+   name: 'yosi',
+   surname: 'izaq'
-   name: 'yosii',
-   surname: 'itzak'
  }      
      actual expected
      
      {
        "name": "yosiyosii"
        "surname": "izaqitzak"
      }
      
      at Context.<anonymous> (test/test.js:44:16)
      at processImmediate (node:internal/timers:466:21)

            3.2.2.20 COMMAND-LINE USAGE
mocha [spec..]

Run tests with Mocha

Commands
  mocha inspect [spec..]  Run tests with Mocha                         [default]
  mocha init <path>       create a client-side Mocha setup at <path>

Rules & Behavior
      --allow-uncaught       Allow uncaught errors to propagate        [boolean]
  -A, --async-only           Require all tests to use a callback (async) or
                             return a Promise                          [boolean]
  -b, --bail                 Abort ("bail") after first test failure   [boolean]
      --check-leaks          Check for global variable leaks           [boolean]
      --delay                Delay initial execution of root suite     [boolean]
      --dry-run              Report tests without executing them       [boolean]
      --exit                 Force Mocha to quit after tests complete  [boolean]
      --fail-zero            Fail test run if no test(s) encountered   [boolean]
      --forbid-only          Fail if exclusive test(s) encountered     [boolean]
      --forbid-pending       Fail if pending test(s) encountered       [boolean]
      --global, --globals    List of allowed global variables            [array]
  -j, --jobs                 Number of concurrent jobs for --parallel; use 1 to
                             run in serial
                                   [number] [default: (number of CPU cores - 1)]
  -p, --parallel             Run tests in parallel                     [boolean]
      --retries              Retry failed tests this many times         [number]
  -s, --slow                 Specify "slow" test threshold (in milliseconds)
                                                          [string] [default: 75]
  -t, --timeout, --timeouts  Specify test timeout threshold (in milliseconds)
                                                        [string] [default: 2000]
  -u, --ui                   Specify user interface    [string] [default: "bdd"]

Reporting & Output
  -c, --color, --colors                     Force-enable color output  [boolean]
      --diff                                Show diff on failure
                                                       [boolean] [default: true]
      --full-trace                          Display full stack traces  [boolean]
  -G, --growl                               Enable Growl notifications [boolean]
      --inline-diffs                        Display actual/expected differences
                                            inline within each string  [boolean]
  -R, --reporter                            Specify reporter to use
                                                      [string] [default: "spec"]
  -O, --reporter-option,                    Reporter-specific options
  --reporter-options                        (<k=v,[k1=v1,..]>)           [array]

Configuration
      --config       Path to config file   [string] [default: (nearest rc file)]
  -n, --node-option  Node or V8 option (no leading "--")                 [array]
      --package      Path to package.json for config                    [string]

File Handling
      --extension          File extension(s) to load
                                           [array] [default: ["js","cjs","mjs"]]
      --file               Specify file(s) to be loaded prior to root suite
                           execution                   [array] [default: (none)]
      --ignore, --exclude  Ignore file(s) or glob pattern(s)
                                                       [array] [default: (none)]
      --recursive          Look for tests in subdirectories            [boolean]
  -r, --require            Require module              [array] [default: (none)]
  -S, --sort               Sort test files                             [boolean]
  -w, --watch              Watch files in the current working directory for
                           changes                                     [boolean]
      --watch-files        List of paths or globs to watch               [array]
      --watch-ignore       List of paths or globs to exclude from watching
                                      [array] [default: ["node_modules",".git"]]

Test Filters
  -f, --fgrep   Only run tests containing this string                   [string]
  -g, --grep    Only run tests matching this string or regexp           [string]
  -i, --invert  Inverts --grep and --fgrep matches                     [boolean]

Positional Arguments
  spec  One or more files, directories, or globs to test
                                                     [array] [default: ["test"]]

Other Options
  -h, --help             Show usage information & exit                 [boolean]
  -V, --version          Show version number & exit                    [boolean]
      --list-interfaces  List built-in user interfaces & exit          [boolean]
      --list-reporters   List built-in reporters & exit                [boolean]

Mocha Resources
    Chat: https://gitter.im/mochajs/mocha
  GitHub: https://github.com/mochajs/mocha.git
    Docs: https://mochajs.org/

            3.2.2.21
        3.2.3


    3.3 sinon

        3.3.1 https://www.sitepoint.com/sinon-tutorial-javascript-testing-mocks-spies-stubs/
In real life projects, code often does all kinds of things that make testing hard. Ajax requests, timers, dates, accessing other browser features… or if you’re using Node.js, databases are always fun, and so is network or file access.

All of these are hard to test because you can’t control them in code. If you’re using Ajax, you need a server to respond to the request, so as to make your tests pass. If you use setTimeout, your test will have to wait. With databases or networking, it’s the same thing — you need a database with the correct data, or a network server.

Real-life isn’t as easy as many testing tutorials make it look. But did you know there is a solution?

By using Sinon, we can make testing non-trivial code trivial!

Let’s find out how.
What Makes Sinon so Important and Useful?

Put simply, Sinon allows you to replace the difficult parts of your tests with something that makes testing simple.

When testing a piece of code, you don’t want to have it affected by anything outside the test. If something external affects a test, the test becomes much more complex and could fail randomly.

If you want to test code making an Ajax call, how can you do that? You need to run a server and make sure it gives the exact response needed for your test. It’s complicated to set up, and makes writing and running unit tests difficult.

And what if your code depends on time? Let’s say it waits one second before doing something. What now? You could use a setTimeout in your test to wait one second, but that makes the test slow. Imagine if the interval was longer, for example five minutes. I’m going to guess you probably don’t want to wait five minutes each time you run your tests.

By using Sinon, we can take both of these issues (plus many others), and eliminate the complexity.
How Does Sinon Work?

Sinon helps eliminate complexity in tests by allowing you to easily create so called test-doubles.

Test-doubles are, like the name suggests, replacements for pieces of code used in your tests. Looking back at the Ajax example, instead of setting up a server, we would replace the Ajax call with a test-double. With the time example, we would use test-doubles to allow us to “travel forwards in time”.

It may sound a bit weird, but the basic concept is simple. Because JavaScript is very dynamic, we can take any function and replace it with something else. Test-doubles just take this idea a little bit further. With Sinon, we can replace any JavaScript function with a test-double, which can then be configured to do a variety of things to make testing complex things simple.

Sinon splits test-doubles into three types:

    Spies, which offer information about function calls, without affecting their behavior
    Stubs, which are like spies, but completely replace the function. This makes it possible to make a stubbed function do whatever you like — throw an exception, return a specific value, etc
    Mocks, which make replacing whole objects easier by combining both spies and stubs

In addition, Sinon also provides some other helpers, although these are outside the scope of this article:

    Fake timers, which can be used to travel forwards in time, for example triggering a setTimeout
    Fake XMLHttpRequest and server, which can be used to fake Ajax requests and responses

With these features, Sinon allows you to solve all of the difficult problems external dependencies cause in your tests. If you learn the tricks for using Sinon effectively, you won’t need any other tools.
Installing Sinon

            3.3.1.1 install Sinon.

For Node.js testing:

    Install Sinon via npm using npm install sinon
    Require Sinon in your test with var sinon = require('sinon');

For browser based testing:

    You can either install Sinon via npm with npm install sinon, use a CDN, or download it from Sinon’s website
    Include sinon.js in your test runner page.

Getting Started

Sinon has a lot of functionality, but much of it builds on top of itself. You learn about one part, and you already know about the next one. This makes Sinon easy to use once you learn the basics and know what each different part does.

We usually need Sinon when our code calls a function which is giving us trouble.

With Ajax, it could be $.get or XMLHttpRequest. With time, the function might be setTimeout. With databases, it could be mongodb.findOne.

To make it easier to talk about this function, I’m going to call it the dependency. The function we are testing depends on the result of another function.

We can say, the basic use pattern with Sinon is to replace the problematic dependency with a test-double.

    When testing Ajax, we replace XMLHttpRequest with a test-double which pretends to make an Ajax request
    When testing time, we replace setTimeout with a pretend timer
    When testing database access, we could replace mongodb.findOne with a test-double which immediately returns some fake data

Let’s see how that works in practice.

            3.3.1.2 Spies

Spies are the simplest part of Sinon, and other functionality builds on top of them.

The primary use for spies is to gather information about function calls. You can also use them to help verify things, such as whether a function was called or not.

var spy = sinon.spy();

//We can call a spy like a function
spy('Hello', 'World');

//Now we can get information about the call
console.log(spy.firstCall.args); //output: ['Hello', 'World']

The function sinon.spy returns a Spy object, which can be called like a function, but also contains properties with information on any calls made to it. In the example above, the firstCall property has information about the first call, such as firstCall.args which is the list of arguments passed.

Although you can create anonymous spies as above by calling sinon.spy with no parameters, a more common pattern is to replace another function with a spy.

var user = {
  ...
  setName: function(name){
    this.name = name;
  }
}

//Create a spy for the setName function
var setNameSpy = sinon.spy(user, 'setName');

//Now, any time we call the function, the spy logs information about it
user.setName('Darth Vader');

//Which we can see by looking at the spy object
console.log(setNameSpy.callCount); //output: 1

//Important final step - remove the spy
setNameSpy.restore();

Replacing another function with a spy works similarly to the previous example, with one important difference: When you’ve finished using the spy, it’s important to remember to restore the original function, as in the last line of the example above. Without this your tests may misbehave.

Spies have a lot of different properties, which provide different information on how they were used. Sinon’s spy documentation has a comprehensive list of all available options.

In practice, you might not use spies very often. You’re more likely to need a stub, but spies can be convenient for example to verify a callback was called:

function myFunction(condition, callback){
  if(condition){
    callback();
  }
}

describe('myFunction', function() {
  it('should call the callback function', function() {
    var callback = sinon.spy();

    myFunction(true, callback);

    assert(callback.calledOnce);
  });
});

In this example I am using Mocha as the test framework and Chai as the assertion library. If you would like to learn more about either of these, then please consult my previous article: Unit Test Your JavaScript Using Mocha and Chai.

            3.3.1.3 Sinon’s Assertions

Before we carry on and talk about stubs, let’s take a quick detour and look at Sinon’s assertions.

In most testing situations with spies (and stubs), you need some way of verifying the result of the test.

We can use any kind of assertion to verify the results. In the previous example with the callback, we used Chai’s assert function which ensures the value is truthy.

assert(callback.calledOnce);

The problem with this is that the error message in a failure is unclear. You’ll simply be told “false was not true”, or some variation of that. As you can probably imagine, it’s not very helpful in finding out what went wrong, and you need to go look at the source code for the test to figure it out. Not fun.

To fix the problem, we could include a custom error message into the assertion.

assert(callback.calledOnce, 'Callback was not called once');

But why bother when we can use Sinon’s own assertions?

describe('myFunction', function() {
  it('should call the callback function', function() {
    var callback = sinon.spy();

    myFunction(true, callback);

    sinon.assert.calledOnce(callback);
  });
});

Using Sinon’s assertions like this gives us a much better error message out of the box. This becomes very useful when you need to verify more complex condition, such as the parameters to a function.

Here are some examples of other useful assertions provided by Sinon:

    sinon.assert.calledWith can be used to verify the a function was called with specific parameters (this is probably the one I use most often)
    sinon.assert.callOrder can verify functions were called in a specific order

As with spies, Sinon’s assertion documentation has all the options available. If you like using Chai, there is also a sinon-chai plugin available, which lets you use Sinon assertions through Chai’s expect or should interface.

            3.3.1.4 Stubs

Stubs are the go-to test-double because of their flexibility and convenience. They have all the functionality of spies, but instead of just spying on what a function does, a stub completely replaces it. In other words, when using a spy, the original function still runs, but when using a stub, it doesn’t.

This makes stubs perfect for a number of tasks, such as:

    Replacing Ajax or other external calls which make tests slow and difficult to write
    Triggering different code paths depending on function output
    Testing unusual conditions, for example what happens when an exception is thrown?

We can create stubs in a similar way to spies…

var stub = sinon.stub();

stub('hello');

console.log(stub.firstCall.args); //output: ['hello']

We can create anonymous stubs as with spies, but stubs become really useful when you use them to replace existing functions.

For example, if we have some code that uses jQuery’s Ajax functionality, testing it is difficult. The code sends a request to whatever server we’ve configured, so we need to have it available, or add a special case to the code to not do that in a test environment — which is a big no-no. You should almost never have test-specific cases in your code.

Instead of resorting to poor practices, we can use Sinon and replace the Ajax functionality with a stub. This makes testing it trivial.

Here’s an example function we’ll test. It takes an object as its parameter, and sends it via Ajax to a predefined URL.

function saveUser(user, callback) {
  $.post('/users', {
    first: user.firstname,
    last: user.lastname
  }, callback);
}

Normally, testing this would be difficult because of the Ajax call and predefined URL, but if we use a stub, it becomes easy.

Let’s say we want to ensure the callback function passed to saveUser is called correctly once the request finishes.

describe('saveUser', function() {
  it('should call callback after saving', function() {

    //We'll stub $.post so a request is not sent
    var post = sinon.stub($, 'post');
    post.yields();

    //We can use a spy as the callback so it's easy to verify
    var callback = sinon.spy();

    saveUser({ firstname: 'Han', lastname: 'Solo' }, callback);

    post.restore();
    sinon.assert.calledOnce(callback);
  });
});

Here, we replace the Ajax function with a stub. This means the request is never sent, and we don’t need a server or anything — we have full control over what happens in our test code!

As we want to ensure the callback we pass into saveUser gets called, we’ll instruct the stub to yield. This means the stub automatically calls the first function passed as a parameter to it. This mimics the behavior of $.post, which would call a callback once the request has finished.

In addition to a stub, we’re creating a spy in this test. We could use a normal function as the callback, but using a spy makes it easy to verify the result of the test using Sinon’s sinon.assert.calledOnce assertion.

In most cases when you need a stub, you can follow the same basic pattern:

    Find the problematic function, such as $.post
    Look at how it works so you can mimic it in the test
    Create a stub
    Set the stub to have the behavior you want in your test

The stub doesn’t need to mimic every behavior. Only the behavior you need for the test is necessary, and anything else can be left out.

Another common usage for stubs is verifying a function was called with a specific set of arguments.

For example, for our Ajax functionality, we want to ensure the correct values are being sent. Therefore, we could have something like:

describe('saveUser', function() {
  it('should send correct parameters to the expected URL', function() {

    //We'll stub $.post same as before
    var post = sinon.stub($, 'post');

    //We'll set up some variables to contain the expected results
    var expectedUrl = '/users';
    var expectedParams = {
      first: 'Expected first name',
      last: 'Expected last name'
    };

    //We can also set up the user we'll save based on the expected data
    var user = {
      firstname: expectedParams.first,
      lastname: expectedParams.last
    }

    saveUser(user, function(){} );
    post.restore();

    sinon.assert.calledWith(post, expectedUrl, expectedParams);
  });
});

Again, we create a stub for $.post(), but this time we don’t set it to yield. This test doesn’t care about the callback, therefore having it yield is unnecessary.

We set up some variables to contain the expected data — the URL and the parameters. It’s a good practice to set up variables like this, as it makes it easy to see at a glance what the requirements for the test are. It also helps us set up the user variable without repeating the values.

This time we used the sinon.assert.calledWith() assertion. We pass the stub as its first parameter, because this time we want to verify the stub was called with the correct parameters.

There’s also another way of testing Ajax requests in Sinon. This is by using Sinon’s fake XMLHttpRequest functionality. We won’t go into detail on it here, but if you want to learn how that works, see my article on Ajax testing with Sinon’s fake XMLHttpRequest.

            3.3.1.5 Mocks

Mocks are a different approach to stubs. If you’ve heard the term “mock object”, this is the same thing — Sinon’s mocks can be used to replace whole objects and alter their behavior similar to stubbing functions.

They are primarily useful if you need to stub more than one function from a single object. If you only need to replace a single function, a stub is easier to use.

You should take care when using mocks! Because of their power, it’s easy to make your tests overly specific — test too many and too specific things — which risks making your tests unintentionally brittle.

Unlike spies and stubs, mocks have assertions built-in. You define your expected results up front by telling the mock object what needs to happen, and then calling the verification function at the end of the test.

Let’s say we’re using store.js to save things into localStorage, and we want to test a function related to that. We can use a mock to help testing it like so:

describe('incrementStoredData', function() {
  it('should increment stored value by one', function() {
    var storeMock = sinon.mock(store);
    storeMock.expects('get').withArgs('data').returns(0);
    storeMock.expects('set').once().withArgs('data', 1);

    incrementStoredData();

    storeMock.restore();
    storeMock.verify();
  });
});

When using mocks, we define the expected calls and their results using a fluent calling style as seen above. This is the same as using assertions to verify test results, except we define them up-front, and to verify them, we call storeMock.verify() at the end of the test.

In Sinon’s mock object terminology, calling mock.expects('something') creates an expectation. As in, the method mock.something() expects to be called. Each expectation, in addition to mock-specific functionality, supports the same functions as spies and stubs.

You may find that it’s often much easier to use a stub than a mock — and that’s perfectly fine. Mocks should be used with care.

For a full list of mock-specific functions, check Sinon’s mock documentation.
Important Best Practice: Use sinon.test()

There is one important best practice with Sinon that should be remembered whenever using spies, stubs or mocks.

If you replace an existing function with a test-double, use sinon.test().

In the earlier example, we used stub.restore() or mock.restore() to clean up after using them. This is necessary as otherwise the test-double remains in place, and could negatively affect other tests or cause errors.

But using the restore() function directly is problematic. It’s possible that the function being tested causes an error and ends the test function before restore() has been called!

We have two ways to solve this: We can wrap the whole thing in a try catch block. This allows us to put the restore() call in a finally block, ensuring it gets run no matter what.

Or, a better approach, we can wrap the test function with sinon.test()

it('should do something with stubs', sinon.test(function() {
  var stub = this.stub($, 'post');

  doSomething();

  sinon.assert.calledOnce(stub);
});

In the above example, note the second parameter to it() is wrapped within sinon.test(). The second thing of note is that we use this.stub() instead of sinon.stub().

Wrapping a test with sinon.test() allows us to use Sinon’s sandboxing feature, allowing us to create spies, stubs and mocks via this.spy(), this.stub() and this.mock(). Any test-doubles you create using sandboxing are cleaned up automatically.

Note that our example code above has no stub.restore() — it’s unnecessary thanks to the test being sandboxed.

If you use sinon.test() where possible, you can avoid problems where tests start failing randomly because an earlier test didn’t clean up its test-doubles due to an error.
Sinon Is Not Magic

Sinon does many things, and occasionally it might seem difficult to understand how it works. Let’s take a look at some plain JavaScript examples of how Sinon works, so we can get a better idea of what it does under the hood. This will help you use it more effectively in different situations.

We can create spies, stubs and mocks manually too. The reason we use Sinon is it makes the task trivial — creating them manually can be quite complicated, but let’s see how that works, to understand what Sinon does.

First, a spy is essentially a function wrapper:

//A simple spy helper
function createSpy(targetFunc) {
  var spy = function() {
    spy.args = arguments;
    spy.returnValue = targetFunc.apply(this, arguments);
    return spy.returnValue;
  };

  return spy;
}

//Let's spy on a simple function:
function sum(a, b) { return a + b; }

var spiedSum = createSpy(sum);

spiedSum(10, 5);

console.log(spiedSum.args); //Output: [10, 5]
console.log(spiedSum.returnValue); //Output: 15

We can get spy functionality quite easily with a custom function like so. But notice that Sinon’s spies provide a much wider array of functionality — including assertion support. This makes Sinon a lot more convenient.
What about a Stub Then?

To make a really simple stub, you can simply replace a function with a new one:

var stub = function() { };

var original = thing.otherFunction;
thing.otherFunction = stub;

//Now any calls to thing.otherFunction will call our stub instead

But again, there are several advantages Sinon’s stubs provide:

    They have the full spy functionality in them
    You can restore original behavior easily with stub.restore()
    You can assert against Sinon stubs

Mocks simply combine the behavior of spies and stubs, making it possible to use their features in different ways.

Even though Sinon may sometimes seem like it does a lot of “magic”, this can be done fairly easily with your own code too, for the most part. Sinon is just much more convenient to use, than having to write your own library for the purpose.
Conclusion

Testing real-life code can sometimes seem way too complex and it’s easy to give up altogether. But with help from Sinon, testing virtually any kind of code becomes a breeze.

Just remember the main principle: If a function makes your test difficult to write, try replacing it with a test-double. This principle applies regardless of what the function does.

Looking to learn more about how to apply Sinon with your own code? Head over to my site and I’ll send you my free Sinon in the real-world guide, which includes Sinon best practices, and three real-world examples of how to apply it in different types of testing situations!

        3.3.2 my example
- test
[i500695@C02X632CJGH6:2018-11-06 12:07:49:~/Desktop/work/code/nodejs/tutorial:]533$ grunt --force

- code
r~/Desktop/work/code/nodejs/tutorial/sinonDemo.js
class User{

        constructor (fname, lname){
                this.fname = fname;
                this.lname = lname;
        }

        getName()
        {
                return this.fname +" "+this.lname;
        }

        sleep(ms){
                return new Promise(resolve => setTimeout(resolve,ms));
        }

        async saveToDB()
        {
                console.log("sleeping...");
                await this.sleep(2000);
                console.log("woke up 2 sec later");
        }

        setName(fname,lname){
                this.fname = fname;
                this.lname = lname;
        }

        callSetThenGetName(){
                console.log("callSetThenGetName()");
                this.setName(this.fname, this.lname);
                this.saveToDB();
                this.getName();
        }
}

r~/Desktop/work/code/nodejs/tutorial/sinonDemoManager.js
user = require('./sinonDemo.js');

class Manager{
        constructor(name){
                this.name =name;
        }

        hireNewEmployee( user)
        {
            console.log("hireNewEmployee()");
            user.callSetThenGetName();
        }
} 
module.exports = Manager ;

r~/Desktop/work/code/nodejs/tutorial/test/UserTests.js
var expect = require('chai').expect;
var assert = require('chai').assert;
const User = require('../sinonDemo.js');
const Manager = require('../sinonDemoManager.js');

var sinon = require('sinon');

//spy keeps tab on target function calls. letting you know how many times it was called and with which arguments
describe ("getName", function(){

        it('should call getName once', function(){
                yosi = new User('yosi', 'izaq');
                var getNameSpy = sinon.spy(User.prototype, "getName"); //stub class getName
                //var getNameSpy = sinon.spy(yosi, "getName"); //stub single instance getName

                yosi.getName();

                getNameSpy.restore();
                assert(getNameSpy.calledOnce);
        });
});



//sinon stubs repace a method so we can verify the method was called but avoid running blocking methods (like waiting for external server response)
//describe.skip and xit instead of it -> skip tests 
describe("saveToDB", function(){

        it('should call saveToDB but use a stub to avoid waiting', function(){
                yosi = new User('yosi', 'izaq');
                var saveToDBStub = sinon.stub(yosi, "saveToDB");

                yosi.saveToDB();

                //saveToDBStub.should.have.been.called();
                saveToDBStub.restore();
                assert(saveToDBStub.called);
        });
});

//sinon mock gives full power to mimic method calls expected results.
describe ('hireNewEmployee', function(){
        it('should create a user and call hireNewEmployee', function(){
        yosi = new User('yosi', 'izaq');
        var userMock = sinon.mock(yosi) ;
        //var userMock = sinon.mock(User.prototype) ;

        userMock.expects('setName').once().withArgs(yosi.fname, yosi.lname);
        userMock.expects('saveToDB').once().withArgs();
        userMock.expects('getName').once().withArgs().returns('yosi');
        manager = new Manager("guy mosko");
        manager.hireNewEmployee(yosi);

        userMock.verify();
        userMock.restore();

        });
});


        3.3.3
    3.4 My grunt file examples


        3.4.1  /Users/i500695/Desktop/work/code/nodejs/tutorial

[i500695@C02X632CJGH6:2018-10-29 16:51:20:~/Desktop/work/code/nodejs/tutorial:]519$ cat Gruntfile.js 
module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

        // section 1 - require modules
    require('load-grunt-tasks')(grunt);

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
                eslint: {
            options: {
                config: 'eslint.json',
                reset: true
            },
            target: ['*.js']
        },
        // task for mocha tests execution, they would be executed by nyc
        mochaTest: {
            local: {
                options: {
                    reporter: 'spec'
                },
                src: ['test/*.js']
            }
        },
        // nyc - executes mochaTest task
        nyc: {
            local: {
                options: {
                    all: true,
                    exclude: [
                        "**/*.spec.js",
                        "**/Gruntfile.js",
                        "**/Mock*",
                        "**/coverage",
                        "**/resources"
                    ],
                    reporter: ['text-summary', 'html'],
                    checkCoverage: true,
                    lines: 90
                },
                cmd: false,
                args: ['grunt', 'mochaTest:local', '--force']
            }
        }
	});


// section 3 - register grunt tasks
        //    grunt.loadNpmTasks('gruntify-eslint');
    grunt.loadNpmTasks('grunt-mocha-test');
    grunt.loadNpmTasks('grunt-simple-nyc');

    // Default task
    //grunt.registerTask('default', [ 'test']);
    grunt.registerTask('default', ['lint', 'test']);
    // Lint task
    //grunt.registerTask('lint', ['eslint:ci']);
    grunt.registerTask('lint', ['eslint']);
    // Mocha test task
    grunt.registerTask('test', ['nyc:local']);
};


    3.5
4. eslint, for static analysis
https://eslint.org/docs/user-guide/command-line-interface

generate report
[i500695@C02X632CJGH6:2018-10-23 16:26:58:~/Desktop/work/SAP/CF_LocAL/portal-cf-site-semantic-service:]566$ eslint .


    4.1  grunt setup eslint
https://mattdufeu.co.uk/add-grunt-and-eslint-to-a-mvc-project/

[i500695@C02X632CJGH6:2018-10-25 09:43:18:~/Desktop/work/code/nodejs/tutorial:]568$ npm install --save-dev eslint
npm WARN tutorial@1.0.0 No repository field.

+ eslint@5.7.0
added 91 packages from 61 contributors and audited 626 packages in 5.536s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-25 09:45:06:~/Desktop/work/code/nodejs/tutorial:]569$ npm install --save-dev grunt-eslint
npm WARN tutorial@1.0.0 No repository field.

+ grunt-eslint@21.0.0
added 1 package from 1 contributor and audited 848 packages in 2.603s
found 0 vulnerabilities

[i500695@C02X632CJGH6:2018-10-25 09:45:22:~/Desktop/work/code/nodejs/tutorial:]570$ npm install --save-dev load-grunt-tasks
npm WARN tutorial@1.0.0 No repository field.

+ load-grunt-tasks@4.0.0
added 12 packages from 1 contributor and audited 868 packages in 2.993s
found 0 vulnerabilities

    4.2

5. Packages

    5.1 sprintf
basic "sprintf":
There is now printf-like support in util.format().  Example: 
util.format('hello %s', 'world');

Full support in package sprintf.
https://www.npmjs.com/package/sprintf-js

npm install sprintf-js

Usage

var sprintf = require("sprintf-js").sprintf,
    vsprintf = require("sprintf-js").vsprintf

sprintf("%2$s %3$s a %1$s", "cracker", "Polly", "wants")
vsprintf("The first 4 letters of the english alphabet are: %s, %s, %s and %s", ["a", "b", "c", "d"])

    5.2 nodemon, monitor nodejs code execution
[i500695@C02X632CJGH6:2018-11-07 18:05:25:~/Desktop/work/code/nodejs/tutorial:]554$ sudo npm install -g nodemon
[i500695@C02X632CJGH6:2018-11-07 18:05:31:~/Desktop/work/code/nodejs/tutorial:]554$ nodemon buffers.js 


    5.3 jsonwebtoken

        5.3.1 web tutorials

            5.3.1.1 https://medium.com/@siddharthac6/json-web-token-jwt-the-right-way-of-implementing-with-node-js-65b8915d550e

            5.3.1.2

        5.3.2
    5.4 rewire

        5.4.1 https://www.npmjs.com/package/rewire
rewire adds a special setter and getter to modules so you can modify their behaviour for better unit testing. You may

inject mocks for other modules or globals like process
inspect private variables
override variables within the module.
Please note: The current version of rewire is only compatible with CommonJS modules. See Limitations.


Installation

npm install rewire


Introduction

Imagine you want to test this module:

// lib/myModules.js
// With rewire you can change all these variables
var fs = require("fs"),
    path = "/somewhere/on/the/disk";
 
function readSomethingFromFileSystem(cb) {
    console.log("Reading from file system ...");
    fs.readFile(path, "utf8", cb);
}
 
exports.readSomethingFromFileSystem = readSomethingFromFileSystem;
Now within your test module:

// test/myModule.test.js
var rewire = require("rewire");
 
var myModule = rewire("../lib/myModule.js");
rewire acts exactly like require. With just one difference: Your module will now export a special setter and getter for private variables.

myModule.__set__("path", "/dev/null");
myModule.__get__("path"); // = '/dev/null'
This allows you to mock everything in the top-level scope of the module, like the fs module for example. Just pass the variable name as first parameter and your mock as second.

var fsMock = {
    readFile: function (path, encoding, cb) {
        expect(path).to.equal("/somewhere/on/the/disk");
        cb(null, "Success!");
    }
};
myModule.__set__("fs", fsMock);
 
myModule.readSomethingFromFileSystem(function (err, data) {
    console.log(data); // = Success!
});
You can also set multiple variables with one call.

myModule.__set__({
    fs: fsMock,
    path: "/dev/null"
});
You may also override globals. These changes are only within the module, so you don't have to be concerned that other modules are influenced by your mock.

myModule.__set__({
    console: {
        log: function () { /* be quiet */ }
    },
    process: {
        argv: ["testArg1", "testArg2"]
    }
});
__set__ returns a function which reverts the changes introduced by this particular __set__ call

var revert = myModule.__set__("port", 3000);
 
// port is now 3000
revert();
// port is now the previous value
For your convenience you can also use the __with__ method which reverts the given changes after it finished.

myModule.__with__({
    port: 3000
})(function () {
    // within this function port is 3000
});
// now port is the previous value again
The __with__ method is also aware of promises. If a thenable is returned all changes stay until the promise has either been resolved or rejected.

myModule.__with__({
    port: 3000
})(function () {
    return new Promise(...);
}).then(function () {
    // now port is the previous value again
});
// port is still 3000 here because the promise hasn't been resolved yet

        5.4.2 How rewire is useful for unit tests
getting a module via require always returns a reference to the same module (which is also cached).
It is possible to delete the module but when the module is instantiated differently according to external conditions (Configuration, environment etc)
delete is not helpful for getting different instances of the module.
rewire has a nice side effect:
"
Caveats

Difference to require()
Every call of rewire() executes the module again and returns a fresh instance.

rewire("./myModule.js") === rewire("./myModule.js"); // = false
This can especially be a problem if the module is not idempotent like mongoose models.

Globals are imported into the module's scope at the time of rewiring
Since rewire imports all gobals into the module's scope at the time of rewiring, property changes on the global object after that are not recognized anymore. This is a problem when using sinon's fake timers after you've called rewire().

Dot notation
Although it is possible to use dot notation when calling __set__, it is strongly discouraged in most cases. For instance, writing myModule.__set__("console.log", fn) is effectively the same as just writing console.log = fn. It would be better to write:

myModule.__set__("console", {
    log: function () {}
});
This replaces console just inside myModule. That is, because rewire is using eval() to turn the key expression into an assignment. Hence, calling myModule.__set__("console.log", fn) modifies the log function on the global console object.

"

Example. In semantic service rewire app (express instance) after stubbing some dependencies that are hard to satisfy when in unit test mode.
/Users/i500695/Desktop/work/SAP/CF_LocAL/portal-cf-site-semantic-service/test/unit/routes/read.spec.js :
    before(() => {
        loggerStub = sinon.stub(cfLogger, 'initLogger').returns(loggerMock);
        configUtilsStub = sinon.stub(configUtils, 'isClpScenario').returns(true);
        passportStub = sinon.stub(passport, 'authenticate').returns((req, res, next) => {
            req.authInfo = StoreVars.authInfo;
            next();
        });
        xsenvGetServiceStub = sinon.stub(xsenv, 'getServices').returns({'uaa':{}});

        app = rewire('../../../src/app');
        isLocal = app.locals.isLocal;
        StoreClient = require('../../../src/services/store/store-client-factory').create();
    });

        5.4.3

    5.5

6. FAQ

    6.1 printing

        6.1.1 Print JSON object
use %o flag in console.log.
e.g.
console.log("queryId() was called\nreq=%o\nres=%o\n", req, res);

        6.1.2

    6.2 modules

        6.2.1 express

            6.2.1.1 process.env vs app.get('env') on getting the express.js environment
q. So, in my node.js 5.2.0 / express.js 4.2.0 I can do

if (app.get('env') === 'development') {
  app.use(//etc

or

var env = process.env.NODE_ENV || 'development';
if (env === 'development') {
  app.use(//etc

So process.env.NODE_ENV and app.get('env') both get the environment's value. Is there any significant difference besides the syntax?

a.  There is no significant difference.

Express app.get('env') returns 'development' if NODE_ENV is not defined. So you don't need the line to test its existence and set default.

        6.2.2

    6.3 general

        6.3.1 Is nodejs interpreted or compiled?
v8 engine, written in c++ (https://chromium.googlesource.com/v8/v8.git/+/master) by google, commpiles and optimized the compiled code of nodejs.
It performs lexing, AST (abstract syntax tree) generation and creates machine code.
It also applies optimizations

        6.3.2 V8
http://thibaultlaurens.github.io/javascript/2013/04/29/how-the-v8-engine-works/
How the V8 engine works?

V8 is a JavaScript engine built at the google development center, in Germany. It is open source and written in C++. It is used for both client side (Google Chrome) and server side (node.js) JavaScript applications.

V8 was first designed to increase the performance of the JavaScript execution inside web browsers. In order to obtain speed, V8 translates JavaScript code into more efficient machine code instead of using an interpreter. It compiles JavaScript code into machine code at execution by implementing a JIT (Just-In-Time) compiler like a lot of modern JavaScript engines such as SpiderMonkey or Rhino (Mozilla) are doing. The main difference with V8 is that it doesn’t produce bytecode or any intermediate code.

The aim of this article is to show and to understand how V8 works, in order to produce optimized code for both client side or server side applications. If you are already asking yourself “Should I care about JavaScript performance?” then I will answer with a quote from Daniel Clifford (tech lead and manager of the V8 team): “It’s not just about making your current application run faster, it’s about enabling things that you have never been able to do in the past”.
V8!
Hidden class

JavaScript is a prototype-based language: there are no classes and objects are created by using a cloning process. JavaScript is also dynamically typed: types and type informations are not explicit and properties can be added to and deleted from objects on the fly. Accessing types and properties effectively makes a first big challenge for V8. Instead of using a dictionary-like data structure for storing object properties and doing a dynamic lookup to resolve the property location (like most JavaScript engines do), V8 creates hidden classes, at runtime, in order to have an internal representation of the type system and to improve the property access time.

Let’s have for instance a Point function and the creation of two Point objects:
hidden class

If the layouts are the same, which is the case here, p and q belong to the same hidden class created by V8. This highlights another advantage of using hidden classes: it allows V8 to group objects for which properties are the same. Here p and q use the same optimized code.

Now, let’s assume that we want to add a z property to our q object, right after its declaration (which is perfectly fine with a dynamically typed language).

How will V8 deal with this scenario? In fact, V8 creates a new hidden class everytime the constructor function declares a property and keeps track of the change in the hidden class. Why? Because if two objects are created (p and q) and if a member is added to the second object (q) after the creation, V8 needs to keep the last hidden class created (for the first object p) and to create a new one (for the second object q) with the new member.
transition information

Everytime a new hidden class is created, the previous one is updated with a class transition indicating what hidden class has to be used instead of it.
Code optimization

Because V8 creates a new hidden class for each property, hidden class creation should be kept to a minimum. To do this, try to avoid adding properties after the object creation, and always initialize object members in the same order (to avoid the creation of different tree of hidden classes).

[Update] Another trick: Monomorphic operations are operations which only work on objects with the same hidden class. V8 creates a hidden class when we call a function. If we call it again with different parameter types, V8 needs to create another hidden class: Prefer monomorphic code to polymorphic code



More example on how V8 optimized JavaScript code


Tagged values

To have an efficient representation of numbers and JavaScript objects, V8 represents both with a 32 bit value. It uses a bit to know if it is an object (flag = 1) or an integer (flag = 0) called here SMall Integer or SMI because of its 31 bits. Then, if a numeric value is bigger than 31 bits, V8 will box the number, turning it into a double and creating a new object to put the number inside.

Code optimization: Try to use 31 bit signed numbers whenever possible to avoid the expensive boxing operation into a JavaScript object.


Arrays

V8 uses two different methods to handle arrays:

    Fast elements: Designed for arrays where the set of keys are very compact. They have a linear storage buffer that can be accessed very efficiently.
    Dictionary elements: Designed for sparse arrays which don’t have every elements inside of them. It is actually a hash table, more expensive to access than “Fast Elements”

Code optimization: Be sure that V8 uses “Fast Elements” to handle arrays, in other words, avoid sparse arrays where keys are not next incremental numbers. Also, try to avoid pre-allocating large arrays. It is better to grow as you go. Finally, don’t delete elements in arrays: it makes the key set sparse.



How V8 compiles JavaScript code?


V8 has two compilers!

    A “Full” Compiler that can generate good code for any JavaScript: good but not great JIT code. The goal of this compiler is to generate code quickly. To achieve its goal, it doesn’t do any type analysis and doesn’t know anything about types. Instead, it uses an Inline Caches or “IC” strategy to refine knowledge about types while the program runs. IC is very efficient and brings about 20 times speed improvment.

    An Optimizing Compiler that produces great code for most of the JavaScript language. It comes later and re-compiles hot functions. The optimizing compiler takes types from the Inline Cache and make decisions about how to optimize the code better. However, some language features are not supported yet like try/catch blocks for instance. (The workaround for try/catch blocks is to write the “non stable” code in a function and call the function in the try block)


Code optimization: V8 also supports de-optimization: the optimizing compiler makes optimistic assumptions from the Inline Cache about the different types, de-optimization comes if these assumptions are invalid. For example, if a hidden class generated was not the one expected, V8 throws away the optimized code and comes back to the Full Compiler to get types again from the Inline Cache. This process is slow and should be avoided by trying to not change functions after they are optimized.

        6.3.3

    6.4 arrays

        6.4.1 convert array to json 

json = { ...array };

json = Object.assign({}, array);

json = array.reduce((json, value, key) => { json[key] = value; return json; }, {});

> arr
[ 'a', 'b' ]
> json = arr.reduce((json, v, k) => {json[k] = v; return json;}, {})
{ '0': 'a', '1': 'b' }
> j2={...arr};
{ '0': 'a', '1': 'b' }
> j3=Object.assign({}, arr)
{ '0': 'a', '1': 'b' }

    6.5 functional programming

        6.5.1  reduce

            6.5.1.1  reduce tutorial


https://www.w3schools.com/jsref/jsref_reduce.asp
Syntax
array.reduce(function(total, currentValue, currentIndex, arr), initialValue)
Parameter Values
Parameter 	Description
function(total,currentValue, index,arr) 	Required. A function to be run for each element in the array.
Function arguments:
Argument 	Description
total 	Required. The initialValue, or the previously returned value of the function
currentValue 	Required. The value of the current element
currentIndex 	Optional. The array index of the current element
arr 	Optional. The array object the current element belongs to
initialValue 	Optional. A value to be passed to the function as the initial value

example:
 <button onclick="myFunction()">Try it</button>

<p>Sum of numbers in array: <span id="demo"></span></p>

<script>
var numbers = [15.5, 2.3, 1.1, 4.7];

function getSum(total, num) {
    return total + Math.round(num);
}
function myFunction(item) {
    document.getElementById("demo").innerHTML = numbers.reduce(getSum, 0);
}
</script> 

my example:
> arr
[ 'a', 'b' ]
> json = arr.reduce((json, v, k) => {json[k] = v; return json;}, {})
{ '0': 'a', '1': 'b' }

            6.5.1.2 reduce an array of string to set
no need for reduce.
Just use Set CTOR
ex:
var arr = [1, 2, 3];
var set = new Set(arr);
console.log(set); // {1,2,3}


var arr = [1, 2, 1];
var set = new Set(arr);
console.log(set); // {1,2}

            6.5.1.3 reduce an array of string to map
            var arr = [
    { key: 'foo', val: 'bar' },
    { key: 'hello', val: 'world' }
];

var result = arr.reduce(function(map, obj) {
    map[obj.key] = obj.val;
    return map;
}, {});

console.log(result);
// { foo:'bar', hello:'world' }

        6.5.2


    6.6  typescript use string variable as property name 
    https://stackoverflow.com/questions/46050957/property-name-on-object-from-variable/46051069
Q: Is there a way in typescript to set a property name from a variable?

Something like this

export function objectFactory(prop: string) {
    return {
        prop: {
            valid: false
        }
    };
}
    
A: 
You are looking for computed properties
(https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Object_initializer#Computed_property_names), this is an ES6 feature and not specific to TypeScript.

export function objectFactory(prop: string) {
    return {
        [prop]: {
            valid: false
        }
    };
}

Note that in TypeScript you also need to specify type or you'll get error.
see. https://stackoverflow.com/questions/44110641/typescript-a-computed-property-name-in-a-type-literal-must-directly-refer-to-a-b
Q: ERROR in ...component.ts (..,..): A computed property name in a type literal must directly refer to a built- in symbol. ...: Cannot find name 'any'.

I'm looking forward an object which contains strings which have other string, i.e:

{ abc: 'xyz' }
What I did:

foo: { [string]: string };

A: 27

An identifying name on the computed value is required:

foo: { [bar: string]: string };



    6.7 Objects

        6.7.1 DFS traverse object properties 
https://stackoverflow.com/questions/15690706/recursively-looping-through-an-object-to-build-a-property-list
ou'll run into issues with this if the object has loop in its object graph, e.g something like:

var object = {
    aProperty: {
        aSetting1: 1
    },
};
object.ref = object;
In that case you might want to keep references of objects you've already walked through & exclude them from the iteration.

Also you can run into an issue if the object graph is too deep like:

var object = {
  a: { b: { c: { ... }} }
};
You'll get too many recursive calls error. Both can be avoided:

function iterate(obj) {
    var walked = [];
    var stack = [{obj: obj, stack: ''}];
    while(stack.length > 0)
    {
        var item = stack.pop();
        var obj = item.obj;
        for (var property in obj) {
            if (obj.hasOwnProperty(property)) {
                if (typeof obj[property] == "object") {
                  var alreadyFound = false;
                  for(var i = 0; i < walked.length; i++)
                  {
                    if (walked[i] === obj[property])
                    {
                      alreadyFound = true;
                      break;
                    }
                  }
                  if (!alreadyFound)
                  {
                    walked.push(obj[property]);
                    stack.push({obj: obj[property], stack: item.stack + '.' + property});
                  }
                }
                else
                {
                    console.log(item.stack + '.' + property + "=" + obj[property]);
                }
            }
        }
    }
}

        6.7.2
    6.8

7. OOD, polymorphism 

    7.1 removing if/else, alternatives to statement branching
https://javascriptweblog.wordpress.com/2010/07/26/no-more-ifs-alternatives-to-statement-branching-in-javascript/

You could do this..
	
//Example 1
function getEventTarget(evt) {
    if (!evt) {
        evt = window.event;
    }
    if (!evt) {
        return;
    }
    var target;
    if (evt.target) {
        target = evt.target;
    } else {
        target = evt.srcElement;
    }
    return target;
}

or you could do this…
	
//Example 2
function getEventTarget(evt) {
    evt = evt || window.event;
    return evt && (evt.target || evt.srcElement);
}


To avoid ambiguity I’ll explain how I’m using a couple of terms in this article:
• statement branching: any construct that alters the sequence of statement execution within the global or functional scope. These include if, else, switch, for and while statements.
• micro-branching: conditional logic contained within a statement that has no effect on the statement execution seqeunce. The following operators facilitate micro-branching: ternary, && and ||.

OK back to the examples…

Example 1 employs statement branching, i.e. its statements are designed to execute non-linearly. Aside from the obvious bloating effect, statement branching tends to become unintuitive as it progresses (its really just one step up on the food chain from the widely discredited goto statement). As humans we are inclined to read function code top-down, line by line through to the last line. Logic built on statement branching forces us to mentally track each possible execution sequence. As branching logic gets more complex the number of forking paths increases and it becomes easy to overlook edge-case flow scenarios. Bugs love overlooked scenarios.

Example 2 uses micro-branching. The logic flows sequentially from top to bottom and even from left to right. There are no forks in the road. There is only one return statement and its at the bottom where we expect it. Best of all it’s short. Nothing is wasted. In fact it’s terse enough to be barely procedural at all.

Statement branching is necessary and useful but having the full toolkit of alternatives at hand helps to keep our JavaScript readable, concise and robust. There’s also an ideological element here: there’s a lot of power in JavaScript’s functional capabilities, but we need to let go of some procedural baggage in order to unleash it.

Alternatives to statement branching fall into two broad categories: micro-branching and no branching at all. Let’s dig deeper into each:


        7.1.1 micro-branching

            7.1.1.1 Guards (&&) and Defaults(||)

The logical boolean operators && and || are familiar syntax in many languages.
JavaScript has a liberal approach to these operators:
• Constructs formed by logical boolean operators can be used as expressions within statements or can form the entire statement
• The operands need not evaluate to booleans but will be coerced to booleans to facilitate the logical operation
• The result of evaluating a logical boolean expression need not be a boolean value
(see ECMA 5 11.11)

This provides for some gorgeously succinct non-branching conditional logic:
	
//invoke callback if there is one
callback && callback();
//delay by argument or 20
delayBy(delay || 20);
//remove node from its parent
node && node.parent && node.parent.removeChild(node);
//log a test in the console id we have one
window.console && console.log('test');

            7.1.1.2 The Ternary operator

Also (and more clumsily) known as the conditional ?: operator, this is another cross-language standard which we can leverage to lay down conditions without affecting the sequence of statement execution.

When used badly ternary operators are no better than bad imitations of if/else branching. The perplexed smiley in the middle of this one says it all:
	
//Bad example - ternary that thinks its an if/else.
var a = 2, b = 1;
a ? (
    b++,
    a = a*2,
    console.log(a,b)
):(
    b--,
    a = a/2,
    alert(a + " " + b)
);

However when used as a conditional assignment or intra-statement switch, the logic is clean and easy to follow.
	
//make an array of the args if any, or return empty array
var args = arguments ? toArray(arguments) : [];
//end game or go to next level
gameOver ? finally() : nextLevel();

            7.1.1.3 Function Delegation

As if/else blocks get bigger and/or nested they get harder to follow. If the statement block(s) are more than a few lines it generally suggests the need for an additional function or functions.

Here is a function for dropping a dragged item in a box. Firstly using if/else and multiple bailing returns….
	
function itemDropped(item, location) {
    if (!item) {
        return false;
    } else if (outOfBounds(location) {
        var error = outOfBounds;
        server.notify(item, error);
        items.resetAll();
        return false;
    } else {
        animateCanvas();
        server.notify(item, location);
        return true;
    }
}

…and secondly reimplemented to use function delegation, a ternary and one trailing return per function. Note the added bonus of being able to name your conditions – like a built-in comment.
	
function itemDropped(item, location) {
    var dropOut = function() {
        server.notify(item, outOfBounds);
        items.resetAll();
        return false;
    }
 
    var dropIn = function() {
        server.notify(item, location);
        animateCanvas();
        return true;
    }
 
    return !!item && (outOfBounds(location) ? dropOut() : dropIn());
}
Be careful with “bailing” returns

Some things just have a natural place. Birds in the sky, fish in the sea and a return statement at the end of a function. Short circuiting a function when an variable is null or some other non-useful value might be handy for developers but it can sometimes be a source of obfuscation for reviewers and bug fixers (and more often than not the bug fixer is the original developer). I’m as guilty as anyone else when it comes to bailing returns but other people’s code is often more readable without them. The example just above and Example 2 at the beginning of this article illustrate strategies for avoiding bailing returns.

        7.1.2 non-branching

            7.1.2.1 Property look-ups (a.k.a. dispatch tables)

My very first blog post touted my preference for hash look-ups over switch statments so I won’t re-hash(!) all the same arguments here. Suffice to say, functions are most expressive when they eschew data considerations and focus on form. Defining data dependent action properties elsewhere enables just such a separation.

Here’s an example that reacts to a toolbar button being clicked in a file manager type application. First using a switch. Note the clicked function is specific to fileManager and as a consequence we start to build up some ominous looking namespace chaining:
	
fileManager.toolbar.clicked = function(buttonId) {
    switch(buttonId) {
        case 'open': fileManager.openNew(true);
            break;
        case 'save': fileManager.saveSelected(true);
            break;
        case 'run': fileManager.executeSelected(true);
            break;
        default: coreUtils.notImplemented();
    }
}
 
fileManager.toolbar.clicked('save');

Now here’s an alternate implementation using a hash table for lookup. Adding a new button will be a breeze – just add a new property to the actions object. And the clicked function is now generic – action objects can be passed as parameters from any toolbar.
	
fileManager.toolbarActions = {
    'open': {fn: fileManager.openNew, args: [true]},
    'save': {fn: fileManager.saveSelected, args: [false]},
    'run': {fn: fileManager.execSelected, args: [false]},
    'default': {fn: coreUtils.notImplemented, ctxt: coreUtils},
}
 
toolbar.clicked = function(actions, buttonId) {
    var action = actions[buttonId] || actions['default'];
    action.fn.apply(action.ctxt, action.args);
}
 
toolbar.clicked(fileManager.toolbarActions, 'save');

            7.1.2.2 Array functions, map, filter, reduce

All the major JavaScript frameworks define a rich set of higher order functions for use with Arrays. ECMA 5 also defines a similar set of functions and they are already implemented in all browsers except for IE<=8.

(A note on performance – if your array is very large you might see some performance degradation with the higher order array function – every function call carries a small but cumulative cost. As with all coding – write it for sturdiness and readability, optimize later if you have to – and you probably won’t have to)

Consider a function that returns all words longer than four letters. First the naive approach. The array is short and the test is simple but the logic will still touch about 50 statements in a loopy-doopy sequence.The author is forced to churn out the same mundane looping syntax that she will probably repeat multiple times elsewhere. It’s donkey work that increases the probability of errors and only serves to obfuscate the more meaningful content.
	
function dropShortWords(words) {
    var wordArray = words.split(" ");
    var longWords = [];
    for (var i=0; i<wordArray.length; i++) {
        var word = wordArray[i];
        if (word.length>4) {
            longWords.push(word);
        }
    }
    return longWords.join(" ");
}
 
dropShortWords("The quick brown fox jumped over the lazy dog"); //"quick brown jumped"

… and here is we define the same function using the higher order filter function. Four lines and we left the looping and branching to the safety of an industry tested utility. Moreover with the distraction of the looping syntax removed, the intent of the function becomes clearer.
	
//(will not work in IE<9)
function dropShortWords(words) {
    var longWords = words.split(" ").filter(function(word){
        return word.length>4;
     });
     return longWords.join(" ");
}
 
dropShortWords("The quick brown fox jumped over the lazy dog"); //"quick brown jumped"


            7.1.2.3 Functions as Data

Functions are first class objects in JavaScript and this allows us to pass them as parameters to other functions. Amongst other things, this provides an alternative to branching.

Here is a simple calculator. With ifs….
	
var calc = {
    run: function(op, n1, n2) {
        var result;
        if (op == "add") {
            result = n1 + n2;
        } else if (op == "sub" ) {
            result = n1 - n2;
        } else if (op == "mult" ) {
            result = n1 * n2;
        } else if (op == "div" ) {
            result = n1 / n2;
        }
        return result;
    }
}
 
calc.run("sub", 5, 3); //2

…and now using run as a higher order function instead:
	
var calc = {
    add : function(a,b) {
        return a + b;
    },
    sub : function(a,b) {
        return a - b;
    },
    mult : function(a,b) {
        return a * b;
    },
    div : function(a,b) {
        return a / b;
    },
    run: function(fn, a, b) {
        return fn && fn(a,b);
    }
}
calc.run(calc.mult, 7, 4); //28

        7.1.3



    7.2 What is polymorphism in Javascript?
https://stackoverflow.com/questions/27642239/what-is-polymorphism-in-javascript#_=_

Q.  I have read some possible article I could found on the internet on polymorphism. But I think I could not quite grasp the meaning of it and its importance. Most of the articles don't say why it is important and how I can achieve polymorphic behavior in OOP (of course in JavaScript).

I can not provide any code example because I haven't got the idea how to implement it, so my questions are below:

    What is it?
    Why we need it ?
    How it works?
    How can I achieve this polymorphic behavior in javascript?

I have got this example. But it is easily understandable what will be outcome of this code. It doesn't give any clear idea about polymorphism itself.

function Person(age, weight) {
    this.age = age;
    this.weight = weight;
    this.getInfo = function() {
        return "I am " + this.age + " years old " +
        "and weighs " + this.weight +" kilo.";
    }
}
function Employee(age, weight, salary) {
    this.salary = salary;
    this.age = age;
    this.weight = weight;
    this.getInfo = function() {
        return "I am " + this.age + " years old " +
        "and weighs " + this.weight +" kilo " +
        "and earns " + this.salary + " dollar.";
    }
}

Employee.prototype = new Person();
Employee.prototype.constructor = Employee;
  // The argument, 'obj', can be of any kind
  // which method, getInfo(), to be executed depend on the object
  // that 'obj' refer to.

function showInfo(obj) {
    document.write(obj.getInfo() + "<br>");
}

var person = new Person(50,90);
var employee = new Employee(43,80,50000);
showInfo(person);
showInfo(employee);


        7.2.1 A1 
What is the purpose of polymorphism?

Polymorphism makes a static type system more flexible without losing (significant) static type safety by loosening the conditions for type equivalence. The proof remains that a program will only run if it doesn't contain any type errors.

A polymorphic function or data type is more general than a monomorphic one, because it can be used in a wider range of scenarios. In this sense polymorphism represents the idea of generalization in strictly typed languages.
How does this apply to Javascript?

Javascript has a weak, dynamic type system. Such a type system is equivalent with a strict type system containing only one type. We can think of such a type as a huge union type (pseudo syntax):

type T =
 | Undefined
 | Null
 | Number
 | String
 | Boolean
 | Symbol
 | Object
 | Array
 | Map
 | ...

Every value will be associated to one of these type alternatives at run-time. And since Javascript is weakly typed, every value can change its type any number of times.

If we take a type theoretical perspective and consider that there is only one type, we can say with certainty that Javascript's type system doesn't have a notion of polymorphism. Instead we have duck typing and implicit type coercion.

But this shouldn't keep us from thinking about types in our programs. Due to the lack of types in Javascript we need to infer them during the coding process. Our mind have to stand in for the missing compiler, i.e. as soon as we look at a program we must recognize not only the algorithms, but also the underlying (maybe polymorphic) types. These types will help us to build more reliable and more robust programs.

In order to do this properly I am going to give you an overview of the most common manifestations of polymorphism.

            7.2.1.1 Parametric polymorphism (aka generics)

Parametric polymorphism says that different types are interchangeable because types doesn't matter at all. A function that defines one or more parameters of parametric polymorphic type must not know anything about the corresponding arguments but treat them all the same, because they can adopt to any type. This is quite restricting, because such a function can only work with those properties of its arguments that are not part of their data:

// parametric polymorphic functions

const id = x => x;

id(1); // 1
id("foo"); // "foo"

const k = x => y => x;
const k_ = x => y => y;

k(1) ("foo"); // 1
k_(1) ("foo"); // "foo"

const append = x => xs => xs.concat([x]);

append(3) ([1, 2]); // [1, 2, 3]
append("c") (["a", "b"]); // ["a", "b", "c"]

            7.2.1.2 Ad-hoc polymorphism (aka overloading)

Ad-hoc polymorphism says that different types are equivalent for a specific purpose only. To be equivalent in this sense a type must implement a set of functions specific to that purpose. A function that defines one or more parameters of ad-hoc polymorphic type then needs to know which sets of functions are associated to each of its arguments.

Ad-hoc polymorphism makes a function compatible to a larger domain of types. The following example illustrates the "map-over" purpose and how types can implement this constraint. Instead of a set of function the "mappable" constraint only includes a single map function:

// Option type
class Option {
  cata(pattern, option) {
    return pattern[option.constructor.name](option.x);
  }
  
  map(f, opt) {
    return this.cata({Some: x => new Some(f(x)), None: () => this}, opt);
  }
};

class Some extends Option {
  constructor(x) {
    super(x);
    this.x = x;
  }
};

class None extends Option {
  constructor() {
    super();
  }
};


// ad-hoc polymorphic function
const map = f => t => t.map(f, t);

// helper/data

const sqr = x => x * x;

const xs = [1, 2, 3];
const x = new Some(5);
const y = new None();

// application

console.log(
  map(sqr) (xs) // [1, 4, 9]
);

console.log(
  map(sqr) (x) // Some {x: 25}
);

console.log(
  map(sqr) (y) // None {}
);

            7.2.1.3 subtype (aka inheritance) polymorphism

                7.2.1.3.1 https://stackoverflow.com/questions/44391149/es6-classes-ability-to-perform-polymorphism
Every JavaScript object has an internal "prototype" property, often called [[prototype]], which points to the object from which it directly inherits.

Every JavaScript function [object] has a property prototype, which is initialized with an [nearly] empty object. When you create a new instance of this function by calling it as a constructor, the [[prototype]] of that new object will point to the constructor's prototype object.

So, when you write this var myPerson = new Person('Jon', 20);,you have the method showInfo because you have this

Person.prototype.showInfo = function(){
    return "Im " + this._name + ", aged " + this._age;
};

With ES6 if you want to see the polymorphism you could do that :

class Person {
    constructor (name, age) {
        this._name = name;
        this._age = age;
    }
        
    showInfo () {
        return "Im " + this._name + ", aged " + this._age;
    }
}

class Employee extends Person {
    constructor (name, age, sex) {
        super(name,age);
        this._sex = sex;
    }
        
    showInfo(){
        return "Im " + this._sex + ", named " + this._name + ", aged " + this._age;
    }
}

var myPerson = new Person('Jon', 20);
var myEmployee = new Employee('Doe', 10, 'men');

document.write(myPerson.showInfo() + "<br><br>");   // Im Jon, aged 20
document.write(myEmployee.showInfo() + "<br><br>"); // Im men, named Doe, aged 10
                7.2.1.3.2

            7.2.1.4 Structural polymorphism (aka strutrual subtyping)
https://stackoverflow.com/questions/27642239/what-is-polymorphism-in-javascript#_=_

Structural polymorphism says that different types are equivalent, if they contain the same structure in such a way, that one type has all the properties of the other one but may include additional properties. That being said, structural polymorphism is duck typing at compile time and certainly offers some additional type safety. But by claiming that two values are of the same type just because they share some properties, it completely ignores the semantic level of values:

const weight = {value: 90, foo: true};
const speed =  {value: 90, foo: false, bar: [1, 2, 3]};

Unfortunately, speed is considered a subtype of weight and as soon as we compare the value properties we are virtually comparing apples with oranges. 

            7.2.1.5
        7.2.2
    7.3

8. ECMA6, ES6, Javascript6

    8.1 lambda functions (aka => , fat arrow)

    8.2 classes
        8.1.1 ES6 classes

        8.1.2 Mock class

            8.1.2.1 https://medium.com/@madhanganesh/how-to-mock-es6-class-749da63268fc
How to mock ES6 class

This post intends to show how to mock a class in JavaScript for the purpose of Unit Testing. The post targets developers who are coming to ES6 from environments that has features like dependency injection and interfaces. Most part of the post will cover what is a class in ES6 and why we need them. Once the underlying model is covered mocking of the same will be obvious. This post will take you through the journey of creating objects in JavaScript.
Object Literal

Object is a first citizen in JavaScript land. The stunningly easy way to create an object makes this language simple to start. Here is a sample object.

var person = {
  name: 'Velu'
};

It is this simple. To create an object you start with object (and not class). In that regards I would argue JavaScript is true Object Oriented (and languages like Java are Class Oriented as you start will class to create objects).

Let us extend the above example to add a behaviour to our sample object, sayName.

var person1 = {
  name: 'Velu',
  sayName: function() {
    console.log(this.name);
  }
}

With this object, if you need to create multiple objects you need to duplicate the sayName function in each of the object. This would mean:

var person1 = {
  name: 'Velu',
  sayName: function() {
    console.log(this.name);
  }
}

var person2 = {
  name: 'Raj',
  sayName: function() {
    console.log(this.name);
  }
}

If you end up creating many people, this would mean there is lot of code duplication. To overcome this comes Constructor Function.
Constructor Function

Let us write a sample Constructor Function and talk about it:

function Person(name) {
  this.name = name;

  this.sayName = function() {
    console.log(this.name);
  }
}

At a first glance this is yet another function in JavaScript. What makes constructor function special is not the function itself but when it is associated with the new keyword. So a constructor function can be used as in:

var person1 = new Person('Velu');

The above line will create an object and literally the code will be transformed into:

var person1 = {
  name: 'Velu',

  sayName: function() {
    console.log(this.name);
  }
}

Now to create more people there is no code duplication. The blueprint is defined in Constructor Function and JavaScript magically converts that to object form at runtime.

With this, there is no code duplication but the underlying object still has duplicate piece. The function sayName is defined only once in the constructor function but still gets copied into each object that gets created. This means more memory. For instance if I create 1 billion people in my Mac Book Pro the node process crashes with out of memory. That brings a need to share the object model not just at code time but also at runtime.
Prototype

So what we need is a mechanism to share functions across objects. In JavaScript the mechanism to share code is again yet another object called prototype. Every JavaScript object that gets created has a built-in link called prototype to another object. This object is shared by all objects created using same Constructor Function. The layout below depicts this:

Now the obvious step is to move the sayName function from object to its prototype. Below code does this:

function Person(name) {
  this.name = name;
}

Person.prototype.sayName = function() {
    console.log(this.name);
}

Also JavaScript ensures following 2 things to make it all possible:

    If a property is accessed on an object and is not present in that object it will be searched and accessed in its prototype
    The “this” reference in the functions attached to prototype with magically bound to the object on which it is invoked

So the below invocation of sayName is ensured that the this will be pointing to person1 object during runtime.

var person1 = new Person('Velu');
person1.sayName();

ES6 Class

Now coming to ES6 class, finally, is just a syntactic sugar that will generate the Constructor Function during runtime. The class syntax just brings this more concisely:

class Person {
  constructor(name) {
    this.name = name;
  }

  sayName() {
    console.log(this.name);
  }
}

Having understood what ES6 class under the hood, there is yet another JavaScript concept to understand. Consider the following JavaScript modules and its dependencies:

In this structure Module A imports both B and C. Now when Module B also imports C the module loaded by A is reused and not a new one. This means if a ES6 class is exported from Module C, the definition of the same can be altered in A and the altered definition will be reflected in C. Armed with this understanding on ES6 classes and module system let us finally see how to mock.
Mocking ES6 class

Let us consider following test scenario. The Employee depends on a utility class Helper to get a random number. The Employee module would look like:

const Helper = require('./helper');

class Employee {
  constructor(name) {
    this.name = name;
  }

  getId() {
    const helper = new Helper();
    const id = helper.getRandom();

    return `${this.name}-${id}`;
  }
}

module.exports = Employee;

The unit test of Employee has to mock the getRandom method to drive the test on Employee.getId. The flow looks like:

Now with all the details we have gather so far, the mocking code is obvious and it goes like:

const expect = require('chai').expect;
const sinon = require('sinon');

const Employee = require('../src/employee');
const Helper = require('../src/helper');

describe('employee test', () => {
  it('should return right id', () => {
    // Arrange
    sinon.stub(Helper.prototype, 'getRandom').callsFake(() => 1);

    // Act
    const employee = new Employee('Velu');
    const id = employee.getId();

    // Assert
    expect(id).to.equals('Velu-1');
  });
});

Basically to mock a method on Helper class just get the reference of the function through class prototype and stub the same. This line stubs the getRandom function to always return 1 so the Employee.getId operation can be validated.

sinon.stub(Helper.prototype, 'getRandom').callsFake(() => 1);

The code base for this can be found https://github.com/madhanganesh/es6-class-mocking-sample
            8.1.2.2

        8.1.3

    8.3


9. Nodejs and C++

    9.1 How NodeJS requires native shared objects

Recently, I faced an issue with requiring native bindings in JavaScript code so I started researching it. If you ever used commands like require(‘my_module.node’) but don’t know how they work from JavaScript perspective — this article is for you.

C++ shares its methods to JavaScript!
What is .node files and why do we need them?
Sometimes, we are using npm packages that have native bindings for their purposes. Sometimes, we are building our own C++ code to extend the NodeJS functionality for our own purposes. In both cases, we need to build external native code to an object, that can be usable by NodeJS.
And that’s what .node files are for. In short, .node files are dynamically shared objects that NodeJS can load to its environment. Making an analogy here, I would say that .node files are very similar to .dll or .so files.
Where does require method come from?
Before digging into internals, let’s remember where require() comes from.
All of JavaScript files are actually wrapped into functions:
const WRAPPER = [
  '(function (exports, require, module, __filename, __dirname) { ',
  '\n})'
];
const JS_SOURCE = 'script here';
const WRAPPED_SCRIPT = WRAPPER[0] + JS_SOURCE + WRAPPER[1];
So, let say, you have some index.js file with the following content:
const fs = require('fs');
When NodeJS tries to load it, it will look like this:
(function (exports, require, module, __filename, __dirname) {
  const fs = require('fs');
})
It means, that all of files\scripts are functions that NodeJS will call when needed. Although, that means that require() method is provided when calling this function.
That function is being called in NativeModule.prototype.compile() method:

As we can see, require() method is pointing to NativeModule.require() method.
Though, there is another type of module. NativeModule is responsible for loading internal modules, but Module is responsible for loading your modules (aka userland).
Module.compile() has similar implementation as well:

Here, compile wraps source into a function and calls it. And, for this case, require argument is internalModule.makeRequireFunction.call(this).
So, for different types of modules NodeJS uses different loaders: NativeModule and Module. Though, we are going to talk about Module only.
Module has the following require() implementation:

So, our require() method, we are heavily using, is actually a pointer to Module.prototype.require() method. If I drop the details, then that’s all you should know, that require() -> Module.prototype.require().
Requiring .node file
Ok, so now, we know what is require() in our code. What happens if we will require a .node file:
const myBindings = require('./build/Release/mybinding.node');
What’s happened there? What was happening in require()?
Well, first of all, it goes into Module.prototype.require() method which calls Module._load() method with a provided path. In our case, ./build/Release/mybinding.node. Here is the implementation:

It checks, if our module exists in cache and, if not, it creates a Module instance and calls tryModuleLoad() function, providing the instance and a filename of our binding. All tryModuleLoad() is trying to do is to call load() method on its instance. Here is an implementation of load() method:

Here, it goes through a list of defined extensions in Module._extensions. This list contains functions that are processing loading of different filetypes. At the time of writing this article, this list contains functions for .js, .json and .node files. Though, I bet that this really will not be changed anyway.
So, if extension is found in that list, in our case .node, then it calls a function with a path to the module you want to require. In case with .node extension it calls a method that has process.dlopen() method, which is a binding from Node C++ sources into JavaScript context.

dlopen() method is actually very similar to how .dll or .so files are loading on Windows and Linux. Here is an implementation of a method that injects into JavaScript context as process.dlopen() method:

It tries to load a shared object via libuv API and if everything works as expected, it registers this dynamically shared object in exports object, returning it into JavaScript context.
Summary
Basically, that’s how require(‘binding.node’) works, so you can build C++ code to shared object, using node-gyp, and require it in your JavaScript code.
Don’t forget to follow me here if you’re interested in such things. Get in touch with me on Twitter. Feel free to ask any questions. Thanks for reading.

    9.2

10. Timers, tags: Timers, setTimeout, setImmediate, setInterval
detailed explanation: <url:#r=_nodejs_eventloop_timers_and_nexttick>
    10.1  https://nodejs.org/en/docs/guides/timers-in-node/

Timers in Node.js and beyond

The Timers module in Node.js contains functions that execute code after a set period of time. Timers do not need to be imported via require(), since all the methods are available globally to emulate the browser JavaScript API. To fully understand when timer functions will be executed, it's a good idea to read up on the the Node.js Event Loop.

Controlling the Time Continuum with Node.js

The Node.js API provides several ways of scheduling code to execute at some point after the present moment. The functions below may seem familiar, since they are available in most browsers, but Node.js actually provides its own implementation of these methods. Timers integrate very closely with the system, and despite the fact that the API mirrors the browser API, there are some differences in implementation.

        10.1.1  "When I say so" Execution ~ setTimeout()

setTimeout() can be used to schedule code execution after a designated amount of milliseconds. This function is similar to window.setTimeout() from the browser JavaScript API, however a string of code cannot be passed to be executed.

setTimeout() accepts a function to execute as its first argument and the millisecond delay defined as a number as the second argument. Additional arguments may also be included and these will be passed on to the function. Here is an example of that:

function myFunc(arg) {
  console.log(`arg was => ${arg}`);
}

setTimeout(myFunc, 1500, 'funky');
The above function myFunc() will execute as close to 1500 milliseconds (or 1.5 seconds) as possible due to the call of setTimeout().

The timeout interval that is set cannot be relied upon to execute after that exact number of milliseconds. This is because other executing code that blocks or holds onto the event loop will push the execution of the timeout back. The only guarantee is that the timeout will not execute sooner than the declared timeout interval.

setTimeout() returns a Timeout object that can be used to reference the timeout that was set. This returned object can be used to cancel the timeout ( see clearTimeout() below) as well as change the execution behavior (see unref() below).

        10.1.2 "Right after this" Execution ~ setImmediate()

setImmediate() will execute code at the end of the current event loop cycle. This code will execute after any I/O operations in the current event loop and before any timers scheduled for the next event loop. This code execution could be thought of as happening "right after this", meaning any code following the setImmediate() function call will execute before the setImmediate() function argument.

The first argument to setImmediate() will be the function to execute. Any subsequent arguments will be passed to the function when it is executed. Here's an example:

console.log('before immediate');

setImmediate((arg) => {
  console.log(`executing immediate: ${arg}`);
}, 'so immediate');

console.log('after immediate');
The above function passed to setImmediate() will execute after all runnable code has executed, and the console output will be:

before immediate
after immediate
executing immediate: so immediate
setImmediate() returns an Immediate object, which can be used to cancel the scheduled immediate (see clearImmediate() below).

Note: Don't get setImmediate() confused with process.nextTick(). There are some major ways they differ. The first is that process.nextTick() will run before any Immediates that are set as well as before any scheduled I/O. The second is that process.nextTick() is non-clearable, meaning once code has been scheduled to execute with process.nextTick(), the execution cannot be stopped, just like with a normal function. Refer to this guide to better understand the operation of process.nextTick().


My Demo:
[i500695@C02X632CJGH6:2019-01-13 13:49:02:~/Desktop/work/code/nodejs/tutorial:]539$ node watchDogDemo.js 
simple emmitter demo
************
an event occurred!
************
WatchDog::constructur() 
WatchDog::startWatch() for the night is cold and full of terror
more complex emmitter demo. A WatchDog thread the checks for a condition ever x ms and emits an event when condition is met
WatchDog::checkEnvVarHasChanged() 
WatchDog::emitEnvVarChanged() 
************
WatchDog::on(envVarHasChanged) called for env var NODE_ENV
************
WatchDog::checkEnvVarHasChanged() 
WatchDog::emitEnvVarChanged() 
************

code:
[i500695@C02X632CJGH6:2019-01-13 14:11:31:~/Desktop/work/code/nodejs/tutorial:]541$ cat !$
cat watchDogDemo.js
const evtEmitter = require('events');

class MyEmitter extends evtEmitter {
  constructor() {
    super(); //must call super for "this" to be defined.
  }
}

console.log('simple emmitter demo');
const myEmitter = new MyEmitter();
myEmitter.on('event1', () => {
                console.log('************');
  console.log('an event occurred!');
                console.log('************');
});
myEmitter.emit('event1');

class WatchDog extends evtEmitter{

        constructor(){
                super(); //defines this
                console.log('WatchDog::constructur() ');
                this.envVarToWatch = 'NODE_ENV';
                this.envVarToWatchValue = process.env.NODE_ENV;
                this.fileToWatch = 'test';
                this.shouldStop=false;
        }

        emitEnvVarChanged(envName){
                console.log('WatchDog::emitEnvVarChanged() ');
                this.emit('envVarHasChanged', 'NODE_ENV'); 
        }

        checkEnvVarHasChanged(){
                console.log('WatchDog::checkEnvVarHasChanged() ');
                this.curVal = process.env.NODE_ENV;
                if (this.curVal !== this.envVarToWatchValue){
                    console.log('WatchDog::checkEnvVarHasChanged() detected change'); 
                    //this.emitEnvVarChanged('NODE_ENV'); 
                }
                this.emitEnvVarChanged('NODE_ENV'); // for real check put in above condition. I want to simulate change so emit always
        }

        sleep(ms) {
          return new Promise(resolve => setTimeout(resolve, ms));
        }

        async startWatch(ms){
                console.log('WatchDog::startWatch() for the night is cold and full of terror');
                this.shouldStop = false; //stop by calling stopWatch 
                while (!this.shouldStop){
                    //console.log('WatchDog::startWatch() before sleep');
                        await this.sleep(ms);
                        this.checkEnvVarHasChanged();
                    //console.log('WatchDog::startWatch() after sleep');
                }
        }

        stopWatch(){
                console.log('WatchDog::stopWatch() ');
                this.shouldStop = true; 
        }
}

const wd = new WatchDog();
wd.on('envVarHasChanged', function(envName){
                console.log('************');
                console.log('WatchDog::on(envVarHasChanged) called for env var %s', envName);
                console.log('************');
        });


wd.startWatch(1000); //ms
//wd.emit('envVarHasChanged');


console.log('more complex emmitter demo. A WatchDog thread the checks for a condition ever x ms and emits an event when condition is met');

        10.1.3 "Infinite Loop" Execution ~ setInterval()

If there is a block of code that should execute multiple times, setInterval() can be used to execute that code. setInterval() takes a function argument that will run an infinite number of times with a given millisecond delay as the second argument. Just like setTimeout(), additional arguments can be added beyond the delay, and these will be passed on to the function call. Also like setTimeout(), the delay cannot be guaranteed because of operations that may hold on to the event loop, and therefore should be treated as an approximate delay. See the below example:

function intervalFunc() {
  console.log('Cant stop me now!');
}
        
        setInterval(intervalFunc, 1500);
In the above example, intervalFunc() will execute about every 1500 milliseconds, or 1.5 seconds, until it is stopped (see below).

Just like setTimeout(), setInterval() also returns a Timeout object which can be used to reference and modify the interval that was set.

        10.1.4 Clearing the Future

What can be done if a Timeout or Immediate object needs to be cancelled? setTimeout(), setImmediate(), and setInterval() return a timer object that can be used to reference the set Timeout or Immediate object. By passing said object into the respective clear function, execution of that object will be halted completely. The respective functions are clearTimeout(), clearImmediate(), and clearInterval(). See the example below for an example of each:

const timeoutObj = setTimeout(() => {
  console.log('timeout beyond time');
}, 1500);

const immediateObj = setImmediate(() => {
  console.log('immediately executing immediate');
});

const intervalObj = setInterval(() => {
  console.log('interviewing the interval');
}, 500);

clearTimeout(timeoutObj);
clearImmediate(immediateObj);
clearInterval(intervalObj);
Leaving Timeouts Behind

Remember that Timeout objects are returned by setTimeout and setInterval. The Timeout object provides two functions intended to augment Timeout behavior with unref() and ref(). If there is a Timeout object scheduled using a set function, unref() can be called on that object. This will change the behavior slightly, and not call the Timeout object if it is the last code to execute. The Timeout object will not keep the process alive, waiting to execute.

In similar fashion, a Timeout object that has had unref() called on it can remove that behavior by calling ref() on that same Timeout object, which will then ensure its execution. Be aware, however, that this does not exactly restore the initial behavior for performance reasons. See below for examples of both:

const timerObj = setTimeout(() => {
  console.log('will i run?');
});

// if left alone, this statement will keep the above
// timeout from running, since the timeout will be the only
// thing keeping the program from exiting
timerObj.unref();

// we can bring it back to life by calling ref() inside
// an immediate
setImmediate(() => {
  timerObj.ref();
});
Further Down the Event Loop

There's much more to the Event Loop and Timers than this guide has covered. To learn more about the internals of the Node.js Event Loop and how Timers operate during execution, check out this Node.js guide: The Node.js Event Loop, Timers, and process.nextTick().

    10.2 The event loop
https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/

The Node.js Event Loop, Timers, and process.nextTick()

What is the Event Loop?

The event loop is what allows Node.js to perform non-blocking I/O operations — despite the fact that JavaScript is single-threaded — by offloading operations to the system kernel whenever possible.

Since most modern kernels are multi-threaded, they can handle multiple operations executing in the background. When one of these operations completes, the kernel tells Node.js so that the appropriate callback may be added to the poll queue to eventually be executed. We'll explain this in further detail later in this topic.

Event Loop Explained

When Node.js starts, it initializes the event loop, processes the provided input script (or drops into the REPL, which is not covered in this document) which may make async API calls, schedule timers, or call process.nextTick(), then begins processing the event loop.

The following diagram shows a simplified overview of the event loop's order of operations.

   ┌───────────────────────────┐
┌─>│           timers          │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │     pending callbacks     │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
│  │       idle, prepare       │
│  └─────────────┬─────────────┘      ┌───────────────┐
│  ┌─────────────┴─────────────┐      │   incoming:   │
│  │           poll            │<─────┤  connections, │
│  └─────────────┬─────────────┘      │   data, etc.  │
│  ┌─────────────┴─────────────┐      └───────────────┘
│  │           check           │
│  └─────────────┬─────────────┘
│  ┌─────────────┴─────────────┐
└──┤      close callbacks      │
   └───────────────────────────┘
note: each box will be referred to as a "phase" of the event loop.

Each phase has a FIFO queue of callbacks to execute. While each phase is special in its own way, generally, when the event loop enters a given phase, it will perform any operations specific to that phase, then execute callbacks in that phase's queue until the queue has been exhausted or the maximum number of callbacks has executed. When the queue has been exhausted or the callback limit is reached, the event loop will move to the next phase, and so on.

Since any of these operations may schedule more operations and new events processed in the poll phase are queued by the kernel, poll events can be queued while polling events are being processed. As a result, long running callbacks can allow the poll phase to run much longer than a timer's threshold. See the timers and poll sections for more details.

NOTE: There is a slight discrepancy between the Windows and the Unix/Linux implementation, but that's not important for this demonstration. The most important parts are here. There are actually seven or eight steps, but the ones we care about — ones that Node.js actually uses - are those above.

Phases Overview

timers: this phase executes callbacks scheduled by setTimeout() and setInterval().
pending callbacks: executes I/O callbacks deferred to the next loop iteration.
idle, prepare: only used internally.
poll: retrieve new I/O events; execute I/O related callbacks (almost all with the exception of close callbacks, the ones scheduled by timers, and setImmediate()); node will block here when appropriate.
check: setImmediate() callbacks are invoked here.
close callbacks: some close callbacks, e.g. socket.on('close', ...).
Between each run of the event loop, Node.js checks if it is waiting for any asynchronous I/O or timers and shuts down cleanly if there are not any.

Phases in Detail

timers

A timer specifies the threshold after which a provided callback may be executed rather than the exact time a person wants it to be executed. Timers callbacks will run as early as they can be scheduled after the specified amount of time has passed; however, Operating System scheduling or the running of other callbacks may delay them.

Note: Technically, the poll phase controls when timers are executed.

For example, say you schedule a timeout to execute after a 100 ms threshold, then your script starts asynchronously reading a file which takes 95 ms:

const fs = require('fs');

function someAsyncOperation(callback) {
  // Assume this takes 95ms to complete
  fs.readFile('/path/to/file', callback);
}

const timeoutScheduled = Date.now();

setTimeout(() => {
  const delay = Date.now() - timeoutScheduled;

  console.log(`${delay}ms have passed since I was scheduled`);
}, 100);


// do someAsyncOperation which takes 95 ms to complete
someAsyncOperation(() => {
  const startCallback = Date.now();

  // do something that will take 10ms...
  while (Date.now() - startCallback < 10) {
    // do nothing
  }
});
When the event loop enters the poll phase, it has an empty queue (fs.readFile() has not completed), so it will wait for the number of ms remaining until the soonest timer's threshold is reached. While it is waiting 95 ms pass, fs.readFile() finishes reading the file and its callback which takes 10 ms to complete is added to the poll queue and executed. When the callback finishes, there are no more callbacks in the queue, so the event loop will see that the threshold of the soonest timer has been reached then wrap back to the timers phase to execute the timer's callback. In this example, you will see that the total delay between the timer being scheduled and its callback being executed will be 105ms.

Note: To prevent the poll phase from starving the event loop, libuv (the C library that implements the Node.js event loop and all of the asynchronous behaviors of the platform) also has a hard maximum (system dependent) before it stops polling for more events.

pending callbacks

This phase executes callbacks for some system operations such as types of TCP errors. For example if a TCP socket receives ECONNREFUSED when attempting to connect, some *nix systems want to wait to report the error. This will be queued to execute in the pending callbacks phase.

poll

The poll phase has two main functions:

Calculating how long it should block and poll for I/O, then
Processing events in the poll queue.
When the event loop enters the poll phase and there are no timers scheduled, one of two things will happen:

If the poll queue is not empty, the event loop will iterate through its queue of callbacks executing them synchronously until either the queue has been exhausted, or the system-dependent hard limit is reached.

If the poll queue is empty, one of two more things will happen:

If scripts have been scheduled by setImmediate(), the event loop will end the poll phase and continue to the check phase to execute those scheduled scripts.

If scripts have not been scheduled by setImmediate(), the event loop will wait for callbacks to be added to the queue, then execute them immediately.

Once the poll queue is empty the event loop will check for timers whose time thresholds have been reached. If one or more timers are ready, the event loop will wrap back to the timers phase to execute those timers' callbacks.

check

This phase allows a person to execute callbacks immediately after the poll phase has completed. If the poll phase becomes idle and scripts have been queued with setImmediate(), the event loop may continue to the check phase rather than waiting.

setImmediate() is actually a special timer that runs in a separate phase of the event loop. It uses a libuv API that schedules callbacks to execute after the poll phase has completed.

Generally, as the code is executed, the event loop will eventually hit the poll phase where it will wait for an incoming connection, request, etc. However, if a callback has been scheduled with setImmediate() and the poll phase becomes idle, it will end and continue to the check phase rather than waiting for poll events.

close callbacks

If a socket or handle is closed abruptly (e.g. socket.destroy()), the 'close' event will be emitted in this phase. Otherwise it will be emitted via process.nextTick().

setImmediate() vs setTimeout()

setImmediate and setTimeout() are similar, but behave in different ways depending on when they are called.

setImmediate() is designed to execute a script once the current poll phase completes.
setTimeout() schedules a script to be run after a minimum threshold in ms has elapsed.
The order in which the timers are executed will vary depending on the context in which they are called. If both are called from within the main module, then timing will be bound by the performance of the process (which can be impacted by other applications running on the machine).

For example, if we run the following script which is not within an I/O cycle (i.e. the main module), the order in which the two timers are executed is non-deterministic, as it is bound by the performance of the process:

// timeout_vs_immediate.js
setTimeout(() => {
  console.log('timeout');
}, 0);

setImmediate(() => {
  console.log('immediate');
});
$ node timeout_vs_immediate.js
timeout
immediate

$ node timeout_vs_immediate.js
immediate
timeout
However, if you move the two calls within an I/O cycle, the immediate callback is always executed first:

// timeout_vs_immediate.js
const fs = require('fs');

fs.readFile(__filename, () => {
  setTimeout(() => {
    console.log('timeout');
  }, 0);
  setImmediate(() => {
    console.log('immediate');
  });
});
$ node timeout_vs_immediate.js
immediate
timeout

$ node timeout_vs_immediate.js
immediate
timeout
The main advantage to using setImmediate() over setTimeout() is setImmediate() will always be executed before any timers if scheduled within an I/O cycle, independently of how many timers are present.

process.nextTick()

Understanding process.nextTick()

You may have noticed that process.nextTick() was not displayed in the diagram, even though it's a part of the asynchronous API. This is because process.nextTick() is not technically part of the event loop. Instead, the nextTickQueue will be processed after the current operation completes, regardless of the current phase of the event loop.

Looking back at our diagram, any time you call process.nextTick() in a given phase, all callbacks passed to process.nextTick() will be resolved before the event loop continues. This can create some bad situations because it allows you to "starve" your I/O by making recursive process.nextTick() calls, which prevents the event loop from reaching the poll phase.

Why would that be allowed?

Why would something like this be included in Node.js? Part of it is a design philosophy where an API should always be asynchronous even where it doesn't have to be. Take this code snippet for example:

function apiCall(arg, callback) {
  if (typeof arg !== 'string')
    return process.nextTick(callback,
                            new TypeError('argument should be string'));
}
The snippet does an argument check and if it's not correct, it will pass the error to the callback. The API updated fairly recently to allow passing arguments to process.nextTick() allowing it to take any arguments passed after the callback to be propagated as the arguments to the callback so you don't have to nest functions.

What we're doing is passing an error back to the user but only after we have allowed the rest of the user's code to execute. By using process.nextTick() we guarantee that apiCall() always runs its callback after the rest of the user's code and before the event loop is allowed to proceed. To achieve this, the JS call stack is allowed to unwind then immediately execute the provided callback which allows a person to make recursive calls to process.nextTick() without reaching a RangeError: Maximum call stack size exceeded from v8.

This philosophy can lead to some potentially problematic situations. Take this snippet for example:

let bar;

// this has an asynchronous signature, but calls callback synchronously
function someAsyncApiCall(callback) { callback(); }

// the callback is called before `someAsyncApiCall` completes.
someAsyncApiCall(() => {
  // since someAsyncApiCall has completed, bar hasn't been assigned any value
  console.log('bar', bar); // undefined
});

bar = 1;
The user defines someAsyncApiCall() to have an asynchronous signature, but it actually operates synchronously. When it is called, the callback provided to someAsyncApiCall() is called in the same phase of the event loop because someAsyncApiCall() doesn't actually do anything asynchronously. As a result, the callback tries to reference bar even though it may not have that variable in scope yet, because the script has not been able to run to completion.

By placing the callback in a process.nextTick(), the script still has the ability to run to completion, allowing all the variables, functions, etc., to be initialized prior to the callback being called. It also has the advantage of not allowing the event loop to continue. It may be useful for the user to be alerted to an error before the event loop is allowed to continue. Here is the previous example using process.nextTick():

let bar;

function someAsyncApiCall(callback) {
  process.nextTick(callback);
}

someAsyncApiCall(() => {
  console.log('bar', bar); // 1
});

bar = 1;
Here's another real world example:

const server = net.createServer(() => {}).listen(8080);

server.on('listening', () => {});
When only a port is passed, the port is bound immediately. So, the 'listening' callback could be called immediately. The problem is that the .on('listening') callback will not have been set by that time.

To get around this, the 'listening' event is queued in a nextTick() to allow the script to run to completion. This allows the user to set any event handlers they want.

process.nextTick() vs setImmediate()

We have two calls that are similar as far as users are concerned, but their names are confusing.

process.nextTick() fires immediately on the same phase
setImmediate() fires on the following iteration or 'tick' of the event loop
In essence, the names should be swapped. process.nextTick() fires more immediately than setImmediate(), but this is an artifact of the past which is unlikely to change. Making this switch would break a large percentage of the packages on npm. Every day more new modules are being added, which means every day we wait, more potential breakages occur. While they are confusing, the names themselves won't change.

We recommend developers use setImmediate() in all cases because it's easier to reason about (and it leads to code that's compatible with a wider variety of environments, like browser JS.)

Why use process.nextTick()?

There are two main reasons:

Allow users to handle errors, cleanup any then unneeded resources, or perhaps try the request again before the event loop continues.

At times it's necessary to allow a callback to run after the call stack has unwound but before the event loop continues.

One example is to match the user's expectations. Simple example:

const server = net.createServer();
server.on('connection', (conn) => { });

server.listen(8080);
server.on('listening', () => { });
Say that listen() is run at the beginning of the event loop, but the listening callback is placed in a setImmediate(). Unless a hostname is passed, binding to the port will happen immediately. For the event loop to proceed, it must hit the poll phase, which means there is a non-zero chance that a connection could have been received allowing the connection event to be fired before the listening event.

Another example is running a function constructor that was to, say, inherit from EventEmitter and it wanted to call an event within the constructor:

const EventEmitter = require('events');
const util = require('util');

function MyEmitter() {
  EventEmitter.call(this);
  this.emit('event');
}
util.inherits(MyEmitter, EventEmitter);

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
You can't emit an event from the constructor immediately because the script will not have processed to the point where the user assigns a callback to that event. So, within the constructor itself, you can use process.nextTick() to set a callback to emit the event after the constructor has finished, which provides the expected results:

const EventEmitter = require('events');
const util = require('util');

function MyEmitter() {
  EventEmitter.call(this);

  // use nextTick to emit the event once a handler is assigned
  process.nextTick(() => {
    this.emit('event');
  });
}
util.inherits(MyEmitter, EventEmitter);

const myEmitter = new MyEmitter();
myEmitter.on('event', () => {
  console.log('an event occurred!');
});

    10.3


11. troubleshooting

    11.1 Error: Cannot find module '../lib/utils/unsupported.js'
[i500695@C02X632CJGH6:2019-01-16 13:54:56:~:]1359$ npm
internal/modules/cjs/loader.js:605
    throw err;
    ^

Error: Cannot find module '../lib/utils/unsupported.js'
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:603:15)
    at Function.Module._load (internal/modules/cjs/loader.js:529:25)
    at Module.require (internal/modules/cjs/loader.js:657:17)
    at require (internal/modules/cjs/helpers.js:22:18)
    at /usr/local/lib/node_modules/npm/bin/npm-cli.js:19:21
    at Object.<anonymous> (/usr/local/lib/node_modules/npm/bin/npm-cli.js:153:3)
    at Module._compile (internal/modules/cjs/loader.js:721:30)
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:732:10)
    at Module.load (internal/modules/cjs/loader.js:620:32)
    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)

Fix:
Try to remove /usr/local/lib/node_modules/npm and reinstall node again. This should work.

On MacOS with Homebrew:

sudo rm -rf /usr/local/lib/node_modules/npm && brew reinstall node

brew update && brew uninstall node && brew install node && brew postinstall 

My fix (that actually worked)
 1385  brew postinstall node
 1386  sudo chown -R $USER /usr/local
 1387  brew update
 1388  brew doctor
 1389  brew link node
 1390  brew cleanup
 1391  brew link node
 1392  brew uninstall node
 1393  brew install node
 1394  brew link --overwrite node

    11.2

12. My demos


    12.1   /Users/i500695/work/code/nodejs/tutorial/Gruntfile.js

module.exports = function(grunt) {
	var banner = '/*n<%= pkg.name %> <%= pkg.version %> - <%= pkg.description %>n<%= pkg.repository.url %>nBuilt on <%= grunt.template.today("yyyy-mm-dd") %>n*/n';

        // section 1 - require modules
    require('load-grunt-tasks')(grunt);

	grunt.initConfig({
		pkg: grunt.file.readJSON('package.json'),
                eslint: {
            options: {
                config: 'eslint.json',
                reset: true
            },
            target: ['*.js']
        },
        // task for mocha tests execution, they would be executed by nyc
        mochaTest: {
            local: {
                options: {
                    reporter: 'spec'
                },
                src: ['test/*.js']
            }
        },
        // nyc - executes mochaTest task
        nyc: {
            local: {
                options: {
                    all: true,
                    exclude: [
                        "**/*.spec.js",
                        "**/Gruntfile.js",
                        "**/Mock*",
                        "**/coverage",
                        "**/resources"
                    ],
                    reporter: ['text-summary', 'html'],
                    checkCoverage: true,
                    lines: 90
                },
                cmd: false,
                args: ['grunt', 'mochaTest:local', '--force']
            }
        }
	});


// section 3 - register grunt tasks
        //    grunt.loadNpmTasks('gruntify-eslint');
    grunt.loadNpmTasks('grunt-mocha-test');
    grunt.loadNpmTasks('grunt-simple-nyc');

    // Default task
    //grunt.registerTask('default', [ 'test']);
    grunt.registerTask('default', ['lint', 'test']);
    // Lint task
    //grunt.registerTask('lint', ['eslint:ci']);
    grunt.registerTask('lint', ['eslint']);
    // Mocha test task
    grunt.registerTask('test', ['nyc:local']);
};

    12.2   /Users/i500695/work/code/nodejs/tutorial/arraysDemo.js

let myarray1 = [] //create an empty array
let myarray2 = ['a', 'b'] //create a non empty array
let myarrayofarrays=[myarray1, myarray2]

let printArr = function(arr){
    arr.forEach(function(item, index, array) {
        console.log(item, index);
});

};
console.log("Print arrays:");
printArr(myarrayofarrays);

let first = myarray2[0];
let last = myarray2[myarray2.length -1];


console.log("arrays add/remove operations:");
let newLength = myarray2.push('c'); //add to end
let lastElem = myarray2.pop(); // remove from end
let firstElem = myarray2.shift(); // remove from front
newLength = myarray2.unshift('aa'); //add to end
newLength = myarray2.unshift('aaa'); //add to end

let posofaa=myarray2.indexOf('aa');
printArr(myarray2);

//myarray2 = [aaa, aa, b]
//

console.log("remove n items from position. splice(pos, n). removing aa:");
let removedItem = myarray2.splice(myarray2.indexOf('aa'), 1);
printArr(myarray2);



console.log("arrays shallow copy");
let myarray3 = myarray2.slice();
printArr(myarray3);

console.log("array as result of regex match");
// Match one d followed by one or more b's followed by one d
// Remember matched b's and the following d
// Ignore case
var myRe = /d(b+)(d)/i;
var myarray4  = myRe.exec('cdbBdbsbz');
printArr(myarray4);

//Delete from array using filter https://stackoverflow.com/questions/10024866/remove-object-from-array-using-javascript
console.log('using filter to delete from array');
let myarray5 = myarray2.filter( (elem) => { return elem !== 'aaa';}) ;
printArr(myarray5);

let arrOfObj = [ {'k1':'val', 'k2':'val2'} , {'k3':'val3', 'k4':'val4'}]
console.log('array of objects print as string: %s', arrOfObj.toString());
console.log('array of objects print as string using join:  %s', arrOfObj.join(", "));
console.log('array of objects print as string using JSON.stringify:  %s', JSON.stringify(arrOfObj));
let myobj = {
        'arr': arrOfObj
}
console.log('nested object print as string using JSON.stringify:  %s', JSON.stringify(myobj, null, 4));

    12.3   /Users/i500695/work/code/nodejs/tutorial/asyncAwaitDemo.js

//async  function f(){
//        return 1;
//}

//f().then( res => console.log("promise returned %s", res));
//console.log("waiting on async promise. val=%s", f().then());
//
//
function createPromise(){
  return new Promise((resolve, reject) => {
    setTimeout(() => resolve("done!"), 1000)
  });
}

async function f1() {

        let result;
        try{
  result = await createPromise(); // wait till the promise resolves (*), await can only be used in an async function. Its better than using .then() w/ success function
        }
        catch (err){
                console.log("promise rejected %s",err);
        }

  console.log("result=%s", result); // "done!"
        return result;
}

f1().then(res => console.log("res=%s",res));



    12.4   /Users/i500695/work/code/nodejs/tutorial/buffers.js

var buf = new Buffer(10); 
console.log("buf= ",buf);


var buf1 = new Buffer([1,2,3,4]); 
console.log("buf1= ",buf1);

var buf2 = new Buffer(256); 
wlen = buf2.write("writing to buffer");
console.log("wrote "+wlen+" bytes to buf2. content(hex)= ",buf2);
console.log("readable content= "+buf2.toString('utf8',0, wlen));

buf = new Buffer(26);
for (var i = 0 ; i < 26 ; i++) {
  buf[i] = i + 97;
}

console.log( buf.toString('ascii'));       // outputs: abcdefghijklmnopqrstuvwxyz
console.log( buf.toString('ascii',0,5));   // outputs: abcde
console.log( buf.toString('utf8',0,5));    // outputs: abcde
console.log( buf.toString(undefined,0,5)); // encoding defaults to 'utf8', outputs abcde




var buf = new Buffer('Simply Easy Learning');
var json = buf.toJSON(buf);

console.log(json);


var buffer1 = new Buffer('TutorialsPoint ');
var buffer2 = new Buffer('Simply Easy Learning');
var buffer3 = Buffer.concat([buffer1,buffer2]);
console.log("buffer3 content: " + buffer3.toString());

var buffera = new Buffer('ABC');
var bufferb = new Buffer('ABCD');
var result = buffera.compare(buffer2);

if(result < 0) {
   console.log(buffera +" comes before " + bufferb);
}else if(result == 0){
   console.log(buffera +" is same as " + bufferb);
}else {
   console.log(buffera +" comes after " + bufferb);
}

var bufferc = new Buffer('ABC');

//copy a buffer
var bufferd = new Buffer(3);
bufferc.copy(bufferd);
console.log("bufferd content: " + bufferd.toString());

var buffere = new Buffer('TutorialsPoint');

//slicing a buffer
var bufferf = bufferd.slice(0,9);
console.log("bufferf content: " + bufferf.toString());


var bufferg = new Buffer('TutorialsPoint');

//length of the buffer
console.log("buffer length: " + bufferg.length);




    12.5   /Users/i500695/work/code/nodejs/tutorial/classes.js

class DemoClass{

        constructor(name){
                this.name = name;
        }

        printMe(){
                console.log("name is %s",this.name);
                console.log("undefined member: %s", this.undef);
                if (!this.undef) {
                        console.log("this.undef is undefined");
                }
                else{
                        console.log("this.undef is defined");
                }
        }
}

function test1(){
    demoC = new DemoClass('demo');
    demoC.printMe();
}

test1()


    12.6   /Users/i500695/work/code/nodejs/tutorial/client.js

var http = require('http');

// Options to be used by request 
var options = {
   host: 'localhost',
   port: '8081',
   path: '/index.htm'  
};

// Callback function is used to deal with response
var callback = function(response){
   // Continuously update stream with data
   var body = '';
   response.on('data', function(data) {
      body += data;
   });
   
   response.on('end', function() {
      // Data received completely.
      console.log(body);
   });
}
// Make a request to the server
var req = http.request(options, callback);
req.end();

// Options to be used by request 
var options1 = {
   host: 'localhost',
   port: '8081',
   path: '/client.js'
};

;
var req1 = http.request(options1, callback);
req1.end();


    12.7   /Users/i500695/work/code/nodejs/tutorial/dictionaryDemo.js

//ES5 JS

var dict = {};

var func1 = function(){
        console.log('func1 called');
}

var func2 = function(){
        console.log('func2 called');
}

//function as value
dict['func1'] = func1;
dict['func2'] = func2;

//function as key
dict[func1] = 'This is func1 value';
dict[func2] = 'This is func2 value';

Object.keys(dict).forEach(function (key, index){
        console.log('dictionary key ', key);
        console.log('dictionary index ', index);
        console.log('dictionary value ', dict[key]);
        if (typeof dict[key] === 'function'){
                console.log('encounter a function value. running it');
                dict[key]();
        }
});


    12.8   /Users/i500695/work/code/nodejs/tutorial/eventEmitterListenersLeakDemo.js

//Assume Logger is a module that emits errors
//var Logger = require('./Logger.js');


const EventEmitter = require('events');

class MyEmitter extends EventEmitter {}

const myEmitter = new MyEmitter();
for (var i = 0; i < 11; i++) {
console.log('number of listeres: ' +EventEmitter.listenerCount(myEmitter, 'event'));
myEmitter.on('event', () => {
  console.log('an event occurred!');
});
}
myEmitter.emit('event');

//Note, to fix (node:85333) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 event listeners added. Use emitter.setMaxListeners() to increase limit
//remove the .on (register event listener)  from loop


    12.9   /Users/i500695/work/code/nodejs/tutorial/evtHandlingDemo.js

console.log("Event handling demo started");

// import events
var events = require('events');


//create eventEmitter
var eventEmitter = new events.EventEmitter();

//bind an event + event handler
//eventEmitter.on('eventName', eventHandler);
//
//emit event
//eventEmitter.emit('eventName');
//

//create event handler
var connectionHandler = function connected()  {

        console.log("connectionHandler called for successful connection");

        eventEmitter.emit('data_received');
}

//bind successful connection event to its event handler
eventEmitter.on('connection', connectionHandler);

eventEmitter.on('data_received', function () {
     console.log("anonymous data_received CB function called");
});

//fire the successful connection event
eventEmitter.emit('connection');

// listener #1
var listner1 = function listner1() {
   console.log('listner1 executed.');
}

// listener #2
var listner2 = function listner2() {
  console.log('listner2 executed.');
}

// Bind the connection event with the listner1 function
eventEmitter.addListener('connection', listner1);

// Bind the connection event with the listner2 function
eventEmitter.on('connection', listner2);

var eventListeners = require('events').EventEmitter.listenerCount
   (eventEmitter,'connection');
console.log(eventListeners + " Listner(s) listening to connection event");

// Fire the connection event 
eventEmitter.emit('connection');

// Remove the binding of listner1 function
eventEmitter.removeListener('connection', listner1);
console.log("Listner1 will not listen now.");

// Fire the connection event 
eventEmitter.emit('connection');

eventListeners = require('events').EventEmitter.listenerCount(eventEmitter,'connection');
console.log(eventListeners + " Listner(s) listening to connection event");

console.log("Program Ended.");

console.log("Event handling demo ended");



    12.10  /Users/i500695/work/code/nodejs/tutorial/expressDemo.js

var  express = require('express');

var app = express();

app.get('/', function(req, res){
        res.send('Hello world!!');
});

var server = app.listen(8081, function(){
        var host = server.address().address ;
        var port = server.address().port ;

        console.log("Example server listening at http://%s:%s",host, port);
});





    12.11  /Users/i500695/work/code/nodejs/tutorial/fsDemo.js

let fs = require("fs");


obj={
        'arr': ['a','b'],
        'innerObj': {
                'c': 1,
                'd': 'ddd'
        }
};

let buffer = new Buffer(JSON.stringify(obj, null, 4));
let filepath1='./fsDemoGeneratedOutput.json';
let filepath2='./fsDemoBufferedOutput.json';

console.log('async write buffer to file using low level api');
fs.open(filepath2, 'w', function(err, fd){
        if (err){
                throw 'error opening file '+ err;
        }

        fs.write(fd, buffer, 0, buffer.length, null, function(err){
                if (err){
                        throw 'error writing to file ' + err;
                }
                
                    fs.close(fd, function() {
                            console.log('finished writing. file closed.');
                    });
    })
});
console.log('finished async write buffer to file using low level api');

//now read back
fs.open(filepath2, 'r', function(err, fd){
        if (err){
                throw 'error opening file '+ err;
        }
                //at this point write has finished
                fs.read(fd, Buffer.alloc(300), 0, 300, 0, function(err, bytesRead, buf) {
                    if (err){
                            throw 'error reading from file ' + err;
                    }

                    console.log('read from file ');
                    console.log(buf.toString('utf8'));
                });
         fs.close(fd, function() {
                 console.log('finished reading. file closed.');
         });
});


console.log('async write JSON to file using higher level api');
fs.writeFile(filepath1, JSON.stringify(obj), 'utf8', function(err){
        if (err){
                console.log('fs.writeFile error '+err);
        }
        console.log('completed writing JSON to file');
});

setTimeout( function(){
        fs.readFile(filepath1, 'utf8' , function (err, data){
        if (err){
                console.log('fs.readFile error '+err);
        }
        let obj1 = JSON.parse(data); // convert to object just for kicks 

        console.log('readFile has read ', data);

        });
}, 1000);




    12.12  /Users/i500695/work/code/nodejs/tutorial/globalsDemo.js

console.log("Demo of nodejs globals");

console.log(" __filename = ", __filename);
console.log(" __dirname = ", __dirname);
console.log(" platform+arch = ", process.platform, process.arch);
console.log(" pid = ", process.pid);
console.log(" title = ", process.title);


console.log("setTimeout(cb,ms) triggers cb after ms...");

function echoMsg (argument) {
    console.log(argument.toString());
}

var to = setTimeout(echoMsg, 2000, "printed after 2 seconds");
var to1 = setTimeout(echoMsg, 2000, "printed after 2 seconds");

clearTimeout(to1);

setInterval(echoMsg, 1000, "Print after one second");



    12.13  /Users/i500695/work/code/nodejs/tutorial/helloWorld.js


console.log("importing http module and loading server");

var http =require("http");

http.createServer( function(request, response) {

    console.log("Sending HTTP header status 200 (ok) , type text/plain");
    response.writeHead(200, {'Content-Type':'text/plain'} ) ;


    console.log("Sending HTTP body status: Hello World nodejs  ");
    response.end('Hello World nodejs \n');
}).listen(8081);

console.log("server up. listen on http://127.0.0.1:8081/");

var fs = require("fs")

var data = fs.readFileSync('helloWorld.js');
console.log("Reading file synchronously. content: ", data.toString());



console.log("Reading file asynchronously by registering a callback function to do something w/ file content...");
fs.readFile('helloWorld.js', function (err,data) {
    if (err) return console.error(err);

    console.log("Printing file content from CB: ", data.toString());
});

console.log("End of demo program");





    12.14  /Users/i500695/work/code/nodejs/tutorial/helloWorldClass.js

class HelloWorld{
    constructor(msg){
            this.msg = msg;
    }

    printHelloWorld()
        {
                console.log(this.msg);
                return this.msg;
        }
}

module.exports = new HelloWorld ("Hello World. This is a demo of basic nodejs");




    12.15  /Users/i500695/work/code/nodejs/tutorial/jsObjectDemo.js

console.log('iterate object keys');
var data = {
  "VERSION": "2006-10-27.a",
  "JOBNAME": "EXEC_",
  "JOBHOST": "Test",
  "LSFQUEUE": "45",
  "LSFLIMIT": "2006-10-27",
  "NEWUSER": "3",
  "NEWGROUP": "2",
  "NEWMODUS": "640"
};

Object.keys(data).forEach(function(key) {
  console.log('Key : ' + key + ', Value : ' + data[key])
})

console.log('iterate array using forEach');
let arr = [1,2,3,4];
yourArray.forEach(function (arrayItem) {
    var x = arrayItem+ 2;
    console.log(x);
});


console.log('iterate array using for');
for (var j = 0; j < arr.length; j++){
  console.log(arr[j].x);
}


console.log('iterate array using for item');
for (let item of arr) {
    console.log(item); // Will display contents of the object inside the array
}

console.log('some use cases of looping through an array in the functional programming way in JavaScript');

//1. Just loop through an array

const myArray = [{x:100}, {x:200}, {x:300}];

myArray.forEach((element, index, array) => {
    console.log(element.x); // 100, 200, 300
    console.log(index); // 0, 1, 2
    console.log(array); // same myArray object 3 times
});
//Note: Array.prototype.forEach() is not a functional way strictly speaking, as the function it takes as the input parameter is not supposed to return a value, which thus cannot be regarded as a pure function.

//2. Check if any of the elements in an array pass a test

const people = [
    {name: 'John', age: 23},
    {name: 'Andrew', age: 3},
    {name: 'Peter', age: 8},
    {name: 'Hanna', age: 14},
    {name: 'Adam', age: 37}];

const anyAdult = people.some(person => person.age >= 18);
console.log(anyAdult); // true
//3. Transform to a new array

const myArray = [{x:100}, {x:200}, {x:300}];

const newArray= myArray.map(element => element.x);
console.log(newArray); // [100, 200, 300]
//Note: The map() method creates a new array with the results of calling a provided function on every element in the calling array.

//4. Sum up a particular property, and calculate its average

const myArray = [{x:100}, {x:200}, {x:300}];

const sum = myArray.map(element => element.x).reduce((a, b) => a + b, 0);
console.log(sum); // 600 = 0 + 100 + 200 + 300

const average = sum / myArray.length;
console.log(average); // 200
//5. Create a new array based on the original but without modifying it

const myArray = [{x:100}, {x:200}, {x:300}];

const newArray= myArray.map(element => {
    return {
        ...element,
        x: element.x * 2
    };
});

console.log(myArray); // [100, 200, 300]
console.log(newArray); // [200, 400, 600]
//6. Count the number of each category

const people = [
    {name: 'John', group: 'A'},
    {name: 'Andrew', group: 'C'},
    {name: 'Peter', group: 'A'},
    {name: 'James', group: 'B'},
    {name: 'Hanna', group: 'A'},
    {name: 'Adam', group: 'B'}];

const groupInfo = people.reduce((groups, person) => {
    const {A = 0, B = 0, C = 0} = groups;
    if (person.group === 'A') {
        return {...groups, A: A + 1};
    } else if (person.group === 'B') {
        return {...groups, B: B + 1};
    } else {
        return {...groups, C: C + 1};
    }
}, {});

console.log(groupInfo); // {A: 3, C: 1, B: 2}
//7. Retrieve a subset of an array based on particular criteria

const myArray = [{x:100}, {x:200}, {x:300}];

const newArray = myArray.filter(element => element.x > 250);
console.log(newArray); // [{x:300}]
//Note: The filter() method creates a new array with all elements that pass the test implemented by the provided function.

//8. Sort an array

const people = [
  { name: "John", age: 21 },
  { name: "Peter", age: 31 },
  { name: "Andrew", age: 29 },
  { name: "Thomas", age: 25 }
];

let sortByAge = people.sort(function (p1, p2) {
  return p1.age - p2.age;
});

console.log(sortByAge);

//9. Find an element in an array

const people = [ {name: "john", age:23},
                {name: "john", age:43},
                {name: "jim", age:101},
                {name: "bob", age:67} ];

const john = people.find(person => person.name === 'john');
console.log(john);

//The Array.prototype.find() method returns the value of the first element in the array that satisfies the provided testing function.




    12.16  /Users/i500695/work/code/nodejs/tutorial/promiseDemo.js

console.log("Starting promise demo");

function readJSONSync(filename){
let fs=require("fs");
        return JSON.parse(fs.readFileSync(filename, 'utf8'));
}

jsonData = readJSONSync("jsonFile");

console.log("Read data synchrounsly, %s ", JSON.stringify(jsonData));

function readJSONCB(filename, cb){
let fs=require("fs");
        fs.readFile(filename, 'utf8', function (err, res){
                if (err) return cb(err);
                cb(null, JSON.parse(res)) ;
        });
}

function printJSON(param1, json){
    console.log("Read data callback, %s ", JSON.stringify(json));
}

readJSONCB("jsonFile", printJSON);

//creating a promise
function readFilePromise(filename, encoding){

        console.log("readFilePromise called for file %s",filename);
        return new Promise( function(fulfill, reject){
                let fs = require("fs");
                fs.readFile(filename, encoding, function(err,res){
                        ////throw error commented code
                        //const errorMsg = new Error("Test error message");
                        //reject(errorMsg);
                        if (err) {

                                reject(err);
                        }
                        else {
                                fulfill(res);
                        }
                });
        });
}

//consuming a Promise
function readFileUsingPromise(filename){
        console.log("readFileUsingPromise called for file %s",filename);
        return readFilePromise(filename,  'utf8').then(function(res){
                console.log("readFileUsingPromise, read: %s", JSON.stringify(JSON.parse(res)));
                return JSON.parse(res);
        })
        .catch(function(err){
                console.log("Caught error %s",err.message);
        })
        ;
}

readFileUsingPromise("jsonFile");


//Manual tests. when lines 33-35 are active
// [i500695@C02X632CJGH6:2018-12-11 10:51:15:~/Desktop/work/code/nodejs/tutorial:]597$ node promiseDemo.js 
// Starting promise demo
// Read data synchrounsly, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise called for file jsonFile
// readFilePromise called for file jsonFile
// Read data callback, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise, read: {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"}
// [i500695@C02X632CJGH6:2018-12-11 10:51:23:~/Desktop/work/code/nodejs/tutorial:]598$ node promiseDemo.js 
// Starting promise demo
// Read data synchrounsly, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// readFileUsingPromise called for file jsonFile
// readFilePromise called for file jsonFile
// Read data callback, {"name":"yosi","lastName":"izaq","Description":"Demo of nodejs promise"} 
// Caught error Test error message
//
//
let getDateTimeFunc = function getDateTime() {

    var date = new Date();

    var hour = date.getHours();
    hour = (hour < 10 ? "0" : "") + hour;

    var min  = date.getMinutes();
    min = (min < 10 ? "0" : "") + min;

    var sec  = date.getSeconds();
    sec = (sec < 10 ? "0" : "") + sec;

    var year = date.getFullYear();

    var month = date.getMonth() + 1;
    month = (month < 10 ? "0" : "") + month;

    var day  = date.getDate();
    day = (day < 10 ? "0" : "") + day;

    return year + ":" + month + ":" + day + ":" + hour + ":" + min + ":" + sec;

}

console.log("Promise chaining demo");

//let toggle = false; //toggle for resolve / reject
let toggle = true; //toggle for resolve / reject
//1st promise.
let buyPhonePromise = new Promise( function(resove, reject){
        if (toggle){
                let phone = {
                        brand: 'apple',
                        color: 'black',
                        model: 'iphone xr'
                };
                resove(phone);
        } else{
                let error= new Error('too expensive lol');
                reject(error);
        }
});

//2nd promise, note takes 1st promise resolve as argument
let configurePhonePromise = function(phone){
        let message = 'successfully bought and configured new ' + phone.brand + ' phone, ' + phone.color + ' '+   phone.model;
        return Promise.resolve(message);
};

//3rd message, add date to message
let addDatePromise = function(message){
        let rmessage = getDateTimeFunc+' '+message;
        return Promise.resolve(message);
};

//chain promises for consumption
let simBuy = function(){

        buyPhonePromise
        .then(configurePhonePromise)
        .then(addDatePromise)
        .then(function(resolved){
                console.log(resolved);
        })
        .catch(function(reject){
                console.log(reject.message);
        });
};

simBuy();

console.log("Promise chaining demo using ES7 async await");


const buyPhonePromiseAA = new Promise( 
        (resolve, reject) => {
        if (toggle){
                console.log("buying phone...");
                const phone = {
                        brand: 'apple',
                        color: 'black',
                        model: 'iphone xr'
                };
                console.log("resolve phone %o",phone);
                resolve(phone);
        } else{
                console.log("not buying phone...");
                let error= new Error('too expensive lol');
                reject(error);
        }
});

//2nd promise, note takes 1st promise resolve as argument
async function  configurePhonePromiseAA (phone){
        return new Promise(
                (res,rej) => {
        let message = 'Async/Await successfully bought and configured new ' + phone.brand + ' phone, ' + phone.color + ' '+   phone.model;
        res(message);
                }
        );
};

//3rd message, add date to message
async function addDatePromiseAA (message){
        return new Promise(
                (res,jeg) => {
        let rmessage = getDateTimeFunc+' '+message;
        res(message);
                }
        )
};

async function simBuyAA(){

        try{
                console.log("Staring async calls...");
                let phone = await buyPhonePromiseAA;  
                console.log("bought phone %s",phone);
                let message = await configurePhonePromiseAA(phone);
                let rmessage = await addDatePromiseAA(message);
                console.log(rmessage);
                console.log("After async calls...");

        }
        catch (err){
                console.log(err);
        }
};

( async () => {
        await simBuyAA();
})();


    12.17  /Users/i500695/work/code/nodejs/tutorial/regex.js

const regexName = /^\w+$/

const testPatterns = ["a-c","$%", "abcd", "a_c", "a+b","a@b"];

let i;

for (i=0; i<testPatterns.length; i++)
{
        console.log("check pattern %s is a valid word. it is %s", testPatterns[i], regexName.test(testPatterns[i]));
}


const regexFilename = /^\w+$/
const filenameReservedRegex = require('filename-reserved-regex');
console.log(" filenameReservedRegex=%s", filenameReservedRegex);
const validFileName = require('valid-filename');

const testFileNames=["abs.js","a..cpp","\a","a:b",">a","v<a","aaa", ".","..","a.","b..", ".a"]; 
for (i=0; i<testFileNames.length; i++)
{
        console.log("check pattern %s is a valid filename. it is %s", testFileNames[i], validFileName(testFileNames[i]));
}



    12.18  /Users/i500695/work/code/nodejs/tutorial/server.js

var http = require('http');
var fs = require('fs');
var url = require('url');

// Create a server
http.createServer( function (request, response) {  
   // Parse the request containing file name
   var pathname = url.parse(request.url).pathname;
   
   // Print the name of the file for which request is made.
   console.log("Request for " + pathname + " received.");
   
   // Read the requested file content from file system
   fs.readFile(pathname.substr(1), function (err, data) {
      if (err) {
         console.log(err);
         // HTTP Status: 404 : NOT FOUND
         // Content Type: text/plain
         response.writeHead(404, {'Content-Type': 'text/html'});
      }else {	
         //Page found	  
         // HTTP Status: 200 : OK
         // Content Type: text/plain
         response.writeHead(200, {'Content-Type': 'text/html'});	
         
         // Write the content of the file to response body
         response.write(data.toString());		
      }
      // Send the response body 
      response.end();
   });   
}).listen(8081);

// Console will print the message
console.log('Server running at http://127.0.0.1:8081/');


    12.19  /Users/i500695/work/code/nodejs/tutorial/serverRunner.js

var server = require('./server/index.js');
var port = process.env.PORT || 3000;

server.listen(port, function(){
        console.log("server running on port %d", port);
});









    12.20  /Users/i500695/work/code/nodejs/tutorial/sinonDemo.js

class User{

        constructor (fname, lname){
                this.fname = fname;
                this.lname = lname;
        }

        getName()
        {
                return this.fname +" "+this.lname;
        }

        sleep(ms){
                return new Promise(resolve => setTimeout(resolve,ms));
        }

        async saveToDB()
        {
                console.log("sleeping...");
                await this.sleep(2000);
                console.log("woke up 2 sec later");
        }

        setName(fname,lname){
                this.fname = fname;
                this.lname = lname;
        }

        callSetThenGetName(){
                console.log("callSetThenGetName()");
                this.setName(this.fname, this.lname);
                this.saveToDB();
                this.getName();
        }
}


//module.exports = new User ("yosi","izaq");
module.exports = User ;

var sinon = require('sinon');
let user = new User("yosi","izaq");
var getNameSpy =  sinon.spy(user,"getName");

var i;
for (i=0;i<10;i++) user.getName();
console.log("user.getName() called %s times", getNameSpy.callCount);
//calling restore removes the spy. this is very important.
getNameSpy.restore();

user.saveToDB();



    12.21  /Users/i500695/work/code/nodejs/tutorial/sinonDemoManager.js

user = require('./sinonDemo.js');

class Manager{
        constructor(name){
                this.name =name;
        }

        hireNewEmployee( user)
        {
            console.log("hireNewEmployee()");
            user.callSetThenGetName();
        }
}

module.exports = Manager ;


    12.22  /Users/i500695/work/code/nodejs/tutorial/streamsDemo.js

var fs = require("fs");
var data = '';

console.log("demo read stream. node streams emit data,end,error,finish events...");
// Create a readable stream
var readerStream = fs.createReadStream('input.txt');

// Set the encoding to be utf8. 
readerStream.setEncoding('UTF8');

console.log("reader register on data CB");
// Handle stream events --> data, end, and error
readerStream.on('data', function(chunk) {
   console.log("reader on data CB got chunk: ", chunk);
   data += chunk;
});

readerStream.on('end',function(){
   console.log("on end CB ");
   console.log(data);
});

readerStream.on('error', function(err){
   console.log("on error CB ");
   console.log(err.stack);
});


console.log("demo write stream.");
//var data1="sample data";

var writeStream = fs.createWriteStream('output.txt');

writeStream.write(data,'UTF8');
writeStream.end();

writeStream.on('finish', function () {
   console.log("writer got finish event");
});


writeStream.on('error', function (err) {
   console.log("writer got error event: ", err.stack);
});

console.log("Demo piping streams"); 
var readerStream1 = fs.createReadStream('input.txt');
var writeStream1 = fs.createWriteStream('piped_output.txt');
readerStream1.pipe(writeStream1);

console.log("check piped output..."); 
fs.readFile('piped_output.txt', function (err,data) {
    if (err) return console.error(err);
    console.log("Printing piped_output.txt from CB: ", data.toString());
});

console.log("Demo chaining streams"); 
console.log("Demo chaining streams. Compressing"); 
var zlib = require('zlib');


var readerStream2 = fs.createReadStream('input.txt');
readerStream2.
        pipe(zlib.createGzip()).
        pipe(fs.createWriteStream('input.txt.gz'));


readerStream2.on('end' , function (){
console.log("input.txt.gz created"); 

console.log("Demo chaining streams. Decompressing"); 
var readerStream3 = fs.createReadStream('input.txt.gz');
        readerStream3.
        pipe(zlib.createGunzip()).
        pipe(fs.createWriteStream('input1.txt'));

        readerStream3.on('end', function () {
            console.log("input.txt.gz decompressed to input1.txt"); 
            
        });
});

console.log("Program Ended");


    12.23  /Users/i500695/work/code/nodejs/tutorial/switchStringDemo.js

//[i500695@C02X632CJGH6:2019-01-01 20:46:56:~/Desktop/work/code/nodejs/tutorial:]500$ node switchStringDemo.js
//process.env.REGION=undefined
//[i500695@C02X632CJGH6:2019-01-01 20:47:05:~/Desktop/work/code/nodejs/tutorial:]501$ export REGION=url
//[i500695@C02X632CJGH6:2019-01-01 20:47:21:~/Desktop/work/code/nodejs/tutorial:]502$ node switchStringDemo.js
//url detected. process.env.REGION=url
//[i500695@C02X632CJGH6:2019-01-01 20:47:23:~/Desktop/work/code/nodejs/tutorial:]503$ export REGION=json
//[i500695@C02X632CJGH6:2019-01-01 20:47:29:~/Desktop/work/code/nodejs/tutorial:]504$ node switchStringDemo.js
//json detected. process.env.REGION=json     
let region = process.env.REGION;

switch (region){

        case "url":
                console.log("url detected. process.env.REGION=%s",region);
                break;
        case "json":
                console.log("json detected. process.env.REGION=%s",region);
                break;
        default:
                console.log("process.env.REGION=%s",region);
                break;

}


    12.24  /Users/i500695/work/code/nodejs/tutorial/uuidDemo.js

let uuid = require('uuid/v1');
let uuidvalidate = require('uuid-validate');

module.exports=  () => {
        uuidv1 = uuid();
console.log("Generated uuid: %s", uuidv1 );
        if (uuidvalidate(uuidv1)) {
                console.log("it is a valid version %s uuid ", uuidvalidate.version(uuidv1));
        }
        else{
                console.log("it is not valid");
        }
        return uuidv1;

};

let genUUIDv1 = module.exports;

genUUIDv1();


    12.25  /Users/i500695/work/code/nodejs/tutorial/watchDogDemo.js

const evtEmitter = require('events');

class MyEmitter extends evtEmitter {
  constructor() {
    super(); //must call super for "this" to be defined.
  }
}

console.log('simple emmitter demo');
const myEmitter = new MyEmitter();
myEmitter.on('event1', () => {
                console.log('************');
  console.log('an event occurred!');
                console.log('************');
});
myEmitter.emit('event1');

class WatchDog extends evtEmitter{

        constructor(){
                super(); //defines this
                console.log('WatchDog::constructur() ');
                this.envVarToWatch = 'NODE_ENV';
                this.envVarToWatchValue = process.env.NODE_ENV;
                this.fileToWatch = 'test';
                this.shouldStop=false;
        }

        emitEnvVarChanged(envName){
                console.log('WatchDog::emitEnvVarChanged() ');
                this.emit('envVarHasChanged', 'NODE_ENV'); 
        }

        checkEnvVarHasChanged(){
                console.log('WatchDog::checkEnvVarHasChanged() ');
                this.curVal = process.env.NODE_ENV;
                if (this.curVal !== this.envVarToWatchValue){
                    console.log('WatchDog::checkEnvVarHasChanged() detected change'); 
                    //this.emitEnvVarChanged('NODE_ENV'); 
                }
                this.emitEnvVarChanged('NODE_ENV'); // for real check put in above condition. I want to simulate change so emit always
        }

        sleep(ms) {
          return new Promise(resolve => setTimeout(resolve, ms));
        }

        async startWatch(ms){
                console.log('WatchDog::startWatch() for the night is cold and full of terror');
                this.shouldStop = false; //stop by calling stopWatch 
                while (!this.shouldStop){
                    //console.log('WatchDog::startWatch() before sleep');
                        await this.sleep(ms);
                        this.checkEnvVarHasChanged();
                    //console.log('WatchDog::startWatch() after sleep');
                }
        }

        stopWatch(){
                console.log('WatchDog::stopWatch() ');
                this.shouldStop = true; 
        }
}

const wd = new WatchDog();
wd.on('envVarHasChanged', function(envName){
                console.log('************');
                console.log('WatchDog::on(envVarHasChanged) called for env var %s', envName);
                console.log('************');
        });


//watchdog using setTimeout.
//wd.startWatch(1000); //ms

//watchdog using setInterval - more efficient since manual loop implementation is not required
const intervalId = setInterval(function() { wd.checkEnvVarHasChanged();}, 2000);
//wd.emit('envVarHasChanged');


console.log('more complex emmitter demo. A WatchDog thread the checks for a condition ever x ms and emits an event when condition is met');


    12.26  



    12.27  
    12.28  
    12.29  
    12.30  
    12.31  
    12.32  
    12.33  
    12.34  
    12.35  
    12.36  
    12.37  
    12.38  
    12.39  
    12.40  
    12.41  
    12.42  
    12.43  
    12.44  
    12.45  
    12.46  
    12.47  
    12.48  
    12.49  
    12.50  
    12.51  
    12.52  
    12.53  
    12.54  
    12.55  
    12.56  
    12.57  
    12.58  
    12.59  
    12.60  
    12.61  
    12.62  
    12.63  
    12.64  
    12.65  
    12.66  
    12.67  
    12.68  
    12.69  
    12.70  
    12.71  
    12.72  
    12.73  
    12.74  
    12.75  
    12.76  
    12.77  
    12.78  
    12.79  
    12.80  
    12.81  
    12.82  
    12.83  
    12.84  
    12.85  
    12.86  
    12.87  
    12.88  
    12.89  
    12.90  
    12.91  
    12.92  
    12.93  
    12.94  
    12.95  
    12.96  
    12.97  
    12.98  
    12.99  
    12.100 
    12.101 



13. Language

    13.1 Object API
        
        13.1.1 Object.assign


            13.1.1.1 Object.assign copy idiom, why should pass {} as first arg
demo, foo w/o{} as first arg 
foosafe with {} as first arg

   [i500695@C02X632CJGH6:2019-06-03 13:39:27:~:]2001$ node
> function foo(bar){
... 
... let src = {a:'b'};
... let ob = Object.assign(bar,src);
... console.log(ob);
... }
undefined
> foo({})
{ a: 'b' }
> foo({c:'d'});
{ c: 'd', a: 'b' }
> foo(null);
Thrown:
TypeError: Cannot convert undefined or null to object
    at Function.assign (<anonymous>)
    at foo (repl:4:17)
> foo(undefined);
Thrown:
TypeError: Cannot convert undefined or null to object
    at Function.assign (<anonymous>)
    at foo (repl:4:17)
> function foosafe(bar){
... let src = {a:'b'};
... let ob = Object.assign({},bar,src);
... console.log(ob);
... }
> foosafe({})
{ a: 'b' }
> foosafe({c:'d'})
{ c: 'd', a: 'b' }
> foosafe(null)
{ a: 'b' }
> foosafe({})
{ a: 'b' }
> foosafe(undefined)
{ a: 'b' } 
> foosafe()
{ a: 'b' }
> foo()
Thrown:
TypeError: Cannot convert undefined or null to object
    at Function.assign (<anonymous>)
    at foo (repl:4:17)
        13.1.2

    13.2
14. Axios

    14.1 axios 101
Tutorial
Init projects
[i500695@C02X632CJGH6:2020-11-24 10:13:32:~/work/code/nodejs/axios:]2036$ npm init -y
Wrote to /Users/i500695/work/code/nodejs/axios/package.json:

{
  "name": "axios",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "",
  "license": "ISC"
}

Install axios
~/work/code/nodejs/axios101:]2043$ npm i axios



Axios Response object
When we send a request to a server, it returns a response. The Axios response object consists of:
* data - the payload returned from the server
* status - the HTTP code returned from the server
* statusText - the HTTP status message returned by the server
* headers - headers sent by server
* config - the original request configuration
* request - the request object

Simple example:
Cat get.js

const ax = require('axios')

ax.get('http://ynet.co.il').then(resp => {
    console.log('get response:',resp.data);
});

async function aget() {
    const resp = await ax.get('http://ynet.co.il');
    console.log('async/await got response:',resp.data);
}

aget();


Axios basic API
The get(), post(), or delete() methods are convenience methods for the basic axios API: axios(config) and axios(url, config).
basic_api.js
const axios = require('axios');

async function makeRequest() {

    const config = {
        method: 'get',
        url: 'http://webcode.me'
    }

    let res = await axios(config)

    console.log(res.status);
}

makeRequest();
The example creates a GET request to webcode.me.
const config = {
    method: 'get',
    url: 'http://webcode.me'
}
We specify the details of the request in the configuration object.

id=__axiosSet_max_response_size__
    14.2 Set max response size

[i500695@C02X632CJGH6:2020-11-26 17:57:03:~/work/code/nodejs/axios101:]2018$ cat !$
cat get_setmaxsize.js
const ax = require('axios')
const http = require('http');
const fs = require('fs');
const path = require('path');
const file='aa'
bigfileurl20mb='http://ipv4.download.thinkbroadband.com:8080/20MB.zip'
bigfileurl80mb='http://ipv4.download.thinkbroadband.com:8080/50MB.zip';
bigfileurl200mb='http://ipv4.download.thinkbroadband.com:8080/200MB.zip';
bigfilehost='ipv4.download.thinkbroadband.com';
// const maxsize = 2048;
const maxsize = 25*1024*1024;

url = 'http://localhost'+'/'+file;
// const url = 'http://localhost';

function getMaxSizeLim(url) {
    console.log('axios url', url);
    const config = {
        method: 'get',
        url: url,
        maxContentLength: maxsize, // response
        // maxBodyLength: maxsize, // request
        headers: {
            'User-Agent': 'Yosi Console',
            'maxContentLength': maxsize,
        }
    };
    ax(config).then(resp => {
        console.log(url+'download finished');
    })
    .catch (err => {
        console.log(url+'got error'+ err.message);
    });
}


function getMaxSizeLimAsStream(url) {
    console.log('axios url response as stream', url);
    const config = {
        method: 'get',
        url: url,
        // port: 8080,
        maxContentLength: maxsize, // response
        maxBodyLength: maxsize, // request
        responseType: 'stream',
        headers: {
            'User-Agent': 'Yosi Console',
            'maxContentLength': maxsize,
        }
    };
    ax(config).then(resp => {
        const fname = path.basename(url)
        resp.data.pipe(fs.createWriteStream(fname));
    })
        .catch (err => {
            console.log('HTTP get error', err.message);
        });
}

function getUsingRequests(url) {

    console.log('request url', url);
        const fname = path.basename(url)
    const opts = {
        method: 'GET',
        url: url,
        encoding: null,
        // hostname: bigfilehost,
        // path: path.basename(url),
    };
    const req = http.request(opts, resp => {
        console.log('get response status', resp.statusCode);
        console.log('get response length', resp.headers['content-length']);
        const file = fs.createWriteStream(fname);
        let size = 0;
        resp.on('data', data => {
            size+=data.length;
            if (size > maxsize) {
                console.log(`size ${size} exceeds limit ${maxsize}`);
                resp.abort(); //aborting response closes the stream
                fs.unlink(fname);
            }

        }).pipe(file);
        file.on('finish', () => {
            console.log('finished writing file');
            file.close();
        })
        // let data='';
        // resp.on('data', chunk => {
        //     data += chunk;
        // });
    });

    req.on('end', ()  => {
        console.log('end getting data. total length', data.length);
    });
    req.on('error', err  => {
        console.log('got error', err);
    });

    // req.write(data);
       req.end();

}

getMaxSizeLim(bigfileurl20mb);
getMaxSizeLim(bigfileurl80mb);
getMaxSizeLim(bigfileurl200mb);

// takes a long time so commented out
// getMaxSizeLimAsStream(bigfileurl20mb);
// getMaxSizeLimAsStream(bigfileurl80mb);
// getMaxSizeLimAsStream(bigfileurl200mb);
[i500695@C02X632CJGH6:2020-11-26 17:57:41:~/work/code/nodejs/axios101:]2019$ node get_setmaxsize.js 
axios url http://ipv4.download.thinkbroadband.com:8080/20MB.zip
axios url http://ipv4.download.thinkbroadband.com:8080/50MB.zip
axios url http://ipv4.download.thinkbroadband.com:8080/200MB.zip
http://ipv4.download.thinkbroadband.com:8080/200MB.zipgot errormaxContentLength size of 26214400 exceeded
http://ipv4.download.thinkbroadband.com:8080/50MB.zipgot errormaxContentLength size of 26214400 exceeded
http://ipv4.download.thinkbroadband.com:8080/20MB.zipdownload finished


    14.3 axios response headers

        14.3.1  simple example
const axios = require('axios');

async function makeGetRequest() {

  let res = await axios.get('http://webcode.me');

  let data = res.data;
  let headers = res.headers;

  console.log(typeof headers);
  console.log(headers);
}

makeGetRequest();

run on repl:
> async function makeGetRequest() {
... 
...   let res = await axios.get('http://webcode.me');
... 
...   let data = res.data;
...   let headers = res.headers;
...   console.log(headers);
... }
undefined
> 
> makeGetRequest();
Promise { <pending> }
> {
  server: 'nginx/1.6.2',
  date: 'Wed, 31 Mar 2021 15:07:00 GMT',
  'content-type': 'text/html',
  'content-length': '348',
  'last-modified': 'Sat, 20 Jul 2019 11:49:25 GMT',
  connection: 'close',
  etag: '"5d32ffc5-15c"',
  'access-control-allow-origin': '*',
  'accept-ranges': 'bytes'
}

    14.4
15. NodeJS tips and tricks 
		
    15.1 python like idioms, tags: nodejs, python


        15.1.1 python like range
https://stackoverflow.com/questions/8273047/javascript-function-similar-to-python-range
function* range(start, stop, step = 1) {
    if (stop == null) {
        // one param defined
        stop = start;
        start = 0;
    }

    for (let i = start; step > 0 ? i < stop : i > stop; i += step) {
        yield i;
    }
}
To use it in a for loop you need the ES6/JS1.7 for-of loop:

for (let i of range(5)) {
    console.log(i);
}
// Outputs => 0 1 2 3 4

for (let i of range(0, 10, 2)) {
    console.log(i);
}
// Outputs => 0 2 4 6 8

for (let i of range(10, 0, -2)) {
    console.log(i);
}
// Outputs => 10 8 6 4 2

        15.1.2 python like list comprehension
https://stackoverflow.com/questions/21372524/python-list-comprehensions-nodejs-javascript/21372656#21372656
List comprehensions put into a language's syntax what would normally be done with map and filter.

So given a Python list comprehension, you can also use map and filter:

# Python - preferred way
squares_of_odds = [x * x for x in a if x % 2 == 1]

# Python - alternate way
map(lambda x: x * x, filter(lambda x: x % 2 == 1, a))
although comprehensions are preferred in Python. JavaScript has map and filter so you can use those now.

// JavaScript - doesn't support real list comprehension
a.map(function(x){return x*x}).filter(function(x){return x%2 == 1})
        15.1.3 JSON.stringfy

            15.1.3.1 my JSON.stringify demo


code: [i500695@WYLQRXL9LQ:2023-01-31 18:36:30:~/work/code/nodejs/tutorial:]2009$ cat !$ | pbcopy
cat jsonStringify.js | pbcopy
// documentation: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify
//
//

console.log('Trivial usage examples');
console.log(JSON.stringify({ x: 5, y: 6 }));
// Expected output: "{"x":5,"y":6}"

console.log(JSON.stringify([new Number(3), new String('false'), new Boolean(false)]));
// Expected output: "[3,"false",false]"

console.log(JSON.stringify({ x: [10, undefined, function(){}, Symbol('')] }));
// Expected output: "{"x":[10,null,null,null]}"

console.log(JSON.stringify(new Date(2006, 0, 2, 15, 4, 5)));
// Expected output: ""2006-01-02T15:04:05.000Z""
//

JSON.stringify({}); // '{}'
JSON.stringify(true); // 'true'
JSON.stringify("foo"); // '"foo"'
JSON.stringify([1, "false", false]); // '[1,"false",false]'
JSON.stringify([NaN, null, Infinity]); // '[null,null,null]'
JSON.stringify({ x: 5 }); // '{"x":5}'

JSON.stringify(new Date(1906, 0, 2, 15, 4, 5));
// '"1906-01-02T15:04:05.000Z"'

JSON.stringify({ x: 5, y: 6 });
// '{"x":5,"y":6}'
JSON.stringify([new Number(3), new String("false"), new Boolean(false)]);
// '[3,"false",false]'

// String-keyed array elements are not enumerable and make no sense in JSON
const a = ["foo", "bar"];
a["baz"] = "quux"; // a: [ 0: 'foo', 1: 'bar', baz: 'quux' ]
JSON.stringify(a);
// '["foo","bar"]'

JSON.stringify({ x: [10, undefined, function () {}, Symbol("")] });
// '{"x":[10,null,null,null]}'

console.log('Note Set/Map etc content is not stringifed, use a custom replacer for this..');
// Standard data structures
JSON.stringify([
  new Set([1]),
  new Map([[1, 2]]),
  new WeakSet([{ a: 1 }]),
  new WeakMap([[{ a: 1 }, 2]]),
]);
// '[{},{},{},{}]'

// TypedArray
JSON.stringify([new Int8Array([1]), new Int16Array([1]), new Int32Array([1])]);
// '[{"0":1},{"0":1},{"0":1}]'
JSON.stringify([
  new Uint8Array([1]),
  new Uint8ClampedArray([1]),
  new Uint16Array([1]),
  new Uint32Array([1]),
]);
// '[{"0":1},{"0":1},{"0":1},{"0":1}]'
JSON.stringify([new Float32Array([1]), new Float64Array([1])]);
// '[{"0":1},{"0":1}]'

// toJSON()
JSON.stringify({
  x: 5,
  y: 6,
  toJSON() {
    return this.x + this.y;
  },
});
// '11'

console.log('Symbols are not printed..');
// Symbols:
JSON.stringify({ x: undefined, y: Object, z: Symbol("") });
// '{}'
JSON.stringify({ [Symbol("foo")]: "foo" });
// '{}'
JSON.stringify({ [Symbol.for("foo")]: "foo" }, [Symbol.for("foo")]);
// '{}'
JSON.stringify({ [Symbol.for("foo")]: "foo" }, (k, v) => {
  if (typeof k === "symbol") {
    return "a symbol";
  }
});
// undefined

// Non-enumerable properties:
JSON.stringify(
  Object.create(null, {
    x: { value: "x", enumerable: false },
    y: { value: "y", enumerable: true },
  }),
);
// '{"y":"y"}'

// // BigInt values throw
// JSON.stringify({ x: 2n });
// // throw 
// // TypeError: BigInt value can't be serialized in JSON

console.log('simple replacer. dont print strings');
function replacer(key, value) {
  // Filtering out properties
  if (typeof value === "string") {
    return undefined;
  }
  return value;
}

const foo = {
  foundation: "Mozilla",
  model: "box",
  week: 45,
  transport: "car",
  month: 7,
};
console.log(JSON.stringify(foo, replacer));

console.log('whitelist array replacer');
const foo1 = {
  foundation: "Mozilla",
  model: "box",
  week: 45,
  transport: "car",
  month: 7,
};

console.log(JSON.stringify(foo1, ["week", "month"]));

console.log('exclude some subproperties');
const nestedObj = {
    level1_str: 'a level 1 string',
    level1_obj: {
        level2_str: ' a level 2 string',
        level2_obj: {
            level3_printme: 'should be printed',
            level3_password: 'should not be printed',
            level3_certificate:  'should not be printed'
        }
    }
};
console.log('Print all without replacer', JSON.stringify(nestedObj, null, 4));
function myreplacer(key, val) {
    const blackListKeys = ['level3_password', 'level3_certificate']
    if (key === 'level1_str') {
        return 'replacer intercepted key level1_str';
    }
    if (key === 'level3_printme') {
        return 'replacer intercepted key level3_printme';
    }
    if (blackListKeys.includes(key)) {
        return '********';
    }
    return val;
}
console.log('Print with replacer', JSON.stringify(nestedObj, myreplacer, 4));
// '{"week":45,"month":7}', only keep "week" and "month" properties

// '{"week":45,"month":7}'
/*
 Syntax
JSON.stringify(value)
JSON.stringify(value, replacer)
JSON.stringify(value, replacer, space)
Copy to Clipboard
Parameters
value
The value to convert to a JSON string.

replacer Optional
A function that alters the behavior of the stringification process, or an array of strings and numbers that specifies properties of value to be included in the output. If replacer is an array, all elements in this array that are not strings or numbers (either primitives or wrapper objects), including Symbol values, are completely ignored. If replacer is anything other than a function or an array (e.g. null or not provided), all string-keyed properties of the object are included in the resulting JSON string.

space Optional
A string or number that's used to insert white space (including indentation, line break characters, etc.) into the output JSON string for readability purposes.

If this is a number, it indicates the number of space characters to be used as indentation, clamped to 10 (that is, any number greater than 10 is treated as if it were 10). Values less than 1 indicate that no space should be used.

If this is a string, the string (or the first 10 characters of the string, if it's longer than that) is inserted before every nested object or array.

If space is anything other than a string or number (can be either a primitive or a wrapper object) — for example, is null or not provided — no white space is used.

Return value
A JSON string representing the given value, or undefined.
 Exceptions
TypeError
Thrown if one of the following is true:

value contains a circular reference.
A BigInt value is encountered.*

JSON.stringify() converts a value to the JSON notation that the value represents. Values are stringified in the following manner:

Boolean, Number, String, and BigInt (obtainable via Object()) objects are converted to the corresponding primitive values during stringification, in accordance with the traditional conversion semantics. Symbol objects (obtainable via Object()) are treated as plain objects.
Attempting to serialize BigInt values will throw. However, if the BigInt has a toJSON() method (through monkey patching: BigInt.prototype.toJSON = ...), that method can provide the serialization result. This constraint ensures that a proper serialization (and, very likely, its accompanying deserialization) behavior is always explicitly provided by the user.
undefined, Function, and Symbol values are not valid JSON values. If any such values are encountered during conversion, they are either omitted (when found in an object) or changed to null (when found in an array). JSON.stringify() can return undefined when passing in "pure" values like JSON.stringify(() => {}) or JSON.stringify(undefined).
The numbers Infinity and NaN, as well as the value null, are all considered null. (But unlike the values in the previous point, they would never be omitted.)
Arrays are serialized as arrays (enclosed by square brackets). Only array indices between 0 and length - 1 (inclusive) are serialized; other properties are ignored.
For other objects:
All Symbol-keyed properties will be completely ignored, even when using the replacer parameter.
If the value has a toJSON() method, it's responsible to define what data will be serialized. Instead of the object being serialized, the value returned by the toJSON() method when called will be serialized. JSON.stringify() calls toJSON with one parameter, the key, which has the same semantic as the key parameter of the replacer function:
if this object is a property value, the property name
if it is in an array, the index in the array, as a string
if JSON.stringify() was directly called on this object, an empty string
Date objects implement the toJSON() method which returns a string (the same as date.toISOString()). Thus, they will be stringified as strings.
Only enumerable own properties are visited. This means Map, Set, etc. will become "{}". You can use the replacer parameter to serialize them to something more useful. Properties are visited using the same algorithm as Object.keys(), which has a well-defined order and is stable across implementations. For example, JSON.stringify on the same object will always produce the same string, and JSON.parse(JSON.stringify(obj)) would produce an object with the same key ordering as the original (assuming the object is completely JSON-serializable).
 *
 *
 The replacer parameter
The replacer parameter can be either a function or an array.

As an array, its elements indicate the names of the properties in the object that should be included in the resulting JSON string. Only string and number values are taken into account; symbol keys are ignored.

As a function, it takes two parameters: the key and the value being stringified. The object in which the key was found is provided as the replacer's this context.

The replacer function is called for the initial object being stringified as well, in which case the key is an empty string (""). It is then called for each property on the object or array being stringified. Array indices will be provided in its string form as key. The current property value will be replaced with the replacer's return value for stringification. This means:

If you return a number, string, boolean, or null, that value is directly serialized and used as the property's value. (Returning a BigInt will throw as well.)
If you return a Function, Symbol, or undefined, the property is not included in the output.
If you return any other object, the object is recursively stringified, calling the replacer function on each property.
Note: When parsing JSON generated with replacer functions, you would likely want to use the reviver parameter to perform the reverse operation.

Typically, array elements' index would never shift (even when the element is an invalid value like a function, it will become null instead of omitted). Using the replacer function allows you to control the order of the array elements by returning a different array.
 *
The space parameter
The space parameter may be used to control spacing in the final string.

If it is a number, successive levels in the stringification will each be indented by this many space characters.
If it is a string, successive levels will be indented by this string.
Each level of indentation will never be longer than 10. Number values of space are clamped to 10, and string values are truncated to 10 characters. 

Note: if a replacer is used for serialization, then a revive method is required in JSON.parse() to reverse the replacer changes back.
see: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#using_the_reviver_parameter
 */

Run:
[i500695@WYLQRXL9LQ:2023-01-31 18:37:52:~/work/code/nodejs/tutorial:]2010$ node jsonStringify.js 
Trivial usage examples
{"x":5,"y":6}
[3,"false",false]
{"x":[10,null,null,null]}
"2006-01-02T13:04:05.000Z"
Note Set/Map etc content is not stringifed, use a custom replacer for this..
Symbols are not printed..
simple replacer. dont print strings
{"week":45,"month":7}
whitelist array replacer
{"week":45,"month":7}
exclude some subproperties
Print all without replacer {
    "level1_str": "a level 1 string",
    "level1_obj": {
        "level2_str": " a level 2 string",
        "level2_obj": {
            "level3_printme": "should be printed",
            "level3_password": "should not be printed",
            "level3_certificate": "should not be printed"
        }
    }
}
Print with replacer {
    "level1_str": "replacer intercepted key level1_str",
    "level1_obj": {
        "level2_str": " a level 2 string",
        "level2_obj": {
            "level3_printme": "replacer intercepted key level3_printme",
            "level3_password": "********",
            "level3_certificate": "********"
        }
    }
}

            15.1.3.2

        15.1.4
    15.2
16. Node features per version 
https://nodejs.org/en/docs/es6/

    16.1 background
CMAScript 2015 (ES6) and beyond

Node.js is built against modern versions of V8 (https://v8.dev/). By keeping up-to-date with the latest releases of this engine, we ensure new features from the JavaScript ECMA-262 specification (http://www.ecma-international.org/publications/standards/Ecma-262.htm) are brought to Node.js developers in a timely manner, as well as continued performance and stability improvements.

All ECMAScript 2015 (ES6) features are split into three groups for shipping, staged, and in progress features:

All shipping features, which V8 considers stable, are turned on by default on Node.js and do NOT require any kind of runtime flag.
Staged features, which are almost-completed features that are not considered stable by the V8 team, require a runtime flag: --harmony.
In progress features can be activated individually by their respective harmony flag, although this is highly discouraged unless for testing purposes. Note: these flags are exposed by V8 and will potentially change without any deprecation notice.
Which features ship with which Node.js version by default?

The website node.green (https://node.green/) provides an excellent overview over supported ECMAScript features in various versions of Node.js, based on kangax's compat-table.

Which features are in progress?

New features are constantly being added to the V8 engine. Generally speaking, expect them to land on a future Node.js release, although timing is unknown.

You may list all the in progress features available on each Node.js release by grepping through the --v8-options argument. Please note that these are incomplete and possibly broken features of V8, so use them at your own risk:

node --v8-options | grep "in progress"

- determine V8 version:
| (node 14)
| [i500695@WYLQRXL9LQ:2022-04-13 12:52:59:~/work/code/javascript/debounce_throttle:]2001$ node -p process.versions.v8
| 8.4.371.23-node.85
| [i500695@WYLQRXL9LQ:2022-04-13 16:51:43:~/work/code/javascript/debounce_throttle:]2002$ sudo n 17
| Password:
|   installing : node-v17.9.0
|        mkdir : /usr/local/n/versions/node/17.9.0
|        fetch : https://nodejs.org/dist/v17.9.0/node-v17.9.0-darwin-arm64.tar.xz
|    installed : v17.9.0
| [i500695@WYLQRXL9LQ:2022-04-13 16:52:17:~/work/code/javascript/debounce_throttle:]2003$ node -p process.versions.v8
| 9.6.180.15-node.16


    16.2  node version 0-4
    16.3  node version 6-7
    16.4  node version 8-9
    16.5  node version 10-11
    16.6  node version 12-13
    16.7  node version 14-15
    16.8  node version 16, tags: node 16 version 
- session,
  -- create presentation (power-point)
  -- git repo of code samples 
  --
        16.8.0  Platform support 
       https://www.redhat.com/en/blog/nodejs-16-here-updated-platform-support-v8-version-9-and-more 
As with most major releases, this release updates the minimum supported levels for platforms and tooling used to build Node.js. Some examples include updating the minimum supported Xcode version to 11 and the GCC version for Linux and AIX platforms to 8.3. Please check the documentation in Node's building instructions for all the latest minimum levels.

More interesting is the work being done to add support for the new Apple M1 architecture. The Red Hat team is active in the Node.js build working group, helping to keep the infrastructure running to support the Power PC and s390 architectures, but also helps with work across the other architectures.

Red Hat's Ash Cripps, a build work group member for Node.js, has been actively working to install/configure M1 machines so that we can test/build binaries that are compiled for M1 and run natively. Node.js 16 will be the first version to provide native M1 support.
        16.8.1  V8 version 9
resources:
sheli wiki: https://wiki.wdf.sap.corp/wiki/display/CPPortals/Main+Features+Node.js+16
https://v8.dev/blog/v8-release-90

            16.8.1.1  RegExp match indices

ex:
[i500695@WYLQRXL9LQ:2022-04-26 15:58:55:~/git/portal-cf-transport-service:]2162$ node -v
v17.9.0
[i500695@WYLQRXL9LQ:2022-04-26 15:58:58:~/git/portal-cf-transport-service:]2163$ node
Welcome to Node.js v17.9.0.
Type ".help" for more information.
> const re=/(a+)(b*)/d
undefined
> const m = re.exec('aaab');
undefined
> m.indices[0]
[ 0, 4 ]
> m.indices[1]
[ 0, 3 ]
> m.indices[2]
[ 3, 4 ]

Note d flag is toggle for creating match indices! (see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions#advanced_searching_with_flags)

BTW, all supported flags are:
d	Generate indices for substring matches.	RegExp.prototype.hasIndices
g	Global search.	RegExp.prototype.global
i	Case-insensitive search.	RegExp.prototype.ignoreCase
m	Multi-line search.	RegExp.prototype.multiline
s	Allows . to match newline characters.	RegExp.prototype.dotAll
u	"unicode"; treat a pattern as a sequence of unicode code points.	RegExp.prototype.unicode
y	Perform a "sticky" search that matches starting at the current position in the target string. See sticky.	RegExp.prototype.sticky 

        16.8.2 Faster super property access
Accessing super properties (for example, super.x) has been optimized by using V8’s inline cache system and optimized code generation in TurboFan. With these changes, super property access is now closer to being on par with regular property access, as can be seen from the graphs below.


            16.8.2.1 v8 dev blog, https://v8.dev/blog/fast-super
V8 already has an optimization mechanism for property access ( data driven inline caching - https://mathiasbynens.be/notes/shapes-ics)
V8 uses ignition interpreter to generate bytecode for tapping into the IC with a new LoadSuperIC cache - https://v8.dev/blog/fast-properties https://docs.google.com/document/d/1mEhMn7dbaJv68lTAvzJRCQpImQoO6NZa61qRimVeA-k/edit?usp=sharing

            16.8.2.2

        16.8.3 for ( async of disallowed
https://betterprogramming.pub/a-quick-look-at-the-node-js-16-features-d616e8b2f29

A grammar ambiguity was recently discovered and fixed in V8 v9.0.
The token sequence for ( async of now no longer parses
The token sequence for (async of is ambiguous. It can be the prefix for either for (async of => {};;) or for (async of foo). Therefore, it is disallowed.

Meanwhile, for await (async of is still allowed, since there is no for (await (;;), and thus no ambiguity.

for async of: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of

demo:
const foo = [1,2,3]; 
for (async of => foo;;) {console.log('infinite loop');} // allowed 
for (async of foo) {console.log(iter);} // disallowed since ambiguity with above syntax 
Uncaught SyntaxError: The left-hand side of a for-of loop may not be 'async'.
allowed syntax:
> for await (async of foo) {console.log('a');}
a
a
a

            16.8.3.1 my demo

            16.8.3.2

        16.8.4 WebAssembly
Faster JS-to-Wasm calls
V8 uses different representations for the parameters of WebAssembly and JavaScript functions. For this reason, when JavaScript calls an exported WebAssembly function, the call goes through a so-called JS-to-Wasm wrapper, responsible for adapting parameters from JavaScript land to WebAssembly land as well as adapting results in the opposite direction.

Unfortunately, this comes with a performance cost, which meant that calls from JavaScript to WebAssembly were not as fast as calls from JavaScript to JavaScript. To minimize this overhead the JS-to-Wasm wrapper can now be inlined at the call site, simplifying the code and removing this extra frame.

Let’s say we have a WebAssembly function to add two double floating point numbers, like this:

double addNumbers(double x, double y) {
  return x + y;
}
and say we call that from JavaScript to add some vectors (represented as typed arrays):

const addNumbers = instance.exports.addNumbers;

function vectorSum(len, v1, v2) {
  const result = new Float64Array(len);
  for (let i = 0; i < len; i++) {
    result[i] = addNumbers(v1[i], v2[i]);
  }
  return result;
}

const N = 100_000_000;
const v1 = new Float64Array(N);
const v2 = new Float64Array(N);
for (let i = 0; i < N; i++) {
  v1[i] = Math.random();
  v2[i] = Math.random();
}

// Warm up.
for (let i = 0; i < 5; i++) {
  vectorSum(N, v1, v2);
}

// Measure.
console.time();
const result = vectorSum(N, v1, v2);
console.timeEnd();
On this simplified microbenchmark, we see the following improvements:


Microbenchmark comparison
The feature is still experimental and can be enabled through the --turbo-inline-js-wasm-calls flag.

For more details, see the design document.

        16.8.5 Promises-based timer functions are supported in Node.js 16 
https://www.stefanjudis.com/snippets/promises-based-timer-functions-are-supported-in-node-js-16/

So to implement sleep like in other languages you need something like:
        sleep(ms) {
          return new Promise(resolve => setTimeout(resolve, ms));
        }

source: /Users/i500695/work/code/nodejs/tutorial/watchDogDemo.js

but as of nodejs-16 it's not needed anymore (see: https://nodejs.org/docs/latest-v16.x/api/timers.html#timers_timers_promises_api)

demo:
[i500695@WYLQRXL9LQ:2022-04-17 19:06:45:~/work/code/nodejs/node16:]2021$ node !$
node timers_promises_demo.mjs
setTimeout result :)
setImmediate result :)
1650211609809
1650211609859
1650211609911
1650211609961
1650211610013
1650211610064
1650211610115
1650211610165
1650211610217

code:
[i500695@WYLQRXL9LQ:2022-04-17 19:06:50:~/work/code/nodejs/node16:]2022$ cat !$
cat timers_promises_demo.mjs
import { setTimeout, setInterval, setImmediate} from 'timers/promises';

const setTORes = await setTimeout(500, "setTimeout result :)");
console.log(setTORes);
const setImmediateRes = await setTimeout(500, "setImmediate result :)");
console.log(setImmediateRes);

const interval = 50;
for await (const startTime of setInterval(interval, Date.Now)) {
    const now = Date.now();
    console.log(now);
    if ((now-startTime) > 1000) {
        break;
    }
}
console.log(Date.now());

        16.8.6  AbortController and AbortSignal APIs 

            16.8.6.1  https://www.nearform.com/blog/using-abortsignal-in-node-js/

                16.8.6.1.1  Promise.race()
const timeout = new Promise((resolve, reject) => {
  setTimeout(() => reject(new Error('timed out')), 10000);
});

await Promise.race([
  someLongRunningTask(),
  timeout
]);

    The intent here is straightforward: Start a potentially long-running task but trigger a timeout if that task takes too long to complete. This is generally a good idea, but there are quite a few problems with this common example.

First, although the promise returned by Promise.race() will be fulfilled as soon as the first of the given promises is settled, the other promises are not cancelled and will keep on running. Although the timeout timer did fire, the long-running task is never actually interrupted and stopped.

Second, what happens to the timeout promise if the long-running task completes before the timeout is triggered? The answer is simple: The timer keeps running, and the promise will end up rejecting, still with an unhandled rejection — unnecessarily risking performance issues and possible memory leaks in your application.

To correctly handle this pattern, we need a reliable mechanism for signalling across the two promises, canceling either the timer or the long-running task as appropriate and ensuring that once the timeout is triggered all resources are cleaned up as quickly as possible. Fortunately, Web Platform APIs provide a standard mechanism for this kind of signalling — the AbortController and AbortSignal APIs.

                16.8.6.1.2 AbortController()
import { setTimeout } from 'timers/promises';

const cancelTimeout = new AbortController();
const cancelTask = new AbortController();

async function timeout() {
  try {
    await setTimeout(10000, undefined, { signal: cancelTimeout.signal });
    cancelTask.abort();
  } catch {
    // Ignore rejections here
  }
}

async function task() {
  try {
    await someLongRunningTask({ signal: cancelTask.signal });
  } finally {
    cancelTimeout.abort();
  }
}

await Promise.race([ timeout(), task() ]);

As with the previous example, two promises are created. However, when each completes, it uses the AbortController and AbortSignal APIs to explicitly signal to the other that it should stop. As long as the code in those is written to support the AbortSignal API, everything just works.

For instance, in the example we make use of the recently added awaitable timers API in Node.js. These are variants of the setTimeout() and setInterval() that return promises.

Copy to Clipboard

import { setTimeout } from 'timers/promises';

// Awaits a promise that fulfills after 10 seconds
await setTimeout(10000);
The awaitable timer API supports the ability to pass in an AbortSignal instance. When the AbortSignal is triggered, the timer is cleared and the promise immediately rejects with an AbortError.

Support for AbortController and AbortSignal is being rolled out across the Node.js core API and can now be found in most of the major subsystems. Before we explore where the API can be used, let’s find out a bit more about the API itself.

                16.8.6.1.3 My example
(thanks Gil for helping)


Test: 
[i500695@WYLQRXL9LQ:2022-06-16 18:00:46:~/work/code/nodejs/node16:]2055$ node abortControllerDemo.mjs 
Cancel promise using AbortController
got signal { signal: AbortSignal { aborted: false } }
aborting task

Code:
import { setTimeout, setInterval, setImmediate} from 'timers/promises';

/*
long running promise 
note use of options argument to pass the abort signal in
also not check for aborted signal after firing the long time operation (simulated by setTimeout)
 */
const someLongRunningTask = async (delay, msg, options) => {
   const signal = {...options};
    console.log('got signal', signal);
   const res = await setTimeout(delay, msg);
    console.log('got signal 2 ', JSON.stringfy(signal, null, 4));
    if (signal.signal.aborted === true) {
        throw new Error('someLongRunningTask cancelled');
    }
   console.log(`waited ${delay}, ${msg}`);
};

console.log('Cancel promise using AbortController');

// straightforward, an AbortController for TO and Task promises
const cancelTO = new AbortController();
const cancelTask = new AbortController();

async function timeout1() {
    try {
        await setTimeout(1000, undefined, {signal: cancelTO.signal}); // note, setTimeout options argument passes cancelTO signal
        console.log('aborting task');
        cancelTask.abort(); // timeout1 cancels task after 1 second
        
    } catch (e) {
        /* handle error */
    }
}

async function task() {
    try {
        await someLongRunningTask(5000,  'long running task finished', {signal: cancelTask.signal}); //  note, setTimeout options argument passes cancelTask signal 
    }
    finally {
        cancelTO.abort(); // task cancels timeout1 
    }
    }

await Promise.race([timeout1(), task()]);



            16.8.6.2 https://javascript.info/fetch-abort 

                16.8.6.2.1 The AbortController object
As we know, fetch returns a promise. And JavaScript generally has no concept of “aborting” a promise. So how can we cancel an ongoing fetch? E.g. if the user actions on our site indicate that the fetch isn’t needed any more.

There’s a special built-in object for such purposes: AbortController. It can be used to abort not only fetch, but other asynchronous tasks as well.

The usage is very straightforward:

The AbortController object
Create a controller:

let controller = new AbortController();
A controller is an extremely simple object.

It has a single method abort(),
And a single property signal that allows to set event listeners on it.
When abort() is called:

controller.signal emits the "abort" event.
controller.signal.aborted property becomes true.
Generally, we have two parties in the process:

The one that performs a cancelable operation, it sets a listener on controller.signal.
The one that cancels: it calls controller.abort() when needed.
Here’s the full example (without fetch yet):

let controller = new AbortController();
let signal = controller.signal;

// The party that performs a cancelable operation
// gets the "signal" object
// and sets the listener to trigger when controller.abort() is called
signal.addEventListener('abort', () => alert("abort!"));

// The other party, that cancels (at any point later):
controller.abort(); // abort!

// The event triggers and signal.aborted becomes true
alert(signal.aborted); // true
As we can see, AbortController is just a mean to pass abort events when abort() is called on it.

We could implement the same kind of event listening in our code on our own, without the AbortController object.

But what’s valuable is that fetch knows how to work with the AbortController object. It’s integrated in it.

my example:
[i500695@WYLQRXL9LQ:2022-04-19 18:45:24:~/work/code/nodejs/node16:]2028$ node !$
node simpleAbort.js
signal.aborted before abort false
operation aborted
signal.aborted after abort true
[i500695@WYLQRXL9LQ:2022-04-19 18:45:32:~/work/code/nodejs/node16:]2029$ cat !$
cat simpleAbort.js
let controller = new AbortController();
let signal = controller.signal;

signal.addEventListener('abort', () => console.log('operation aborted'));

console.log('signal.aborted before abort', signal.aborted);
controller.abort();
console.log('signal.aborted after abort', signal.aborted);

                16.8.6.2.2 Using with fetch
To be able to cancel fetch, pass the signal property of an AbortController as a fetch option:

let controller = new AbortController();
fetch(url, {
  signal: controller.signal
});
The fetch method knows how to work with AbortController. It will listen to abort events on signal.

Now, to abort, call controller.abort():

controller.abort();
We’re done: fetch gets the event from signal and aborts the request.

When a fetch is aborted, its promise rejects with an error AbortError, so we should handle it, e.g. in try..catch.

Here’s the full example with fetch aborted after 1 second:

// abort in 1 second
let controller = new AbortController();
setTimeout(() => controller.abort(), 1000);

try {
  let response = await fetch('/article/fetch-abort/demo/hang', {
    signal: controller.signal
  });
} catch(err) {
  if (err.name == 'AbortError') { // handle abort()
    alert("Aborted!");
  } else {
    throw err;
  }
}

my demo:
[i500695@WYLQRXL9LQ:2022-04-20 17:13:10:~/work/code/nodejs/node16:]2038$ cat !$
cat fetchabort.mjs
import fetch from 'node-fetch';

async function demo_fetch_abort(abortDelay) {
    const controller = new AbortController();
    setTimeout( () => controller.abort(), abortDelay);
    try {
        let resp = await fetch('https://javascript.info/fetch-abort', {signal: controller.signal});
        console.log(resp);

    } catch (e) {
        if (e.name === 'AbortError') {
            console.log('fetch was aborted');
        }
        else {
            console.log(`got error ${e}`);
        }
        /* handle error */
    }
}

console.log('Demo aborting fetch using node 16 AbortController. First run abort fetch if longer than 1 sec (expect success)');
demo_fetch_abort(1000);
console.log('Demo aborting fetch using node 16 AbortController. Second run abort fetch if longer than 10ms (expect abort), will print before first :) ');
demo_fetch_abort(10);
[i500695@WYLQRXL9LQ:2022-04-20 17:13:14:~/work/code/nodejs/node16:]2039$ node !$
node fetchabort.mjs
Demo aborting fetch using node 16 AbortController. First run abort fetch if longer than 1 sec (expect success)
Demo aborting fetch using node 16 AbortController. Second run abort fetch if longer than 10ms (expect abort), will print before first :) 
fetch was aborted
Response {
  ...
    type: 'default',
    url: 'https://javascript.info/fetch-abort',
    status: 200,
    statusText: 'OK',
  
}


                16.8.6.2.3 AbortController is scalable
AbortController is scalable. It allows to cancel multiple fetches at once.

Here’s a sketch of code that fetches many urls in parallel, and uses a single controller to abort them all:

let urls = [...]; // a list of urls to fetch in parallel

let controller = new AbortController();

// an array of fetch promises
let fetchJobs = urls.map(url => fetch(url, {
  signal: controller.signal
}));

let results = await Promise.all(fetchJobs);

// if controller.abort() is called from anywhere,
// it aborts all fetches
If we have our own asynchronous tasks, different from fetch, we can use a single AbortController to stop those, together with fetches.

We just need to listen to its abort event in our tasks:

let urls = [...];
let controller = new AbortController();

let ourJob = new Promise((resolve, reject) => { // our task
  ...
  controller.signal.addEventListener('abort', reject);
});

let fetchJobs = urls.map(url => fetch(url, { // fetches
  signal: controller.signal
}));

// Wait for fetches and our task in parallel
let results = await Promise.all([...fetchJobs, ourJob]);

// if controller.abort() is called from anywhere,
// it aborts all fetches and ourJob

                16.8.6.2.4 my fetch abort example
test: 
[i500695@WYLQRXL9LQ:2022-06-15 18:39:39:~/work/code/nodejs/node16:]2038$ node fetchabort.mjs 30
got delay argument 30
Demo aborting fetch using node 16 AbortController. First run abort fetch if longer than 1 sec (expect success)
fetch from  https://www.brainyquote.com/quote_of_the_day
fetch was aborted
[i500695@WYLQRXL9LQ:2022-06-15 18:39:56:~/work/code/nodejs/node16:]2039$ node fetchabort.mjs 3000
got delay argument 3000
Demo aborting fetch using node 16 AbortController. First run abort fetch if longer than 1 sec (expect success)
fetch from  https://www.brainyquote.com/quote_of_the_day
<meta name="twitter:description" content="&quot;Childhood is a short season.&quot; - Helen Hayes">
code: 
[i500695@WYLQRXL9LQ:2022-06-15 18:42:21:~/work/code/nodejs/node16:]2054$ cat fetchabort.mjs 
import fetch from 'node-fetch';

const delay = process.argv[2] ?? 10000;
console.log('got delay argument', delay);
const url1 = 'https://www.brainyquote.com/quote_of_the_day';
async function demo_fetch_abort(abortDelay, url) {
    const controller = new AbortController();
    setTimeout( () => controller.abort(), abortDelay);
    console.log('fetch from ', url);
    try {
        let resp = await fetch(url, {signal: controller.signal});
        const text = await resp.text();
        const lines = text.split('\n');
        //console.log(typeof text);
        console.log( lines.find( elem => elem.includes('twitter:description') ) );
    } catch (e) {
        if (e.name === 'AbortError') {
            console.log('fetch was aborted');
        }
        else {
            console.log(`got error ${e}`);
        }
        /* handle error */
    }
}

console.log('Demo aborting fetch using node 16 AbortController. First run abort fetch if longer than 1 sec (expect success)');
demo_fetch_abort(delay, url1);
// console.log('Demo aborting fetch using node 16 AbortController. Second run abort fetch if longer than 10ms (expect abort), will print before first :) ');
// demo_fetch_abort(10);
                16.8.6.2.5
            16.8.6.3 

                16.8.6.3.1 



            16.8.6.4
        16.8.7 Web Crypto API
Node.js provides an implementation of the standard Web Crypto API. All of the new Web Crypto methods are available on the subtle interface. 

More info: https://nodejs.org/api/webcrypto.html
https://www.nearform.com/blog/implementing-the-web-cryptography-api-for-node-js-core/

            16.8.7.1 Example generate key and use it to sign:

[i500695@WYLQRXL9LQ:2022-05-30 18:23:30:~/work/code/nodejs/node16:]2075$ cat webcrypto_hmac.mjs 
import { webcrypto } from 'crypto';
const { subtle } = webcrypto;
 
(async function() {
  const key = await subtle.generateKey({
    name: 'HMAC',
    hash: 'SHA-256',
    length: 256
  }, true, ['sign', 'verify']);
 
  const digest = await subtle.sign({
    name: 'HMAC'
  }, key, 'foo bar');
 
  console.log(digest);
})();

[i500695@WYLQRXL9LQ:2022-05-30 18:24:59:~/work/code/nodejs/node16:]2075$ node webcrypto_hmac.mjs
ArrayBuffer {
  [Uint8Contents]: <55 6d f0 91 59 16 a6 2c 58 24 18 05 73 ee 80 79 a8 08 29 f3 2e 07 f2 52 b3 e9 76 49 53 cd d3 6b>,
  byteLength: 32
}
            16.8.7.2 webcrypto api
Most of the cryptographic functions require the use of a key. In the Web Crypto API, keys are represented by CryptoKey objects. These may be generated (using subtle.generateKey()), imported (using subtle.importKey()) or derived (using subtle.deriveKey()). All keys are either symmetric, meaning a single key that is shared and kept secret by the parties using the cryptographic functions, or asymmetric, meaning a pair of keys that are mathematically bound to one another, one of which is meant to be shared while the other is kept private.

The Web Cryptography API supports both symmetric and asymmetric key algorithms:

Symmetric Key Algorithms	
AES-CTR (encrypt/decrypt)
AES-CBC (encrypt/decrypt)
AES-GCM (encrypt/decrypt)
AES-KW (key wrap/unwrap)
HMAC (cryptographic digest)
HKDF (key and bit derivation)
PBKDF2 (key and bit derivation)

Asymmetric Key Algorithms
RSASSA-PKCS1-v1_5 (sign/verify)
RSA-PSS (sign/verify)
RSA-OAEP (encrypt/decrypt)
ECDSA (sign/verify)
ECDH (key and bit derivation)

- full API: https://developer.mozilla.org/en-US/docs/Web/API/SubtleCrypto 
- Doesn’t Node.js already have crypto?
Anyone who has used Node.js for a period of time knows that the platform already has support for low-level cryptographic functions accessible by using require('crypto'). This existing module provides mechanisms for all the same cryptographic primitives as Web Crypto — and in several cases, provides support for a broader range of algorithms than what is minimally defined by the W3C standard.

So, if Node.js already has a crypto module, why does it need the Web Crypto API? This is a good question, and it’s one that has been asked many times over the years. In fact, there has until recently been an active reluctance to add the Web Crypto API into Node.js at all. What has changed? As JavaScript becomes more ubiquitous across all platforms and environments (client, server, edge, etc.), the need for cross-platform and cross-environment compatibility becomes more important to enable the portability of code (and knowledge!) across environments.

There is also the fact that Promise-based development is advancing in JavaScript. Promises (and async/await syntax) can make reasoning about asynchronous code easier in many ways. The Web Crypto API is defined entirely around asynchronous APIs that return promises, while the existing Node.js crypto module uses a combination of synchronous primitives, callbacks and stream APIs. Adopting Web Crypto into Node.js provides an additional promise-based approach that appeals to many developers.

So, instead of continuing to debate whether we should or should not adopt Web Crypto in Node.js, I decided to just go ahead and write it — and while the pull request has not landed at the time of this writing, I do expect it to land soon.

The Node.js implementation of the SubtleCrypto interface is accessible using require('crypto').webcrypto or import { webcrypto } from 'crypto' if you are using ESM syntax. The API has been implemented to be entirely compatible with the browser implementations.

Unfortunately, implementing the new API was not particularly straightforward or easy due to a number of issues in Node’s native C/C++ internals.

-

            16.8.7.3 Using the Web Cryptography APIs

                16.8.7.3.1  Generating symmetric and asymmetric keys
The prior examples illustrate a few of the basics on how the Web Crypto API is used. Here, I want to show a few more examples and offer a few more details on each.

The Web Crypto API is accessed using:

const { subtle, getRandomValues } = require('crypto').webcrypto;
If you are using ESM module syntax, that would be:

import { webcrypto } from 'crypto'
The subtle property is a singleton instance of SubtleCrypto and is equivalent to window.crypto.subtle in Web browsers. The getRandomValues() function is the Web Crypto API equivalent to Node.js’ existing randomFillSync() method for synchronously generating random data.

Generating symmetric and asymmetric keys
The AES cipher and cryptographic digest algorithms require the use of symmetric (“secret”) keys. For AES and HMAC, these can be generated using the subtle.generateKey() method.

Example 5: Generating an AES key

const { subtle } = require('crypto').webcrypto;

// Node.js Web Crypto only supports 128-bit and 256-bit AES keys
async function generateKey(length) {
  return subtle.generateKey(
    { name: 'AES-CBC', length },
    true,
    ['encrypt', 'decrypt']);
}
If successful, the promise returned will be resolved with a single CryptoKey object representing the generated key. The arguments and key usages (e.g. ‘encrypt’ and ‘decrypt’ in the example) are validated based on the named algorithm and will vary from one key type to the next.

my example:
[i500695@WYLQRXL9LQ:2022-05-30 18:44:49:~/work/code/nodejs/node16:]2081$ cat !$
cat webcrypto_key_gen.mjs
// non esm module syntax:
//const { subtle, getRandomValues } = require('crypto').webcrypto;

// esm module syntax:
import { webcrypto } from 'crypto'
const { subtle } = webcrypto;

const getAESKey = async function generateKey(length) {
  return subtle.generateKey(
    { name: 'AES-CBC', length: 256 },
    true,
    ['encrypt', 'decrypt'])};

const aesKey = await getAESKey();
console.log('Generated AES Cipher Block Chaining key', aesKey);




[i500695@WYLQRXL9LQ:2022-05-30 18:44:51:~/work/code/nodejs/node16:]2082$ node !$
node webcrypto_key_gen.mjs
Generated AES Cipher Block Chaining key CryptoKey {
  type: 'secret',
  extractable: true,
  algorithm: { name: 'AES-CBC', length: 256 },
  usages: [ 'encrypt', 'decrypt' ]
}
Example 6: Generating an elliptic curve key pair

const { subtle } = require('crypto').webcrypto;

async function generateKeyPair() {
  return subtle.generateKey(
    { name: 'ECDSA', namedCurve: 'P-521' },
    false,
    ['sign', 'verify']);
}
If successful, the promise returned will be resolved with an object containing publicKey and privateKey properties.

In both examples, the boolean argument identifies whether the resulting keys are exportable using the subtle.exportKey() function. If a generated key is not exportable, there will be no way of accessing the raw key data, which means the key data will be lost once the CryptoKey object is garbage collected.
                16.8.7.3.2

            16.8.7.4

        16.8.8 Apple silicon processors supported
A change that’s completely new in v16 is the publication of builds for Apple Silicon processors.

This should improve performance on new Mac hardware. Node.js will run natively on the Apple M1, instead of using emulation layer.

        16.8.9 base64 utility methods 
https://medium.com/codex/whats-new-in-nodejs-16-c6d455ebfb90
Atob and btoa for your base64
Those two functions allow us to encode and decode base64 string. They are very easy to use as all they need are strings!

const base64 = atob("foobar"); // Results as a base64 encoded string
const initialString = btoa(base64); // back to "foobar

        16.8.10 ES 2021 support 
dashboard of nodejs supported features per version: https://node.green/ 
String Replace all
Numeric separators
Weak refs – great for in memory caches allows GC to clean up better
FinalizationRegistry (a destructor) – works well with weak refs
||= , a || = b
&&= , a &&= b
??= , a ??= b

demo:
[i500695@WYLQRXL9LQ:2022-06-19 17:49:53:~/work/code/nodejs/node16:]2085$ cat !$
cat es2021.mjs
console.log('string replaceALl now supported. No need to use regex or split and join');
const str='This is a demo string';
const str_with_commas=str.replaceAll(' ',',');
console.log(`replace all spaces in: ${str}. result is: ${str_with_commas}`);
const bignum=100_000_000_000;
console.log('can now represent nums with _ as separator. e.g. 100_000_000_000 value is:', bignum);
[i500695@WYLQRXL9LQ:2022-06-19 17:49:58:~/work/code/nodejs/node16:]2086$ node !$
node es2021.mjs
string replaceALl now supported. No need to use regex or split and join
replace all spaces in: This is a demo string. result is: This,is,a,demo,string
can now represent nums with _ as separator. e.g. 100_000_000_000 value is: 100000000000

        16.8.11 deprecated
https://www.geekstrick.com/news/node-16-is-released-with-updated-platform-support-and-much-more/
fs.rmdir no longer supported. Instead use fs.rm(dir, {recursive:true})


        16.8.12
    16.9  node version 17
    16.10 node version 18, tags: node version 18
Node.js major release is updated every six months. The new release becomes the Current release for six months, which gives library authors time to add support for them.

After six months, odd-numbered releases, such as 17, become unsupported, and even-numbered releases, such as 16, move to the Active LTS (long-term support) status and are ready for general use. LTS release typically guarantees that critical bugs will be fixed for a total of 30 months. Production applications should only use Active LTS or Maintenance LTS releases.

Node.js 18 was released on April 19, 2022. It becomes the Current release. It comes with 5 major features:

Experimental fetch API
Web Streams API
HTTP Timeouts
Experimental test runner
V8 JavaScript engine is updated to V8 10.1

First, install 18 LTS 
[i500695@WYLQRXL9LQ:2023-01-26 16:49:28:~/work/code/nodejs/node18:]2081$ nvm install 18.12.0 #LTS version
Downloading and installing node v18.12.0...
Downloading https://nodejs.org/dist/v18.12.0/node-v18.12.0-darwin-arm64.tar.xz...
############################################################################################################################################################################################################# 100.0%
Computing checksum with sha256sum
Checksums matched!
Now using node v18.12.0 (npm v8.19.2)
Creating default alias: default -> 18.12.0 (-> v18.12.0)
[i500695@WYLQRXL9LQ:2023-01-26 16:50:40:~/work/code/nodejs/node18:]2082$ nvm use 18.12.0
Now using node v18.12.0 (npm v8.19.2)
[i500695@WYLQRXL9LQ:2023-01-26 16:50:49:~/work/code/nodejs/node18:]2083$ node --version
v18.12.0

        16.10.1 sources
https://betterprogramming.pub/5-major-features-of-node-js-18-5f4a164cc9fc
https://nodesource.com/blog/11-features-nodeJS-18-to-try
https://youtu.be/XLGIPoBYqD4

examples: 
        16.10.2 features

            16.10.2.1 fetch finally arrives to NodeJS 
bringing uniformity with browsers
example:
[i500695@WYLQRXL9LQ:2023-01-29 17:37:23:~/work/code/nodejs/node18:]2085$ cat fetch.js 
const url = 'https://jsonplaceholder.typicode.com/todos/1'
const getJsonFromUrl= async (url)  => {
    console.log(`GET from ${url}`);
    const resp = await fetch(url);
    if (resp.ok) {
        const jsonData = await resp.json();
        console.log(`Got json ${JSON.stringify(jsonData, null, 4)} from ${url}`);
        //console.log(`Got json ${JSON.stringify(jsonData, null, ' ')} from ${url}`);
        //console.log(`Got json ${JSON.stringify(jsonData, null, "\t")} from ${url}`);
    }
    else {
        console.error(`Got error ${resp.status} ${resp.statusText}`);
    }
}

getJsonFromUrl(url);

[i500695@WYLQRXL9LQ:2023-01-29 17:37:26:~/work/code/nodejs/node18:]2086$ node !$
node fetch.js
GET from https://jsonplaceholder.typicode.com/todos/1
(node:1350) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
Got json {
    "userId": 1,
    "id": 1,
    "title": "delectus aut autem",
    "completed": false
} from https://jsonplaceholder.typicode.com/todos/1

Note:
a. fetch only rejects on network errors. It does not reject on HTTP errors.
b. need to check response.ok and when not ok response.status response.statusText
c. initial fetch response contains headers and more info but doesn't yet contain the body (since it needs to be gathered from the underlying TCP stream and marshalled + parsed)
interface Response extends Body {
  readonly headers: Headers;
  readonly ok: boolean;
  readonly redirected: boolean;
  readonly status: number;
  readonly statusText: string;
  readonly type: ResponseType;
  readonly url: string;
  clone(): Response;
}
d. To get the JSON from body call .json() - which is asynchronous
e. fetch is supported since 2015 on all browsers (- IE)
f. In NodeJS it is based on https://undici.nodejs.org/#/ client lib
g. fetch, FormData, Headers, Request, Response are now global objects in JavaScript

            16.10.2.2 webstreams API
Again, trying to make NodeJS streams more compatible with browser streams.
Streams allow process in chunks instead of waiting for entire download of a resource (file, image, video etc) to complete, then deserialized into memory
Also streams allow detection of start/end and errors and can be canceled and chained

                16.10.2.2.1 Read Demo
[i500695@WYLQRXL9LQ:2023-01-29 18:54:57:~/work/code/nodejs/node18:]2090$ node readableStreamDemo.js
GET from https://jsonplaceholder.typicode.com/todos/1 using ReadableStream and ReadableStreamDefaultController
(node:3673) ExperimentalWarning: The Fetch API is an experimental feature. This feature could change at any time
(Use `node --trace-warnings ...` to show where the warning was created)
got response.body = ReadableStream { locked: false, state: 'readable', supportsBYOB: false }
streamReader= ReadableStreamDefaultReader {
  stream: ReadableStream { locked: true, state: 'readable', supportsBYOB: false },
  readRequests: 0,
  close: Promise { <pending> }
}
controller= ReadableStreamDefaultController {}
ReadableStream { locked: false, state: 'readable', supportsBYOB: false }
false Uint8Array(83) [
  123, 10,  32,  32,  34, 117, 115, 101, 114,  73, 100,  34,
   58, 32,  49,  44,  10,  32,  32,  34, 105, 100,  34,  58,
   32, 49,  44,  10,  32,  32,  34, 116, 105, 116, 108, 101,
   34, 58,  32,  34, 100, 101, 108, 101,  99, 116, 117, 115,
   32, 97, 117, 116,  32,  97, 117, 116, 101, 109,  34,  44,
   10, 32,  32,  34,  99, 111, 109, 112, 108, 101, 116, 101,
  100, 34,  58,  32, 102,  97, 108, 115, 101,  10, 125
]
Got stream done. Done state=true
result is: { userId: 1, id: 1, title: 'delectus aut autem', completed: false }
code:
[i500695@WYLQRXL9LQ:2023-01-30 11:00:51:~/work/code/nodejs/node18:]2092$ cat readableStreamDemo.js |pbcopy
const url = 'https://jsonplaceholder.typicode.com/todos/1'
const getJsonFromUrl= (url)  => {
    console.log(`GET from ${url} using ReadableStream and ReadableStreamDefaultController`);
    fetch(url).then( (resp) => {
        console.log('got response.body =',resp.body); //should print got response.body =ReadableStream { locked: false, state: 'readable', supportsBYOB: false }
        return resp.body;
    })
    .then( responseBody => {
        const streamReader = responseBody.getReader();
        console.log('streamReader=', streamReader);
        // should print
        // streamReader= ReadableStreamDefaultReader {
        //   stream: ReadableStream { locked: true, state: 'readable', supportsBYOB: false },
        //   readRequests: 0,
        //   close: Promise { <pending> }

        // now return a ReadableStream
        return new ReadableStream({
            start(controller) {
                console.log('controller=', controller);

                // push is the chunk handler
                function push() {
                    //ReadableStreamDefaultReader promise return function w/ 2
                    //params. done - boolean (true when stream is done)
                    //Uint8Array - binary buffer
                    streamReader.read().then( ({done, value}) => {
                        if (done) {
                            console.log(`Got stream done. Done state=${done}`);
                            controller.close();
                            return;
                        }
                        controller.enqueue(value); //put current chunk in Q
                        console.log(done,value); //should print false and Uint8Array content
                        push(); //call push again to process next chunk
                    });

                }
                push(); //process first chunk and cont. until done

            },
        });
    })
    .then( stream => {
        console.log(stream)// will print ReadableStream { locked: false, state: 'readable', supportsBYOB: false}
        return new Response( stream, {
            headers: { 'Content-Type': 'application/json'},
        }).json();
    }).then ( result => {
        console.log('result is:', result); //the end result all the chunks parsed as json
    });
};

getJsonFromUrl(url);

- Code explanation
define the function arrow syntax: const getJsonFromUrl= (url)  => {
- call fetch: fetch(url).then( (resp) => {} which returns a promise which returns the response
- returns the response.body promise 
        return resp.body;
- when response.body is ready handle it by extracting a ReadableStreamDefaultReader
    .then( responseBody => {
        const streamReader = responseBody.getReader();
and return a new ReadableStream to process the stream:
        return new ReadableStream({
- The ReadableStream type has three optional callbacks. see: 
interface UnderlyingSource<R = any> {
  cancel?: UnderlyingSourceCancelCallback;
  pull?: UnderlyingSourcePullCallback<R>;
  start?: UnderlyingSourceStartCallback<R>;
  type?: undefined;
}
- The ReadableStream in the example implements the start callback.
            start(controller) {
start() receives a controller (of type ReadableStreamDefaultController)

- The controller can put data on stream Q and close it

    -- Put data in Q:
controller.enqueue(value);
    -- Close stream
controller.close();
- override push to define how data is processed 
function push() {
- Once the new ReadableStream is returned it's processed by 
.then((stream) => {

- which creates a Response w/ the stream content
        return new Response( stream, {
- And at last we print the response
    }).then ( result => {
        console.log('result is:', result); //the end result all the chunks parsed as json

                16.10.2.2.2 Other streams
ReadableStream
ReadableStreamDefaultReader
ReadableStreamBYOBReader
ReadableStreamBYOBRequest
ReadableByteStreamController
ReadableStreamDefaultController
TransformStream
TransformStreamDefaultController
WritableStream
WritableStreamDefaultWriter
WritableStreamDefaultController
ByteLengthQueuingStrategy
CountQueuingStrategy
TextEncoderStream
TextDecoderStream
CompressionStream
DecompressionStream

                16.10.2.2.3
            16.10.2.3 HTTP timeouts

There are two server side timeouts
for headers and for the whole request:
server.headersTimeout and server.requestTimeout
if they expire the server responds w/ 408 (the request will not be sent to RequestListener) and close connection
demo:


                16.10.2.3.1 - side note import.meta
                https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/import.meta
import.meta
The import.meta meta-property exposes context-specific metadata to a JavaScript module. It contains information about the module, such as the module's URL.

Syntax
import.meta
Value
The import.meta object is created by the host environment, as an extensible null-prototype object where all properties are writable, configurable, and enumerable. The spec doesn't specify any properties to be defined on it, but hosts usually implement the following property:

url
The full URL to the module, includes query parameters and/or hash (following the ? or #). In browsers, this is either the URL from which the script was obtained (for external scripts), or the URL of the containing document (for inline scripts). In Node.js, this is the file path (including the file:// protocol).

Description
The import.meta syntax consists of the keyword import, a dot, and the identifier meta. Because import is a reserved word, not an identifier, this is not a property accessor, but a special expression syntax.

The import.meta meta-property is available in JavaScript modules; using import.meta outside of a module (including direct eval() within a module) is a syntax error.

                    16.10.2.3.1.1 Use for Passing query parameters
Using query parameters in the import specifier allows module-specific argument passing, which may be complementary to reading parameters from the application-wide window.location (or on Node.js, through process.argv). For example, with the following HTML:

<script type="module">
  import "./index.mjs?someURLInfo=5";
</script>
Copy to Clipboard
The index.mjs module is able to retrieve the someURLInfo parameter through import.meta:

// index.mjs
new URL(import.meta.url).searchParams.get("someURLInfo"); // 5
Copy to Clipboard
The same applies when a module imports another:

// index.mjs
import "./index2.mjs?someURLInfo=5";

// index2.mjs
new URL(import.meta.url).searchParams.get("someURLInfo"); // 5
The ES module implementation in Node.js supports resolving module specifiers containing query parameters (or the hash), as in the latter example. However, you cannot use queries or hashes when the module is specified through the CLI command (like node index.mjs?someURLInfo=5), because the CLI entrypoint uses a more CommonJS-like resolution mode, treating the path as a file path rather than a URL. To pass parameters to the entrypoint module, use CLI arguments and read them through process.argv instead (like node index.mjs --someURLInfo=5).

                    16.10.2.3.1.2 Getting current module's file path
In Node.js CommonJS modules, there's a __dirname variable that contains the absolute path to the folder containing current module, which is useful for resolving relative paths. However, ES modules cannot have contextual variables except for import.meta. Therefore, to get the current module's file path, you can use import.meta.url.


                        16.10.2.3.1.2.1 Before (CommonJS)

const fs = require("fs/promises");
const path = require("path");

const filePath = path.join(__dirname, "someFile.txt");
fs.readFile(filePath, "utf8").then(console.log);

                        16.10.2.3.1.2.2 After (ES modules)
import fs from "node:fs/promises";
import { fileURLToPath } from "node:url";

const filePath = fileURLToPath(new URL('./someFile.txt', import.meta.url));
fs.readFile(filePath, "utf8").then(console.log);

                        16.10.2.3.1.2.3

                16.10.2.3.2 demo
[i500695@WYLQRXL9LQ:2023-02-01 16:57:16:~/work/code/nodejs/node18:]2007$ node httpTimeoutes.mjs
headersTimeout= 60000
requestTimeout= 300000
^C
[i500695@WYLQRXL9LQ:2023-02-01 16:58:48:~/work/code/nodejs/node18:]2008$ cat !$
cat httpTimeoutes.mjs
import express from 'express';
import path, {dirname} from 'path';
import {fileURLToPath} from 'url';

const app = express();
const __dirname = dirname(fileURLToPath(import.meta.url));
app.use(express.static(path.join(__dirname, 'index.html')));

app.get('/*', (req, res) => {
    setTimeout( () => res.sendFile(path.join(__dirname, './index.html')), 2000);
});

const server = app.listen(8080);
console.log('headersTimeout=', server.headersTimeout);
console.log('requestTimeout=', server.requestTimeout);

                16.10.2.3.3
            16.10.2.4 Native Test Runner
import the new 'node:test' module.
Write UT and report results in TAP format (TAP= Test Anything Protocol)

Example tests run:
[i500695@WYLQRXL9LQ:2023-02-02 16:05:23:~/work/code/nodejs/node18:]2020$ node fetch-spec.mjs 
GET from https://jsonplaceholder.typicode.com/todos/1
TAP version 13
Got json {
    "userId": 1,
    "id": 1,
    "title": "delectus aut autem",
    "completed": false
} from https://jsonplaceholder.typicode.com/todos/1
# Subtest: Standalone Test fetch positive
ok 1 - Standalone Test fetch positive
  ---
  duration_ms: 112.746666
  ...
GET from null
got error TypeError, message Failed to parse URL from null
# Subtest: Nested Tests, fetch negatives
    # Subtest: Fetch null url
    ok 1 - Fetch null url
      ---
      duration_ms: 0.390417
      ...
GET from https://jsonplaceholder.typicode.com/todos/nonexistent
Got error 404 Not Found
got error Error, message Got error 404 Not Found
    # Subtest: Fetch wrong url
    ok 2 - Fetch wrong url
      ---
      duration_ms: 29.089209
      ...
    1..2
ok 2 - Nested Tests, fetch negatives
  ---
  duration_ms: 29.896416
  ...
1..2
# tests 2
# pass 2
# fail 0
# cancelled 0
# skipped 0
# todo 0
# duration_ms 154.950833

Tests code:
[i500695@WYLQRXL9LQ:2023-02-02 16:09:33:~/work/code/nodejs/node18:]2021$ cat fetch.mjs 
const url = 'https://jsonplaceholder.typicode.com/todos/1'
export async function getJsonFromUrl(url){
    console.log(`GET from ${url}`);
    const resp = await fetch(url);
    if (resp.ok) {
        const jsonData = await resp.json();
        console.log(`Got json ${JSON.stringify(jsonData, null, 4)} from ${url}`);
        //console.log(`Got json ${JSON.stringify(jsonData, null, ' ')} from ${url}`);
        //console.log(`Got json ${JSON.stringify(jsonData, null, "\t")} from ${url}`);
        return jsonData;
    }
    else {
        console.error(`Got error ${resp.status} ${resp.statusText}`);
        throw new Error(`Got error ${resp.status} ${resp.statusText}`);
    }
}


//getJsonFromUrl(url);
// module.exports={ getJsonFromUrl};

[i500695@WYLQRXL9LQ:2023-02-02 16:09:38:~/work/code/nodejs/node18:]2021$ cat fetch-spec.mjs 
import test from 'node:test';
import assert from 'node:assert/strict';
import {getJsonFromUrl} from './fetch.mjs';

test('Standalone Test fetch positive', async (t) => {
    const url = 'https://jsonplaceholder.typicode.com/todos/1'
    const expected = {
        userId: 1,
        id: 1,
        title: "delectus aut autem",
        completed: false
    };
    const data = await getJsonFromUrl(url);
    assert.deepStrictEqual(data, expected);
});

test('Nested Tests, fetch negatives', async (t) => {
    await t.test('Fetch null url', async (t) => {
        const url = null;
        await assert.rejects(
            getJsonFromUrl(url),
            err => {
                console.log(`got error ${err.name}, message ${err.message}`); // would print got error TypeError, message Failed to parse URL from null
                //assert.strictEqual(err.name, 'TypeError');
                //assert.strictEqual(err.message, 'Failed to parse URL from null');
                return true;
            }
        );
    });
    await t.test('Fetch wrong url', async (t) => {
        const url =  'https://jsonplaceholder.typicode.com/todos/nonexistent';
        await assert.rejects(
            getJsonFromUrl(url),
            err => {
                console.log(`got error ${err.name}, message ${err.message}`); // would print got error TypeError, message Failed to parse URL from null
                assert.equal(err.name, 'Error');
                assert.equal(err.message, 'Got error 404 Not Found');
                return true;
            }
        );
    });
});

            16.10.2.5 V8 version 10.1
performance improvements:
- class fields and private class methods

features:
- findLast and findLastIndex methods on arrays

- locale improvements: Intl.Locale (https://v8.dev/blog/v8-release-74#intl.locale) improvments (https://v8.dev/blog/v8-release-99#intl.locale-extensions)
  added properties calendars, collations, hourCycles, numberingSystems, timeZones, textInfo, and weekInfo.
- Intl supportedValuesOf (https://v8.dev/blog/v8-release-99#intl-enumeration) 

demo code:
[i500695@WYLQRXL9LQ:2023-02-05 18:41:24:~/work/code/nodejs/node18_features_demos/node18_features_demos:]2034$ cat v8_ver10_1_features.mjs | pbcopy
import { setTimeout } from 'timers/promises';

console.log('Demo new features in V8 10.1');


console.log('Locale improvements. mainly added properties: calendars, collations, hourCycles, numberingSystems, timeZones, textInfo, and weekInfo.');
function printIntlLocaleDetails(localeStr) {
    console.log('Printing locale', localeStr);
    try {
        const locale= new Intl.Locale(localeStr);
        console.log(`${locale} details:`);
        console.log(`locale calendar: ${locale.calendars}, collations: ${locale.collations}, hourCycles: ${locale.hourCycles}, numberingSystems: ${locale.numberingSystems}, writing direction: ${JSON.stringify(locale.textInfo)}, week info: ${JSON.stringify(locale.weekInfo)}`);
        console.log('locale timeZones', locale.timeZones);
    }
    catch (err) {
        console.log(`cant init locale due to error ${err.name} ${err.message}`);
    }
}
//const eUSLocale= new Intl.Locale('en-us');
// printIntlLocaleDetails('en-us');

function allLocalesDetails() {
//Locale list courtesy of SAP help :) - https://help.sap.com/docs/SAP_BUSINESSOBJECTS_BUSINESS_INTELLIGENCE_PLATFORM/09382741061c40a989fae01e61d54202/46758c5e6e041014910aba7db0e91070.html?locale=en-US
const all_locales=[	'af-ZA',	'sq-AL',	'ar-DZ',	'ar-BH',	'ar-EG',	'ar-IQ',	'ar-JO',	'ar-KW',	'ar-LB',	'ar-LY',	'ar-MA',	'ar-OM',	'ar-QA',	'ar-SA',	'ar-SY',	'ar-TN',	'ar-AE',	'ar-YE',	'hy-AM',	'az-AZ',	'eu-ES',	'be-BY',	'bn-IN',	'bs-BA',	'bg-BG',	'ca-ES',	'zh-CN',	'zh-HK',	'zh-MO',	'zh-SG',	'zh-TW',	'hr-HR',	'cs-CZ',	'da-DK',	'nl-BE',	'nl-NL',	'en-AU',	'en-BZ',	'en-CA',	'en-IE',	'en-JM',	'en-NZ',	'en-PH',	'en-ZA',	'en-TT',	'en-VI',	'en-GB',	'en-US',	'en-ZW',	'et-EE',	'fo-FO',	'fi-FI',	'fr-BE',	'fr-CA',	'fr-FR',	'fr-LU',	'fr-MC',	'fr-CH',	'gl-ES',	'ka-GE',	'de-AT',	'de-DE',	'de-LI',	'de-LU',	'de-CH',	'el-GR',	'gu-IN',	'he-IL',	'hi-IN',	'hu-HU',	'is-IS',	'id-ID',	'it-IT',	'it-CH',	'ja-JP',	'kn-IN',	'kk-KZ',	'kok-IN',	'ko-KR',	'lv-LV',	'lt-LT',	'mk-MK',	'ms-BN',	'ms-MY',	'ml-IN',	'mt-MT',	'mr-IN',	'mn-MN',	'se-NO',	'nb-NO',	'nn-NO',	'fa-IR',	'pl-PL',	'pt-BR',	'pt-PT',	'pa-IN',	'ro-RO',	'ru-RU',	'sr-BA',	'sr-CS',	'sk-SK',	'sl-SI',	'es-AR',	'es-BO',	'es-CL',	'es-CO',	'es-CR',	'es-DO',	'es-EC',	'es-SV',	'es-GT',	'es-HN',	'es-MX',	'es-NI',	'es-PA',	'es-PY',	'es-PE',	'es-PR',	'es-ES',	'es-UY',	'es-VE',	'sw-KE',	'sv-FI',	'sv-SE',	'syr-SY',	'ta-IN',	'te-IN',	'th-TH',	'tn-ZA',	'tr-TR',	'uk-UA',	'uz-UZ',	'vi-VN',	'cy-GB',	'xh-ZA',	'zu-ZA',];	
}

const all_locale_abber = [['Afrikaans (South Africa)',	'af-ZA'], ['Albanian (Albania)',	'sq-AL'], ['Arabic (Algeria)',	'ar-DZ'], ['Arabic (Bahrain)',	'ar-BH'], ['Arabic (Egypt)',	'ar-EG'], ['Arabic (Iraq)',	'ar-IQ'], ['Arabic (Jordan)',	'ar-JO'], ['Arabic (Kuwait)',	'ar-KW'], ['Arabic (Lebanon)',	'ar-LB'], ['Arabic (Libya)',	'ar-LY'], ['Arabic (Morocco)',	'ar-MA'], ['Arabic (Oman)',	'ar-OM'], ['Arabic (Qatar)',	'ar-QA'], ['Arabic (Saudi Arabia)',	'ar-SA'], ['Arabic (Syria)',	'ar-SY'], ['Arabic (Tunisia)',	'ar-TN'], ['Arabic (United Arab Emirates)',	'ar-AE'], ['Arabic (Yemen)',	'ar-YE'], ['Armenian (Armenia)',	'hy-AM'], ['Azerbaijani (Azerbaijan)',	'az-AZ'], ['Basque (Spain)',	'eu-ES'], ['Belarusian (Belarus)',	'be-BY'], ['Bengali (India)',	'bn-IN'], ['Bosnian (Bosnia and Herzegovina)',	'bs-BA'], ['Bulgarian (Bulgaria)',	'bg-BG'], ['Catalan (Spain)',	'ca-ES'], ['Chinese (China)',	'zh-CN'], ['Chinese (Hong Kong SAR China)',	'zh-HK'], ['Chinese (Macao SAR China)',	'zh-MO'], ['Chinese (Singapore)',	'zh-SG'], ['Chinese (Taiwan)',	'zh-TW'], ['Croatian (Croatia)',	'hr-HR'], ['Czech (Czech Republic)',	'cs-CZ'], ['Danish (Denmark)',	'da-DK'], ['Dutch (Belgium)',	'nl-BE'], ['Dutch (Netherlands)',	'nl-NL'], ['English (Australia)',	'en-AU'], ['English (Belize)',	'en-BZ'], ['English (Canada)',	'en-CA'], ['English (Ireland)',	'en-IE'], ['English (Jamaica)',	'en-JM'], ['English (New Zealand)',	'en-NZ'], ['English (Philippines)',	'en-PH'], ['English (South Africa)',	'en-ZA'], ['English (Trinidad and Tobago)',	'en-TT'], ['English (U.S. Virgin Islands)',	'en-VI'], ['English (United Kingdom)',	'en-GB'], ['English (United States)',	'en-US'], ['English (Zimbabwe)',	'en-ZW'], ['Estonian (Estonia)',	'et-EE'], ['Faroese (Faroe Islands)',	'fo-FO'], ['Finnish (Finland)',	'fi-FI'], ['French (Belgium)',	'fr-BE'], ['French (Canada)',	'fr-CA'], ['French (France)',	'fr-FR'], ['French (Luxembourg)',	'fr-LU'], ['French (Monaco)',	'fr-MC'], ['French (Switzerland)',	'fr-CH'], ['Galician (Spain)',	'gl-ES'], ['Georgian (Georgia)',	'ka-GE'], ['German (Austria)',	'de-AT'], ['German (Germany)',	'de-DE'], ['German (Liechtenstein)',	'de-LI'], ['German (Luxembourg)',	'de-LU'], ['German (Switzerland)',	'de-CH'], ['Greek (Greece)',	'el-GR'], ['Gujarati (India)',	'gu-IN'], ['Hebrew (Israel)',	'he-IL'], ['Hindi (India)',	'hi-IN'], ['Hungarian (Hungary)',	'hu-HU'], ['Icelandic (Iceland)',	'is-IS'], ['Indonesian (Indonesia)',	'id-ID'], ['Italian (Italy)',	'it-IT'], ['Italian (Switzerland)',	'it-CH'], ['Japanese (Japan)',	'ja-JP'], ['Kannada (India)',	'kn-IN'], ['Kazakh (Kazakhstan)',	'kk-KZ'], ['Konkani (India)	k','ok-IN'], ['Korean (South Korea)',	'ko-KR'], ['Latvian (Latvia)',	'lv-LV'], ['Lithuanian (Lithuania)',	'lt-LT'], ['Macedonian (Macedonia)',	'mk-MK'], ['Malay (Brunei)',	'ms-BN'], ['Malay (Malaysia)',	'ms-MY'], ['Malayalam (India)',	'ml-IN'], ['Maltese (Malta)',	'mt-MT'], ['Marathi (India)',	'mr-IN'], ['Mongolian (Mongolia)',	'mn-MN'], ['Northern Sami (Norway)',	'se-NO'], ['Norwegian Bokml (Norway)',	'nb-NO'], ['Norwegian Nynorsk (Norway)',	'nn-NO'], ['Persian (Iran)',	'fa-IR'], ['Polish (Poland)',	'pl-PL'], ['Portuguese (Brazil)',	'pt-BR'], ['Portuguese (Portugal)',	'pt-PT'], ['Punjabi (India)',	'pa-IN'], ['Romanian (Romania)',	'ro-RO'], ['Russian (Russia)',	'ru-RU'], ['Serbian (Bosnia and Herzegovina)',	'sr-BA'], ['Serbian (Serbia And Montenegro)',	'sr-CS'], ['Slovak (Slovakia)',	'sk-SK'], ['Slovenian (Slovenia)',	'sl-SI'], ['Spanish (Argentina)',	'es-AR'], ['Spanish (Bolivia)',	'es-BO'], ['Spanish (Chile)',	'es-CL'], ['Spanish (Colombia)',	'es-CO'], ['Spanish (Costa Rica)',	'es-CR'], ['Spanish (Dominican Republic)',	'es-DO'], ['Spanish (Ecuador)',	'es-EC'], ['Spanish (El Salvador)',	'es-SV'], ['Spanish (Guatemala)',	'es-GT'], ['Spanish (Honduras)',	'es-HN'], ['Spanish (Mexico)',	'es-MX'], ['Spanish (Nicaragua)',	'es-NI'], ['Spanish (Panama)',	'es-PA'], ['Spanish (Paraguay)',	'es-PY'], ['Spanish (Peru)',	'es-PE'], ['Spanish (Puerto Rico)',	'es-PR'], ['Spanish (Spain)',	'es-ES'], ['Spanish (Uruguay)',	'es-UY'], ['Spanish (Venezuela)',	'es-VE'], ['Swahili (Kenya)',,	'sw-KE'], ['Swedish (Finland)',	'sv-FI'], ['Swedish (Sweden)',	'sv-SE'], ['Syriac (Syria)	s','yr-SY'], ['Tamil (India)',	'ta-IN'], ['Telugu (India)',	'te-IN'], ['Thai (Thailand)',	'th-TH'], ['swana (South Africa)',	'tn-ZA'], ['Turkish (Turkey)',	'tr-TR'], ['Ukrainian (Ukraine)',	'uk-UA'], ['Uzbek (Uzbekistan)',	'uz-UZ'], ['Vietnamese (Vietnam)',	'vi-VN'], ['Welsh (United Kingdom)',	'cy-GB'], ['Xhosa (South Africa)',	'xh-ZA'], ['Zulu (South Africa)',	'zu-ZA'],];

let pauseTimes=0;
console.log('--------------------------------------------------------------------------------');
for (const locale_abber of all_locale_abber) {
    pauseTimes++;
    if (pauseTimes == 5){
        console.log('--------------------------------------------------------------------------------');
        await setTimeout(1500);
        pauseTimes = 0;
    }
    console.log(`Printing the details of locale ${locale_abber[0]} ${locale_abber[1]}`);
    printIntlLocaleDetails(locale_abber[1]);
}

console.log('--------------------------------------------------------------------------------');
console.log('Locale improvements. get array of supported values in V8 for Intl APIs using Intl.supportedValuesOf(code). code can be calander, collation, currency, numberingSystems, timeZone etc');
console.log(Intl.supportedValuesOf('calendar'));
await setTimeout(1000);
console.log('--------------------------------------------------------------------------------');
console.log(Intl.supportedValuesOf('collation'));
await setTimeout(1000);
console.log('--------------------------------------------------------------------------------');
console.log(Intl.supportedValuesOf('currency'));
await setTimeout(1000);
console.log('--------------------------------------------------------------------------------');
console.log(Intl.supportedValuesOf('numberingSystem'));
await setTimeout(1000);
console.log('--------------------------------------------------------------------------------');
console.log(Intl.supportedValuesOf('timeZone'));
await setTimeout(1000);
console.log('--------------------------------------------------------------------------------');

console.log('Array findLast and findLastIndex...');
const myArray = [
    {val: 1 },
    {val: 2 },
    {val: 3 },
    {val: 4 },
    {val: 5 },
    {val: 6 },
    {val: 7 },
    {val: 8 },
    {val: 9 },
    {val: 10},
    {val: 11},
];

console.log(`Find element divisible by 5 ${JSON.stringify(myArray.find( elem => elem.val %5 == 0))}`);
console.log(`Find last element divisible by 5 ${JSON.stringify(myArray.findLast( elem => elem.val %5 == 0))}`);
console.log(`Find index of element divisible by 5 ${myArray.findIndex( elem => elem.val %5 == 0)}`);
console.log(`Find index of last element divisible by 5 ${myArray.findLastIndex( elem => elem.val %5 == 0)}`);
console.log('--------------------------------------------------------------------------------');


            16.10.2.6
        16.10.3
    16.11 node version 19
    16.12 node version 20

17. NodeJS Design patterns 
 open  ~/Downloads/Node.js_Design_Patterns__Mario_Casciaro.pdf
    17.1  basics

        17.1.1  nodejs philosophy
- Modules and packages 
  Node.js uses the concept of module as a fundamental mean to structure the code of a
program. It is the brick for creating applications and reusable libraries called packages
(a package is also frequently referred to as just module; since, usually it has one
single module as an entry point). In Node.js, one of the most evangelized principles
is to design small modules, not only in terms of code size, but most importantly in
terms of scope.

- This principle has its roots in the Unix philosophy, particularly in two of its
precepts, which are as follows:
• "Small is beautiful."
• "Make each program do one thing well."
Node.js brought these concepts to a whole new level. Along with the help of npm,
the official package manager, Node.js helps solving the dependency hell problem
by making sure that each installed package will have its own separate set of
dependencies, thus enabling a program to depend on a lot of packages without
incurring in conflicts. The Node way, in fact, involves extreme levels of reusability,
whereby applications are composed of a high number of small, well-focused
dependencies. While this can be considered unpractical or even totally unfeasible
in other platforms, in Node.js this practice is encouraged. As a consequence, it is
not rare to find npm packages containing less than 100 lines of code or exposing
only one single function.
Besides the clear advantage in terms of reusability, a small module is also considered
to be the following:
• Easier to understand and use
• Simpler to test and maintain
• Perfect to share with the browser
Having smaller and more focused modules empowers everyone to share or reuse
even the smallest piece of code; it's the Don't Repeat Yourself (DRY) principle
applied at a whole new level

- small surface area 
In addition to being small in size and scope, Node.js modules usually also have the
characteristic of exposing only a minimal set of functionality. The main advantage
here is an increased usability of the API, which means that the API becomes clearer
to use and is less exposed to erroneous usage. Most of the time, in fact, the user of a
component is interested only in a very limited and focused set of features, without
the need to extend its functionality or tap into more advanced aspects.
In Node.js, a very common pattern for defining modules is to expose only one piece
of functionality, such as a function or a constructor, while letting more advanced
aspects or secondary features become properties of the exported function or
constructor. This helps the user to identify what is important and what is secondary.
It is not rare to find modules that expose only one function and nothing else, for the
simple fact that it provides a single, unmistakably clear entry point.

-  KISS principal 

        17.1.2 reactor pattern

            17.1.2.1 background


- IO is slow. RAM access is in the nanoseconds. Disk/network milliseconds
- bandwidth wise, similar. RAM reads are in order of GB/s. Disk/Network MB/s up to GB/s 
- human IO (UX) is orders of magnitude slower 

blocking IO calls (ex: buffer = socketfd.read() ) requires specific solutions for handling multiple request in parallel
a common model is to spawn (or acquire from pool) a worker thread so that when it blocks the main thread still unblocked
The cons of this model is that the worker threads are idle or blocked for a long time (processing an incoming 
request can further block on disk R/W etc) and that threads are not a cheap resource (they consume memory and 
have CPU context-switch cost)

most OSes support also non blocking IO calls 
In addition to blocking I/O, most modern operating systems support another
mechanism to access resources, called non-blocking I/O. In this operating mode,
the system call always returns immediately without waiting for the data to be read
or written. If no results are available at the moment of the call, the function will
simply return a predefined constant, indicating that there is no data available to
return at that moment.
For example, in Unix operating systems, the fcntl() function is used to
manipulate an existing file descriptor to change its operating mode to non-blocking
(with the O_NONBLOCK flag). Once the resource is in non-blocking mode, any read
operation will fail with a return code, EAGAIN, in case the resource doesn't have any
data ready to be read 

The most basic pattern for accessing this kind of non-blocking I/O is to actively
poll the resource within a loop until some actual data is returned; this is called
busy-waiting. The following pseudocode shows you how it's possible to read
from multiple resources using non-blocking I/O and a polling loop:
resources = [socketA, socketB, pipeA];
while(!resources.isEmpty()) {
for(i = 0; i < resources.length; i++) {
resource = resources[i];
//try to read
var data = resource.read();
if(data === NO_DATA_AVAILABLE)
//there is no data to read at the moment
continue;
if(data === RESOURCE_CLOSED)
//the resource was closed, remove it from the list
resources.remove(i);
else
//some data was received, process it
consumeData(data);
}
}
You can see that, with this simple technique, it is already possible to handle
different resources in the same thread, but it's still not efficient. In fact, in the
preceding example, the loop will consume precious CPU only for iterating over
resources that are unavailable most of the time. Polling algorithms usually result
in a huge amount of wasted CPU time.


Busy-waiting is definitely not an ideal technique for processing non-blocking
resources, but luckily, most modern operating systems provide a native mechanism
to handle concurrent, non-blocking resources in an efficient way; this mechanism
is called synchronous event demultiplexer or event notification interface. This
component collects and queues I/O events that come from a set of watched
resources, and block until new events are available to process. The following is the
pseudocode of an algorithm that uses a generic synchronous event demultiplexer to
read from two different resources:
socketA, pipeB;
watchedList.add(socketA, FOR_READ); //[1]
watchedList.add(pipeB, FOR_READ);
while(events = demultiplexer.watch(watchedList)) { //[2]
//event loop
foreach(event in events) { //[3]
//This read will never block and will always retu
data = event.resource.read();
if(data === RESOURCE_CLOSED)
//the resource was closed, remove it from the w
demultiplexer.unwatch(event.resource);
else
//some actual data was received, process it
consumeData(data);
}
}
These are the important steps of the preceding pseudocode:
|    1. The resources are added to a data structure, associating ea
|    with a specific operation, in our example a read.
|    2. The event notifier is set up with the group of resources to
|    This call is synchronous and blocks until any of the watch
|    ready for a read. When this occurs, the event demultiplex
|    the call and a new set of events is available to be processe
|    3. Each event returned by the event demultiplexer is process
|    the resource associated with each event is guaranteed to b
|    and to not block during the operation. When all the event
|    flow will block again on the event demultiplexer until new
|    available to be processed. This is called the event loop.

how concurrency works in a single-threaded
application using a synchronous event demultiplexer and non-blocking I/O. We can
see that using only one thread does not impair our ability to run multiple I/O bound
tasks concurrently. The tasks are spread over time, instead of being spread across
multiple threads. This has the clear advantage of minimizing the total idle time of the
thread, as clearly shown in the image. This is not the only reason for choosing this
model. To have only a single thread, in fact, also has a beneficial impact on the way
programmers approach concurrency in general. Throughout the book, we will see how
the absence of in-process race conditions and multiple threads to synchronize, allows
us to use much simpler concurrency strategies.


            17.1.2.2 reactor pattern 
reactor pattern is a specialization of the algorithm above. 
main idea is to have a handler (callback in nodejs) associated with each IO op. 
callback is invoked when an event is produced and processed by the event loop 

This is what happens in an application using the reactor pattern:
| 1. The application generates a new I/O operation by submitting a request to
| the Event Demultiplexer. The application also specifies a handler, which will
| be invoked when the operation completes. Submitting a new request to the
| Event Demultiplexer is a non-blocking call and it immediately returns the
| control back to the application.
| 2. When a set of I/O operations completes, the Event Demultiplexer pushes the
| new events into the Event Queue.
| 3. At this point, the Event Loop iterates over the items of the Event Queue.
| 4. For each event, the associated handler is invoked.
| 5. The handler, which is part of the application code, will give back the
| control to the Event Loop when its execution completes (5a). However,
| new asynchronous operations might be requested during the execution
| of the handler (5b), causing new operations to be inserted in the Event
| Demultiplexer (1), before the control is given back to the Event Loop.
| 6. When all the items in the Event Queue are processed, the loop will block
| again on the Event Demultiplexer which will then trigger another cycle.
| The asynchronous behavior is now clear: the application expresses the interest to
| access a resource at one point in time (without blocking) and provides a handler,
| which will then be invoked at another point in time when the operation completes

            17.1.2.3 libuv
Each operating system has its own interface for the Event Demultiplexer:
epoll on Linux, kqueue on Mac OS X, and I/O Completion Port API (IOCP) on
Windows. Besides that, each I/O operation can behave quite differently depending
on the type of the resource, even within the same OS. For example, in Unix, regular
filesystem files do not support non-blocking operations, so, in order to simulate a
non-blocking behavior, it is necessary to use a separate thread outside the Event
Loop. All these inconsistencies across and within the different operating systems
required a higher-level abstraction to be built for the Event Demultiplexer. This is
exactly why the Node.js core team created a C library called libuv, with the
objective to make Node.js compatible with all the major platforms and normalize
the non-blocking behavior of the different types of resource; libuv today represents
the low-level I/O engine of Node.js.
Besides abstracting the underlying system calls, libuv also implements the reactor
pattern, thus providing an API for creating event loops, managing the event queue,
running asynchronous I/O operations, and queuing other types of tasks.
A great resource to learn more about libuv is the free
online book created by Nikhil Marathe, which is available
at http://nikhilm.github.io/uvbook/.

            17.1.2.4 nodejs structure
The reactor pattern and libuv are the basic building blocks of Node.js, but we need
the following three other components to build the full platform:
• A set of bindings responsible for wrapping and exposing libuv and other
low-level functionality to JavaScript.
• V8, the JavaScript engine originally developed by Google for the Chrome
browser. This is one of the reasons why Node.js is so fast and efficient.
V8 is acclaimed for its revolutionary design, its speed, and for its efficient
memory management.
• A core JavaScript library (called node-core) that implements the high-level
Node.js API.

+----------------------------------------------------------------------+
|                                                                      |
|    +------------------------------------------------------+          |
|    |                                                      |          |
|    |                                                      |          |
|    |     User Land Modules and apps                       |          |                                    
|    |                                                      |          |                                    
|    |                                                      |          |                                    
|    |                                                      |          |                                    
|    |                                                      |          |                                    
|    |                                                      |          |                                    
|    +------------------------------------------------------+          |                                    
|                                                                      |                                    
|    +------------------------------------------------------+          |                                    
|    |   NodeJS                                             |          |                                    
|    |                                                      |          |                                    
|    |    +-----------------------------------------+       |          |                                    
|    |    |                                         |       |          |                                    
|    |    |                                         |       |          |                                    
|    |    |   node-core (core JS API)               |       |          |                                    
|    |    |                                         |       |          |                                    
|    |    |                                         |       |          |                                    
|    |    +-----------------------------------------+       |          |                                    
|    |                                                      |          |                                    
|    |     +----------------------------------------+       |          |                                    
|    |     |                                        |       |          |
|    |     |   Bindings                             |       |          |
|    |     |                                        |       |          |
|    |     |                                        |       |          |
|    |     +--------------+-------------------------+       |          |
|    |    ++--------------+                         |       |          |
|    |    |               |    +--------------------+       |          |
|    |    |  V8           |    |    libuv           |       |          |
|    |    +---------------+    |                    |       |          |
|    +----+---------------+----+--------------------+-------+          |
|                                                                      |
+----------------------------------------------------------------------+

            17.1.2.5 The callback pattern
Callbacks are the materialization of the handlers of the reactor pattern and they are
literally one of those imprints that give Node.js its distinctive programming style.
Callbacks are functions that are invoked to propagate the result of an operation
and this is exactly what we need when dealing with asynchronous operations.
They practically replace the use of the return instruction that, as we know, always
executes synchronously. JavaScript is a great language to represent callbacks,
because as we know, functions are first class objects and can be easily assigned to
variables, passed as arguments, returned from another function invocation, or stored
into data structures. Also, closures are an ideal construct for implementing callbacks.
With closures, we can in fact reference the environment in which a function was
created, practically, we can always maintain the context in which the asynchronous
operation was requested, no matter when or where its callback is invoked.

The continuation-passing style
In JavaScript, a callback is a function that is passed as an argument to another
function and is invoked with the result when the operation completes. In functional
programming, this way of propagating the result is called continuation-passing
style, for brevity, CPS. It is a general concept, and it is not always associated with
asynchronous operations. In fact, it simply indicates that a result is propagated by
passing it to another function (the callback), instead of directly returning it to the caller.
Synchronous continuation-passing style
To clarify the concept, let's take a look at a simple synchronous function:
function add(a, b) {
return a + b;
}
There is nothing special here; the result is passed back to the caller using the
return instruction; this is also called direct style, and it represents the most
common way of returning a result in synchronous programming. The equivalent
continuation-passing style of the preceding function would be as follows:
function add(a, b, callback) {
callback(a + b);
}
The add() function is a synchronous CPS function, which means that it will
return a value only when the callback completes its execution. The following
code demonstrates this statement:
console.log('before');
add(1, 2, function(result) {
console.log('Result: ' + result);
});
console.log('after');
Since add() is synchronous, the previous code will trivially print the following:
before
Result: 3
after

Asynchronous continuation-passing style
Now, let's consider the case where the add() function is asynchronous, which is
as follows:
function addAsync(a, b, callback) {
setTimeout(function() {
callback(a + b);
}, 100);
}
In the previous code, we simply use setTimeout() to simulate an asynchronous
invocation of the callback. Now, let's try to use this function and see how the order
of the operations changes:
console.log('before');
addAsync(1, 2, function(result) {
console.log('Result: ' + result);
});
console.log('after');
The preceding code will print the following:
before
after
Result: 3
Since setTimeout() triggers an asynchronous operation, it will not wait anymore
for the callback to be executed, but instead, it returns immediately giving the control
back to addAsync(), and then back to its caller. This property in Node.js is crucial,
as it allows the stack to unwind, and the control to be given back to the event loop as
soon as an asynchronous request is sent, thus allowing a new event from the queue
to be processed.

When the asynchronous operation completes, the execution is then resumed
starting from the callback provided to the asynchronous function that caused the
unwinding. The execution will start from the Event Loop, so it will have a fresh stack.
This is where JavaScript comes in really handy, in fact, thanks to closures it is trivial to
maintain the context of the caller of the asynchronous function, even if the callback is
invoked at a different point in time and from a different location.

Non continuation-passing style callbacks
There are several circumstances in which the presence of a callback argument might
make you think that a function is asynchronous or is using a continuation-passing
style; that's not always true, let's take, for example, the map() method of the
Array object:
var result = [1, 5, 7].map(function(element) {
return element – 1;
});
Clearly, the callback is just used to iterate over the elements of the array, and not to
pass the result of the operation. In fact, the result is returned synchronously using a
direct style. The intent of a callback is usually clearly stated in the documentation of
the API.
Synchronous or asynchronous?
We have seen how the order of the instructions changes radically depending
on the nature of a function - synchronous or asynchronous. This has strong
repercussions on the flow of the entire application, both in correctness and efficiency.
The following is an analysis of these two paradigms and their pitfalls. In general,
what must be avoided, is creating inconsistency and confusion around the nature
of an API, as doing so can lead to a set of problems which might be very hard to
detect and reproduce. To drive our analysis, we will take as example the case of an
inconsistently asynchronous function.

An unpredictable function
One of the most dangerous situations is to have an API that behaves synchronously
under certain conditions and asynchronously under others. Let's take the following
code as an example:
var fs = require('fs');
var cache = {};
function inconsistentRead(filename, callback) {
if(cache[filename]) {
//invoked synchronously
callback(cache[filename]);
} else {
//asynchronous function 
fs.readFile(filename, 'utf8', function(err, data) {
cache[filename] = data;
callback(data);
});
}
}

The preceding function uses the cache variable to store the results of different
file read operations. Please bear in mind that this is just an example, it does not
have error management, and the caching logic itself is suboptimal. Besides this,
the preceding function is dangerous because it behaves asynchronously until the
cache is not set—which is until the fs.readFile() function returns its results—but
it will also be synchronous for all the subsequent requests for a file already in the
cache—triggering an immediate invocation of the callback.
Unleashing Zalgo
Now, let's see how the use of an unpredictable function, such as the one that we
defined previously, can easily break an application. Consider the following code:
function createFileReader(filename) {
var listeners = [];
inconsistentRead(filename, function(value) {
listeners.forEach(function(listener) {
listener(value);
});
});
return {
onDataReady: function(listener) {
listeners.push(listener);
}
};
}
When the preceding function is invoked, it creates a new object that acts as a notifier,
allowing to set multiple listeners for a file read operation. All the listeners will be
invoked at once when the read operation completes and the data is available. The
preceding function uses our inconsistentRead() function to implement this
functionality. Let's now try to use the createFileReader() function:
var reader1 = createFileReader('data.txt');
reader1.onDataReady(function(data) {
console.log('First call data: ' + data);//...sometime later we try to read again from
//the same file
var reader2 = createFileReader('data.txt');
reader2.onDataReady(function(data) {
console.log('Second call data: ' + data);
});
});
The preceding code will print the following output:
First call data: some data
As you can see, the callback of the second operation is never invoked. Let's see why:
• During the creation of reader1, our inconsistentRead() function behaves
asynchronously, because there is no cached result available. Therefore, we
have all the time to register our listener, as it will be invoked later in another
cycle of the event loop, when the read operation completes.
• Then, reader2 is created in a cycle of the event loop in which the
cache for the requested file already exists. In this case, the inner call to
inconsistentRead() will be synchronous. So, its callback will be invoked
immediately, which means that also all the listeners of reader2 will be
invoked synchronously. However, we are registering the listeners after the
creation of reader2, so they will never be invoked.
The callback behavior of our inconsistentRead() function is really unpredictable,
as it depends on many factors, such as the frequency of its invocation, the filename
passed as argument, and the amount of time taken to load the file.
The bug that we've just seen might be extremely complicated to identify and
reproduce in a real application. Imagine to use a similar function in a web server,
where there can be multiple concurrent requests; imagine seeing some of those
requests hanging, without any apparent reason and without any error being logged.
This definitely falls under the category of nasty defects.
Isaac Z. Schlueter, creator of npm and former Node.js project lead, in one of his blog
posts compared the use of this type of unpredictable functions to unleashing Zalgo.
If you're not familiar with Zalgo, you are invited to find out what it is.

see running example:
[i500695@WYLQRXL9LQ:2022-05-19 18:35:25:~/work/code/nodejs/nodejs_design_patterns:]2007$ cat data.txt 
some text file 
[i500695@WYLQRXL9LQ:2022-05-19 18:35:28:~/work/code/nodejs/nodejs_design_patterns:]2008$ cat unleashing_zalgo.js 
var fs = require('fs');
var cache = {};
function inconsistentRead(filename, callback) {
    if(cache[filename]) {
        //invoked synchronously
        console.log(`invoked synchronously for reading file ${filename}`);
        callback(cache[filename]);
    } else {
        //asynchronous function 
        console.log(`invoked asynchronously for reading file ${filename}`);
        fs.readFile(filename, 'utf8', function(err, data) {
            cache[filename] = data;
            callback(data);
        });
    }
}

function createFileReader(filename) {
    console.log(`creating a reader for file ${filename}`);
    var listeners = [];
    inconsistentRead(filename, function(value) {
        listeners.forEach(function(listener) {
            console.log(`updating listener ${listener} with value ${value}`);
            listener(value);
        });
    });
    return {
        onDataReady: function(listener) {
            listeners.push(listener);
        }
    };
}
// When the preceding function is invoked, it creates a new object that acts as a notifier,
// allowing to set multiple listeners for a file read operation. All the listeners will be
// invoked at once when the read operation completes and the data is available. The
// preceding function uses our inconsistentRead() function to implement this
// functionality. Let's now try to use the createFileReader() function:
//
var reader1 = createFileReader('data.txt');
reader1.onDataReady(function(data) {
    console.log('First call data: ' + data);//...sometime later we try to read again from
    //the same file
    var reader2 = createFileReader('data.txt');
    reader2.onDataReady(function(data) {
        console.log('Second call data: ' + data);
    });
});
creating a reader for file data.txt
invoked asynchronously for reading file data.txt
updating listener function(data) {
    console.log('First call data: ' + data);//...sometime later we try to read again from
    //the same file
    var reader2 = createFileReader('data.txt');
    reader2.onDataReady(function(data) {
        console.log('Second call data: ' + data);
    });
} with value some text file 

First call data: some text file 

creating a reader for file data.txt
invoked synchronously for reading file data.txt

Using synchronous APIs
The lesson to learn from the unleashing Zalgo example is that it is imperative for an
API to clearly define its nature, either synchronous or asynchronous.
One suitable fix for our inconsistentRead() function, is to make it totally
synchronous. This is possible because Node.js provides a set of synchronous
direct style APIs for most of the basic I/O operations. For example, we can use the
fs.readFileSync() function in place of its asynchronous counterpart. The code
would now be as follows:
var fs = require('fs');
var cache = {};
function consistentReadSync(filename) {
if(cache[filename]) {
return cache[filename];
} else {
cache[filename] = fs.readFileSync(filename, 'utf8');
return cache[filename];
}
}
We can see that the entire function was also converted to a direct style. There is no
reason for the function to have a continuation-passing style if it is synchronous.
In fact, we can state that it is always a good practice to implement a synchronous
API using a direct style; this will eliminate any confusion around its nature and
will also be more efficient from a performance perspective.

Please bear in mind that changing an API from CPS to a direct style, or from
asynchronous to synchronous, or vice versa might also require a change to the
style of all the code using it. For example, in our case, we will have to totally
change the interface of our createFileReader() API and adapt it to work
always synchronously.
Also, using a synchronous API instead of an asynchronous one has some caveats:
• A synchronous API might not be always available for the needed
functionality.
• A synchronous API will block the event loop and put the concurrent requests
on hold. It practically breaks the Node.js concurrency, slowing down the
whole application. We will see later in the book what this really means for
our applications.
In our consistentReadSync() function, the risk of blocking the event loop is
partially mitigated, because the synchronous I/O API is invoked only once per each
filename, while the cached value will be used for all the subsequent invocations. If
we have a limited number of static files, then using consistentReadSync() won't
have a big effect on our event loop. Things can change quickly if we have to read
many files and only once. Using synchronous I/O in Node.js is strongly discouraged
in many circumstances; however, in some situations, this might be the easiest and
most efficient solution. Always evaluate your specific use case in order to choose the
right alternative.

Deferred execution
Another alternative for fixing our inconsistentRead() function is to make it purely
asynchronous. The trick here is to schedule the synchronous callback invocation
to be executed "in the future" instead of being run immediately in the same event
loop cycle. In Node.js, this is possible using process.nextTick(), which defers
the execution of a function until the next pass of the event loop. Its functioning is
very simple; it takes a callback as an argument and pushes it on the top of the event
queue, in front of any pending I/O event, and returns immediately. The callback will
then be invoked as soon as the event loop runs again
Let's apply this technique to fix our inconsistentRead() function as follows:
var fs = require('fs');
var cache = {};
function consistentReadAsync(filename, callback) {
    if(cache[filename]) {
        process.nextTick(function() {
                callback(cache[filename]);
                });
    } else {
        //asynchronous function
        fs.readFile(filename, 'utf8', function(err, data) {
                cache[filename] = data;
                callback(data);
                });
    }
}
Now, our function is guaranteed to invoke its callback asynchronously,
under any circumstances.
Another API for deferring the execution of code is setImmediate(), which—despite
the name—might actually be slower than process.nextTick(). While their purpose
is very similar, their semantic is quite different. Callbacks deferred with process.
nextTick() run before any other I/O event is fired, while with setImmediate(),
the execution is queued behind any I/O event that is already in the queue. Since
process.nextTick() runs before any already scheduled I/O, it might cause I/O
starvation under certain circumstances, for example, a recursive invocation; this
can never happen with setImmediate(). We will learn to appreciate the difference
between these two APIs when we analyze the use of deferred invocation for running
synchronous CPU-bound tasks later in the book.

            17.1.2.6 Node.js callback conventions
In Node.js, continuation-passing style APIs and callbacks follow a set of specific
conventions. These conventions apply to the Node.js core API but they are also
followed virtually by every userland module and application. So, it's very important
that we understand them and make sure that we comply whenever we need to
design an asynchronous API.
Callbacks come last
In Node.js, if a function accepts in input a callback, this has to be passed as the last
argument. Let's take the following Node.js core API as an example:
fs.readFile(filename, [options], callback)
As you can see from the signature of the preceding function, the callback is always
put in last position, even in the presence of optional arguments. The motivation
for this convention is that the function call is more readable in case the callback is
defined in place.
Error comes first
In CPS, errors are propagated as any other type of result, which means using the
callback. In Node.js, any error produced by a CPS function is always passed as
the first argument of the callback, and any actual result is passed starting from the
second argument. If the operation succeeds without errors, the first argument
will be null or undefined. The following code shows you how to define a callback
complying with this convention:
fs.readFile('foo.txt', 'utf8', function(err, data) {
if(err)
handleError(err);
else
processData(data);
});
It is a good practice to always check for the presence of an error, as not doing so will
make it harder for us to debug our code and discover the possible points of failures.
Another important convention to take into account is that the error must always be
of type Error. This means that simple strings or numbers should never be passed as
error objects.

Propagating errors
Propagating errors in synchronous, direct style functions is done with the
well-known throw command, which causes the error to jump up in the call
stack until it's caught.
In asynchronous CPS however, proper error propagation is done by simply passing
the error to the next callback in the CPS chain. The typical pattern looks as follows:
var fs = require('fs');
function readJSON(filename, callback) {
    fs.readFile(filename, 'utf8', function(err, data) {
            var parsed;
            if(err)
            //propagate the error and exit the current function
            return callback(err);
            try {
            //parse the file contents
            parsed = JSON.parse(data);
            } catch(err) {
            //catch parsing errors
            return callback(err);
            }
            //no errors, propagate just the data
            callback(null, parsed);
            });
};
The detail to notice in the previous code is how the callback is invoked when we
want to pass a valid result and when we want to propagate an error.

Uncaught exceptions
You might have seen from the readJSON() function defined previously that in
order to avoid any exception to be thrown into the fs.readFile() callback, we
put a try-catch block around JSON.parse(). Throwing inside an asynchronous
callback, in fact, will cause the exception to jump up to the event loop and never be
propagated to the next callback.

In Node.js, this is an unrecoverable state and the application will simply shut down
printing the error to the stderr interface. To demonstrate this, let's try to remove the
try-catch block from the readJSON() function defined previously:
var fs = require('fs');
function readJSONThrows(filename, callback) {
    fs.readFile(filename, 'utf8', function(err, data) {
            if(err)
            return callback(err);
            //no errors, propagate just the data
            callback(null, JSON.parse(data));
            });
};
Now, in the function we just defined, there is no way of catching an eventual
exception coming from JSON.parse(). Let's try, for example, to parse an invalid
JSON file with the following code:
readJSONThrows('nonJSON.txt', function(err) {
console.log(err);
});
This would result in the application being abruptly terminated and the following
exception being printed on the console:
SyntaxError: Unexpected token d
at Object.parse (native)
at [...]/06_uncaught_exceptions/uncaught.js:7:25
at fs.js:266:14
at Object.oncomplete (fs.js:107:15)
Now, if we look at the preceding stack trace, we will see that it starts somewhere
from the fs.js module, practically from the point at which the native API has
completed reading and returned its result back to the fs.readFile() function, via
the event loop. This clearly shows us that the exception traveled from our callback
into the stack that we saw, and then straight into the event loop, where it's finally
caught and thrown in the console.

This also means that wrapping the invocation of readJSONThrows() with a
try-catch block will not work, because the stack in which the block operates
is different from the one in which our callback is invoked. The following code
shows the anti-pattern that we just described:
try {
readJSONThrows('nonJSON.txt', function(err, result) {
[...]
});
} catch(err) {
console.log('This will not catch the JSON parsing exception');
}
The preceding catch statement will never receive the JSON parsing exception,
as it will travel back to the stack in which the exception was thrown, and we just
saw that the stack ends up in the event loop and not with the function that triggers
the asynchronous operation.
We already said that the application is aborted the moment an exception reaches
the event loop; however, we still have a last chance to perform some cleanup
or logging before the application terminates. In fact, when this happens, Node.js
emits a special event called uncaughtException just before exiting the process.
The following code shows a sample use case:
process.on('uncaughtException', function(err){
console.error('This will catch at last the ' +
'JSON parsing exception: ' + err.message);
//without this, the application would continue
process.exit(1);
});
It's important to understand that an uncaught exception leaves the application in a
state that is not guaranteed to be consistent, which can lead to unforeseeable problems.
For example, there might still have incomplete I/O requests running, or closures might
have become inconsistent. That's why it is always advised, especially in production, to
exit anyway from the application after an uncaught exception is received.
running examples:
[i500695@WYLQRXL9LQ:2022-05-22 18:32:27:~/work/code/nodejs/nodejs_design_patterns:]2012$ node error_propogation.js 
failed to read file. got error SyntaxError: Unexpected token s in JSON at position 0
    at JSON.parse (<anonymous>)
    at /Users/i500695/work/code/nodejs/nodejs_design_patterns/error_propogation.js:10:27
    at FSReqCallback.readFileAfterClose [as oncomplete] (node:internal/fs/read_file_context:68:3)
[i500695@WYLQRXL9LQ:2022-05-22 18:32:30:~/work/code/nodejs/nodejs_design_patterns:]2013$ node error_propogation_bad.js 
undefined:1
some text file 
^

SyntaxError: Unexpected token s in JSON at position 0
    at JSON.parse (<anonymous>)
    at /Users/i500695/work/code/nodejs/nodejs_design_patterns/error_propogation_bad.js:7:33
    at FSReqCallback.readFileAfterClose [as oncomplete] (node:internal/fs/read_file_context:68:3)

[i500695@WYLQRXL9LQ:2022-05-22 18:32:34:~/work/code/nodejs/nodejs_design_patterns:]2014$ cat error_propogation.js 
var fs = require('fs');
function readJSON(filename, callback) {
    fs.readFile(filename, 'utf8', function(err, data) {
        var parsed;
        if(err)
            //propagate the error and exit the current function
            return callback(err);
        try {
            //parse the file contents
            parsed = JSON.parse(data);
        } catch(err) {
            //catch parsing errors
            return callback(err);
        }
        //no errors, propagate just the data
        callback(null, parsed);
    });
};

readJSON('data.txt', ( err, data)=>{
    if (err) {
        console.log('failed to read file. got error', err);
    }
    else {
        console.log('File content:', data);
    }
});

[i500695@WYLQRXL9LQ:2022-05-22 18:40:35:~/work/code/nodejs/nodejs_design_patterns:]2017$ cat !$
cat error_propogation_bad.js
var fs = require('fs');
console.log('demo what happens when an error is not caught in async method. It is thrown and ends up in event loop. Causing abort with uncaught exception');
function readJSONThrows(filename, callback) {
    fs.readFile(filename, 'utf8', function(err, data) {
            if(err)
            return callback(err);
            //no errors, propagate just the data
            callback(null, JSON.parse(data));
            });
};

readJSONThrows('data.txt', function(err) {
console.log(err);
});

console.log('This exception can not be caught by wrapping with try catch since the exception has different call stack and bubbles up to the event loop');
try {
    readJSONThrows('nonJSON.txt', function(err, result) {
        console.log(result);
    });
} catch(err) {
    console.log('This will not catch the JSON parsing exception');
}

console.log('the last stop before process is aborted is to handle the uncaughtException');
process.on('uncaughtException', function(err){
    console.error('This will catch at last the ' +
'JSON parsing exception: ' + err.message);
    //without this, the application would continue
    process.exit(1);
});

            17.1.2.7
        17.1.3 The module system
Modules are the bricks for structuring non-trivial applications, but also the main mechanism to enforce information hiding by keeping private all the functions and variables that are not explicitly marked to be exported. In this section, we will introduce the Node.js module system and its most common usage patterns.

            17.1.3.1 The revealing module pattern
One of the major problems with JavaScript is the absence of namespacing. Programs run in the global scope polluting it with data that comes from both internal application code and dependencies. A popular technique to solve this problem is called revealing module pattern and it looks like the following:
   var module = (function() {
     var privateFoo = function() {...};
     var privateVar = [];
     var export = {
       publicFoo: function() {...},
       publicBar: function() {...}
}
     return export;
   })();
This pattern leverages a self-invoking function to create a private scope, exporting only the parts that are meant to be public. In the preceding code, the module variable contains only the exported API, while the rest of the module content is practically inaccessible from outside. As we will see in a moment, the idea behind this pattern is used as a base for the Node.js module system.


            17.1.3.2 Node.js modules explained
CommonJS is a group with the aim to standardize the JavaScript ecosystem, and one of their most popular proposals is called CommonJS modules. Node.js built its module system on top of this specification, with the addition of some custom extensions. To describe how it works, we can make an analogy with the revealing module pattern, where each module runs in a private scope, so that every variable that is defined locally does not pollute the global namespace.


example custom implementation of require 
[i500695@WYLQRXL9LQ:2022-05-23 18:00:17:~/work/code/nodejs/nodejs_design_patterns:]2023$ cat !$
cat module_loader.js
const fs = require('fs');
const path = require('path');

function loadModule(filename, module, require) {
    console.log(`loading source code of ${filename}`);
    var wrappedSrc =
        '(function(module, exports, require) {' +
        fs.readFileSync(filename, 'utf8') +
        '})(module, module.exports, require);';
    eval(wrappedSrc);
}

var my_require = function(moduleName) {
    console.log('Require invoked for module: ' + moduleName);
    // var id = require.resolve(moduleName);
    let id =  require.resolve(moduleName);
    if(my_require.cache[id]) {
        return my_require.cache[id].exports;
    }
    //module metadata
    var module = {
        exports: {},
        id: id };   //Update the cache
    my_require.cache[id] = module;
    //load the module
    loadModule(id, module, my_require);
    //return exported variables
    return module.exports;
};
my_require.cache = {};
my_require.resolve = function(moduleName) {
    /* resolve a full module id from the moduleName */
    return path.basename(moduleName);
}

let foo = my_require('./foo_module.js');
foo.run();
console.log(JSON.stringify(foo, null, 4));
[i500695@WYLQRXL9LQ:2022-05-23 18:00:40:~/work/code/nodejs/nodejs_design_patterns:]2024$ node module_loader.js 
Require invoked for module: ./foo_module.js
loading source code of /Users/i500695/work/code/nodejs/nodejs_design_patterns/foo_module.js
example module
{}

Defining a module
By looking at how our homemade require() function works, we should now know how to define a module. The following code gives us an example:
   //load another dependency
   var dependency = require('./anotherModule');
   //a private function
   function log() {
     console.log('Well done ' + dependency.username);
   }
   //the API to be exported for public use
   module.exports.run = function() {
log(); };
The essential concept to remember is that everything inside a module is private unless it's assigned to the module.exports variable. The contents of this variable are then cached and returned when the module is loaded using require().
Defining globals
Even if all the variables and functions that are declared in a module are defined in its local scope, it is still possible to define a global variable. In fact, the module system exposes a special variable called global, which can be used for this purpose. Everything that is assigned to this variable will end up automatically in the global scope.
Please note that polluting the global scope is considered a bad practice
and nullifies the advantage of having a module system. So, use it only
if you really know what you are doing.


            17.1.3.3 module.exports vs exports
For many developers who are not yet familiar with Node.js, a common source of confusion is the difference between using exports and module.exports to expose a public API. The code of our homemade require function should again clear
any doubt. The variable exports is just a reference to the initial value of module. exports; we have seen that such a value is essentially a simple object literal created before the module is loaded.

see: https://www.geeksforgeeks.org/difference-between-module-exports-and-exports-in-node-js/#:~:text=1-,When%20we%20want%20to%20export%20a%20single%20class%2Fvariable%2Ffunction,2. 
The module is a plain JavaScript Object representing the current module. It is local to each module and also it is private. It has exports property which is a plain JavaScript variable, set to module.exports. At the end of the file, Node.js return module.exports to the required function.

About module.exports: 
When we want to export a single class/variable/function from one module to another module, we use module.exports way.

Example: Create two file calculator.js and operation.js and export the Arithmetic class from calculator.js to operation.js using module.exports method. Here, we have created a class Arithmetic and exported the whole class using module.exports.

Filename: calculator.js

class Artimatics {
    constructor(a, b) {
        this.a = a;
        this.b = b;
    }
  
    add() {
        return this.a + this.b;
    }
    subtract() {
        return this.a - this.b;
    }
  
    multiply() {
        return this.a * this.b;
    }
  
    divide() {
        if (this.b != 0) {
            return this.a / this.b;
        }
        return "divided by zero !!!!";
    }
};
  
module.exports = Artimatics;
Filename: operation.js

const Artimatics = require('./calculator.js');
  
const op = new Artimatics(100,40);
  
console.log(`Addition -> ${op.add()}`);
console.log(`subtraction -> ${op.subtract()}`);
console.log(`Multiplication -> ${op.multiply()}`);
console.log(`Division -> ${op.divide()}`);
Run the operation.js file using the following command:

node operation.js
Output:


Using module.exports 

About exports:  
When we want to export multiple variables/functions from one module to another, we use exports.

Example: Create a two file calculator.js and operation.js and export multiple functions from calculator.js file. 

Filename: calculator.js


exports.add = (a, b) => a + b;
exports.subtract = (a, b) => a - b;
exports.multiply = (a, b) => a * b;
exports.divide = (a, b) => {
    if (b != 0) {
        return a / b;
    }
    return `Divided by zero !!!`;
}
Filename: operation.js

const Artimatics = require('./calculator.js');
  
console.log(`Addition -> ${Artimatics.add(100,40)}`);
console.log(`subtraction -> ${Artimatics.subtract(100,40)}`);
console.log(`Multiplication -> ${Artimatics.multiply(100,40)}`);
console.log(`Division -> ${Artimatics.divide(100,40)}`);
Run the operation.js file using the following command:

node operation.js
Output:


Using exports

Key difference between module.exports and exports: 

S.no

Module.exports

Exports

a When we want to export a single class/variable/function from one module to another module, we use the module.exports way.	When we want to export multiple variables/functions from one module to another, we use exports way.
b It is the object reference that gets returned from the require() calls.	The exports is not returned by require()


            17.1.3.4 require is synchronous
Another important detail that we should take into account is that our homemade require function is synchronous. In fact, it returns the module contents using a simple direct style, and no callback is required. This is true for the original Node.js require() function too. As a consequence, any assignment to module.export must be synchronous as well. For example, the following code is incorrect:
   setTimeout(function() {
     module.exports = function() {...};
}, 100);
This property has important repercussions in the way we define modules, as it limits us to mostly using synchronous code during the definition of a module. This is actually one of the most important reasons why the core Node.js libraries offer synchronous APIs as an alternative to most of the asynchronous ones.

If we need some asynchronous initialization steps for a module, we can always
define and export an uninitialized module that is initialized asynchronously at
a later time. The problem with this approach though, is that loading such a module using require does not guarantee that it's ready to be used. In Chapter 6, Recipes, we will analyze this problem in detail and we will present some patterns to solve this issue elegantly.

            17.1.3.5 The resolving algorithm
The term dependency hell, describes a situation whereby the dependencies of a software, in turn depend on a shared dependency, but require different incompatible versions. Node.js solves this problem elegantly by loading a different version of a module depending on where the module is loaded from. All the merits of this feature go to npm and also to the resolving algorithm used in the require function.
Let's now give a quick overview of this algorithm. As we saw, the resolve() function takes a module name (which we will call here, moduleName) as input and it returns the full path of the module. This path is then used to load its code and also to identify the module uniquely. The resolving algorithm can be divided into the following three major branches:
• File modules: If moduleName starts with "/" it's considered already an absolute path to the module and it's returned as it is. If it starts with "./", then moduleName is considered a relative path, which is calculated starting from the requiring module.
• Core modules: If moduleName is not prefixed with "/" or "./", the algorithm will first try to search within the core Node.js modules.
• Package modules: If no core module is found matching moduleName, then the search continues by looking for a matching module into the first node_modules directory that is found navigating up in the directory structure starting from the requiring module. The algorithm continues to search for a match by looking into the next node_modules directory up in the directory tree, until it reaches the root of the filesystem.

For file and package modules, both the individual files and directories can match
moduleName. In particular, the algorithm will try to match the following:
• <moduleName>.js
• <moduleName>/index.js
• The directory/file specified in the main property of <moduleName>/ package.json
The complete, formal documentation of the resolving algorithm can be found at http://nodejs.org/api/modules.html#modules_ all_together.
The node_modules directory is actually where npm installs the dependencies of each package. This means that, based on the algorithm we just described, each package can have its own private dependencies. For example, consider the following directory structure:
 myApp
├── foo.js
└── node_modules
    ├── depA
    │   └── index.js
    ├── depB
│ ├── bar.js
    │   └── node_modules
│
│
└── depC
└── depA
    └── index.js
├── foobar.js
└── node_modules
    └── depA
        └── index.js

        In the preceding example, myApp, depB, and depC all depend on depA; however,
they all have their own private version of the dependency! Following the rules of the resolving algorithm, using require('depA') will load a different file depending on the module that requires it, for example:
• Calling require('depA') from /myApp/foo.js will load /myApp/node_ modules/depA/index.js
• Calling require('depA') from /myApp/node_modules/depB/bar.js will load /myApp/node_modules/depB/node_modules/depA/index.js
• Calling require('depA') from /myApp/node_modules/depC/foobar.js will load /myApp/node_modules/depC/node_modules/depA/index.js
The resolving algorithm is the magic behind the robustness of the Node.js dependency management, and is what makes it possible to have hundreds or even thousands of packages in an application without having collisions or problems of version compatibility.
The resolving algorithm is applied transparently for us when we invoke require(); however, if needed, it can still be used directly by any module by simply invoking require.resolve().


            17.1.3.6 The module cache
Each module is loaded and evaluated only the first time it is required, since any subsequent call of require() will simply return the cached version. This should result clear by looking at the code of our homemade require function. Caching is crucial for performances, but it also has some important functional implications:
• It makes it possible to have cycles within module dependencies
• It guarantees, to some extent, that always the same instance is returned
when requiring the same module from within a given package
The module cache is exposed in the require.cache variable, so it is possible to directly access it if needed. A common use case is to invalidate any cached module by deleting the relative key in the require.cache variable, a practice very useful during testing but very dangerous if applied in normal circumstances.


            17.1.3.7 Cycles
Many consider circular dependencies as an intrinsic design issue, but it is something which might actually happen in a real project, so it's useful for us to know at least how this works in Node.js. If we look again at our homemade require() function, we immediately get a glimpse of how this might work and what are its caveats.
Suppose we have two modules defined as follows:
• Module a.js:
       exports.loaded = false;
       var b = require('./b');
       module.exports = {
         bWasLoaded: b.loaded,
         loaded: true
       };
• Module b.js:
       exports.loaded = false;
       var a = require('./a');
       module.exports = {
         aWasLoaded: a.loaded,
         loaded: true
       };
Now, let's try to load these from another module, main.js, as follows:
   var a = require('./a');
   var b = require('./b');
   console.log(a);
   console.log(b);
The preceding code will print the following output:
{ bWasLoaded: true, loaded: true }
{ aWasLoaded: false, loaded: true }
This result reveals the caveats of circular dependencies. While both the modules are completely initialized the moment they are required from the main module, the a.js module will be incomplete when it is loaded from b.js. In particular,
its state will be the one that it reached the moment it required b.js. This behavior should ring another bell, which will be confirmed if we swap the order in which the two modules are required in main.js.

        If you try it, you will see that this time it will be the module a.js that will receive an incomplete version of b.js. We understand now that this can become quite a fuzzy business if we lose control of which module is loaded first, which can happen quite easily if the project is big enough.

            17.1.3.8 Module definition patterns
The module system, besides being a mechanism for loading dependencies, is also
a tool for defining APIs. As for any other problem related to API design, the main
factor to consider is the balance between private and public functionality. The aim is to maximize information hiding and API usability, while balancing these with other software qualities like extensibility and code reuse.
In this section, we will analyze some of the most popular patterns for defining
modules in Node.js; each one has its own balance of information hiding, extensibility, and code reuse.

                17.1.3.8.1 Named exports
The most basic method for exposing a public API is using named exports, which consists in assigning all the values we want to make public to properties of the object referenced by exports (or module.exports). In this way, the resulting exported object becomes a container or namespace for a set of related functionality.
The following code shows a module implementing this pattern:
   //file logger.js
   exports.info = function(message) {
     console.log('info: ' + message);
   };
   exports.verbose = function(message) {
     console.log('verbose: ' + message);
};
The exported functions are then available as properties of the loaded module, as shown in the following code:
   //file main.js
   var logger = require('./logger');
   logger.info('This is an informational message');
   logger.verbose('This is a verbose message');
Most of the Node.js core modules use this pattern.

                17.1.3.8.2 Exporting a function
One of the most popular module definition patterns consists in reassigning the whole module.exports variable to a function. Its main strength it's the fact that
it exposes only a single functionality, which provides a clear entry point for the module, and makes it simple to understand and use; it also honors the principle
of small surface area very well. This way of defining modules is also known in the community as substack pattern, after one of its most prolific adopters, James Halliday (nickname substack). The following code is an example of this pattern:
   //file logger.js
   module.exports = function(message) {
     console.log('info: ' + message);
};
A possible extension of this pattern is using the exported function as namespace for other public APIs. This is a very powerful combination, because it still gives the module the clarity of a single entry point (the main exported function), but it also allows us to expose other functionalities that have secondary or more advanced use cases. The following code shows you how to extend the module we defined previously by using the exported function as a namespace:
   module.exports.verbose = function(message) {
     console.log('verbose: ' + message);
};
The following code demonstrates how to use the module that we just defined:
   //file main.js
   var logger = require('./logger');
   logger('This is an informational message');
   logger.verbose('This is a verbose message');
Even though exporting just a function might seem a limitation, in reality, it's a perfect way to put the emphasis on a single functionality—the most important for the module—while giving less visibility to secondary aspects, which are instead exposed as properties of the exported function itself.
                17.1.3.8.3 Exporting a constructor
A module that exports a constructor is a specialization of a module that exports a function. The difference is that with this new pattern, we allow the user to create new instances using the constructor, but we also give them the ability to extend its prototype and forge new classes. The following is an example of this pattern:
   //file logger.js
   function Logger(name) {
     this.name = name;
   };
   Logger.prototype.log = function(message) {
     console.log('[' + this.name + '] ' + message);
   };
   Logger.prototype.info = function(message) {
     this.log('info: ' + message);
   };
   Logger.prototype.verbose = function(message) {
     this.log('verbose: ' + message);
   };
   module.exports = Logger;
And, we can use the preceding module as follows:
   //file logger.js
   var Logger = require('./logger');
   var dbLogger = new Logger('DB');
   dbLogger.info('This is an informational message');
   var accessLogger = new Logger('ACCESS');
   accessLogger.verbose('This is a verbose message');
Exporting a constructor still provides a single entry point for the module, but compared to the substack pattern, it exposes a lot more of the module internals; however on the other side it allows much more power when it comes to extending its functionality.

A variation of this pattern consists in applying a guard against invocations that don't use the new instruction. This little trick allows us to use our module as a factory.
The following code shows you how this works:
   function Logger(name) {
     if(!(this instanceof Logger)) {
       return new Logger(name);
     }
     this.name = name;
   };
The trick is simple; we check whether this exists and is an instance of Logger. If any of these conditions is false, it means that the Logger() function was invoked without using new, so we proceed with creating the new instance properly and returning it to the caller. This technique allows us to use the module also as a factory, as shown in the following code:
   //file logger.js
   var Logger = require('./logger');
   var dbLogger = Logger('DB');
   accessLogger.verbose('This is a verbose message');

                17.1.3.8.4 Exporting an instance
We can leverage the caching mechanism of require() to easily define stateful instances—objects with a state created from a constructor or a factory, which can be shared across different modules. The following code shows an example of this pattern:
   //file logger.js
   function Logger(name) {
     this.count = 0;
     this.name = name;
   };
   Logger.prototype.log = function(message) {
     this.count++;
     console.log('[' + this.name + '] ' + message);
   };
   module.exports = new Logger('DEFAULT');
This newly defined module can then be used as follows:
   //file main.js
   var logger = require('./logger');
   logger.log('This is an informational message');

Because the module is cached, every module that requires the logger module
will actually always retrieve the same instance of the object, thus sharing its state. This pattern is very much like creating a Singleton, however, it does not guarantee the uniqueness of the instance across the entire application, as it happens in the traditional Singleton pattern. When analyzing the resolving algorithm, we have seen in fact, that a module might be installed multiple times inside the dependency tree of an application. This results with multiple instances of the same logical module, all running in the context of the same Node.js application. In Chapter 5, Wiring Modules, we will analyze the consequences of exporting stateful instances and some of the patterns we can use as alternatives.
An extension to the pattern we just described, consists in exposing the constructor used to create the instance, in addition to the instance itself. This allows the user to create new instances of the same object, or even to extend it if necessary. To enable this, we just need to assign a new property to the instance, as shown in the following line of code:
   module.exports.Logger = Logger;
Then, we can use the exported constructor to create other instances of the class, as follows:
   var customLogger = new logger.Logger('CUSTOM');
   customLogger.log('This is an informational message');
From a usability perspective, this is similar to using an exported function as namespace; the module exports the default instance of an object—the piece of functionality we might want to use most of the time—while more advanced features, such as the ability to create new instances or extend the object, are still made available through less exposed properties.

                17.1.3.8.5 Modifying other modules or the global scope
A module can even export nothing. This can look a bit out of place, however,
we should not forget that a module can modify the global scope and any object
in it, including other modules in the cache. Please note that these are in general considered bad practices, but since this pattern can be useful and safe under some circumstances (for example, for testing) and is sometimes used in the wild, it is worth to know and understand it. So, we said a module can modify other modules or objects in the global scope. Well, this is called monkey patching, which generally refers to the practice of modifying the existing objects at runtime to change or extend their behavior or to apply temporary fixes.
The following example shows you how we can add a new function to another module:
   //file patcher.js
   // ./logger is another module
   require('./logger').customMessage = function() {
     console.log('This is a new functionality');
   };
Using our new patcher module would be as easy as writing the following code: //file main.js
   require('./patcher');
   var logger = require('./logger');
   logger.customMessage();
In the preceding code, patcher must be required before using the logger module for the first time in order to allow the patch to be applied.
The techniques described here are all dangerous ones to apply. The main concern
is that, to have a module that modifies the global namespace or other modules is an
operation with side effects. In other words, it affects the state of entities outside their scope, which can have consequences that are not always predictable, especially when multiple modules interact with the same entities. Imagine to have two different modules trying to set the same global variable, or modifying the same property
of the same module; the effects might be unpredictable (which module wins?), but most importantly it would have repercussions on the entire application.
            17.1.3.9
        17.1.4 The observer pattern

The observer pattern
Another important and fundamental pattern used in Node.js is the observer pattern. Together with reactor, callbacks, and modules, this is one of the pillars of the platform and an absolute prerequisite for using many node-core and userland modules.
Observer is an ideal solution for modeling the reactive nature of Node.js, and a
perfect complement for callbacks. Let's give a formal definition as follows:
Pattern (observer): defines an object (called subject), which can notify a
set of observers (or listeners), when a change in its state happens.
The main difference from the callback pattern is that the subject can actually notify multiple observers, while a traditional continuation-passing style callback will usually propagate its result to only one listener, the callback.


            17.1.4.1 the EventEmitter

                17.1.4.1.1 observer pattern in OOP language (e.g. c++)


see:
https://www.bogotobogo.com/DesignPatterns/observer.php
in OOP we have subject interface 
it has three public methods:
Attach(Observer)
Detach(Observer)
Update()
update pseudocode 
for obs in Observers:
    obs->update() 

ConcreteSubject implements Subject 
GetState() {return this.subjectState}
SetState()
subjectState 

Also, Observer interface with one method:
Update() 

and ConcreteObserver 
Update() {observerState = subject->GetState()}
observerState

#include <iostream>
#include <vector>
#include <time.h>
#include <sys/types.h>
#include <sys/timeb.h>
#include <string.h>

using namespace std ; 

class Subject; 

class Observer 
{ 
public: 
 Observer() {}; 
 ~Observer() {}; 
 virtual void Update(Subject* theChangeSubject) = 0; 
}; 

class Subject 
{ 
public: 
 Subject() {}; 
 virtual ~Subject() {}; 
 virtual void Attach(Observer*); 
 virtual void Detach(Observer*); 
 virtual void Notify();  
private: 
 vector<Observer*> _observers; 
}; 

void Subject::Attach (Observer* o) 
{ 
 _observers.push_back(o); 
} 

void Subject::Detach (Observer* o) 
{ 
 int count = _observers.size(); 
 int i; 

 for (i = 0; i < count; i++) { 
   if(_observers[i] == o) 
   break; 
 } 
 if(i < count) 
  _observers.erase(_observers.begin() + i); 

} 

void Subject::Notify () 
{ 
 int count = _observers.size(); 

 for (int i = 0; i < count; i++) 
   (_observers[i])->Update(this); 
}

class ClockTimer : public Subject 
{ 
public: 
 ClockTimer() { _strtime( tmpbuf ); }; 
 int GetHour(); 
 int GetMinute();
 int GetSecond(); 
 void Tick();   
private: 
 char tmpbuf[128]; 
}; 

 /* Set time zone from TZ environment variable. If TZ is not set, 
  * the operating system is queried to obtain the default value 
  * for the variable. 
 */ 
void ClockTimer::Tick() 
{ 
    _tzset(); 

// Obtain operating system-style time. 
    _strtime( tmpbuf ); 
    Notify(); 
} 

int ClockTimer::GetHour() 
{ 
 char timebuf[128]; 
 strncpy(timebuf, tmpbuf, 2); 
 timebuf[2] = NULL; 
  
 return atoi(timebuf); 
} 

int ClockTimer::GetMinute() 
{ 
 char timebuf[128]; 
 strncpy(timebuf, tmpbuf+3, 2); 
 timebuf[2] = NULL; 

 return atoi(timebuf); 
} 

int ClockTimer::GetSecond() 
{ 
 char timebuf[128];
 strncpy(timebuf, tmpbuf+6, 2); 
 timebuf[2] = NULL; 

 return atoi(timebuf); 
}


class DigitalClock: public Observer 
{ 
public: 
 DigitalClock(ClockTimer *);  
 ~DigitalClock();   
  void Update(Subject *);   
  void Draw();     
private: 
 ClockTimer *_subject;  
}; 

DigitalClock::DigitalClock (ClockTimer *s) 
{ 
 _subject = s; 
 _subject->Attach(this); 
} 

DigitalClock::~DigitalClock () 
{ 
 _subject->Detach(this); 
} 

void DigitalClock::Update (Subject *theChangedSubject) 
{ 
 if(theChangedSubject == _subject) 
  Draw(); 
} 

void DigitalClock::Draw () 
{ 
 int hour = _subject->GetHour(); 
 int minute = _subject->GetMinute(); 
 int second = _subject->GetSecond(); 

 cout << "Digital time is " << hour << ":" 
          << minute << ":" 
          << second << endl;           
}

class AnalogClock: public Observer 
{ 
public: 
 AnalogClock(ClockTimer *);  
 ~AnalogClock();    
  void Update(Subject *);  
  void Draw();     
private: 
 ClockTimer *_subject;   
}; 

AnalogClock::AnalogClock (ClockTimer *s) 
{ 
 _subject = s; 
 _subject->Attach(this); 
} 

AnalogClock::~AnalogClock () 
{ 
 _subject->Detach(this); 
} 

void AnalogClock::Update (Subject *theChangedSubject) 
{ 
 if(theChangedSubject == _subject) 
  Draw(); 
} 

void AnalogClock::Draw () 
{ 
 int hour = _subject->GetHour(); 
 int minute = _subject->GetMinute(); 
 int second = _subject->GetSecond(); 

 cout << "Analog time is " << hour << ":" 
         << minute << ":" 
         << second << endl; 
}

int main(void) 
{ 
 ClockTimer timer; 

 DigitalClock digitalClock(&timer;); 
 AnalogClock analogClock(&timer;); 
  
 timer.Tick();  
  
 return 0; 
}

Here are the summary of the pattern:

a. Objects (DigitalClock or AnalogClock object) use the Subject interfaces (Attach() or Detach()) either to subscribe (register) as observers or unsubscribe (remove) themselves from being observers.
DigitalClock::DigitalClock (ClockTimer *s) 
{ 
 _subject = s; 
 _subject->Attach(this); 
} 


DigitalClock::~DigitalClock () 
{ 
_subject->Detach(this); 
} 

b. Each subject can have many observers.
class Subject 
{ 
public: 
 Subject() {}; 
 ~Subject() {}; 
 void Attach(Observer*); 
 void Detach(Observer*); 
 void Notify(); 
private: 
 vector<Observer*> _observers; 
}; 

c. All observers need to implement the Observer interface. This interface just has one method, Update(), that gets called when the Subject's state changes.
class AnalogClock: public Observer 
{ 
public: 
 AnalogClock(ClockTimer *);  
 ~AnalogClock();    
  void Update(Subject *);  
  void Draw();     
private: 
 ClockTimer *_subject;   
};

e. In addition to the attach() and detach() methods, the concrete subject implements a Notify() method that is used to update all the current observers whenever state changes. But in this case, all of them are done in the parent class, Subject.
void Subject::Attach (Observer* o) 
{ 
 _observers.push_back(o); 
} 

void Subject::Detach(Observer* o) 
{ 
 int count = _observers.size(); 
 int i; 

 for (i = 0; i < count; i++) { 
   if(_observers[i] == o) 
   break; 
 } 
 if(i < count) 
  _observers.erase(_observers.begin() + i); 

} 

void Subject::Notify() 
{ 
 int count = _observers.size(); 

 for (int i = 0; i < count; i++) 
   (_observers[i])->Update(this); 
}

f. The Concrete object may also have methods for setting and getting its state.
class ClockTimer : public Subject 
{ 
public: 
 ClockTimer() { _strtime( tmpbuf ); }; 
 int GetHour(); 
 int GetMinute();
 int GetSecond(); 
 void Tick();   
private: 
 char tmpbuf[128]; 
}; 
g. Concrete observers can be any class that implements the Observer interface. Each observer subscribe (register) with a concrete subject to receive update.
DigitalClock::DigitalClock (ClockTimer *s) 
{ 
 _subject = s; 
 _subject->Attach(this); 
} 
The two objects of Observer Pattern are loosely coupled, they can interact but with little knowledge of each other.

                17.1.4.1.2 nodejs EventEmitter
In traditional object-oriented programming, the observer pattern requires interfaces, concrete classes, and a hierarchy; in Node.js, all becomes much simpler. The observer pattern is already built into the core and is available through the EventEmitter class. The EventEmitter class allows us to register one or more functions as listeners, which will be invoked when a particular event type is fired. The following image visually explains the concept:
  Listener
Event A
EventEmitter Listener
Event B
 Listener
The EventEmitter is a prototype, and it is exported from the events core module. The following code shows how we can obtain a reference to it:
   var EventEmitter = require('events').EventEmitter;
   var eeInstance = new EventEmitter();
The essential methods of the EventEmitter are given as follows:
• on(event, listener): This method allows you to register a new listener
(a function) for the given event type (a string)
• once(event, listener): This method registers a new listener, which is
then removed after the event is emitted for the first time
• emit(event, [arg1], [...]): This method produces a new event and
provides additional arguments to be passed to the listeners
• removeListener(event, listener): This method removes a listener for the specified event type

All the preceding methods will return the EventEmitter instance to allow chaining. The listener function has the signature, function([arg1], [...]), so it simply accepts the arguments provided the moment the event is emitted. Inside the listener, this refers to the instance of the EventEmitter that produces the event.
We can already see that there is a big difference between a listener and a traditional Node.js callback; in particular, the first argument is not an error, but it can be any data passed to emit() at the moment of its invocation.

                17.1.4.1.3
            17.1.4.2 Create and use an EventEmitter
Let's see how we can use an EventEmitter in practice. The simplest way is to create a new instance and use it directly. The following code shows a function, which uses an EventEmitter to notify its subscribers in real time when a particular pattern is found in a list of files:
   var EventEmitter = require('events').EventEmitter;
   var fs = require('fs');
   function findPattern(files, regex) {
     var emitter = new EventEmitter();
     files.forEach(function(file) {
       fs.readFile(file, 'utf8', function(err, content) {
         if(err)
           return emitter.emit('error', err);
         emitter.emit('fileread', file);
         var match = null;
         if(match = content.match(regex))
           match.forEach(function(elem) {
             emitter.emit('found', file, elem);
}); });
});
     return emitter;
   }
The EventEmitter created by the preceding function will produce the following three events:
• fileread: This event occurs when a file is read
• found: This event occurs when a match has been found
• error: This event occurs when an error has occurred during the reading of the file

Let's see now how our findPattern() function can be used:
   findPattern(
       ['fileA.txt', 'fileB.json'],
       /hello \w+/g
     )
     .on('fileread', function(file) {
       console.log(file + ' was read');
     })
     .on('found', function(file, match) {
       console.log('Matched "' + match + '" in file ' + file);
     })
     .on('error', function(err) {
       console.log('Error emitted: ' + err.message);
     });

- findPattern demo 

- My old demo 
code: 
[i500695@WYLQRXL9LQ:2022-05-26 18:47:20:~/work/code/nodejs/tutorial:]2044$ cat !$
cat evtHandlingDemo.js
console.log("Event handling demo started");

// import events
var events = require('events');


//create eventEmitter
var eventEmitter = new events.EventEmitter();

//bind an event + event handler
//eventEmitter.on('eventName', eventHandler);
//
//emit event
//eventEmitter.emit('eventName');
//

//create event handler
var connectionHandler = function connected()  {

        console.log("connectionHandler called for successful connection");

        eventEmitter.emit('data_received');
}

//bind successful connection event to its event handler
eventEmitter.on('connection', connectionHandler);

eventEmitter.on('data_received', function () {
     console.log("anonymous data_received CB function called");
});

//fire the successful connection event
eventEmitter.emit('connection');

// listener #1
var listner1 = function listner1() {
   console.log('listner1 executed.');
}

// listener #2
var listner2 = function listner2() {
  console.log('listner2 executed.');
}

// Bind the connection event with the listner1 function
eventEmitter.addListener('connection', listner1);

// Bind the connection event with the listner2 function
eventEmitter.on('connection', listner2);

var eventListeners = require('events').EventEmitter.listenerCount
   (eventEmitter,'connection');
console.log(eventListeners + " Listner(s) listening to connection event");

// Fire the connection event 
eventEmitter.emit('connection');

// Remove the binding of listner1 function
eventEmitter.removeListener('connection', listner1);
console.log("Listner1 will not listen now.");

// Fire the connection event 
eventEmitter.emit('connection');

eventListeners = require('events').EventEmitter.listenerCount(eventEmitter,'connection');
console.log(eventListeners + " Listner(s) listening to connection event");

console.log("Program Ended.");

console.log("Event handling demo ended");

run:
[i500695@WYLQRXL9LQ:2022-05-26 18:47:13:~/work/code/nodejs/tutorial:]2043$ node !$
node evtHandlingDemo.js
Event handling demo started
connectionHandler called for successful connection
anonymous data_received CB function called
3 Listner(s) listening to connection event
connectionHandler called for successful connection
anonymous data_received CB function called
listner1 executed.
listner2 executed.
Listner1 will not listen now.
connectionHandler called for successful connection
anonymous data_received CB function called
listner2 executed.
2 Listner(s) listening to connection event
Program Ended.
Event handling demo ended

            17.1.4.3
        17.1.5 summary
    17.2 asynchronous control flow patterns

    17.3 the module system patterns

    17.4 streams

    17.5 Design patterns

    17.6 wiring modules

    17.7 recipes 
18. Data structures 

    18.1  Map
nodejs map data structure 
https://flaviocopes.com/javascript-data-structures-map/
https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/forEach 
		
        18.1.1  introduction
A Map data structure allows to associate data to a key.
Before ES6
ECMAScript 6 (also called ES2015) introduced the Map data structure to the JavaScriptworld, along with Set
Before its introduction, people generally used objects as maps, by associating some object or value to a specific key value:
const car = {}
car['color'] = 'red'
car.owner = 'Flavio'
console.log(car['color']) //red
console.log(car.color) //red
console.log(car.owner) //Flavio
console.log(car['owner']) //Flavio

object has some corner cases and shortcomings that proper map data-structure addresses 

map basics:
[i500695@WYLQRXL9LQ:2022-06-06 18:16:38:~/work/code/nodejs:]2000$ node
Welcome to Node.js v18.3.0.
Type ".help" for more information.
> const myMap = new Map();
> myMap
Map(0) {}
> myMap.set(1, "1");
Map(1) { 1 => '1' }
> myMap.set(2, "2");
Map(2) { 1 => '1', 2 => '2' }
> myMap.has(2)
true
> myMap.size
2
> for (const k of myMap.keys()) {console.log(`${k}`);}
1
2
> for (const [k,v] of myMap) {console.log(`${k}=${v}`);
... }
1=1
2=2
undefined
> const keys1 = [...myMap.keys()]
> keys1
[ 1, 2 ]
> const valuess1 = [...myMap.values()]
> valuess1
[ '1', '2' ]

> const initializedMap = [['a', 97], ['b', 98], ['c', 99]]; //actually an array
> initializedMap
[ [ 'a', 97 ], [ 'b', 98 ], [ 'c', 99 ] ]
> function printMapElem(v,k,m){console.log(`m[${k}] = m[${v}]`);}
> initializedMap.forEach(printMapElem)
m[0] = m[a,97]
m[1] = m[b,98]
m[2] = m[c,99]
undefined
> const initializedMapForRealJJJ = new Map([['a', 97], ['b', 98], ['c', 99]]);
> initializedMapForRealJJJ.forEach(printMapElem)
m[a] = m[97]
m[b] = m[98]
m[c] = m[99]
> initializedMap.at('a')
[ 'a', 97 ]

        18.1.2 Map properties

Description
The species accessor property returns the default constructor for Map objects. Subclass constructors may over-ride it to change the constructor assignment.

Examples
Species in ordinary objects
The species property returns the default constructor function, which is the Map constructor for Map objects:

        18.1.3 Map.prototype[@@toStringTag]
> console.log(initializedMapForRealJJJ)
Map(3) { 'a' => 97, 'b' => 98, 'c' => 99 }
undefined
> Object.prototype.toString.call(initializedMapForRealJJJ)
'[object Map]'

        18.1.4 Map.prototype[@@iterator]()
> const iter = initializedMapForRealJJJ[Symbol.iterator]();
undefined
> for (const i of iter){console.log(i)}
[ 'a', 97 ]
[ 'b', 98 ]
[ 'c', 99 ]

        18.1.5 Map.prototype.clear()
clears map 
> myMap.clear()
> myMap
Map(0) {}

        18.1.6 Map.prototype.delete()
The delete() method removes the specified element from a Map object by key.
> initializedMapForRealJJJ.delete('b')
true
> initializedMapForRealJJJ
Map(2) { 'a' => 97, 'c' => 99 }

    18.2

19. getters, setters and proxies 

    19.1  https://www.invivoo.com/en/data-encapsulation-in-javascript-getters-and-setters/#:~:text=A%20getter%20is%20defined%20by,the%20property%20as%20a%20parameter.
Hiding the details of method implementation is easy.
Getters/setters have been officially introduced to the language in ECMAScript 5.1 (ECMA-262). They are currently supported in all major desktop and mobile browsers.

    19.2

20.  Node version managers, switchers, tags:Node version managers, switchers, toggle 

    20.1  https://github.com/nvm-sh/nvm

        20.1.1  introduction
nvm allows you to quickly install and use different versions of node via the command line.
$ nvm use 16
Now using node v16.9.1 (npm v7.21.1)
$ node -v
v16.9.1
$ nvm use 14
Now using node v14.18.0 (npm v6.14.15)
$ node -v
v14.18.0
$ nvm install 12
Now using node v12.22.6 (npm v6.14.5)
$ node -v
v12.22.6

        20.1.2 install 
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash

        20.1.3 install and use a specific node version
[i500695@WYLQRXL9LQ:2023-01-26 16:49:28:~/work/code/nodejs/node18:]2081$ nvm install 18.12.0 #LTS version
Downloading and installing node v18.12.0...
Downloading https://nodejs.org/dist/v18.12.0/node-v18.12.0-darwin-arm64.tar.xz...
############################################################################################################################################################################################################# 100.0%
Computing checksum with sha256sum
Checksums matched!
Now using node v18.12.0 (npm v8.19.2)
Creating default alias: default -> 18.12.0 (-> v18.12.0)
[i500695@WYLQRXL9LQ:2023-01-26 16:50:40:~/work/code/nodejs/node18:]2082$ nvm use 18.12.0
Now using node v18.12.0 (npm v8.19.2)

        20.1.4 
    20.2 n install and switch between different Node
`n` is a popular Node.js version management tool that allows you to install and switch between different Node.js versions on your system. Here's how you can install and use `n`:

| 1. Install `n` using npm by running the following command in your terminal:
| 
| ```
| npm install -g n
| ```
| 
| Note: You may need to use `sudo` to install `n` globally, depending on your system configuration.
| 
| 2. Once `n` is installed, you can use it to install and manage different Node.js versions. To install the latest version of Node.js, simply run the following command:
| 
| ```
| n latest
| ```
| 
| This will download and install the latest version of Node.js on your system.
| 
| 3. To switch between different Node.js versions, use the `n` command followed by the version number you want to switch to. For example, if you want to switch to version 14.17.0, run the following command:
| 
| ```
| n 14.17.0
| ```
| 
| This will switch your system to use Node.js version 14.17.0.
| 
| 4. You can also list all installed Node.js versions by running the following command:
| 
| ```
| n ls
| ```
| 
| This will display a list of all the installed Node.js versions on your system.
| 
| 5. If you want to remove a specific Node.js version, use the `n rm` command followed by the version number. For example, to remove version 14.17.0, run the following command:

```
n rm 14.17.0
```

Note that removing a Node.js version will also remove all the globally installed packages associated with that version.

That's it! You should now be able to install and switch between different Node.js versions on your system using the `n` module.

    20.3
21. commonly used patterns and idioms

    21.1 JSON.stringify 
Most used by me, stringify with 4 spaces indent to right:
        console.log(`Got json ${JSON.stringify(jsonData, null, 4)} from ${url}`);

1 space:
        console.log(`Got json ${JSON.stringify(jsonData, null, ' ')} from ${url}`);
1 tab:
        console.log(`Got json ${JSON.stringify(jsonData, null, "\t")} from ${url}`);


https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify

examples:
JSON.stringify({}); // '{}'
JSON.stringify(true); // 'true'
JSON.stringify("foo"); // '"foo"'
JSON.stringify([1, "false", false]); // '[1,"false",false]'
JSON.stringify([NaN, null, Infinity]); // '[null,null,null]'
JSON.stringify({ x: 5 }); // '{"x":5}'

JSON.stringify(new Date(1906, 0, 2, 15, 4, 5));
// '"1906-01-02T15:04:05.000Z"'

JSON.stringify({ x: 5, y: 6 });
// '{"x":5,"y":6}'
JSON.stringify([new Number(3), new String("false"), new Boolean(false)]);
// '[3,"false",false]'

// String-keyed array elements are not enumerable and make no sense in JSON
const a = ["foo", "bar"];
a["baz"] = "quux"; // a: [ 0: 'foo', 1: 'bar', baz: 'quux' ]
JSON.stringify(a);
// '["foo","bar"]'

JSON.stringify({ x: [10, undefined, function () {}, Symbol("")] });
// '{"x":[10,null,null,null]}'

// Standard data structures
JSON.stringify([
  new Set([1]),
  new Map([[1, 2]]),
  new WeakSet([{ a: 1 }]),
  new WeakMap([[{ a: 1 }, 2]]),
]);
// '[{},{},{},{}]'

// TypedArray
JSON.stringify([new Int8Array([1]), new Int16Array([1]), new Int32Array([1])]);
// '[{"0":1},{"0":1},{"0":1}]'
JSON.stringify([
  new Uint8Array([1]),
  new Uint8ClampedArray([1]),
  new Uint16Array([1]),
  new Uint32Array([1]),
]);
// '[{"0":1},{"0":1},{"0":1},{"0":1}]'
JSON.stringify([new Float32Array([1]), new Float64Array([1])]);
// '[{"0":1},{"0":1}]'

// toJSON()
JSON.stringify({
  x: 5,
  y: 6,
  toJSON() {
    return this.x + this.y;
  },
});
// '11'

// Symbols:
JSON.stringify({ x: undefined, y: Object, z: Symbol("") });
// '{}'
JSON.stringify({ [Symbol("foo")]: "foo" });
// '{}'
JSON.stringify({ [Symbol.for("foo")]: "foo" }, [Symbol.for("foo")]);
// '{}'
JSON.stringify({ [Symbol.for("foo")]: "foo" }, (k, v) => {
  if (typeof k === "symbol") {
    return "a symbol";
  }
});
// undefined

// Non-enumerable properties:
JSON.stringify(
  Object.create(null, {
    x: { value: "x", enumerable: false },
    y: { value: "y", enumerable: true },
  }),
);
// '{"y":"y"}'

// BigInt values throw
JSON.stringify({ x: 2n });
// TypeError: BigInt value can't be serialized in JSON

    21.2

22. chatgpt Q&A

    22.1 arrays

        22.1.1 splice
basically splice removes part of array and returns it and can optionally add items
so it both returns an array (deleted part, from start index and if no deleteCount up to end) and modifies in place the array

            22.1.1.1 q. Explain array splice nodejs
a.  In Node.js, the splice() method is used to modify an array by removing or replacing existing elements and/or inserting new elements into the array. The syntax for using the splice() method in Node.js is as follows:

array.splice(startIndex, deleteCount, item1, item2, ...)
Here's what each of the parameters means:

startIndex: The index at which to start changing the array. If negative, it specifies an offset from the end of the array (e.g. -1 would be the last element in the array).
deleteCount: The number of elements to remove from the array. If set to 0, no elements are removed. If greater than the number of elements between startIndex and the end of the array, all elements after startIndex will be removed.
item1, item2, etc.: Elements to insert into the array at the startIndex. If you don't want to insert any new elements, you can omit these parameters.
Here's an example that demonstrates the use of splice():

const myArray = ['apple', 'banana', 'cherry', 'date'];
myArray.splice(1, 2, 'orange', 'kiwi');
console.log(myArray); // Output: ['apple', 'orange', 'kiwi', 'date']
In this example, splice() removes two elements starting from index 1 ('banana' and 'cherry') and inserts two new elements ('orange' and 'kiwi') in their place. The resulting array is ['apple', 'orange', 'kiwi', 'date'].




            22.1.1.2 izaqyos@me.com q. what does it do when passed just startIndex param
When only the startIndex parameter is passed to the splice() method in Node.js, it doesn't remove any elements from the array. It simply returns a new array that contains all the elements from the startIndex to the end of the array.

Here's an example that demonstrates this:

const myArray = ['apple', 'banana', 'cherry', 'date'];
const newArray = myArray.splice(1);
console.log(newArray); // Output: ['banana', 'cherry', 'date']
In this example, splice(1) returns a new array that contains all the elements from index 1 ('banana') to the end of the array ('date'). The original myArray remains unchanged. The resulting newArray is ['banana', 'cherry', 'date'].

            22.1.1.3 splice demo
> let c = [1,2,3,4]
> c.splice()
[]
> c
[ 1, 2, 3, 4 ]
> c.splice(2)
[ 3, 4 ]
> c
[ 1, 2 ]
> c.splice(0,1,6,7,8)
[ 1 ]
> c
[ 6, 7, 8, 2 ]
> const chunkWrapper = {data: [1,2,3,4,5,6]};
> let maxChunkSize = 3;
> let reserveForNextChunk = chunkWrapper.data.splice(maxChunkSize);
> console.log(reserveForNextChunk)
[ 4, 5, 6 ]
> console.log(chunkWrapper.data)
[ 1, 2, 3 ]
            22.1.1.4
        22.1.2

    22.2

23. compression

    23.1  jszip

        23.1.1  nodejs use jszip and fs to recursively compress a directory use import instead of require

To recursively compress a directory using jszip and fs in Node.js using import statements, you can follow the below steps:

Install the required packages: First, install the required packages, jszip and fs using npm. Run the following command in your terminal or command prompt:

Copy code
npm install jszip fs
Import the packages: In your JavaScript file, import the packages using the import statement. Since jszip does not support ES6 modules, you need to use the default property to access the jszip module. The fs module can be imported directly.

javascript
Copy code
import JSZip from 'jszip';
import fs from 'fs';
Create a function to recursively compress the directory: Next, create a function to recursively compress the directory using jszip and fs. The function should take the path of the directory to compress as a parameter.

javascript
Copy code
async function compressDirectory(path) {
  const zip = new JSZip();
  const files = await fs.promises.readdir(path);
  for (const file of files) {
    const filePath = `${path}/${file}`;
    const stats = await fs.promises.stat(filePath);
    if (stats.isDirectory()) {
      zip.folder(file);
      await compressDirectory(filePath, zip);
    } else {
      const data = await fs.promises.readFile(filePath);
      zip.file(file, data);
    }
  }
  return zip;
}
Call the function and create the zip file: Finally, call the compressDirectory function with the path of the directory to compress and create the zip file.

javascript
Copy code
const path = './my-directory';
compressDirectory(path).then((zip) => {
  zip.generateAsync({ type: 'nodebuffer' }).then((content) => {
    fs.writeFileSync('my-directory.zip', content);
  });
});
This function will recursively compress all the files and directories inside the specified directory and create a zip file named my-directory.zip in the current working directory.

ex:
[i500695@WYLQRXL9LQ:2023-04-20 12:55:26:~/work/code/nodejs/compression/jszip:]2037$ node compress_dir_recurs.mjs 
[i500695@WYLQRXL9LQ:2023-04-20 12:57:03:~/work/code/nodejs/compression/jszip:]2038$ ls output.zip 
output.zip
[i500695@WYLQRXL9LQ:2023-04-20 12:57:06:~/work/code/nodejs/compression/jszip:]2039$ cat compress_dir_recurs.mjs 
// const JSZip = import('jszip');
// const fs = import('fs');
import JSZip from 'jszip';
import fs from 'fs';


async function addFilesToZip(zip, basePath) {
  const files = await fs.promises.readdir(basePath);

  for (const file of files) {
    const fullPath = `${basePath}/${file}`;
    const stat = await fs.promises.stat(fullPath);

    if (stat.isDirectory()) {
      await addFilesToZip(zip.folder(file), fullPath);
    } else {
      const data = await fs.promises.readFile(fullPath);
      zip.file(file, data);
    }
  }
}
async function compressDirectory(directoryPath, zipFilePath) {
  const zip = new JSZip();
  await addFilesToZip(zip, directoryPath);
  const content = await zip.generateAsync({ type: 'nodebuffer' });
  await fs.promises.writeFile(zipFilePath, content);
}
compressDirectory(process.cwd(), process.cwd()+'/output.zip');


        23.1.2
    23.2

24.
