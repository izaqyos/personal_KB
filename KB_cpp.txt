.........................................Table Of Contents...............................................................
1. Beautifiers. <URL:#tn=1. Beautifiers.>
	1.1. Method 1: Verfication Program for C++/C <URL:#tn=	1.1. Method 1: Verfication Program for C++/C>
	1.2. Method 2: Verfication Program for C++/C <URL:#tn=	1.2. Method 2: Verfication Program for C++/C>
	1.3. Method 3: Verfication Program for Java/C++/Others <URL:#tn=	1.3. Method 3: Verfication Program for Java/C++/Others>
	1.4. Method 4: Shell script: Verfication Program for C++/C <URL:#tn=	1.4. Method 4: Shell script: Verfication Program for C++/C>
2. Debug <URL:#tn=2. Debug>
	2.1 Generate core dumps <URL:#tn=	2.1 Generate core dumps>
	2.2 gdb <URL:#tn=	2.2 gdb>
		2.2.1 catch exceptions in debugger instead of in code <URL:#tn=		2.2.1 catch exceptions in debugger instead of in code>
		2.2.2 My examples <URL:#tn=		2.2.2 My examples>
			2.2.2.1 Debug optimised executables <URL:#tn=			2.2.2.1 Debug optimised executables>
		2.2.3 how to generate gcc debug symbol outside the build target <URL:#tn=		2.2.3 how to generate gcc debug symbol outside the build target>
			2.2.3.1 http://stackoverflow.com/questions/866721/how-to-generate-gcc-debug-symbol-outside-the-build-target <URL:#tn=			2.2.3.1 http://stackoverflow.com/questions/866721/how-to-generate-gcc-debug-symbol-outside-the-build-target>
			2.2.3.2 <URL:#tn=			2.2.3.2>
		2.2.4 <URL:#tn=		2.2.4>
3. Printing, IO, write, read <URL:#tn=3. Printing, IO, write, read>
	3.1 printf quick ref <URL:#tn=	3.1 printf quick ref>
		3.1.1  print size_t <URL:#tn=		3.1.1  print size_t>
		3.1.2 <URL:#tn=		3.1.2>
	3.2 Printing a hex dump of a buffer (or print char * hex buffer) <URL:#tn=	3.2 Printing a hex dump of a buffer (or print char * hex buffer)>
		3.2.1 Crude solution <URL:#tn=		3.2.1 Crude solution>
		3.2.2 Somewhat nicer print <URL:#tn=		3.2.2 Somewhat nicer print>
4. Standard template library, STL, namespace std <URL:#tn=4. Standard template library, STL, namespace std>
	4.1 string, std::string <URL:#tn=	4.1 string, std::string>
		4.1.1 check for equality, compare <URL:#tn=		4.1.1 check for equality, compare>
		4.1.2 STL String Examples <URL:#tn=		4.1.2 STL String Examples>
		4.1.3 More string examples <URL:#tn=		4.1.3 More string examples>
		4.1.4 String class example <URL:#tn=		4.1.4 String class example>
		4.1.5 Get bytes from std::string in C++ <URL:#tn=		4.1.5 Get bytes from std::string in C++>
		4.1.7 std::string reference <URL:#tn=		4.1.7 std::string reference>
		4.1.8 <URL:#tn=		4.1.8>
	4.2 Vector <URL:#tn=	4.2 Vector>
		4.2.1 Types <URL:#tn=		4.2.1 Types>
		4.2.2 CTOR/DTOR <URL:#tn=		4.2.2 CTOR/DTOR>
		4.2.3 Size <URL:#tn=		4.2.3 Size>
		4.2.4 Altering <URL:#tn=		4.2.4 Altering>
		4.2.5 Access <URL:#tn=		4.2.5 Access>
		4.2.6 Iteration <URL:#tn=		4.2.6 Iteration>
			4.2.6.1 C++ STL: Which method of iteration over a STL container is better? <URL:#tn=			4.2.6.1 C++ STL: Which method of iteration over a STL container is better?>
			4.2.6.2 std::for_each <URL:#tn=			4.2.6.2 std::for_each>
		4.2.7 <URL:#tn=		4.2.7>
	4.3 set <URL:#tn=	4.3 set>
		4.3.1 http://www.cplusplus.com/reference/set/set/ <URL:#tn=		4.3.1 http://www.cplusplus.com/reference/set/set/>
		4.3.2 My examples <URL:#tn=		4.3.2 My examples>
			4.3.2.1 Create set from range, iterate set <URL:#tn=			4.3.2.1 Create set from range, iterate set>
			4.3.2.2 More set usage, template function takes container as argument <URL:#tn=			4.3.2.2 More set usage, template function takes container as argument>
			4.3.2.3 <URL:#tn=			4.3.2.3>
		4.3.3 <URL:#tn=		4.3.3>
	4.4 map <URL:#tn=	4.4 map>
	4.5 <URL:#tn=	4.5>
5. Exception handling <URL:#tn=5. Exception handling>
	5.1 Articles against exceptions handling. <URL:#tn=	5.1 Articles against exceptions handling.>
		5.1.1 " <URL:#tn=		5.1.1 ">
		5.1.2. Posted in November 13th, 2007 by Mark in Programming <URL:#tn=		5.1.2. Posted in November 13th, 2007 by Mark in Programming>
	5.2 <URL:#tn=	5.2>
6. Conversions <URL:#tn=6. Conversions>
	6.1 Hex string to integer <URL:#tn=	6.1 Hex string to integer>
7. CPPUnit, Unit tests framework for C++ <URL:#tn=7. CPPUnit, Unit tests framework for C++>
	7.1 JUnit <URL:#tn=	7.1 JUnit>
	7.2 CPP Unit <URL:#tn=	7.2 CPP Unit>
8. Configuration file parsing <URL:#tn=8. Configuration file parsing>
	8.1  Rick Wagner, Configuration File Reader for C++ <URL:#tn=	8.1  Rick Wagner, Configuration File Reader for C++>
9. Memory mangament <URL:#tn=9. Memory mangament>
	9.1 Pointers, Smart pointers <URL:#tn=	9.1 Pointers, Smart pointers>
		9.1.1 Auto Ptr, Using auto_ptr Effectively <URL:#tn=		9.1.1 Auto Ptr, Using auto_ptr Effectively>
	9.2 <URL:#tn=	9.2>
10. C++ Tutorial, http://www.java2s.com/Tutorial/Cpp/CatalogCpp.htm <URL:#tn=10. C++ Tutorial, http://www.java2s.com/Tutorial/Cpp/CatalogCpp.htm>
11. Compilation Errors FAQs <URL:#tn=11. Compilation Errors FAQs>
	11.1 GCC <URL:#tn=	11.1 GCC>
		11.1.1 undefined vtable <URL:#tn=		11.1.1 undefined vtable>
		11.1.2 class has virtual functions but non-virtual destructor <URL:#tn=		11.1.2 class has virtual functions but non-virtual destructor>
		11.1.3 may be used uninitialized in this function <URL:#tn=		11.1.3 may be used uninitialized in this function>
			11.1.3.1 My example <URL:#tn=			11.1.3.1 My example>
			11.1.3.2 <URL:#tn=			11.1.3.2>
		11.1.4 jump into scope of identifier with variably modified type <URL:#tn=		11.1.4 jump into scope of identifier with variably modified type>
			11.1.4.1 Example <URL:#tn=			11.1.4.1 Example>
			11.1.4.2 <URL:#tn=			11.1.4.2>
		11.1.5 gcc warning" 'will be initialized after' <URL:#tn=		11.1.5 gcc warning" 'will be initialized after'>
		11.1.6 error: stropts.h: No such file or directory <URL:#tn=		11.1.6 error: stropts.h: No such file or directory>
		11.1.7 <URL:#tn=		11.1.7>
12. C language <URL:#tn=12. C language>
	12.1 Time <URL:#tn=	12.1 Time>
            12.1.1 Variables and Definitions <URL:#tn=            12.1.1 Variables and Definitions>
            12.1.2 asctime <URL:#tn=            12.1.2 asctime>
            12.1.3 clock <URL:#tn=            12.1.3 clock>
            12.1.4 ctime <URL:#tn=            12.1.4 ctime>
            12.1.5 difftime <URL:#tn=            12.1.5 difftime>
            12.1.6 gmtime <URL:#tn=            12.1.6 gmtime>
            12.1.7 localtime <URL:#tn=            12.1.7 localtime>
            12.1.8 mktime <URL:#tn=            12.1.8 mktime>
            12.1.9 strftime <URL:#tn=            12.1.9 strftime>
            12.1.10 time <URL:#tn=            12.1.10 time>
	12.2 more time APIs <URL:#tn=	12.2 more time APIs>
		12.2.1 std::clock vs. chrono <URL:#tn=		12.2.1 std::clock vs. chrono>
		12.2.2 gettimeofday <URL:#tn=		12.2.2 gettimeofday>
			12.2.2.1 time.c <URL:#tn=			12.2.2.1 time.c>
			12.2.2.2 GETTIMEOFDAY(2)           Linux Programmer's Manual          GETTIMEOFDAY(2) <URL:#tn=			12.2.2.2 GETTIMEOFDAY(2)           Linux Programmer's Manual          GETTIMEOFDAY(2)>
			12.2.2.3 <URL:#tn=			12.2.2.3>
		12.2.3 Print date and time using gettimeofday <URL:#tn=		12.2.3 Print date and time using gettimeofday>
			12.2.3.1 Getting Current Time with Milliseconds <URL:#tn=			12.2.3.1 Getting Current Time with Milliseconds>
			12.2.3.2 <URL:#tn=			12.2.3.2>
		12.2.4 <URL:#tn=		12.2.4>
	12.3 <URL:#tn=	12.3>
13. Open source libraries <URL:#tn=13. Open source libraries>
	13.1 Networking <URL:#tn=	13.1 Networking>
		13.1.1  Authentication <URL:#tn=		13.1.1  Authentication>
			13.1.1.1  RADIUS <URL:#tn=			13.1.1.1  RADIUS>
				13.1.1.1.1  GNU RADIUS <URL:#tn=				13.1.1.1.1  GNU RADIUS>
			13.1.1.2 <URL:#tn=			13.1.1.2>
		13.1.2 <URL:#tn=		13.1.2>
	13.2 Security, Cryptography <URL:#tn=	13.2 Security, Cryptography>
14. Books <URL:#tn=14. Books>
15. Operators <URL:#tn=15. Operators>
	15.1  Bitwise Operators <URL:#tn=	15.1  Bitwise Operators>
	15.2 <URL:#tn=	15.2>
16. Design patterns <URL:#tn=16. Design patterns>
	16.1 Singelton <URL:#tn=	16.1 Singelton>
		16.1.1 First example <URL:#tn=		16.1.1 First example>
		16.1.2 2nd example <URL:#tn=		16.1.2 2nd example>
		16.1.3 <URL:#tn=		16.1.3>
	16.2 <URL:#tn=	16.2>
17. Coding standards <URL:#tn=17. Coding standards>
	17.1 C++ Coding Standard,  http://www.possibility.com/Cpp/CppCodingStandard.html <URL:#tn=	17.1 C++ Coding Standard,  http://www.possibility.com/Cpp/CppCodingStandard.html>
		17.1.1. Introduction <URL:#tn=		17.1.1. Introduction>
		17.1.2. Resources- Take a Look! <URL:#tn=		17.1.2. Resources- Take a Look!>
		17.1.3. Names <URL:#tn=		17.1.3. Names>
		17.1.4. Documentation <URL:#tn=		17.1.4. Documentation>
		17.1.5. Complexity Management <URL:#tn=		17.1.5. Complexity Management>
		17.1.6. Classes <URL:#tn=		17.1.6. Classes>
		17.1.8. Formatting Methods with Multiple Arguments <URL:#tn=		17.1.8. Formatting Methods with Multiple Arguments>
		17.1.7. Process <URL:#tn=		17.1.7. Process>
		17.1.9. Exceptions <URL:#tn=		17.1.9. Exceptions>
		17.1.10. Templates <URL:#tn=		17.1.10. Templates>
		17.1.11. Namespaces <URL:#tn=		17.1.11. Namespaces>
		17.1.12. Miscellaneous <URL:#tn=		17.1.12. Miscellaneous>
		17.1.13. Portability <URL:#tn=		17.1.13. Portability>
		17.1.14. Popular Myths <URL:#tn=		17.1.14. Popular Myths>
	17.2 Const correctness <URL:#tn=	17.2 Const correctness>
	17.3 <URL:#tn=	17.3>
18. Nuts and bolts, odds and ends <URL:#tn=18. Nuts and bolts, odds and ends>
	18.1 templates <URL:#tn=	18.1 templates>
		18.1.1 Push the limits of the meta compiler <URL:#tn=		18.1.1 Push the limits of the meta compiler>
	18.2 Limits <URL:#tn=	18.2 Limits>
	18.3 <URL:#tn=	18.3>
19. Program Library HOWTO <URL:#tn=19. Program Library HOWTO>
	19.1 Introduction <URL:#tn=	19.1 Introduction>
	19.2 Static Libraries <URL:#tn=	19.2 Static Libraries>
	19.3 Shared Libraries <URL:#tn=	19.3 Shared Libraries>
		19.3.1 Conventions <URL:#tn=		19.3.1 Conventions>
			19.3.1.1 Shared Library Names <URL:#tn=			19.3.1.1 Shared Library Names>
			19.3.1.2 Filesystem Placement <URL:#tn=			19.3.1.2 Filesystem Placement>
		19.3.2 How Libraries are Used <URL:#tn=		19.3.2 How Libraries are Used>
		19.3.3 Environment Variables <URL:#tn=		19.3.3 Environment Variables>
			19.3.3.1 LD_LIBRARY_PATH <URL:#tn=			19.3.3.1 LD_LIBRARY_PATH>
			19.3.3.2 LD_DEBUG <URL:#tn=			19.3.3.2 LD_DEBUG>
			19.3.3.3 Other Environment Variables <URL:#tn=			19.3.3.3 Other Environment Variables>
		19.3.4 Creating a Shared Library <URL:#tn=		19.3.4 Creating a Shared Library>
		19.3.5 Installing and Using a Shared Library <URL:#tn=		19.3.5 Installing and Using a Shared Library>
		19.3.6 Incompatible Libraries <URL:#tn=		19.3.6 Incompatible Libraries>
	19.4 Dynamically Loaded (DL) Libraries <URL:#tn=	19.4 Dynamically Loaded (DL) Libraries>
		19.4.1 dlopen() <URL:#tn=		19.4.1 dlopen()>
		19.4.2 dlerror() <URL:#tn=		19.4.2 dlerror()>
		19.4.3 dlsym() <URL:#tn=		19.4.3 dlsym()>
		19.4.4 dlclose() <URL:#tn=		19.4.4 dlclose()>
		19.4.5 DL Library Example <URL:#tn=		19.4.5 DL Library Example>
	19.5 Miscellaneous <URL:#tn=	19.5 Miscellaneous>
		19.5.1 nm command <URL:#tn=		19.5.1 nm command>
			19.5.1.1  Description <URL:#tn=			19.5.1.1  Description>
			19.5.1.2 nm(1) - Linux man page <URL:#tn=			19.5.1.2 nm(1) - Linux man page>
			19.5.1.3 Short explanation <URL:#tn=			19.5.1.3 Short explanation>
			19.5.1.4 <URL:#tn=			19.5.1.4>
		19.5.2 Library constructor and destructor functions <URL:#tn=		19.5.2 Library constructor and destructor functions>
			19.5.2.1 Special functions _init and _fini (OBSOLETE/DANGEROUS) <URL:#tn=			19.5.2.1 Special functions _init and _fini (OBSOLETE/DANGEROUS)>
		19.5.3 Shared Libraries Can Be Scripts <URL:#tn=		19.5.3 Shared Libraries Can Be Scripts>
		19.5.4 Symbol Versioning and Version Scripts <URL:#tn=		19.5.4 Symbol Versioning and Version Scripts>
		19.5.5 GNU libtool <URL:#tn=		19.5.5 GNU libtool>
		19.5.6 Removing symbols for space <URL:#tn=		19.5.6 Removing symbols for space>
		19.5.7 Extremely small executables <URL:#tn=		19.5.7 Extremely small executables>
		19.5.8 C++ vs. C <URL:#tn=		19.5.8 C++ vs. C>
		19.5.9 Speeding up C++ initialization <URL:#tn=		19.5.9 Speeding up C++ initialization>
		19.5.10 Linux Standard Base (LSB) <URL:#tn=		19.5.10 Linux Standard Base (LSB)>
	19.6 More Examples <URL:#tn=	19.6 More Examples>
		19.6.1 File libhello.c <URL:#tn=		19.6.1 File libhello.c>
		19.6.2 File libhello.h <URL:#tn=		19.6.2 File libhello.h>
		19.6.3 File demo_use.c <URL:#tn=		19.6.3 File demo_use.c>
		19.6.4 File script_static <URL:#tn=		19.6.4 File script_static>
		19.6.5 File script_shared <URL:#tn=		19.6.5 File script_shared>
		19.6.6 File demo_dynamic.c <URL:#tn=		19.6.6 File demo_dynamic.c>
		19.6.7 File script_dynamic <URL:#tn=		19.6.7 File script_dynamic>
	19.7 Other Information Sources <URL:#tn=	19.7 Other Information Sources>
		19.7.1  Linux Commands For Shared Library Management & Debugging Problem <URL:#tn=		19.7.1  Linux Commands For Shared Library Management & Debugging Problem>
		19.7.2 Anatomy of Linux dynamic libraries <URL:#tn=		19.7.2 Anatomy of Linux dynamic libraries>
  1.000000 <URL:#tn=  1.000000>
  0.000000 <URL:#tn=  0.000000>
  1.557408 <URL:#tn=  1.557408>
  1.000000 <URL:#tn=  1.000000>
		19.7.3 <URL:#tn=		19.7.3>
	19.8 Visiblity <URL:#tn=	19.8 Visiblity>
		19.8.1 gcc <URL:#tn=		19.8.1 gcc>
		19.8.2 <URL:#tn=		19.8.2>
	19.9 <URL:#tn=	19.9>
20. FAQ, Cookbook <URL:#tn=20. FAQ, Cookbook>
	20.1 How to parse a simple text file <URL:#tn=	20.1 How to parse a simple text file>
		20.1.1 my example <URL:#tn=		20.1.1 my example>
		20.1.2 <URL:#tn=		20.1.2>
	20.2 Compilation errors <URL:#tn=	20.2 Compilation errors>
		20.2.1  stray '\xxx' in program <URL:#tn=		20.2.1  stray '\xxx' in program>
	20.3 Initializing private static members <URL:#tn=	20.3 Initializing private static members>
	20.4 Is there a GCC preprocessor directive to check if the code is being compiled on a 64 bit machine? <URL:#tn=	20.4 Is there a GCC preprocessor directive to check if the code is being compiled on a 64 bit machine?>
27.4k260117 <URL:#tn=27.4k260117>
	20.5 list .so symbols <URL:#tn=	20.5 list .so symbols>
	20.6 Link/Load errors <URL:#tn=	20.6 Link/Load errors>
		20.6.1 error while loading shared libraries <URL:#tn=		20.6.1 error while loading shared libraries>
		20.6.2 <URL:#tn=		20.6.2>
	20.7 popen2 <URL:#tn=	20.7 popen2>
	20.8 What's the scope of the “using” declaration in C++? <URL:#tn=	20.8 What's the scope of the “using” declaration in C++?>
	20.9 Why “using namespace X;” is not allowed inside class/struct level? <URL:#tn=	20.9 Why “using namespace X;” is not allowed inside class/struct level?>
	20.10 Why do you use typedef when declaring an enum in C++? <URL:#tn=	20.10 Why do you use typedef when declaring an enum in C++?>
	20.11 Class members function pointers <URL:#tn=	20.11 Class members function pointers>
		20.11.1  My example <URL:#tn=		20.11.1  My example>
	20.12 c++ simple command line parser <URL:#tn=	20.12 c++ simple command line parser>
		20.12.1 boost::program_options <URL:#tn=		20.12.1 boost::program_options>
			20.12.1.1 Tutorial <URL:#tn=			20.12.1.1 Tutorial>
			20.12.1.2 first.cpp <URL:#tn=			20.12.1.2 first.cpp>
			20.12.1.3 My example <URL:#tn=			20.12.1.3 My example>
			20.12.1.4 http://www.radmangames.com/programming/how-to-use-boost-program_options <URL:#tn=			20.12.1.4 http://www.radmangames.com/programming/how-to-use-boost-program_options>
			20.12.1.5 <URL:#tn=			20.12.1.5>
		20.12.2 <URL:#tn=		20.12.2>
	20.13 c++ print source file name and line <URL:#tn=	20.13 c++ print source file name and line>
	20.14 initialization list question, with emphasis on std vector <URL:#tn=	20.14 initialization list question, with emphasis on std vector>
	20.15 boost regex <URL:#tn=	20.15 boost regex>
		20.15.1 <URL:#tn=		20.15.1>
	20.16 Translate IPv6 address from string to binary and back to string (normalizing it on the way) <URL:#tn=	20.16 Translate IPv6 address from string to binary and back to string (normalizing it on the way)>
	20.17 <URL:#tn=	20.17>
21. Multithreading <URL:#tn=21. Multithreading>
	21.1 POSIX thread (pthread) libraries <URL:#tn=	21.1 POSIX thread (pthread) libraries>
		21.1.1 Thread Basics: <URL:#tn=		21.1.1 Thread Basics:>
		21.1.2 Thread Creation and Termination: <URL:#tn=		21.1.2 Thread Creation and Termination:>
		21.1.3 Thread Synchronization: <URL:#tn=		21.1.3 Thread Synchronization:>
		21.1.4 Thread Scheduling: <URL:#tn=		21.1.4 Thread Scheduling:>
		21.1.5 Thread Pitfalls: <URL:#tn=		21.1.5 Thread Pitfalls:>
		21.1.6 Thread Debugging: <URL:#tn=		21.1.6 Thread Debugging:>
			21.1.6.1 Debugging Programs with Multiple Threads <URL:#tn=			21.1.6.1 Debugging Programs with Multiple Threads>
4.10 Debugging Programs with Multiple Threads <URL:#tn=4.10 Debugging Programs with Multiple Threads>
			21.1.6.2 GDB: Stopping and starting multi-thread programs <URL:#tn=			21.1.6.2 GDB: Stopping and starting multi-thread programs>
			21.1.6.3 GDB/MI: Threads commands <URL:#tn=			21.1.6.3 GDB/MI: Threads commands>
			21.1.6.4 <URL:#tn=			21.1.6.4>
		21.1.7 Thread Man Pages: <URL:#tn=		21.1.7 Thread Man Pages:>
	21.2 posix thread join thread timeout <URL:#tn=	21.2 posix thread join thread timeout>
		21.2.1 http://man7.org/linux/man-pages/man3/pthread_tryjoin_np.3.html <URL:#tn=		21.2.1 http://man7.org/linux/man-pages/man3/pthread_tryjoin_np.3.html>
		21.2.2 <URL:#tn=		21.2.2>
	21.3 pthread idioms & FAQ <URL:#tn=	21.3 pthread idioms & FAQ>
		21.3.1  Pass member function to thread execution <URL:#tn=		21.3.1  Pass member function to thread execution>
			21.3.1.1  Pass member function to thread execution <URL:#tn=			21.3.1.1  Pass member function to thread execution>
				21.3.1.1.1  http://stackoverflow.com/questions/1151582/pthread-function-from-a-class <URL:#tn=				21.3.1.1.1  http://stackoverflow.com/questions/1151582/pthread-function-from-a-class>
				21.3.1.1.2 <URL:#tn=				21.3.1.1.2>
			21.3.1.2 <URL:#tn=			21.3.1.2>
		21.3.2 Read-Write lock, pthread_rwlock_t <URL:#tn=		21.3.2 Read-Write lock, pthread_rwlock_t>
			21.3.2.1 API <URL:#tn=			21.3.2.1 API>
			21.3.2.2 Simple Example <URL:#tn=			21.3.2.2 Simple Example>
			21.3.2.3 Another example, using class ctor/dtor for auto lock/unlock in function scope <URL:#tn=			21.3.2.3 Another example, using class ctor/dtor for auto lock/unlock in function scope>
			21.3.2.4 <URL:#tn=			21.3.2.4>
		21.3.3 <URL:#tn=		21.3.3>
	21.4 <URL:#tn=	21.4>
23. Advanced Interview questions <URL:#tn=23. Advanced Interview questions>
	23.1 Advanced C++ and STL interview questions <URL:#tn=	23.1 Advanced C++ and STL interview questions>
	23.2 http://www.devbistro.com/tech-interview-questions/Cplusplus.jsp <URL:#tn=	23.2 http://www.devbistro.com/tech-interview-questions/Cplusplus.jsp>
	23.3 http://www.decompile.com/interview/C%2B%2B_Interview_Questions_Page_02.htm <URL:#tn=	23.3 http://www.decompile.com/interview/C%2B%2B_Interview_Questions_Page_02.htm>
1. C++ comments use both // and /* */ whereas standard C uses only //. If you can construct an expression in a C program that contains /* and */, it will compile cleanly in both compilers but give different runtime results. <URL:#tn=1. C++ comments use both // and /* */ whereas standard C uses only //. If you can construct an expression in a C program that contains /* and */, it will compile cleanly in both compilers but give different runtime results.>
2. Literal characters in C (such as 'a'), are of type int. Therefore, in C, sizeof('a') is the same as sizeof(int). Literal characters in C++ are of type char. On all Borland C++ compilers, sizeof(int) != sizeof(char). <URL:#tn=2. Literal characters in C (such as 'a'), are of type int. Therefore, in C, sizeof('a') is the same as sizeof(int). Literal characters in C++ are of type char. On all Borland C++ compilers, sizeof(int) != sizeof(char).>
	23.3 <URL:#tn=	23.3>
	23.4 <URL:#tn=	23.4>
	23.5 <URL:#tn=	23.5>
	23.6 <URL:#tn=	23.6>
	23.7 <URL:#tn=	23.7>
	23.8 <URL:#tn=	23.8>
	23.9 <URL:#tn=	23.9>
24. Secure coding <URL:#tn=24. Secure coding>
	24.1 Cisco, CERT course <URL:#tn=	24.1 Cisco, CERT course>
		24.1.1  strings <URL:#tn=		24.1.1  strings>
			24.1.1.1 Character strings <URL:#tn=			24.1.1.1 Character strings>
				24.1.1.1.1 ARR01-C. Do not apply the sizeof operator to a pointer when taking the size of an array <URL:#tn=				24.1.1.1.1 ARR01-C. Do not apply the sizeof operator to a pointer when taking the size of an array>
				24.1.1.1.2 did I get this <URL:#tn=				24.1.1.1.2 did I get this>
				24.1.1.1.3 UTF-8 <URL:#tn=				24.1.1.1.3 UTF-8>
					24.1.1.1.3.1 MSC10-C. Character Encoding - UTF8 Related Issues <URL:#tn=					24.1.1.1.3.1 MSC10-C. Character Encoding - UTF8 Related Issues>
						24.1.1.1.3.1.1 learn by doing <URL:#tn=						24.1.1.1.3.1.1 learn by doing>
						24.1.1.1.3.1.2 <URL:#tn=						24.1.1.1.3.1.2>
				24.1.1.1.4 Wide Strings <URL:#tn=				24.1.1.1.4 Wide Strings>
				24.1.1.1.5 String Literals <URL:#tn=				24.1.1.1.5 String Literals>
					24.1.1.1.5.1 STR30-C. Do not attempt to modify string literals <URL:#tn=					24.1.1.1.5.1 STR30-C. Do not attempt to modify string literals>
					24.1.1.1.5.2 did I get this <URL:#tn=					24.1.1.1.5.2 did I get this>
					24.1.1.1.5.3 <URL:#tn=					24.1.1.1.5.3>
				24.1.1.1.6 Standard strings <URL:#tn=				24.1.1.1.6 Standard strings>
				24.1.1.1.7 character types <URL:#tn=				24.1.1.1.7 character types>
					24.1.1.1.7.1  Did I get this <URL:#tn=					24.1.1.1.7.1  Did I get this>
					24.1.1.1.7.2 Excerpt on 2s complement <URL:#tn=					24.1.1.1.7.2 Excerpt on 2s complement>
					24.1.1.1.7.3 <URL:#tn=					24.1.1.1.7.3>
				24.1.1.1.8 Sizing Strings <URL:#tn=				24.1.1.1.8 Sizing Strings>
					24.1.1.1.8.1 STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator <URL:#tn=					24.1.1.1.8.1 STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator>
					24.1.1.1.8.2 My example, sizing_strings.cpp <URL:#tn=					24.1.1.1.8.2 My example, sizing_strings.cpp>
					24.1.1.1.8.3 test <URL:#tn=					24.1.1.1.8.3 test>
					24.1.1.1.8.4 <URL:#tn=					24.1.1.1.8.4>
				24.1.1.1.9 <URL:#tn=				24.1.1.1.9>
			24.1.1.2 Common String Manipulation Errors <URL:#tn=			24.1.1.2 Common String Manipulation Errors>
				24.1.1.2.1 Improperly Bounded String Copies <URL:#tn=				24.1.1.2.1 Improperly Bounded String Copies>
					24.1.1.2.1.1 Did I get this? <URL:#tn=					24.1.1.2.1.1 Did I get this?>
					24.1.1.2.1.2 Unbounded Strings in C++ <URL:#tn=					24.1.1.2.1.2 Unbounded Strings in C++>
					24.1.1.2.1.3 <URL:#tn=					24.1.1.2.1.3>
				24.1.1.2.2 Off-by-one errors <URL:#tn=				24.1.1.2.2 Off-by-one errors>
					24.1.1.2.2.1 did I get this <URL:#tn=					24.1.1.2.2.1 did I get this>
					24.1.1.2.2.2 <URL:#tn=					24.1.1.2.2.2>
				24.1.1.2.3 Null-Termination Errors <URL:#tn=				24.1.1.2.3 Null-Termination Errors>
					24.1.1.2.3.1 did I get this <URL:#tn=					24.1.1.2.3.1 did I get this>
					24.1.1.2.3.2 <URL:#tn=					24.1.1.2.3.2>
				24.1.1.2.4 String Truncation <URL:#tn=				24.1.1.2.4 String Truncation>
				24.1.1.2.5 String Errors without Functions <URL:#tn=				24.1.1.2.5 String Errors without Functions>
					24.1.1.2.5.1  did I get this? <URL:#tn=					24.1.1.2.5.1  did I get this?>
					24.1.1.2.5.2 <URL:#tn=					24.1.1.2.5.2>
				24.1.1.2.6 <URL:#tn=				24.1.1.2.6>
			24.1.1.3 String Vulnerabilities and Exploits <URL:#tn=			24.1.1.3 String Vulnerabilities and Exploits>
				24.1.1.3.1 Tainted Data <URL:#tn=				24.1.1.3.1 Tainted Data>
				24.1.1.3.2 Buffer Overflows <URL:#tn=				24.1.1.3.2 Buffer Overflows>
				24.1.1.3.3 Process Memory Organization <URL:#tn=				24.1.1.3.3 Process Memory Organization>
				24.1.1.3.4 Stack Management <URL:#tn=				24.1.1.3.4 Stack Management>
					24.1.1.3.4.1 Did I get this <URL:#tn=					24.1.1.3.4.1 Did I get this>
				24.1.1.3.5 Stack smashing <URL:#tn=				24.1.1.3.5 Stack smashing>
				24.1.1.3.6 Code Injection <URL:#tn=				24.1.1.3.6 Code Injection>
					24.1.1.3.6.1 learn by coding <URL:#tn=					24.1.1.3.6.1 learn by coding>
				24.1.1.3.7 Arc Injection <URL:#tn=				24.1.1.3.7 Arc Injection>
				24.1.1.3.8 Return-Oriented Programming <URL:#tn=				24.1.1.3.8 Return-Oriented Programming>
				24.1.1.3.9 <URL:#tn=				24.1.1.3.9>
			24.1.1.4 Mitigation Strategies <URL:#tn=			24.1.1.4 Mitigation Strategies>
				24.1.1.4.1 String Handling <URL:#tn=				24.1.1.4.1 String Handling>
				24.1.1.4.2 C11 Annex K, Bounds-Checking Interfaces <URL:#tn=				24.1.1.4.2 C11 Annex K, Bounds-Checking Interfaces>
				24.1.1.4.3 Dynamic Allocation Functions <URL:#tn=				24.1.1.4.3 Dynamic Allocation Functions>
				24.1.1.4.4 C++ std::basic_string <URL:#tn=				24.1.1.4.4 C++ std::basic_string>
				24.1.1.4.5 Invalidating String Object References <URL:#tn=				24.1.1.4.5 Invalidating String Object References>
					24.1.1.4.5.1 String Copy Question 1 <URL:#tn=					24.1.1.4.5.1 String Copy Question 1>
					24.1.1.4.5.2 <URL:#tn=					24.1.1.4.5.2>
			24.1.1.5 gets( ) <URL:#tn=			24.1.1.5 gets( )>
				24.1.1.5.1 did I get this <URL:#tn=				24.1.1.5.1 did I get this>
				24.1.1.5.2 <URL:#tn=				24.1.1.5.2>
			24.1.1.6 C11 Annex K, Bounds-Checking Interfaces: gets() <URL:#tn=			24.1.1.6 C11 Annex K, Bounds-Checking Interfaces: gets()>
			24.1.1.7 Dynamic Allocation Functions <URL:#tn=			24.1.1.7 Dynamic Allocation Functions>
				24.1.1.7.1 did I get this <URL:#tn=				24.1.1.7.1 did I get this>
				24.1.1.7.2 <URL:#tn=				24.1.1.7.2>
			24.1.1.8 strcpy( ) and strcat( ) <URL:#tn=			24.1.1.8 strcpy( ) and strcat( )>
			24.1.1.9 Dynamic Allocation Functions <URL:#tn=			24.1.1.9 Dynamic Allocation Functions>
				24.1.1.9.1  learn by doing <URL:#tn=				24.1.1.9.1  learn by doing>
				24.1.1.9.2 <URL:#tn=				24.1.1.9.2>
			24.1.1.10 Summary Alternatives <URL:#tn=			24.1.1.10 Summary Alternatives>
				24.1.1.10.1  Did I get this? <URL:#tn=				24.1.1.10.1  Did I get this?>
				24.1.1.10.2 <URL:#tn=				24.1.1.10.2>
			24.1.1.11 strncpy( ) and strncat( ) <URL:#tn=			24.1.1.11 strncpy( ) and strncat( )>
			24.1.1.12 Dynamic Allocation Functions <URL:#tn=			24.1.1.12 Dynamic Allocation Functions>
			24.1.1.13 Summary of Alternatives <URL:#tn=			24.1.1.13 Summary of Alternatives>
			24.1.1.14 memcpy( ) and memmove( ) <URL:#tn=			24.1.1.14 memcpy( ) and memmove( )>
			24.1.1.15 strlen( ) <URL:#tn=			24.1.1.15 strlen( )>
			24.1.1.16 <URL:#tn=			24.1.1.16>
			24.1.1.17 Object Size Checking <URL:#tn=			24.1.1.17 Object Size Checking>
			24.1.1.18 Test <URL:#tn=			24.1.1.18 Test>
				24.1.1.18.1  1st attempt <URL:#tn=				24.1.1.18.1  1st attempt>
7. Which of the following calls is guaranteed not to produce undefined behavior, given that c is declared as char? (answered incorrectly) <URL:#tn=7. Which of the following calls is guaranteed not to produce undefined behavior, given that c is declared as char? (answered incorrectly)>
10. Which behavior is exhibited by the following invocation of strtoul()? (answered incorrectly) <URL:#tn=10. Which behavior is exhibited by the following invocation of strtoul()? (answered incorrectly)>
11. What is the problem with the following code? (answered incorrectly) <URL:#tn=11. What is the problem with the following code? (answered incorrectly)>
				24.1.1.18.2 2nd attempt <URL:#tn=				24.1.1.18.2 2nd attempt>
				24.1.1.18.3 <URL:#tn=				24.1.1.18.3>
			24.1.1.19 <URL:#tn=			24.1.1.19>
		24.1.2 Integers <URL:#tn=		24.1.2 Integers>
		24.1.3 <URL:#tn=		24.1.3>
	24.2 <URL:#tn=	24.2>
25. references <URL:#tn=25. references>
	25.1 C++ QUICK REFERENCE <URL:#tn=	25.1 C++ QUICK REFERENCE>
		25.1.1 PREPROCESSOR <URL:#tn=		25.1.1 PREPROCESSOR>
		25.1.2 LITERALS <URL:#tn=		25.1.2 LITERALS>
		25.1.3 DECLARATIONS <URL:#tn=		25.1.3 DECLARATIONS>
		25.1.4 STORAGE CLASSES <URL:#tn=		25.1.4 STORAGE CLASSES>
		25.1.5 STATEMENTS <URL:#tn=		25.1.5 STATEMENTS>
		25.1.6 FUNCTIONS <URL:#tn=		25.1.6 FUNCTIONS>
		25.1.7 EXPRESSIONS <URL:#tn=		25.1.7 EXPRESSIONS>
		25.1.8 CLASSES <URL:#tn=		25.1.8 CLASSES>
		25.1.9 TEMPLATES <URL:#tn=		25.1.9 TEMPLATES>
		25.1.10 NAMESPACES <URL:#tn=		25.1.10 NAMESPACES>
		25.1.11 C/C++ STANDARD LIBRARY <URL:#tn=		25.1.11 C/C++ STANDARD LIBRARY>
		25.1.12 STDIO.H, CSTDIO (Input/output) <URL:#tn=		25.1.12 STDIO.H, CSTDIO (Input/output)>
		25.1.13 STDLIB.H, CSTDLIB (Misc. functions) <URL:#tn=		25.1.13 STDLIB.H, CSTDLIB (Misc. functions)>
		25.1.14 STRING.H, CSTRING (Character array handling functions) <URL:#tn=		25.1.14 STRING.H, CSTRING (Character array handling functions)>
		25.1.15 CTYPE.H, CCTYPE (Character types) <URL:#tn=		25.1.15 CTYPE.H, CCTYPE (Character types)>
		25.1.16 MATH.H, CMATH (Floating point math) <URL:#tn=		25.1.16 MATH.H, CMATH (Floating point math)>
		25.1.17 TIME.H, CTIME (Clock) <URL:#tn=		25.1.17 TIME.H, CTIME (Clock)>
		25.1.18 ASSERT.H, CASSERT (Debugging aid) <URL:#tn=		25.1.18 ASSERT.H, CASSERT (Debugging aid)>
		25.1.19 NEW.H, NEW (Out of memory handler) <URL:#tn=		25.1.19 NEW.H, NEW (Out of memory handler)>
		25.1.20 IOSTREAM.H, IOSTREAM (Replaces stdio.h) <URL:#tn=		25.1.20 IOSTREAM.H, IOSTREAM (Replaces stdio.h)>
		25.1.21 FSTREAM.H, FSTREAM (File I/O works like cin, cout as above) <URL:#tn=		25.1.21 FSTREAM.H, FSTREAM (File I/O works like cin, cout as above)>
		25.1.22 IOMANIP.H, IOMANIP (Output formatting) <URL:#tn=		25.1.22 IOMANIP.H, IOMANIP (Output formatting)>
		25.1.23 STRING (Variable sized character array) <URL:#tn=		25.1.23 STRING (Variable sized character array)>
		25.1.24 VECTOR (Variable sized array/stack with built in memory allocation) <URL:#tn=		25.1.24 VECTOR (Variable sized array/stack with built in memory allocation)>
		25.1.25 DEQUE (array/stack/queue) <URL:#tn=		25.1.25 DEQUE (array/stack/queue)>
		25.1.26 UTILITY (Pair) <URL:#tn=		25.1.26 UTILITY (Pair)>
		25.1.27 MAP (associative array) <URL:#tn=		25.1.27 MAP (associative array)>
		25.1.28 ALGORITHM (A collection of 60 algorithms on sequences with iterators) <URL:#tn=		25.1.28 ALGORITHM (A collection of 60 algorithms on sequences with iterators)>
	25.2 <URL:#tn=	25.2>
26. Make <URL:#tn=26. Make>
	26.1  Tutorials <URL:#tn=	26.1  Tutorials>
	26.2 Troubleshooting <URL:#tn=	26.2 Troubleshooting>
		26.2.1 gcc makefile error: “No rule to make target …” <URL:#tn=		26.2.1 gcc makefile error: “No rule to make target …”>
			26.2.1.1  Problem <URL:#tn=			26.2.1.1  Problem>
			26.2.1.2 Solutions <URL:#tn=			26.2.1.2 Solutions>
			26.2.1.3 <URL:#tn=			26.2.1.3>
		26.2.2 <URL:#tn=		26.2.2>
	26.3 Sergey's example <URL:#tn=	26.3 Sergey's example>
		26.3.1 c:\work\code\CPP\make\example\Makefile <URL:#tn=		26.3.1 c:\work\code\CPP\make\example\Makefile>
		26.3.2 c:\work\code\CPP\make\example\make-settings.gmk <URL:#tn=		26.3.2 c:\work\code\CPP\make\example\make-settings.gmk>
		26.3.3 dynamic/Makefile <URL:#tn=		26.3.3 dynamic/Makefile>
		26.3.4 main/Makefile <URL:#tn=		26.3.4 main/Makefile>
		26.3.5 static/Makefile <URL:#tn=		26.3.5 static/Makefile>
		26.3.6 <URL:#tn=		26.3.6>
	26.4 <URL:#tn=	26.4>
27. Concurrency <URL:#tn=27. Concurrency>
	27.1 Theory <URL:#tn=	27.1 Theory>
		27.1.1 Mutex <URL:#tn=		27.1.1 Mutex>
			27.1.1.1 How does a mutex work? What does it cost? <URL:#tn=			27.1.1.1 How does a mutex work? What does it cost?>
			27.1.1.2 <URL:#tn=			27.1.1.2>
		27.1.2 <URL:#tn=		27.1.2>
	27.2 <URL:#tn=	27.2>
28. Cisco related <URL:#tn=28. Cisco related>
	28.1 COSI <URL:#tn=	28.1 COSI>
		28.1.1 Overview of the Software Development Process <URL:#tn=		28.1.1 Overview of the Software Development Process>
			28.1.1.1 Types of Programming Languages <URL:#tn=			28.1.1.1 Types of Programming Languages>
			28.1.1.2 Compiling <URL:#tn=			28.1.1.2 Compiling>
			28.1.1.3 Linking <URL:#tn=			28.1.1.3 Linking>
			28.1.1.4 Distributing <URL:#tn=			28.1.1.4 Distributing>
		28.1.2 Including Files in Source Code <URL:#tn=		28.1.2 Including Files in Source Code>
			28.1.2.1 Sourcing Files <URL:#tn=			28.1.2.1 Sourcing Files>
			28.1.2.2 Language Constructs for Sourcing <URL:#tn=			28.1.2.2 Language Constructs for Sourcing>
			28.1.2.3 <URL:#tn=			28.1.2.3>
		28.1.3 Static and Dynamic Linking <URL:#tn=		28.1.3 Static and Dynamic Linking>
			28.1.3.1 Static Linking <URL:#tn=			28.1.3.1 Static Linking>
				28.1.3.1.1 Dynamic Linking <URL:#tn=				28.1.3.1.1 Dynamic Linking>
		28.1.4 Java Architecture and Technologies <URL:#tn=		28.1.4 Java Architecture and Technologies>
			28.1.4.1 Object-Oriented Terminology <URL:#tn=			28.1.4.1 Object-Oriented Terminology>
			28.1.4.2 Java Language <URL:#tn=			28.1.4.2 Java Language>
			28.1.4.3 Java Build Process <URL:#tn=			28.1.4.3 Java Build Process>
			28.1.4.4 Class Loaders and Address Space Models <URL:#tn=			28.1.4.4 Class Loaders and Address Space Models>
		28.1.5 	Linux Kernel and KLMs <URL:#tn=		28.1.5 	Linux Kernel and KLMs>
			28.1.5.1 	Linking Models for Extending the Kernel <URL:#tn=			28.1.5.1 	Linking Models for Extending the Kernel>
			28.1.5.2 Kernel Address Space and KLMs <URL:#tn=			28.1.5.2 Kernel Address Space and KLMs>
		28.1.6 <URL:#tn=		28.1.6>
	28.2 Using GPL V.2/LGPL V.2.1 Open Source Licenses <URL:#tn=	28.2 Using GPL V.2/LGPL V.2.1 Open Source Licenses>
		28.2.1 GPLv2 Overview <URL:#tn=		28.2.1 GPLv2 Overview>
		28.2.2 LGPLv2.1 Overview <URL:#tn=		28.2.2 LGPLv2.1 Overview>
		28.2.3 Understanding Cisco's GPL and LGPL Policies <URL:#tn=		28.2.3 Understanding Cisco's GPL and LGPL Policies>
		28.2.4 Cisco's Policies on GPL and LGPL: Avoid the "Red Flag" <URL:#tn=		28.2.4 Cisco's Policies on GPL and LGPL: Avoid the "Red Flag">
		28.2.5 GPL Red Flags <URL:#tn=		28.2.5 GPL Red Flags>
			28.2.5.1 Making Modifications to GPL Source Code <URL:#tn=			28.2.5.1 Making Modifications to GPL Source Code>
			28.2.5.2 Embedding GPL Code into Cisco Code or Vice Versa <URL:#tn=			28.2.5.2 Embedding GPL Code into Cisco Code or Vice Versa>
			28.2.5.3 Static & Dynamic Linking <URL:#tn=			28.2.5.3 Static & Dynamic Linking>
			28.2.5.4 Intimate Knowledge <URL:#tn=			28.2.5.4 Intimate Knowledge>
			28.2.5.5 Additional Examples <URL:#tn=			28.2.5.5 Additional Examples>
		28.2.6 LGPL Red Flags <URL:#tn=		28.2.6 LGPL Red Flags>
			28.2.6.1. Making Modifications to LGPL Source Code <URL:#tn=			28.2.6.1. Making Modifications to LGPL Source Code>
    			28.2.6.2. Embedding LGPL Code into Cisco Code or Vice Versa <URL:#tn=    			28.2.6.2. Embedding LGPL Code into Cisco Code or Vice Versa>
    			28.2.6.3. Static Linking <URL:#tn=    			28.2.6.3. Static Linking>
 		28.2.7.  Special Cases <URL:#tn= 		28.2.7.  Special Cases>
	28.3 <URL:#tn=	28.3>
29. g++ <URL:#tn=29. g++>
	29.1  manual <URL:#tn=	29.1  manual>
1. <URL:#tn=1.>
2. <URL:#tn=2.>
3. <URL:#tn=3.>
0.12 0.01 cc1 <options> <URL:#tn=0.12 0.01 cc1 <options>>
0.00 0.01 as <options> <URL:#tn=0.00 0.01 as <options>>
1. <URL:#tn=1.>
2. <URL:#tn=2.>
3. <URL:#tn=3.>
1. <URL:#tn=1.>
2. <URL:#tn=2.>
3. <URL:#tn=3.>
1. <URL:#tn=1.>
	29.2 <URL:#tn=	29.2>
30. IDE <URL:#tn=30. IDE>
	30.1 Eclipse CDT <URL:#tn=	30.1 Eclipse CDT>
		30.1.1  Troubleshoot <URL:#tn=		30.1.1  Troubleshoot>
			30.1.1.1  Eclipse says: “Workspace in use or cannot be created, chose a different one.” How do I unlock a workspace? <URL:#tn=			30.1.1.1  Eclipse says: “Workspace in use or cannot be created, chose a different one.” How do I unlock a workspace?>
			30.1.1.2 <URL:#tn=			30.1.1.2>
		30.1.2 <URL:#tn=		30.1.2>
	30.2 <URL:#tn=	30.2>
31. Idioms <URL:#tn=31. Idioms>
	31.1 Iteration <URL:#tn=	31.1 Iteration>
		31.1.1 std vector <URL:#tn=		31.1.1 std vector>
		31.1.2 <URL:#tn=		31.1.2>
	31.2 <URL:#tn=	31.2>
32. functors <URL:#tn=32. functors>
	32.1 http://stackoverflow.com/questions/356950/c-functors-and-their-uses <URL:#tn=	32.1 http://stackoverflow.com/questions/356950/c-functors-and-their-uses>
	32.2 <URL:#tn=	32.2>
33. C11 <URL:#tn=33. C11>
	33.1 Top differences vs C99 <URL:#tn=	33.1 Top differences vs C99>
		33.1.1 auto <URL:#tn=		33.1.1 auto>
		33.1.2 nullptr <URL:#tn=		33.1.2 nullptr>
		33.1.3 Range-based for loops <URL:#tn=		33.1.3 Range-based for loops>
		33.1.4 Override and final <URL:#tn=		33.1.4 Override and final>
		33.1.5 Strongly-typed enums <URL:#tn=		33.1.5 Strongly-typed enums>
		33.1.6 Smart pointers <URL:#tn=		33.1.6 Smart pointers>
		33.1.7 Lambdas <URL:#tn=		33.1.7 Lambdas>
		33.1.8 non-member begin() and end() <URL:#tn=		33.1.8 non-member begin() and end()>
		33.1.9 static_assert and type traits <URL:#tn=		33.1.9 static_assert and type traits>
		33.1.10 Move semantics <URL:#tn=		33.1.10 Move semantics>
		33.1.11 <URL:#tn=		33.1.11>
	33.2 <URL:#tn=	33.2>
34. Boost <URL:#tn=34. Boost>
	34.1 lexical_cast , convert number to string (like itoa in C) <URL:#tn=	34.1 lexical_cast , convert number to string (like itoa in C)>
		34.1.1 My example <URL:#tn=		34.1.1 My example>
	34.2 <URL:#tn=	34.2>
35. C++11, C++14 <URL:#tn=35. C++11, C++14>
	35.1 FAQ <URL:#tn=	35.1 FAQ>
		35.1.1 What does T&& (double ampersand) mean in C++11? <URL:#tn=		35.1.1 What does T&& (double ampersand) mean in C++11?>
			35.1.1.1  stackoverflow answer <URL:#tn=			35.1.1.1  stackoverflow answer>
			35.1.1.2 My answer <URL:#tn=			35.1.1.2 My answer>
			35.1.1.3 <URL:#tn=			35.1.1.3>
		35.1.2  books <URL:#tn=		35.1.2  books>
			35.1.2.1  Effective modern c++ <URL:#tn=			35.1.2.1  Effective modern c++>
				35.1.2.1.1   auto <URL:#tn=				35.1.2.1.1   auto>
				35.1.2.1.2    Distinguish between () and {} when creating objects. <URL:#tn=				35.1.2.1.2    Distinguish between () and {} when creating objects.>
				35.1.2.1.3   Prefer nullptr to 0 and NULL. <URL:#tn=				35.1.2.1.3   Prefer nullptr to 0 and NULL.>
				35.1.2.1.4 <URL:#tn=				35.1.2.1.4>
				35.1.2.1.5   Prefer deleted functions to private undefined ones. <URL:#tn=				35.1.2.1.5   Prefer deleted functions to private undefined ones.>
				35.1.2.1.6   Declare overriding functions override. <URL:#tn=				35.1.2.1.6   Declare overriding functions override.>
				35.1.2.1.7   Prefer const_iterators to iterators. <URL:#tn=				35.1.2.1.7   Prefer const_iterators to iterators.>
				35.1.2.1.8    Declare functions noexcept if they won’t emit exceptions. <URL:#tn=				35.1.2.1.8    Declare functions noexcept if they won’t emit exceptions.>
				35.1.2.1.9   Use constexpr whenever possible. <URL:#tn=				35.1.2.1.9   Use constexpr whenever possible.>
				35.1.2.1.10  Make const member functions thread safe. <URL:#tn=				35.1.2.1.10  Make const member functions thread safe.>
				35.1.2.1.11  Understand special member function generation. <URL:#tn=				35.1.2.1.11  Understand special member function generation.>
				35.1.2.1.12  Smart Pointers <URL:#tn=				35.1.2.1.12  Smart Pointers>
					35.1.2.1.12.1  Use std::unique_ptr for exclusive-ownership resource management. <URL:#tn=					35.1.2.1.12.1  Use std::unique_ptr for exclusive-ownership resource management.>
					35.1.2.1.12.2  Use std::shared_ptr for shared-ownership resource management. <URL:#tn=					35.1.2.1.12.2  Use std::shared_ptr for shared-ownership resource management.>
				35.1.2.1.13  Use std::weak_ptr for std::shared_ptr-like pointers that can dangle. <URL:#tn=				35.1.2.1.13  Use std::weak_ptr for std::shared_ptr-like pointers that can dangle.>
				35.1.2.1.14  Prefer std::make_unique and std::make_shared to direct use of new. <URL:#tn=				35.1.2.1.14  Prefer std::make_unique and std::make_shared to direct use of new.>
				35.1.2.1.15  When using the Pimpl Idiom, define special member functions in the implementation file. <URL:#tn=				35.1.2.1.15  When using the Pimpl Idiom, define special member functions in the implementation file.>
				35.1.2.1.16  Rvalue References, Move Semantics, and Perfect Forwarding <URL:#tn=				35.1.2.1.16  Rvalue References, Move Semantics, and Perfect Forwarding>
					35.1.2.1.16.1  Understand std::move and std::forward. <URL:#tn=					35.1.2.1.16.1  Understand std::move and std::forward.>
					35.1.2.1.16.2 <URL:#tn=					35.1.2.1.16.2>
					35.1.2.1.16.3 <URL:#tn=					35.1.2.1.16.3>
					35.1.2.1.16.4 <URL:#tn=					35.1.2.1.16.4>
					35.1.2.1.16.5 <URL:#tn=					35.1.2.1.16.5>
					35.1.2.1.16.6 <URL:#tn=					35.1.2.1.16.6>
					35.1.2.1.16.7 <URL:#tn=					35.1.2.1.16.7>
				35.1.2.1.17 <URL:#tn=				35.1.2.1.17>
				35.1.2.1.18 <URL:#tn=				35.1.2.1.18>
				35.1.2.1.19 <URL:#tn=				35.1.2.1.19>
				35.1.2.1.20 <URL:#tn=				35.1.2.1.20>
				35.1.2.1.21 <URL:#tn=				35.1.2.1.21>
				35.1.2.1.22 <URL:#tn=				35.1.2.1.22>
				35.1.2.1.23 <URL:#tn=				35.1.2.1.23>
				35.1.2.1.24 <URL:#tn=				35.1.2.1.24>
				35.1.2.1.25 <URL:#tn=				35.1.2.1.25>
				35.1.2.1.26 <URL:#tn=				35.1.2.1.26>
				35.1.2.1.27 <URL:#tn=				35.1.2.1.27>
				35.1.2.1.28 <URL:#tn=				35.1.2.1.28>
				35.1.2.1.29 <URL:#tn=				35.1.2.1.29>
				35.1.2.1.30 <URL:#tn=				35.1.2.1.30>
				35.1.2.1.31 <URL:#tn=				35.1.2.1.31>
			35.1.2.2 <URL:#tn=			35.1.2.2>
		35.1.3 <URL:#tn=		35.1.3>
	35.2 <URL:#tn=	35.2>
36. Youtube course https://www.youtube.com/watch?v=8jLOx1hD3_o&t=25s , c++ with visual Studio code <URL:#tn=36. Youtube course https://www.youtube.com/watch?v=8jLOx1hD3_o&t=25s , c++ with visual Studio code>
    36.1 getting started <URL:#tn=    36.1 getting started>
    36.2 C++ basics <URL:#tn=    36.2 C++ basics>
        36.2.1 iostream and main <URL:#tn=        36.2.1 iostream and main>
        36.2.2 comments <URL:#tn=        36.2.2 comments>
        36.2.3 Errors and warnings <URL:#tn=        36.2.3 Errors and warnings>
            36.2.3.1 Compilation time errors <URL:#tn=            36.2.3.1 Compilation time errors>
            36.2.3.2 runtime errors <URL:#tn=            36.2.3.2 runtime errors>
            36.2.3.3 warnings <URL:#tn=            36.2.3.3 warnings>
            36.2.3.4 <URL:#tn=            36.2.3.4>
        36.2.4 statements and functions <URL:#tn=        36.2.4 statements and functions>
        36.2.5 IO <URL:#tn=        36.2.5 IO>
        36.2.6 execution and memory model <URL:#tn=        36.2.6 execution and memory model>
        36.2.7 core language vs Standard library vs STL <URL:#tn=        36.2.7 core language vs Standard library vs STL>
        36.2.8 Variable types <URL:#tn=        36.2.8 Variable types>
        36.2.9 <URL:#tn=        36.2.9>
    36.3 <URL:#tn=    36.3>
    36.3 <URL:#tn=    36.3>
37. <URL:#tn=37.>
.................................................END TOC..............................................



























































Description: 	C++, CPP, Knwoledge. Mainly bits and pieces since I'm working with it for 10 years now so its burned to my cortex :)
Author:		Yosi Izaq.

1. Beautifiers.

	For 100[percnt] assurance you need a SCIENTIFIC way to validate and trust a beautifier program. The method described in this section will enable the beautifier program to be accepted as "trust-worthy" and reliable.

	In order to verify that beautifier programs like bcpp , indent or cb is not damaging or changing the input source-code after formatting, you can use one of the following technique -
	1.1. Method 1: Verfication Program for C++/C

		bash$ man diff
		bash$ diff -b --ignore-all-space originalfile formattedfile
		

	1.2. Method 2: Verfication Program for C++/C

	Generate the object code from the original input source code using the compiler -

		  g++ -c myprogram.cpp
		

	Here g++ is GNU C++ compiler. This will create object output myprogram.o

	Save this file -

		   mv myprogram.o myprogram_orig.o
		

	Now run bcpp -

		   bcpp myprogram.cpp
		

	This will create the formatted output program file myprogram.cpp and move the original file to myprogram.cpp.orig. Compile the new file with -

		   g++ -c myprogram.cpp
		

	Now use the unix 'diff' command to compare the two object files -

		   diff myprogram.o myprogram_orig.o
		

	Both these files MUST BE IDENTICAL . This verifies that bcpp is working perfectly. On DOS or Windows 95 you may want to use the free Cygnus Cygwin 'diff' or 'MKS' utilities.

	If for some reason you are not able to diff the object files then you MUST use the assembly output as described below.

	You can use the assembler output instead of object output from the C++ compiler for doing the comparison. Like -

		    g++ -S myprogram.cpp
		

	This creates myprogram.s. Verify with -

		    diff myprogram.s myprogram_orig.s
		

	This step gives 100[percnt] guarantee that your valuable source code is intact and bcpp is JUST doing ONLY formatting and is NOT changing or damaging your code in any way. This method gives you 100[percnt] quality assurance and life term or long term WARRANTY on beautifier programs like 'bcpp', 'cb' or 'indent'.

	It is strongly recommended that you do these two steps every time you run beautifier programs like bcpp , indent or cb .
	1.3. Method 3: Verfication Program for Java/C++/Others

	Since you cannot compile the Java source code to machine code and you can compile Java source to byte-codes you cannot use the technique given in Method 2 above. When you do diff on Java class files it will always be different.

	In this method, a different technique will be given which can be used to validate any beautifier program for Java. Also this method is quite powerful and can be used to validate any beautifier program for any language like C, C++, PERL, SQL, HTML or Java. Since all beautifier program simply rearrange or insert whitespaces , you can strip all the whitespaces from original source file and dump it to a file called verify1.out and strip all the whitespaces from beautified source file and dump it to a file called verify2.out. Now, do a diff on verify1.out and verify2.out. If there is no difference, then beautifier program is working properly. The method is not 100[percnt] perfect and can catch atleast 98[percnt] of the errors/bugs in the beautifier program. Use this method in conjunction with other methods. But this method is better than not having a verification at all and blindly trusting the beautifier program!!

	Note: A whitespace can be one of following - blank space ' ', form-feed '\f', newline '\n', carriage return '\r', horizontal tab '\t' or vertical tab '\v'.

		bash$ java StripWhitespaces  sample.java > verify1.out
		bash$ java StripWhitespaces  sample_beutified.java > verify2.out
		bash$ diff verify1.out verify2.out
		bash$ java StripWhitespaces  sample.cpp > verify1.out
		bash$ java StripWhitespaces  sample_beutified.cpp > verify2.out
		bash$ diff verify1.out verify2.out
		bash$ java StripWhitespaces  sample.sql > verify1.out
		bash$ java StripWhitespaces  sample_beutified.sql > verify2.out
		bash$ diff verify1.out verify2.out
		

	The source code of StripWhitespaces Java program is not given here. It is left as an exercise for students (you) to write a small program in Java which will simply strip whitespaces from the input text file and output to standard console output. Students are also urged to write this small program (StripWhitespaces) in C, PERL, Unix shell script (Korn, Bourne) and AWK script. Students can see howto the same task can be accomplished in these five different languages and can do comparison of ease of programing. You should put a newline '\n' character after every 50 characters while generating verify1.out and verify2.out so that when you do a diff you can see on which lines differences are coming up. Otherwise, verify*.out files will just contain one line and it will be difficult to pin-point where exactly the beautifier program is failing (got this point ???).
	1.4. Method 4: Shell script: Verfication Program for C++/C

	This is a Korn shell script to verify beautifier program. Requires "pdksh*.rpm" from Linux 'contrib' cdrom. Save this file as 'text' file and chmod a+rx on it. You can re-write this shell script in PERL so that you can use it on Window 95/NT or MSDOS. Uncomment the PRGM variable to point to bcpp , cb or indent

		#!/bin/ksh
		# Verification program to check C++ Beautifiers 'bcpp', 'indent' or cb
		############################################################
		# Copyright 
		# The copyright policy is GNU/GPL.
		# Author: Al Dev (Alavoor Vasudevan) alavoor[AT]yahoo.com
		############################################################
		check_beautify_now()
		{
			# Remove all the temp files....
			\rm -f ${TMP_FILE}
			\rm -f ${TMP_CPPFILE}*.*
			FNAME=$1
			if [ ! -f ${FNAME} ]; then
				print "\nError: The file ${FNAME} does not exist!!. Aborting now ...."
				exit
			fi
			\cp  -f ${FNAME} ${TMP_CPPFILE}.cpp
			${COMPILER} -c ${TMP_CPPFILE}.cpp
			if [ ! -f ${TMP_CPPFILE}.o ]; then
				print "Fatal Error: Failed to compile ${FNAME}. Aborting now... "
				exit
			fi
			\mv -f ${TMP_CPPFILE}.o ${TMP_CPPFILE}_orig.o
			aa=`basename $PRGM`
			print "\nRunning, verifying $aa on ${FNAME}"
			${PRGM} ${TMP_CPPFILE}.cpp
			${COMPILER} -c ${TMP_CPPFILE}.cpp
			\rm -f $TMP_FILE
			diff ${TMP_CPPFILE}.o ${TMP_CPPFILE}_orig.o 1> $TMP_FILE 2>> $TMP_FILE
			result=""
			result=`wc -c $TMP_FILE | awk '{print $1}' `
			if [ "$result" = "0" ]; then
				print "Success!! Beautifier $aa is working properly!!\n"
			else
				print "Fatal Error: Something wrong!! Beautifier is not working!!"
				exit
			fi
		#	${COMPILER} -S ${TMP_CPPFILE}.cpp
		#	diff ${TMP_CPPFILE}.s ${TMP_CPPFILE}_orig.s
			# Remove all the temp files....
			\rm -f ${TMP_FILE}
			\rm -f ${TMP_CPPFILE}*.*
		}
		########## Main of program begins here ##################3
		#PRGM=/usr/bin/bcpp
		#PRGM=/usr/bin/cb
		PRGM=/usr/bin/indent
		COMPILER=/usr/bin/g++
		TMP_FILE=beautify.tmp
		TMP_CPPFILE=beautify-tmp_cppfile
		print -n "Enter the C++ file name <default is *.cpp> : "
		read ans
		if [ "$ans" = "" -o "$ans" = " " ]; then
			ans="ALL"
		else
			FILENAME=$ans
		fi
		# Remove all the temp files....
		\rm -f ${TMP_FILE}
		\rm -f ${TMP_CPPFILE}*.*
		if [ "$ans" != "ALL" ]; then
			check_beautify_now ${FILENAME}
		else
			ls *.cpp |
			while read FILENAME 
			do
				check_beautify_now ${FILENAME}
			done
		fi

2. Debug

	2.1 Generate core dumps
If you want to debug why your C/C++ application segfaults once in a while (daemon that segfaults once in few days) under Linux the obvious way is to tell your program to create core dump files on segfault. It took me few hours to make my program coredump - by default under Linux setuid programs do not dump core. To force a program to do so, you should execute this after setuid:
prctl(PR_SET_DUMPABLE, 1);
and include:
#include <sys/prctl.h>
Of course you should also enable core dump with setrlimit:
setrlimit(RLIMIT_CORE, &limit);
To tune where your core dumps are stored, search google for core_pattern or /proc/sys/kernel/core_pattern, I donÂ¿t feel like copy-pasting.
Hope this helps somebody.

	2.2 gdb

		2.2.1 catch exceptions in debugger instead of in code
			do 
			> catch throw

		2.2.2 My examples

			2.2.2.1 Debug optimised executables

- Check CPU, then google for it, ex: "procedure calling convention Intel Xeon CPU"
Check manual for which registers contain what values 
ex, rdi, rsi, rdx, rsx hold 1st-4th arguments

- Check registers 
(gdb) info registers 
rax            0x0      0
rbx            0x7fff7c207d18   140735275891992
rcx            0xadf1a30        182393392
rdx            0x1      1
rsi            0xadf1b40        182393664
rdi            0xade1288        182325896
rbp            0x0      0x0
rsp            0x7fff7c207c98   0x7fff7c207c98
r8             0xadf1a40        182393408
r9             0x3      3
r10            0x0      0
r11            0x2b8e84936830   47891109603376
r12            0x0      0
r13            0x2b8e84e13d40   47891114704192
r14            0xade1700        182327040
r15            0xadf1740        182392640
rip            0x2b8e84936830   0x2b8e84936830 <LWNetDnsGetAddressesForDnsQueryList>
eflags         0x202    [ IF ]
cs             0x33     51
ss             0x2b     43
ds             0x0      0
es             0x0      0
fs             0x0      0
gs             0x0      0
fctrl          0x37f    895
fstat          0x0      0
ftag           0xffff   65535
fiseg          0x0      0
fioff          0x0      0
foseg          0x0      0
fooff          0x0      0
fop            0x0      0
mxcsr          0x1f80   [ IM DM ZM OM UM PM ]
(gdb)  p ((PLW_DLINKED_LIST)  0xade1288)->pNext

		2.2.3 how to generate gcc debug symbol outside the build target

			2.2.3.1 http://stackoverflow.com/questions/866721/how-to-generate-gcc-debug-symbol-outside-the-build-target
 Q: know I can generate debug symbol using -g option. However the symbol is embeded in the target file. Could gcc generate debug symbol outside the result executable/library? Like .pdb file of windows VC++ compiler did.

 A: You need to use objcopy to separate the debug information:

objcopy --only-keep-debug "${tostripfile}" "${debugdir}/${debugfile}"
strip --strip-debug --strip-unneeded "${tostripfile}"
objcopy --add-gnu-debuglink="${debugdir}/${debugfile}" "${tostripfile}"
I use the bash script below to separate the debug information into files with a .debug extension in a .debug directory. This way I can tar the libraries and executables in one tar file and the .debug directories in another. If I want to add the debug info later on I simply extract the debug tar file and voila I have symbolic debug information.

This is the bash script:

#!/bin/bash

scriptdir=`dirname ${0}`
scriptdir=`(cd ${scriptdir}; pwd)`
scriptname=`basename ${0}`

set -e

function errorexit()
{
  errorcode=${1}
  shift
  echo $@
  exit ${errorcode}
}

function usage()
{
  echo "USAGE ${scriptname} <tostrip>"
}

tostripdir=`dirname "$1"`
tostripfile=`basename "$1"`


if [ -z ${tostripfile} ] ; then
  usage
  errorexit 0 "tostrip must be specified"
fi

cd "${tostripdir}"

debugdir=.debug
debugfile="${tostripfile}.debug"

if [ ! -d "${debugdir}" ] ; then
  echo "creating dir ${tostripdir}/${debugdir}"
  mkdir -p "${debugdir}"
fi
echo "stripping ${tostripfile}, putting debug info into ${debugfile}"
objcopy --only-keep-debug "${tostripfile}" "${debugdir}/${debugfile}"
strip --strip-debug --strip-unneeded "${tostripfile}"
objcopy --add-gnu-debuglink="${debugdir}/${debugfile}" "${tostripfile}"
chmod -x "${debugdir}/${debugfile}"

Just add the .debug directory with the .debug files to your production box and GDB should pick them up. After the debug session you can remove them again.

A: Compile with debug information:

gcc -g -o main main.c
Separate the debug information:

objcopy --only-keep-debug main main.debug
or

cp main main.debug
strip --only-keep-debug main.debug
Strip debug information from origin file:

objcopy --strip-debug main
or

strip --strip-debug --strip-unneeded main
debug by debuglink mode:

objcopy --add-gnu-debuglink main.debug main
gdb main
You can also use exec file and symbol file separatly:

gdb -s main.debug -e main
or

gdb
(gdb) exec-file main
(gdb) symbol-file main.debug
For details:

(gdb) help exec-file
(gdb) help symbol-file
Ref:
https://sourceware.org/gdb/onlinedocs/gdb/Files.html#Files https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html

			2.2.3.2

		2.2.4
3. Printing, IO, write, read

	3.1 printf quick ref

  %[flags][min field width][precision][length]conversion specifier
  -----  ---------------  ---------  ------ -------------------
   \             #          .#         /             \
    \                                 /               \
   #,0,-,+, ,',I                 hh,h,l,ll,j,z,L    c,d,u,x,X,e,f,g,s,p,%
   -------------                 ---------------    -----------------------
   # | Alternate,                 hh | char,           c | unsigned char,
   0 | zero pad,                   h | short,          d | signed int,
   - | left align,                 l | long,           u | unsigned int,
   + | explicit + - sign,         ll | long long,      x | unsigned hex int,
     | space for + sign,           j | [u]intmax_t,    X | unsigned HEX int,
   ' | locale thousands grouping,  z | size_t,         e | [-]d.dddeÂ±dd double,
   I | Use locale's alt digits     t | ptrdiff_t,      E | [-]d.dddEÂ±dd double,
                                   L | long double,  ---------=====
   if no precision   => 6 decimal places            /  f | [-]d.ddd double,
   if precision = 0  => 0 decimal places      _____/   g | e|f as appropriate,
   if precision = #  => # decimal places               G | E|F as appropriate,
   if flag = #       => always show decimal point      s | string,
                                             ..............------
                                            /          p | pointer,
   if precision      => max field width    /           % | %

   Examples of common combinations:
format	output
printf("%08X",32_bit_var);	ABCD1234
printf("%lu",32_bit_var);	2882343476
printf("%'d",32_bit_var);	-1,412,623,820
printf("%10s","string");	string
printf("%-10s","string");	string
printf("%-10.10s","truncateiftoolong");	truncateif

Note for the %'d one to work you must have already set your locale as in the following example:

#include <locale.h>
#include <stdio.h>

int main(void)
{
    setlocale(LC_ALL,"");
    printf("%'Id\n",1234);
}

$ ./numtest
1,234

$ LANG=fa_IR.utf8 ./numtest

Note also if one is using the C99 integer types that guarantee a specific number of bits,
then you must use the corresponding conversion specifier for portability.
This can be seen in the use of PRIu32 in the example below:

#include <inttypes.h>
#include <stdio.h>

int main(void)
{
    uint32_t ui=1234;
    printf("%"PRIu32"\n",ui);
}


		3.1.1  print size_t

%zu

ex:
printf("Length: %d \n", (unsigned int)MyStrlen(str));
is ok; %d expects an int argument, but it's guaranteed that int and unsigned int have the same representation for values that are in the range of both. This:

printf("Length: %u\n", (unsigned int)MyStrlen(str));
is better, since %u expects an unsigned int argument.

The correct format for size_t is "%zu":

printf("Length: %zu\n", MyStrlen(str));
but this is a "new" feature in C99, and there are likely still some implementations that don't support it. (In particular, Microsoft has been very slow to support C99.) For maximum portability (assuming your string is less that 232-1 bytes long) you can use this:

printf("Length: %lu\n", (unsigned long)MyStrlen(str));
This answers the question you asked about printf; pb2q ably diagnosed the actual cause of the problem you're seeing (and beat me to it!).

		3.1.2

	3.2 Printing a hex dump of a buffer (or print char * hex buffer)

		3.2.1 Crude solution


void dumpbuff(char *buff, int N)
{
int i;

for(i=0;i<N;i+=16
if(i + 16 <= N)
printline(data+i, 16);
else
printline(data+1, N - i);
}

void printline(char *data, int N)
{
int i;

for(i=0;i<N;i++)
printf("%02x ", data[i]):
printf(" ");
for(i=0;i<N;i++)
if(isgraph((unsigned) data[i]))
printf("%c", data[i]);
else
printf(".");
printf("\n");
}

		3.2.2 Somewhat nicer print
void dump_buffer(unsigned n, const unsigned char* buf)
{
int on_this_line = 0;
while (n-- 0) {
	fprintf(stderr, "%02X ", *buf++);
	on_this_line += 1;
	if (on_this_line == 16 || n == 0) {
		int i;
		fputs(" ", stderr);
		for (i = on_this_line; i < 16; i++)
			fputs(" ", stderr);
		for (i = on_this_line; i 0; i--)
			fputc(isprint(buf[-i]) ? buf[-i] : '.', stderr);
		fputs("\n", stderr);
		on_this_line = 0;
		}
	}
}

4. Standard template library, STL, namespace std

	4.1 string, std::string

		4.1.1 check for equality, compare
		use oprator ==
		or use compare:
		 Syntax:

		  #include <string>
		  int compare( const string& str );
		  int compare( const char* str );
		  int compare( size_type index, size_type length, const string& str );
		  int compare( size_type index, size_type length, const string& str, size_type index2,
		  size_type length2 );
		  int compare( size_type index, size_type length, const char* str, size_type length2 );

		The compare() function either compares str to the current string in a variety of ways, returning
		Return Value 	Case
		less than zero 	this < str
		zero 	this == str
		greater than zero 	this > str

		The various functions either:

		    * compare str to the current string,
		    * compare str to a substring of the current string, starting at index for length characters,
		    * compare a substring of str to a substring of the current string, where index2 and length2 refer to str and index and length refer to the current string,
		    * or compare a substring of str to a substring of the current string, where the substring of str begins at zero and is length2 characters long, and the substring of the current string begins at index and is length characters long.

		For example, the following code uses compare() to compare four strings with eachother:

		 string names[] = {"Homer", "Marge", "3-eyed fish", "inanimate carbon rod"};            

		 for( int i = 0; i < 4; i++ ) {
		   for( int j = 0; j < 4; j++ ) {
		     cout << names[i].compare( names[j] ) << " ";
		   }
		   cout << endl;
		 }              

		Data from the above code was used to generate this table, which shows how the various strings compare to eachother:
							Homer 	Marge 	3-eyed fish 	inanimate carbon rod
		"Homer".compare( x )			0 	-1 	1 	-1
		"Marge".compare( x ) 			1 	0 	1 	-1
		"3-eyed fish".compare( x ) 		-1 	-1 	0 	-1
		"inanimate carbon rod".compare( x ) 	1 	1 	1 	0

		For char * types use strcmp or better, the safer strncmp.
		Syntax:

		  #include <string.h>
		  int strncmp( const char *str1, const char *str2, size_t count );

		The strncmp() function compares at most count characters of str1 and str2. The return value is as follows:
		Return value 	Explanation
		less than 0 	''str1'' is less than ''str2''
		equal to 0 	''str1'' is equal to ''str2''
		greater than 0 	''str1'' is greater than str2''

		If there are less than count characters in either string, then the comparison will stop after the first null termination is encountered.

		"

		4.1.2 STL String Examples
By William R Speirs
First, it is important to know that strings take care of all the memory creation and deletion for you. There is no need to call malloc and you will never forget to call free. Also when you include the header file for STL strings you use the following command: #include <string> notice you don't put the .h in there. You will also need to include the proper namespace: using std::string;
Second, if you have any questions about how to use any part of STL strings the best site to consult is the creators of STL strings: SGI. You can find information on all of STL here. If you have any questions about any of the other C++ libraries, like the IOStreams library, you can consult these 2 sites: MSDN or CPlusPlus.com

Let's take a look at what some routine string manipulation functions looks like with normal C calls and then the same manipulation with STL calls.

First a few common commands to get the size of a string, and to pass a string as a character pointer to some function foo(char *arg).
C Code	C++ with STL Strings

{
	char *str = "Hello"

	printf("LENGTH: %d\n", strlen(str));

	// pass to function foo
	foo(str);
}

	

{
	string str = "Hello";

	cout << "LENGTH: " << str.length() << endl;

	// pass to function foo
	foo(str.c_str());
}


This example is of simply copying one string to another, and showing that equal (=) copies a string in STL; whereas in C you only copy the pointer, not the data. This is an important distinction.
C Code	C++ with STL Strings

{
	// have to do this so we have enough memory allocated
	char str1[12] = {'H', 'e', 'l', 'l', 'o'}; // 12 because strcat adds a null!!!
	char *str2 = str1; // sets only the pointer, doesn't copy data

	// very dangerous, could overflow the buffer if not enough memory
	strcat(str2, " World"); 

	printf("STR1: %s\n", str1);
	printf("STR2: %s\n", str2);
}

	

{
	// don't have to call malloc, memory made for us
	string str1 = "Hello";
	string str2 = str1; // copy the actual data

	// makes the right amount of memory for us
	str2 += " World";

	cout << "STR1: " << str1 << endl;
	cout << "STR2: " << str2 << endl;
}

Output

STR1: Hello World
STR2: Hello World

	

STR1: Hello
STR2: Hello World


This example shows the use of the + operator to concatenate strings together. The output of these two programs is the same; however, the C++ with STL strings is only 4 lines long, and a lot easier to read.
C Code	C++ with STL Strings

{
	char *str1 = "Hello"; 
	char *str2 = "World";
	// + 2 for the space & null
	char *finalStr = (char *)malloc(strlen(str1) + strlen(str2) + 2);

	strcpy(finalStr, str1); // copy on the first word
	strcat(finalStr, " ");  // add a space between the words
	strcat(finalStr, str2); // add on the second word

	printf("FINAL: %s\n", finalStr);

	free(finalStr); // need to free our memory
}

	

{
	string str1 = "Hello";
	string str2 = "World";
	// makes and frees the memory for us
	string finalStr = str1 + " " + str2;

	cout << "FINAL: " << finalStr << endl;
}


This example is almost the same as the one above except now we deal with char * in both of them, and show the use of an anonymous strings, because you are not allowed to use the plus operator (+) on char *s to create a string. So instead anonymous strings are made out of the char *s.
C Code	C++ with STL Strings

int main(int argc, char **argv)
{
	// + 2 for the space & null
	char *finalStr = (char *)malloc(strlen(argv[0]) + strlen(argv[1]) + 2);

	strcpy(finalStr, argv[0]); // copy on the first word
	strcat(finalStr, " ");     // add a space between the words
	strcat(finalStr, argv[1]); // add on the second word

	printf("FINAL: %s\n", finalStr);

	free(finalStr); // need to free our memory
}

	

int main(int argc, char **argv)
{
	// makes and frees the memory for us, using anonymous strings
	string finalStr = string(argv[0]) + " " + string(argv[1]);

	cout << "FINAL: " << finalStr << endl;
}


The strtok function is often used to parse strings. While STL strings do not have that exact function it has find and find_first_of. The only difference is that find searches for a particular string while find_first_of can find any one of a number of strings. Also the find functions do not modify your original string in any way. Since it does not break the string into a token you can take the characters from that point towards the end, or the characters from the beginning to that character... you have full control over this. You do not have that same control with strtok and you need to make a copy of your original string if you want to ever use it again.
C Code	C++ with STL Strings

{
	char str[] = "hello world";
	// modifies str with call to strtok
	char *hello = strtok(str, " ");
	// won't get "world" because it takes off the 'w'
	char *world = strtok(NULL, "wx");
	
	printf("HELLO: %s\n", hello);
	printf("WORLD: %s\n", world);
	printf("STR: %s\n", str);
}

	

{
	string str = "hello world";
	// this won't modify str
	string hello(str.begin(), str.begin() + str.find(" "));
	// search for the first 'w' or 'x'
	string world(str.begin() + str.find_first_of("wx"), str.end());

	cout << "HELLO: " << hello << endl;
	cout << "WORLD: " << world << endl;
	cout << "STR: " << str << endl;
}

Output

HELLO: hello
WORLD: orld
STR: hello

	

HELLO: hello
WORLD: world
STR: hello world


Once you get over the initial learning curve of using STL strings you will find them much easier to use then character pointers and arrays of characters. The code becomes a lot easier to read, and a lot smaller. You will find you make a lot less mistakes, and your code will not have as many, if any, buffer overflows.

NEW!!!
I have gotten a few questions on converting other data types into strings. While the obvious ones like char * are done for you, numbers are not. To solve this problem you can use an ostringstream. This is done by sending the variable to the stream, and then returning the stream as a string. Included below is a function called ToString(const T &arg); that takes an argument of ANY type and converts it into a string if such a conversion is allowed. The function and an example use of it are shown below:

#include < string >
#include < sstream >
#include < iostream >

using std::cout;
using std::endl;
using std::string;
using std::ostringstream;

template < class T >
string ToString(const T &arg)
{
	ostringstream	out;

	out << arg;

	return(out.str());
}

int main(int argc, char **argv)
{
	string integer = ToString(1234);
	string floating_point = ToString(1238.1239);
	string some_string = ToString("Why would you do this?");

	cout << integer << floating_point << some_string << endl;

	string combine_all = integer + floating_point + some_string;

	cout << combine_all << endl;

	return(0);
}


		4.1.3 More string examples
constructors 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    char *line = "short line for testing";
    
    // with no arguments
    string s1;
    s1 = "Anatoliy";
    cout << "s1  is: " << s1 << endl;

    // copy constructor
    string s2 (s1);
    cout << "s2  is: " << s2 << endl;

    // one argumen
    string s3 (line);
    cout << "s3  is: " << s3 << endl;

    // first argumen C string
    // second number of characters
    string s4 (line,10);
    cout << "s4  is: " << s4 << endl;

    // 1 - C++ string
    // 2 - start position
    // 3 - number of characters
    string s5 (s3,6,4); // copy word 'line' from s3
    cout << "s5  is: " << s5 << endl;

    // 1 - number characters
    // 2 - character itself
    string s6 (15,'*');
    cout << "s6  is: " << s6 << endl;

    // 1 - start iterator
    // 2 - end iterator
    string s7 (s3.begin(),s3.end()-5);
    cout << "s7  is: " << s7 << endl;

    // you can instantiate string with assignment
    string s8 = "Anatoliy";
    cout << "s8  is: " << s8 << endl;

    return 0;
}
OUTPUT:
// s1  is: Anatoliy
// s2  is: Anatoliy
// s3  is: short line for testing
// s4  is: short line
// s5  is: line
// s6  is: ***************
// s7  is: short line for te
// s8  is: Anatoliy


getline 1.

/* 1 getline ( intut_stream, str, delim ); Extracts characters from intut_stream and stores them in str until s.max_size() characters have been extracted, the end of file occurs, or delim is encountered, in which case delim is extracted from istr but is not stored in s 2 getline( Iter, str ) Inputs a string value for str as in the preceding funcï¿½ tion with delim = */

#include <iostream>
#include <string>
#include <vector>
#include <fstream>
using namespace std;

int main () 
{
    string str;
    cout << "Enter string (EOL = $) : ";
    getline (cin, str, '$');
    cout << "Str is : " << str << endl;

    ifstream In("data.dat");
    vector v;

    cout << endl << "Read data from file" << endl;
    while ( ! In.eof() )
    {
    	getline (In, str);
    	v.push_back(str);
    }

    copy (v.begin(),v.end(),
    		ostream_iterator(cout,"\n"));
    cout << endl;
    	

    return 0;
}
OUTPUT:
// Enter string (EOL = $) : Str is : first line
// second line$
// 
// Read data from file
// file: "data.dat"
// second line
// last line


 << >> operators 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str;

    cout << "Enter string for testing : ";
    cin  >> str;
    cout << "\nString is : " << str << endl;

    cout << "Enter string for testing "
    	 << "(d to quit) : ";
    while ( cin >> str )
    {
    	cout << endl;
    	cout << "String is : " << str << endl;
    	cout << "Enter string for testing "
             << "(d to quit) : ";
    }

    return 0;
}
OUTPUT:
// Enter string for testing : first
// String is : first
// Enter string for testing (d to quit) : second
// String is : second
// Enter string for testing (d to quit) : third
// String is : third
// Enter string for testing (d to quit) : 


 + += = operators 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Hello";
    cout << "str is : " << str << endl;
    str += ",";
    str += ' ';
    cout << "str is : " << str << endl;

    string s;
    s = str + "World";
    cout << "s is : " << s << endl;

    char ch = '!';
    s += ch;
    cout << "s is : " << s << endl;

    return 0;
}
OUTPUT:
// str is : Hello
// str is : Hello, 
// s is : Hello, World
// s is : Hello, World!


append 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Nobody is perfect";
    string s   = ""; // empty string
    char *ch   = "abcdef";

    // append string str at the end of s; 
    // return s
    
    // appends at the end of s a copy of the n characters
    // in str, starting at position pos; if n is too
    // large, characters are copied only until the end  
    // of str is reached;
    // returns s
    s.append(str,0,6);
    cout << "s is : " << s << endl;

    // appends copies of the characters in the range [inpIt1,
    // inpIt2] to s; returns s
    string::iterator inpIt1 = str.begin()+6;
                    //start from ' is'
    string::iterator inpIt2 = str.end();

    s.append(inpIt1,inpIt2);
    cout << "s is : " << s << endl;

    // appends three !
    s.append(3,'!');
    cout << "s is : " << s << endl;
    
    // appends the first n characters in ch at the end
    // of s; returns s
    s.append(ch,3);
    cout << "s is : " << s << endl;
    
    // appends charArray at the end of s; returns s
    s.append(ch,3);
    cout << "s is : " << s << endl;

    return 0;
}
OUTPUT:
// s is : Nobody
// s is : Nobody is perfect
// s is : Nobody is perfect!!!
// s is : Nobody is perfect!!!abc
// s is : Nobody is perfect!!!abcabc


assign 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Nobody is perfect";
    string s   = "";
    char *ch   = "Robert Frost";

    // assigns a copy of str to s; returns s
    s.assign(str);
    cout << "s is : " << s << endl;

    
    // assigns to s a copy of the n characters in str, startï¿½
    // ing at position 10: if n is too large, characters are
    // copied only until the end of str is reached: returns s
    s.assign(str,10,7); // perfect
    cout << "s is : " << s << endl;

    // assigns to s a string consisting of the first n characï¿½
    // ters in ch: returns s
    s.assign(ch,6);
    cout << "s is : " << s << endl;

    // assigns to s a copy of ch: returns s
    s.assign(ch);
    cout << "s is : " << s << endl;

    // assigns  to s a string consisting of the characters in
    // the range str.begin(), str.end(); returns s
    s.assign(str.begin(),str.end());
    cout << "s is : " << s << endl;

    // assigns to s a string consisting of n copies of ch;
    // returns s
    s.assign(17,'*');
    cout << "s is : " << s << endl;

    return 0;
}
OUTPUT:
// s is : Nobody is perfect
// s is : perfect
// s is : Robert
// s is : Robert Frost
// s is : Nobody is perfect
// s is : *****************


at 1.

// returns s[pos]

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string s = "Nobody is perfect";

    // Returns s[pos]
    for ( int pos = 0; pos < s.length(); ++pos )
    	cout << s.at(pos) << " ";
    cout << endl;

    return 0;
}
OUTPUT:
// N o b o d y   i s   p e r f e c t 


begin 1.

// Returns an iterator positioned at the // first character in a string

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ is best computer language";

    string::iterator It = str.begin();

    while ( It != str.end() )
    {
    	if ( *It == ' ' )
    		*It = '\n';
    	cout << *It++;
    }
    cout << endl;
    
    return 0;
}
OUTPUT:
// C++
// is
// best
// computer
// language


c_str 1.

// returns (the base address of) a char // array containing the characters stored in s, // terminated by a null character.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Anatoliy";
    char *ary = new char[str.length()+1];

    // strcpy ( ary, str ); that is wrong way
    strcpy ( ary, str.c_str() ); // that is correct

    cout << ary << endl;
    
    return 0;
}
OUTPUT:
// Anatoliy


capacity 1.

// returns the size (of type size_type) // of the storage allocated in string

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ is best computer language";

    string::size_type cap;
    cap = str.capacity();

    cout << "Capacity of str is: " << cap << endl;
    cout << "Size of str is    : " << str.size() 
         << endl;
    cout << "Length of str is  : " << str.length() 
         << endl;

    cout << "Resize the str for 50 character" << endl;
    str.resize(50);
    cap = str.capacity();
    
    cout << "Capacity of str is: " << cap << endl;
    cout << "Size of str is    : " << str.size() 
         << endl;
    cout << "Length of str is  : " << str.length() 
         << endl;

    return 0;
}
OUTPUT:
// Capacity of str is: 32
// Size of str is    : 29
// Length of str is  : 29
// Resize the str for 50 character
// Capacity of str is: 64
// Size of str is    : 50
// Length of str is  : 50


compare 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str1 = "string";
    string str2 = "String";
    string str3 = "second string";
    char ch[]   = "first string";

    cout << "string str1 is : " << str1 << endl;
    cout << "string str2 is : " << str2 << endl;
    cout << "char ary ch is : " << ch   << endl;
    cout << "string str3 is : " << str3 << endl;
    cout << endl;

    // compare str1 and str2
    cout << "1." << endl;
    size_t comp = str1.compare(str2);
    cout << "String str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
         << "not equal";
    cout << " to string str2" << endl;

    // compare str1 and literal string "string"
    cout << "2." << endl;
    comp = str1.compare("string");
    cout << "String str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
        << "not equal";
    cout << " to array of char \"string\"" << endl;

    // 3. and 4. doesn't work with Microsoft 
    // Visual Studio compiler
	
    // compare str3 start from pos 7 to 5
    // with str1
    cout << "3." << endl;
    comp = str3.compare(str1,7,5);
    cout << "Part of string str3 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
        << "not equal";
    cout << " to str1" << endl;

    // compare str3 start from pos 7
    // with literal string "string"
    cout << "4." << endl;
    comp = str3.compare("string",7);
    cout << "Part of string str3 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
        << "not equal";
    cout << " to C string \"string\"" << endl;

    // next 4 'compare' functions
    // doesn't work with GNU compiler
	
    cout << "5." << endl;
    comp = str1.compare(6,10,ch);
    cout << "String str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
    << "not equal";
    cout << " to part of char ary \"first string\"" 
    << endl;

    cout << "6." << endl;
    comp = str1.compare(0,3,str3);
    cout << "Part of str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
    << "not equal";
    cout << " to string \"second string\"" 
    << endl;

    cout << "7." << endl;
    comp = str1.compare(1,3,str2,1,3);
    cout << "String str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
    << "not equal";
    cout << " to part of string \"second string\"" 
    << endl;

    cout << "8." << endl;
    comp = str1.compare(1,3,str2,1,3);
    cout << "String str1 is ";
    ( comp == 0 ) ? cout << "equal" : cout 
    << "not equal";
    cout << " to part of string \"second string\"" 
    << endl;

    return 0;
}
OUTPUT: GNU compiler
// string str1 is : string
// string str2 is : String
// char ary ch is : first string
// string str3 is : second string
// 
// 1.
// String str1 is not equal to string str2
// 2.
// String str1 is equal to array of char "string"
// 3.
// Part of string str3 is equal to str1
// 4.
// Part of string str3 is equal to C string "string"
// 5.
// 6.
// 7.
// 8.

OUTPUT: Microsoft Visual Studio compiler
// string str1 is : string
// string str2 is : String
// char ary ch is : first string
// string str3 is : second string
//
// 1.
// String str1 is not equal to string str2
// 2.
// String str1 is equal to array of char "string"
// 3.
// 4.
// 5.
// String str1 is not equal to part of char ary "first
// string"
// 6.
// Part of str1 is not equal to string "second string"
// 7.
// String str1 is equal to part of string "second string"
// 8.
// String str1 is equal to part of string "second string"
// Press any key to continue


copy 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "First Name: Robert";
    char fname[255];
    cout << "str is: " << str << endl;

    int n = str.find(':');

    str.copy(fname, // copy to array
            n+1,    // how many char
            0);     // start position from str
    
    // must terminate fname with '\0';
    fname[n+1] = 0;
    
    cout << "fname is: " << fname << endl;

    return 0;
}
OUTPUT:
// str is: First Name: Robert
// fname is: First Name:


empty 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "*******";

    while ( ! str.empty() )
    {
    	cout << str << endl;
    	str.erase(str.end()-1);
    }
    cout << endl;

    return 0;
}
OUTPUT:
// *******
// ******
// *****
// ****
// ***
// **
// *


end 1.

// returns an iterator porsitioned immediately // after the last character in string

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string s;
    string str = "*************************";
    size_t pos = str.length();

    while ( pos )
    {
    	s.assign ( str.begin(),str.end() - pos+1);
    	cout << s << endl;
    	pos -= 5;
    }

    return 0;
}
OUTPUT:
// *
// ******
// ***********
// ****************
// *********************


erase 1.

#include <iostream>
#include <string>
#include <algorithm>
using namespace std;

int main () 
{
    string str, s;

    for ( char ch = 'a'; ch <= 'z'; ch++ )
        str.append(1,ch);
    s = str;
    cout << "str is: " << str << endl;
    cout << "s   is: " << str << endl;
    
    // removes 13 characters from the beginning
    str.erase(0,13);
    cout << "Erased range fron str : " << str << endl; 
    // removes 13 characters starts from 14
    str = s.erase(13,13);
    cout << "Erased range from s   : " << str << endl;

    // removes one character pointed by s.begin()
    cout << endl << "Erase one, second character from s"
         << endl;
    s.erase(s.begin()+1);
    cout << "s     is: " << s << endl;
    
    // removes range of characters
    s.erase(s.begin(),s.begin()+4);
    cout << "s     is: " << s << endl;

    return 0;
}
OUTPUT:
// str is: abcdefghijklmnopqrstuvwxyz
// s   is: abcdefghijklmnopqrstuvwxyz
// Erased range fron str : nopqrstuvwxyz
// Erased range from s   : abcdefghijklm
// 
// Erase one, second character from s
// s     is: acdefghijklm
// s     is: fghijklm


find 1.

#include <iostream>
#include <string>
#include <algorithm>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    int pos1, pos2; // size_t or size_type 
                    // work not correct
    // search for first string "best" inside of str
    // default position is 0
    pos1 = str.find ("best");
    cout << "Word best is found on position " << pos1+1 
         << endl;
    
    // if pattern is not found - return -1
    pos2 = str.find ("best",pos1+1);
    cout << "Word best is found on position " << pos2+1 
         << endl;

    // search for first occurrence of character
    pos1 = str.find('g');
    cout << "First character 'g' found on position " 
         << pos1
    	 << endl;

    // search for first occurrence of string
    string s = "is";
    pos1 = str.find (s);
    cout << "Word 'is' is found on position " << pos1+1 
         << endl;
    
    return 0;
}
OUTPUT:
// Word best is found on position 8
// Word best is found on position 0
// First character 'g' found on position 15
// Word 'is' is found on position 5


find_first_not_of 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    cout << "str is: " << str << endl;

    int n = str.find_first_not_of("aeiouAEIOU");

    cout << "First consonant found at " << n+1
    	 << " position" << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best language
// First consonant found at 1 position


find_first_not_of 2.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    cout << "str is: " << str << endl;

    // search first not ' ',
    // start from position 7
    int n = str.find_first_not_of(' ',7);
    cout << "first not of space character "
    	 << "found at position " << n+1 << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best language
// first not of space character found at position 8


find_first_not_of 3.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    string  s = "C++";
    
    cout << "str is: " << str << endl;
    
    // search character from pattern 
    // using the first x chï¿½racters in pattern.
    // the value position must be given
    int n = str.find_first_not_of("CBCD",0,3);
    cout << "first not 'C' is found at position "
    	 << n+1 << endl;
    
    // search first not of 
    // pattern is string
    n = str.find_first_not_of(s);
    cout << "first not of C++ is found "
    	 << "at position " << n+1 << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best language
// first not 'C' is found at position 2
// first not of C++ is found at position 4


find_first_of 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    string  s = "be";
    
    cout << "str is: " << str << endl;

    // search be start from position 2
    // if position is ommited - default is 0
    int n = str.find_first_of(s,2);
    cout << "first 'be' found at position "
    	 << n+1 << endl;

    // same as above but search for character
    n = str.find_first_of('l');
    cout << "first character 'l' found at "
    	 << "position " << n+1 << endl;

    // search 'first of' for the characters in
    // charary
    char charary[] = " bea";
    cout << "charary[] = \" bea\"" << endl;
    n = str.find_first_of(charary,0);
    cout << "first character from charary "
    	 << "found at position " << n+1 << endl;
    cout << "Note: position 4 is space" << endl;

    // same as above but third argumen is
    // number of character from which searching
    // starts
    // this variant of find_first_of dosn't
    // work properly with GNU compiler
    n = str.find_first_of(" bae",0,3);
    cout << "first character from charary "
    	 << "found at position " << n+1 << endl;

    return 0;
}
OUTPUT:
// str is: C++ is best language
// first 'be' found at position 8
// first character 'l' found at position 13
// charary[] = " bea"
// first character from charary found at position 4
// Note: position 4 is space
// first character from charary found at position 4


find_last_not_of 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    string  s  = "langue";
    int pos = str.length()-1;
    cout << "str is: " << str << endl;
    
    // returns the highest position <= pos of a character
    // in str that does not match any charcter in s; 
    // returns nopos if there  is  no such position:
    // npos is the default value for pos
    int n =  str.find_last_not_of(s, pos);
    cout << "last_not_of 'langue' found at position "
    	 << n+1 << endl;

    // same as above but search for single character
    n = str.find_last_not_of('e');
    cout << "last_not_of 'e' found at position "
    	 << n+1 << endl;

    char ary[] = "be";
    // seawrch for occurence last_not_of
    // from pattern ary in str
    n = str.find_last_not_of(ary);
    cout << "last_not_of 'be' found at position "
    	 << n+1 << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best language
// last_not_of 'langue' found at position 12
// last_not_of 'e' found at position 19
// last_not_of 'be' found at position 19


find_last_of 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string  str("C++ is best language");
    string  s  = "g";
    cout << "str is: " << str << endl;
    cout << "s   is: " << s   << endl;

 	int n = str.find_last_of(s);
 	cout << "last_of '" << s << "' faund"
 		 << " at position " << n+1 << endl;

    n = str.find_last_of(' ');
    cout << "last_of ' ' faund"
    	 << " at position " << n+1 << endl;

    n = str.find_last_of(" la");
    cout << "last_of \" la\" faund"
    	 << " at position " << n+1 << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best language
// s   is: g
// last_of 'g' faund at position 19
// last_of ' ' faund at position 12
// last_of " la" faund at position 18


insert 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ language";
    string s   = "is best";
    char ch[]  = "C++ language";
    
    cout << "str is: " << str << endl;
    cout << "s   is: " << s   << endl;
    cout << "ch  is: " << s   << endl;
    
    // insert a copy of s into str
    // at position pos;
    string::size_type pos = 4;
    str.insert(pos,s);
    cout << "str is: " << str << endl;
    
    // insert a copy of ch into str at
    // the position specified by iterator
    // return an iterator positioned at
    // this copy
    int n = str.find('l');
    str.insert(str.begin() + n,' ');
    cout << "str is: " << str << endl;
    
    // like above but n x copies of char
    str.insert(str.end(),3,'!');
    cout << "str is: " << str << endl;
    
    // insert 4 char from ch into s
    // at the position 0
    s.insert(0,ch,4);
    cout << "s   is: " << s   << endl;
    
    // insert 8 characters from str
    // start from position n ('langu...')
    // into s at position x (end string)
    n = str.find('l');
    int x = s.length();
    s.insert(x,str,n,8);
    cout << "s   is: " << s   << endl;
    
    n = s.find('l');
    s.insert(s.begin()+n,' ');
    cout << "s   is: " << s   << endl;
    
    // insert range (begin - begin+7) of str 
    // into s at position begin+4
    s.insert(s.begin()+4,str.begin(),str.begin()+7);
    cout << "s   is: " << s   << endl;
    return 0;
}
OUTPUT:
// str is: C++ language
// s   is: is best
// ch  is: is best
// str is: C++ is bestlanguage
// str is: C++ is best language
// str is: C++ is best language!!!
// s   is: C++ is best
// s   is: C++ is bestlanguage
// s   is: C++ is best language
// s   is: C++ C++ is is best language


length 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ is best computer language";
    cout << "str is: " << str << endl;
    
    cout << "Length of str is : "
         << str.length() << endl;
    
    return 0;
}
OUTPUT:
// str is: C++ is best computer language
// Length of str is : 29


max_size 1.

// returns a reverse iterator positioned // at the last character in string


#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ is best computer language";
    cout << "str is: " << str << endl;

    cout << "max_size of str is: "
         << str.max_size() << endl;

    return 0;
}
OUTPUT:
// str is: C++ is best computer language
// max_size of str is: 4294967294


rbegin 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "C++ is best computer language";
    cout << "str is: " << str << endl;

    // usual iterator doesn't work
    string::reverse_iterator It = str.rbegin();
    while ( It != str.rend() )
        cout << *It++;
    cout << endl;

    return 0;
}
OUTPUT:
// str is: C++ is best computer language
// egaugnal retupmoc tseb si ++C


replace 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "STL is created from Dennis Ritchie";
    string s1  = "was";
    string s2  = "developed";
    string s3  = "Stepanov alexander";
    cout << "str is: " << str << endl;

    cout << "replace 'is' for 'was'" << endl;
    str.replace(4, // start position in str
            2,     // how many characters
            s1);   // source for replasment
    
    cout << "str is: " << str << endl;
    
    cout <<"replace 'created' for 'developed'" << endl;
    int n = str.find('c'); // pos of 'created'
    int x = str.find("from") -1;

    str.replace(str.begin()+n,// start pointer
            str.begin()+x,    // end pointer
            s2);              // source
    
    cout << "str is: " << str << endl;

    cout << "replace 'Dennis' for 'alexander'" << endl;
    int x1 = str.find('D'); // search Dennis
    int x2 = str.find(' ',x1+1); // space after
    int y1 = s3.find("alex"); // search 'alex'
    int y2 = strlen("alexander");

    str.replace(x1, // start position in str
            x2-x1,  // how characters to replace
            s3,     // source for replacement
            y1,     // start positio from source
            y2);    // how chracter start from y1
    
    cout << "str is: " << str << endl;

    cout << "replace 'from' for 'by'" << endl;
    char ary[] = "bytes";
    n = str.find("from");

    // same variant possible with iterators
    // instead of number of position
    str.replace(n, // start position in str
            4,     // how many characters
            ary,   // source
            2);    // first 2 characters from source
    
    cout << "str is: " << str << endl;

    cout << "replace 'a' for 'A' (alexander)" << endl;
    n = str.find("alexander");

    str.replace(n,  // start position in str
            1,      // how character(s)
            1,      // how many copies of character
            'A');   // character for replasment
    cout << "str is: " << str << endl;

    cout << "replace 'Ritchie' for 'Stepanov'" << endl;
    x1 = str.find('R');
    y1 = s3.find(' ');

    str.replace(str.begin()+x1, // start pointer
            str.end(), // to the end of str
            s3.begin(), // start pointer from source
            s3.begin()+y1 // end pointer from
            );              // source
    cout << "str is: " << str << endl;

    return 0;
}
OUTPUT:
// str is: STL is created from Dennis Ritchie
// replace 'is' for 'was'
// str is: STL was created from Dennis Ritchie
// replace 'created' for 'developed'
// str is: STL was developed from Dennis Ritchie
// replace 'Dennis' for 'alexander'
// str is: STL was developed from alexander Ritchie
// replace 'from' for 'by'
// str is: STL was developed by alexander Ritchie
// replace 'a' for 'A' (alexander)
// str is: STL was developed by Alexander Ritchie
// replace 'Ritchie' for 'Stepanov'
// str is: STL was developed by Alexander Stepanov


reverse 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Anatoliy Urbanskiy";
    cout << str.reverse() << endl;

    return 0;
}
OUTPUT:


resize 1.

// if <=s.size(), truncates rightmost // character in s to make it of size n; otherwise, adds // copies of character ch to end of s to increase it size // to n, or adds a default character value (usually a // blank) if ch is omitted; return type is void


#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "Alexander Stepanov";
    cout << "str is: " << str << endl;
    cout << "size of str is: "
         << str.size() << endl;

    str.resize(11);

    cout << "after str.resize(11)" << endl;
    cout << "str is: " << str << endl;
    cout << "size of str is: "
         << str.size() << endl;

    str.resize(20,'.');

    cout << "after str.resize(20,'.')" << endl;
    cout << "str is: " << str << endl;
    cout << "size of str is: "
         << str.size() << endl;

    return 0;
}
OUTPUT:
// str is: Alexander Stepanov
// size of str is: 18
// after str.resize(11)
// str is: Alexander S
// size of str is: 11
// after str.resize(9,'.')
// str is: Alexander S.........
// size of str is: 20


rfind 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "We go step by step to the target";
    string s1  = "step";
    cout << "str is: " << str << endl;
    cout << "s1  is: " << s1  << endl;

    cout << "int n1 = str.find(s1)" << endl;
    int n1 = str.find(s1);
    cout << "n1 = " << n1+1 << endl;
    
    cout << "int n2 = str.rfind(s1)" << endl;
    int n2 = str.rfind(s1);
    cout << "n2 = " << n2+1 << endl;
    
    cout << "n3 = str.rfind(s1,n2-1)" << endl;
    int n3 = str.rfind(s1,n2-1);
    cout << "n3 = " << n3+1 << endl;

    cout << "n1 = str.rfind('t')" << endl;
    n1 = str.rfind('t');
    cout << "n1 = " << n1+1 << endl;
    
    cout << "n2 = str.rfind('t',n1-1)" << endl;
    n2 = str.rfind('t',n1-1);
    cout << "n2 = " << n2+1 << endl;
    
    char ch[] = "step";
    cout << "char ch[] = \"step\"" << endl;
    cout << "n1 = str.rfind(ch)" << endl;
    n1 = str.rfind(ch);
    cout << "n1 = " << n1+1 << endl;
    
    cout << "n2 = str.rfind(\"stabc\",10,2)" << endl;
    n2 = str.rfind("stabc", // pattern
            10,             // start position
            2);             // for first 2 char
                            // in pattern
    cout << "n2 = " << n2+1 << endl;
    
    return 0;
}
OUTPUT:
// str is: We go step by step to the target
// s1  is: step
// int n1 = str.find(s1)
// n1 = 7
// int n2 = str.rfind(s1)
// n2 = 15
// n3 = str.rfind(s1,n2-1)
// n3 = 7
// n1 = str.rfind('t')
// n1 = 32
// n2 = str.rfind('t',n1-1)
// n2 = 27
// char ch[] = "step"
// n1 = str.rfind(ch)
// n1 = 15
// n2 = str.rfind("stabc",10,2)
// n2 = 7


size 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "We go step by step to the target";
    string::size_type size = str.size();

    cout << "str is: " << str << endl;
    cout << "size of str = " << size << endl;
    
    return 0;
}
OUTPUT:
// str is: We go step by step to the target
// size of str = 32


substr 1.

// str.subsr(pos,n); // returns a copy of the substring consisting // of n characters from str, beginning at position pos // (default value 0); if n is too large or is omitted, // characters are copied only until the end of s is // reached

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str = "We go step by step to the target";
    cout << "str is: " << str << endl;

    int n = str.find("step");
    
    string s = str.substr(n);
    cout << "s   is: " << s << endl;

    s = str.substr(n,12);
    cout << "s   is: " << s << endl;
    
    return 0;
}
OUTPUT:
// str is: We go step by step to the target
// s   is: step by step to the target
// s   is: step by step


swap 1.

#include <iostream>
#include <string>
using namespace std;

int main () 
{
    string str1 = "Robert";
    string str2 = "Forest";
    cout << "str1 is: " << str1 << endl;
    cout << "str2 is: " << str2 << endl;
    cout << endl;

    cout << "str1.swap(str2)" << endl;
    cout << endl;

    str1.swap(str2);
    cout << "str1 is: " << str1 << endl;
    cout << "str2 is: " << str2 << endl;
    
    return 0;
}
OUTPUT:
// str1 is: Robert
// str2 is: Forest
// 
// str1.swap(str2)
// 
// str1 is: Forest
// str2 is: Robert

"
		4.1.4 String class example

Simple example of a program using string class and comparison with C char:

    view source
    print?
    01	#include <string>
    02	#include <iostream>
    03	#include <string.h>   // Required by strcpy()
    04	#include <stdlib.h>   // Required by malloc()
    05	 
    06	using namespace std;
    07	 
    08	main()
    09	{
    10	   string SS;     // C++ STL string
    11	   char CC[17];   // C character string (16 characters + NULL termination)
    12	                  // Storage pre-allocated
    13	   char *CC2;     // C character string. No storage allocated.
    14	 
    15	   SS = "This is a string";
    16	   strcpy(CC,"This is a string");
    17	 
    18	   CC2 = (char *) malloc(17);    // Allocate memory for storage of string.
    19	   strcpy(CC2,"This is a string");
    20	  
    21	   cout << SS << endl;
    22	   cout << CC << endl;
    23	   cout << CC2 << endl;
    24	}
    Results:

    This is a string
    This is a string
    This is a string

    The C and C++ methods of managing a character data type are both valid but we will see that the C++ string class offers more functionality and convenience. The STL string does not require memory to be pre-allocated nor allocated manually. The STL string class also provides many methods of string assignment. 

Example of a program using many of the build-in functions of the string class:

    view source
    print?
    01	#include <string>
    02	#include <iostream>
    03	 
    04	using namespace std;
    05	 
    06	main()
    07	{
    08	   string a("abcd efg");
    09	   string b("xyz ijk");
    10	   string c;
    11	 
    12	   cout << a << " " << b << endl;                        // Output: abcd efg xyz ijk
    13	 
    14	   cout << "String empty: "    << c.empty()    << endl;  // String empty: 1
    15	                                                         // Is string empty? Yes it is empty. (TRUE)
    16	   c = a + b;                                            // concatenation
    17	   cout << c << endl;                                    // abcd efgxyz ijk
    18	   cout << "String length: "   << c.length()   << endl;  // String length: 15
    19	   cout << "String size: "     << c.size()     << endl;  // String size: 15
    20	   cout << "String capacity: " << c.capacity() << endl;  // String capacity: 15
    21	   cout << "String empty: "    << c.empty()    << endl;  // String empty: 0
    22	                                                         // Is string empty? No it is NOT empty. (FALSE)
    23	   string d = c;
    24	   cout << d << endl;                                    // abcd efgxyz ijk
    25	 
    26	                                                         // First character: a
    27	   cout << "First character: " << c[0] << endl;          // Strings start with index 0 just like C.
    28	 
    29	   string f("    Leading and trailing blanks      ");
    30	   cout << "String f:" << f << endl;
    31	   cout << "String length: " << f.length() << endl;      // String length: 37
    32	   cout << "String f:" << f.append("ZZZ") << endl;       // String f:    Leading and trailing blanks      ZZZ
    33	   cout << "String length: " << f.length() << endl;      // String length: 40
    34	 
    35	   string g("abc abc abd abc");
    36	   cout << "String g: " << g << endl;                    // String g: abc abc abd abc
    37	   cout << "Replace 12,1,\"xyz\",3: " << g.replace(12,1,"xyz",3) << endl;  // Replace 12,1,"xyz",3: abc abc abd xyzbc
    38	   cout << g.replace(0,3,"xyz",3) << endl;               // xyz abc abd xyzbc
    39	   cout << g.replace(4,3,"xyz",3) << endl;               // xyz xyz abd xyzbc
    40	   cout << g.replace(4,3,"ijk",1) << endl;               // xyz i abd xyzbc
    41	   cout << "Find: " << g.find("abd",1) << endl;          // Find: 6
    42	   cout << g.find("qrs",1) << endl;
    43	 
    44	   string h("abc abc abd abc");
    45	   cout << "String h: " << h << endl;
    46	   cout << "Find \"abc\",0: " << h.find("abc",0) << endl; // Find "abc",0: 0
    47	   cout << "Find \"abc\",1: " << h.find("abc",1) << endl; // Find "abc",1: 4
    48	   cout << "Find_first_of \"abc\",0: " << h.find_first_of("abc",0) << endl; // Find_first_of "abc",0: 0
    49	   cout << "Find_last_of \"abc\",0: " << h.find_last_of("abc",0) << endl;   // Find_last_of "abc",0: 0
    50	   cout << "Find_first_not_of \"abc\",0: " << h.find_first_not_of("abc",0) << endl;  // Find_first_not_of "abc",0: 3
    51	   cout << "Find_first_not_of \" \": " << h.find_first_not_of(" ") << endl;  // Find_first_not_of " ": 0
    52	   cout << "Substr 5,9: " << h.substr(5,9) << endl;       // Substr 5,9: bc abd ab
    53	   cout << "Compare 0,3,\"abc\": " << h.compare(0,3,"abc") << endl;  // Compare 0,3,"abc": 0
    54	   cout << "Compare 0,3,\"abd\": " << h.compare(0,3,"abd") << endl;  // Compare 0,3,"abd": -1
    55	   cout << h.assign("xyz",0,3) << endl;                   // xyz
    56	   cout << "First character: " << h[0] << endl; // Strings start with 0 // First character: x
    57	 
    58	 
    59	}

Compile: g++ program.cpp

[Potential Pitfall]: In Red Hat Linux versions 7.x one could omit the "using namespace std;" statement. Use of this statement is good programming practice and is required in Red Hat 8.0.

[Potential Pitfall]: Red Hat 8.0 requires the reference to "#include <iostream>". Red Hat versions 7.x used "#include <iostream.h>". (Also fstream, ...)

	Output: ./a.out

    abcd efg xyz ijk
    String empty: 1
    abcd efgxyz ijk
    String length: 15
    String size: 15
    String capacity: 15
    String empty: 0
    abcd efgxyz ijk
    First character: a
    String f:    Leading and trailing blanks      
    String length: 37
    String f:    Leading and trailing blanks      ZZZ
    String length: 40
    String g: abc abc abd abc
    Replace 12,1,"xyz",3: abc abc abd xyzbc
    xyz abc abd xyzbc
    xyz xyz abd xyzbc
    xyz i abd xyzbc
    Find: 6
    4294967295
    String h: abc abc abd abc
    Find "abc",0: 0
    Find "abc",1: 4
    Find_first_of "abc",0: 0
    Find_last_of "abc",0: 0
    Find_first_not_of "abc",0: 3
    Find_first_not_of " ": 0
    Substr 5,9: bc abd ab
    Compare 0,3,"abc": 0
    Compare 0,3,"abd": -1
    xyz
    First character: x

	
[Potential Pitfall]: There have been some changes in the behavior of the string class from Red Hat 7.x to Red Hat 8.0:

    * The compare function arguments have changed from X.compare("string",int-1, int-2); to X.compare(int-1, int-2, "string");
    * The return value of the compare function call h.compare("abc",0,3) in 7.x was 12. In Red Hat 8.0 h.compare(0,3,"abc") it is 0.
    * String capacity function call "c.capacity()" is 15. The returned value in Red Hat 7.x was 16.

String class functions:

    * Constructors:

          view source
          print?
          1	string sVar1("abc");
          2	string sVar1(C-string-variable);
          3	string sVar2(10," ");  // Generate string initialized to 10 blanks.
          4	string sVar3(Var1, string-index);  // Initialize with characters from string starting with index string-index.
          5	string sVar4(iterator-index-begin, iterator-index-end)

    * Destructor:

          view source
          print?
          1	Var.~string();         // Destructor

    * Replace:
          o Var.replace(beginning,end-position,string-class-variable)
          o Var.replace(beginning,end-position,C-char-variable)
          o Var.replace(beginning,end-position,string-class-variable,length)
          o Var.replace(beginning,end-position,integer-number,single-char)
          o Var.replace(beginning,end-position,new-beginning-porition,new-end-position)

      Code samples:

          view source
          print?
          01	string g("abc abc abd abc");
          02	cout << g.replace(4,1,"ijk",3) << endl;
          03	 
          04	string h("abc abc abd abc");
          05	cout << h.replace(4,6,"ijk",3) << endl;
          06	 
          07	string k("abc abc abd abc");
          08	cout << k.replace(4,3,"ijk",3) << endl;
          09	  
          10	string l("abc abc abd abc");
          11	cout << k.replace(12,1,"xyz",3) << endl;

      Output:

          abc ijkbc abd abc - Beginning with the 4th index (character number 5) replace one character with 3 characters from string "ijk"
          abc ijkd abc
          abc ijk abd abc
          abc abc abd xyzbc 

    * Find: (also rfind(), find_first_of(), find_last_of(), find_first_not_of(), find_last_not_of())

      Arguments/parameters:
          o Val.find(const string& argument)
            Find first occurence of argument within string Val
          o find(const string& argument, size_type index)
            Find first occurence of argument within string Val starting search from position index.
          o find(const char* argument)
          o find(const char* argument, size_type index)
          o find(const char* argument, size_type index, size_type length)
            Find first occurence of argument within string Val starting search from position index and search for length number of characters.

STL C++ string functions:
Assuming declaration: string Var;

    Function/Operation 	Description
    Var = string2
    Var.assign("string-to-assign") 	Assignment of value to string. When assigning a C "char" data type, first check if NULL to avoid failure/crash.
    i.e.: if( szVar ) sVar.assign( szVar );
    where szVar is a C "char *" data type and sVar is of type "string".
    Var.swap(string2)
    swap(string1,string2) 	Swap with value held in string2.
    Function swap will exchange contents of two string class variables.
    Var += string2
    Var.append()
    Var.push_back() 	Append string/characters.
    Var.insert() 	Insert characters
    Var.erase()
    Var = "" 	Clear string variable. No arguments necessary.
    + 	Concatenate
    ==, !=, <, <=, >, >= 	Compare strings.
    Var.compare(string)
    Var.compare( size_t pos1, size_t len, string ) const;
    Var.compare( size_t pos1, size_t len1, const string, size_t pos2, size_t len2 ) const; 	Compare strings. Returns int:

        * 0: if equal.
        * -1: Not equal. 1st non matching character in Var is less in value based on ASCII table than in compare string.
        * +1: Not equal. 1st non matching character is greater in value based on ASCII table.

    Where string is another STL string or null terminated C string.
    Var.length() 	Return length of string. No arguments necessary. The methods length(), size() and capacity() all return the same value.
    Var.size() 	Return length of string. No arguments necessary.
    Var.capacity() 	Return length of string + 1. Red Hat 7.x. Red Hat 8.0+ returns the number of characters without the "+1". Number of characters that can be held without re-allocation.
    No arguments necessary.
    Var.max_size() 	Returns a very large number. No arguments necessary.
    Var.empty() 	Returns 1 if an empty string.
    Returns 0 if not empty.
    << 	Output stream
    >>
    getline() 	Input stream
    Var.c_str() 	Returns C string pointer. C char string is null terminated. Do not free memory using this pointer!
    Var.data() 	Returns C string pointer. C char string is NOT null terminated. Do not free memory using this pointer!
    Var[]
    Var.at(integer) 	Access individual characters. Return single character at specified position (integer).
    Var.find(string)
    Var.find(string, positionFirstChar)
    Var.find(string, positionFirstChar, len) 	Find first occurance of string or substring. Returns int position of first occurance in string. Where len is the length of the sequence to search for.
    Returns string::npos if not found.
    i.e. if(Var.find("abc") == string::npos) cout << "Not found" << endl;
    Var.rfind() 	Find last occurance of string or substring.
    Var.find_first_of(string, position)
    Var.find_first_of( string, size_t position, size_t len ) 	Find strings and substrings.
    Where string is another STL string or null terminated C string.
    If position = 0, than start at beginning of string.
    Var.find_last_of() 	Find strings and substrings.
    Var.find_first_not_of()
    Var.find_last_not_of() 	Find strings and substrings.
    Var.replace(pos1, len1, string)
    Var.replace(itterator1, itterator2, const string)
    Var.replace(pos1, len1, string, pos2, len2) 	Replace section of string with new characters.
    pos2 and len2 are given when using only a substring of string. Where string is another STL string or null terminated C string.
    Var.substr(pos, len) 	Return substring of text given a start position in string object and length.
    Var.begin()
    Var.end() 	Iterators
    Var.rbegin()
    Var.rend() 	Reverse iterators

Note that in most cases the string functions have been overloaded to accept both string class arguments and C char variables.

ANSI C++ string class iterators:

Iterators provide the ability to access the individual characters in a string.

    view source
    print?
    01	#include <iostream>
    02	#include <string>
    03	using namespace std;
    04	    
    05	int main()
    06	{
    07	   string alphabetLC="abcdefghijklmnopqrstuvwxyz";
    08	 
    09	   string::const_iterator cii;
    10	   int ii;
    11	 
    12	   for(cii=alphabetLC.begin(); cii!=alphabetLC.end(); cii++)
    13	   {
    14	      cout << ii++ << " " << *cii << endl;
    15	   }
    16	}
    This will print the integer position in the string followed by the letter for all characters in the alphabet.

    0 a
    1 b
    2 c
    3 d
    4 e
    5 f
    6 g
    7 h
    ...
    ..

Iterator types:

    * string::traits_type
    * string::value_type
    * string::size_type
    * string::difference_type
    * string::reference
    * string::const_reference
    * string::pointer
    * string::const_pointer
    * string::iterator
    * string::const_iterator
    * string::reverse_iterator
    * string::const_reverse_iterator
    * string::npos

ANSI C++ string class and the C standard library:

The full use of the C standard library is available for use by utilizing the ".c_str" function return of the string class.

    view source
    print?
    01	#include <strings.h>
    02	#include <string>
    03	#include <stdio.h>
    04	using namespace std;
    05	    
    06	int main()
    07	{
    08	   char *phrase1="phrase";
    09	   string phrase2("Second phrase");
    10	   char  phraseA[128];
    11	   char  *phraseB;
    12	    
    13	   strcpy(phraseA,phrase2.c_str());
    14	   phraseB = strstr(phrase2.c_str(),phrase1);
    15	 
    16	   printf("phraseA: %s\n",phraseA);
    17	   printf("phraseB: %s\n",phraseB);
    18	   printf("phrase2: %s\n",phrase2.c_str());
    19	}  

Compile and run:

    [prompt]$ g++ test.cpp
    [prompt]$ ./a.out
    phraseA: Second phrase
    phraseB: phrase
    phrase2: Second phrase

Using ostringstream and an internal write:

In memory I/O string processing used as a data type conversion. This can also be used to make use of formatting of output in memory.

File: int2string.cpp

    view source
    print?
    01	#include <iostream>
    02	#include <sstream>
    03	#include <string>
    04	using namespace std;
    05	  
    06	string int2string(const int& number)
    07	{
    08	   ostringstream oss;
    09	   oss << number;
    10	   return oss.str();
    11	}
    12	  
    13	main()
    14	{
    15	   int number=7878;
    16	   string test="SSSSS";
    17	   test += int2string(number);
    18	   cout << test << endl;
    19	}

Compile and run:

        [prompt]$ g++ int2string.cpp
        [prompt]$ a.out
        SSSSS7878
        

[Potential Pitfall]: Returned string value must be used right away without other memory being set as string destructor will free the memory associated with its contents. It is much safer for the function to return a char data type or pass the string reference as an argument. 	
Using istringstream and an internal read:

This is used to make use of reading and parsing a string in memory. It will also allow data type conversion from a string to the type read.

File: test.cpp

    view source
    print?
    01	#include <iostream>
    02	#include <sstream>
    03	#include <string>
    04	using namespace std;
    05	  
    06	main()
    07	{
    08	   string test="AAA 123 SSSSS 3.141592654";
    09	   istringstream totalSString( test );
    10	   string string1, string2;
    11	   int    integer1;
    12	   double PI;
    13	 
    14	   totalSString >> string1 >> integer1 >> string2 >> PI;
    15	    
    16	   cout << "Individual parsed variables:" << endl;
    17	   cout << "First string:  " << string1   << endl;
    18	   cout << "First integer: " << integer1  << endl;
    19	   cout << "Value of PI:   " << PI        << endl;
    20	}

Compile and run:

        [prompt]$ g++ test.cpp
        [prompt]$ a.out
        Individual parsed variables:
        First string:  AAA
        First integer: 123
        Value of PI:   3.14159
        

Code snipets:

    * Read lines from standard input:
      view source
      print?
      01	while( getline(std::cin, sLine) )
      02	{
      03	   if( sLine.empty() );                     // Ignore empty lines
      04	   else
      05	   {
      06	      cout << sLine[0] << sLine[1] << endl;
      07	      ....
      08	      ...
      09	   }
      10	}
    * Read lines from input file:
      view source
      print?
      01	#define SYS_CONFIG_FILE "/etc/file.conf"
      02	#include <string>
      03	#include <algorithm>
      04	#include <vector>
      05	#include <cctype>
      06	#include <iostream>
      07	#include <fstream>
      08	 
      09	using namespace std;
      10	 
      11	string::size_type posBeginIdx, posEndIdx;
      12	string::size_type ipos=0;
      13	string            sLine, sValue;
      14	string            sKeyWord;
      15	const string      sDelim( ":" );
      16	 
      17	ifstream myInputFile(SYS_CONFIG_FILE, ios::in);
      18	if( !myInputFile )
      19	{
      20	   sError = "File SYS_CONFIG_FILE could not be opened";
      21	   return sError; // ERROR
      22	}
      23	 
      24	while( getline(myInputFile,sLine) )
      25	{
      26	   if( sLine.empty() );                     // Ignore empty lines
      27	   else
      28	   {
      29	      posEndIdx = sLine.find_first_of( sDelim );
      30	      sKeyWord  = sLine.substr( ipos, posEndIdx ); // Extract word
      31	      posBeginIdx = posEndIdx + 1;  // Beginning of next word (after ':')
      32	   ....
      33	   ...
      34	   }
      35	}
    * Strip blank characters:
      view source
      print?
      01	void
      02	stripLeadingAndTrailingBlanks(string& StringToModify)
      03	{
      04	   if(StringToModify.empty()) return;
      05	 
      06	   int startIndex = StringToModify.find_first_not_of(" ");
      07	   int endIndex = StringToModify.find_last_not_of(" ");
      08	   string tempString = StringToModify;
      09	   StringToModify.erase();
      10	 
      11	   StringToModify = tempString.substr(startIndex, (endIndex-startIndex+ 1) );
      12	}

The String Class and Debugging in GDB:

The first thing you will notice when using the C++ string class is that you can't de-reference any of the string class variables directly with GDB, ddd,... One must create a helper routine (for older versions of gdb) or use string class funtions (newer versions of gdb) to print out the value of the string variable.

    view source
    print?
    01	#include <string>
    02	#include <iostream>
    03	 
    04	using namespace std;
    05	 
    06	// Helper routine ps to print a string class variable.
    07	 
    08	void ps(string& s){ cout << s << endl; }
    09	 
    10	int main()
    11	{
    12	   string a("String A");
    13	   string b;
    14	 
    15	   b = "String B";
    16	 
    17	   cout << "Hello!" << endl;
    18	}

Compile program with symbolic code for the debugger: g++ -g testprog.cpp

Start gdb debugger: gdb ./a.out

    (gdb) l 1,18                             - List lines 1 to 18
    1       #include <string>
    2       #include <iostream>
    3
    4       using namespace std;
    5
    6       // Helper routine ps to print a string class variable.
    7
    8       void ps(string& s){ cout << s << endl; }
    9
    10      int main()
    11      {
    12         string a("String A");
    13         string b;
    14
    15         b = "String B";
    16
    17         cout << "Hello!" << endl;
    18      }
    (gdb) break 17
    Breakpoint 1 at 0x804893b: file testprog.cpp, line 17.
    (gdb) run
    Starting program: /home/user1/a.out

    Breakpoint 1, main () at testprog.cpp:17
    17         cout << "Hello!" << endl;
    (gdb) p a                                - Gdb can't de-reference string class variable "a" 
    $1 = {static npos = Cannot access memory at address 0x83a32d0
    (gdb) call ps(a)
    String A                                 - Call helper function ps to print string conents.
    (gdb) call ps(b)
    String B
    (gdb) c
    Continuing.
    Hello!

    Program exited normally.
    (gdb) quit
        

With newer versions of gdb, one may use built-in string class functions:

    (gdb) p a.c_str()
    $1 = 0x8049e34 "String A"
    (gdb) p b.c_str()
    $3 = 0x8049e4c "String B"
    (gdb) p b.empty()
    $2 = false
    (gdb) p b.size()
    $4 = 8
        

Dereference string and wstring using GDB macro functions. See YoLinux.com GDB tutorial on dereferencing STL strings and containers.

Tips:

    * The string class is NOT a native data type, it is an object class and thus can not be handled like the traditional pointer to variable in gdb.
    * One can pass strings by reference (i.e. argument declarations using (string& variable-name )), by value (string variable-name ), and by pointer (string *variable-name ).
    * When using a reference, one may mimic the protection of a variable that passing by value enables by using (const string& variable-name )

		4.1.5 Get bytes from std::string in C++
If you just need read-only access, then c_str will do it:

char const *c = myString.c_str();

If you need read/write access, then you can copy the string into a vector. vectors manage dynamic memory for you. You don't have to mess with allocation/deallocation then:

std::vector<char> bytes(myString.begin(), myString.end());
bytes.push_back('\0');
char *c = &bytes[0];

-	If he wants a byte array does he need the terminating '\0'? In which case you can use data() for read only. 

- data()

public member function
std::string::data
<string>

const char* data() const;

Get string data
Returns a pointer to an array of characters with the same content as the string.

Notice that no terminating null character is appended (see member c_str for such a functionality).

The returned array points to an internal location which should not be modified directly in the program. Its contents are guaranteed to remain unchanged only until the next call to a non-constant member function of the string object.

Parameters
none

Return Value
Pointer to an internal array containing the same content as the string.

Example

// string::data
#include <iostream>
#include <string>
using namespace std;

int main ()
{
  int length;

  string str = "Test string";
  char* cstr = "Test string";

  if ( str.length() == strlen (cstr) )
  {
    cout << "str and cstr have the same length.\n";

    length = str.length();

    if ( memcmp (cstr, str.data(), length ) == 0 )
      cout << "str and cstr have the same content.\n";
  } 
  return 0;
}



Output:

str and cstr have the same length.
str and cstr have the same content.


Basic template member declaration
( basic_string<charT,traits,Allocator> )

 

	

const charT* data ( ) const;



See also

string::copy
    Copy sequence of characters from string (public member function)

string::c_str
    Get C string equivalent (public member function)

string::assign
    Assign content to string (public member function)


-


		4.1.7 std::string reference 
typedef basic_string<char> string;
String class
Strings are objects that represent sequences of characters.

The standard string class provides support for such objects with an interface similar to that of a standard container of bytes, but adding features specifically designed to operate with strings of single-byte characters.

The string class is an instantiation of the basic_string class template that uses char (i.e., bytes) as its character type, with its default char_traits and allocator types (see basic_string for more info on the template).

Note that this class handles bytes independently of the encoding used: If used to handle sequences of multi-byte or variable-length characters (such as UTF-8), all members of this class (such as length or size), as well as its iterators, will still operate in terms of bytes (not actual encoded characters).

Member types
member type	definition
value_type	char
traits_type	char_traits<char>
allocator_type	allocator<char>
reference	char&
const_reference	const char&
pointer	char*
const_pointer	const char*
iterator	a random access iterator to char (convertible to const_iterator)
const_iterator	a random access iterator to const char
reverse_iterator	reverse_iterator<iterator>
const_reverse_iterator	reverse_iterator<const_iterator>
difference_type	ptrdiff_t
size_type	size_t

Member functions
(constructor)
Construct string object (public member function )
(destructor)
String destructor (public member function )
operator=
String assignment (public member function )

Iterators:
begin
Return iterator to beginning (public member function )
end
Return iterator to end (public member function )
rbegin
Return reverse iterator to reverse beginning (public member function )
rend
Return reverse iterator to reverse end (public member function )
cbegin 
Return const_iterator to beginning (public member function )
cend 
Return const_iterator to end (public member function )
crbegin 
Return const_reverse_iterator to reverse beginning (public member function )
crend 
Return const_reverse_iterator to reverse end (public member function )

Capacity:
size
Return length of string (public member function )
length
Return length of string (public member function )
max_size
Return maximum size of string (public member function )
resize
Resize string (public member function )
capacity
Return size of allocated storage (public member function )
reserve
Request a change in capacity (public member function )
clear
Clear string (public member function )
empty
Test if string is empty (public member function )
shrink_to_fit 
Shrink to fit (public member function )

Element access:
operator[]
Get character of string (public member function )
at
Get character in string (public member function )
back 
Access last character (public member function )
front 
Access first character (public member function )

Modifiers:
operator+=
Append to string (public member function )
append
Append to string (public member function )
push_back
Append character to string (public member function )
assign
Assign content to string (public member function )
insert
Insert into string (public member function )
erase
Erase characters from string (public member function )
replace
Replace portion of string (public member function )
swap
Swap string values (public member function )
pop_back 
Delete last character (public member function )

String operations:
c_str
Get C string equivalent (public member function )
data
Get string data (public member function )
get_allocator
Get allocator (public member function )
copy
Copy sequence of characters from string (public member function )
find
Find content in string (public member function )
rfind
Find last occurrence of content in string (public member function )
find_first_of
Find character in string (public member function )
find_last_of
Find character in string from the end (public member function )
find_first_not_of
Find absence of character in string (public member function )
find_last_not_of
Find non-matching character in string from the end (public member function )
substr
Generate substring (public member function )
compare
Compare strings (public member function )

Member constants
npos
Maximum value for size_t (public static member constant )

Non-member function overloads
operator+
Concatenate strings (function )
relational operators
Relational operators for string (function )
swap
Exchanges the values of two strings (function )
operator>>
Extract string from stream (function )
operator<<
Insert string into stream (function )
getline
Get line from stream into string (function )
		4.1.8
	4.2 Vector
The vector template class provides a form of dynamic array that expands at the end as necessary to accommodate additional elements.

		4.2.1 Types


Assume that T is some type (eg, int) and the following declarations:

   T e;
   vector<T> v, v1;
   vector<T>::iterator iter, iter2, beg, end;
   vector<T>::reverse_iterator riter;  /* beg, end could also be here */
   int i, n;
   bool b;

		4.2.2 CTOR/DTOR
Common vector constructors, functions, operators, etc
Result 	Method 	
	Description
Constructors and destructors
  	vector<T> v; 	L
	Creates an empty vector of T's.
  	vector<T> v(n); 	
	Creates vector of n default values.
  	vector<T> v(n, e); 	L
	Creates vector of n copies of e.
  	vector<T> v(beg, end); 	L
	Creates vector with elements copied from range beg..end.
  	v.~vector<T>(); 	L
	Destroys all elems and frees memory.

		4.2.3 Size
i =  	v.size(); 	L
	Number of elements.
i =  	v.capacity(); 	
	Max number of elements before reallocation.
i =  	v.max_size(); 	
	Implementation max number of elements.
b =  	v.empty(); 	L
	True if empty. Same as v.size()==0
  	v.reserve(n); 	
	Sets capacity to n before reallocation


		4.2.4 Altering
v =  	v1; 	L
	Assigns v1 to v.
v[i] =  	e; 	
	Sets ith element. Subscripts from zero.
v.at(i) =  	e; 	
	As subscription, but may throw out_of_range.
v.front() =  	e; 	L 	Same as v[0] = e.
v.back() =  	e; 	L 	Same as v[v.size()-1] = e.
  	v.push_back(e); 	L
	Adds e to end of v. Expands v if necessary.
  	v.pop_back(); 	L
	Removes last element of v.
  	v.clear(); 	L
	Removes all elements.
iter =  	v.assign(n, e); 	L
	Replaces existing elements with n copies of e.
iter =  	v.assign(beg, end); 	L
	Replaces existing elements with copies from range beg..end.
iter2 =  	v.insert(iter, e); 	L
	Inserts a copy of e at iter position and returns its position.
  	v.insert(iter, n, e); 	L
	Inserts n copies of e starting at iter position.
  	v.insert(iter, beg, end); 	L
	Inserts all elements in range beg..end, starting at iter position.
iter2 =  	v.erase(iter); 	L
	Removes element at iter position and returns position of next element.
iter =  	v.erase(beg, end); 	L
	Removes range beg..end and returns position of next element.


		4.2.5 Access
e =  	v[i]; 	
	ith element. No range checking.
e =  	v.at(i); 	
	As subscription, but may throw out_of_range.
e =  	v.front(); 	L
	First element. No range checking.
e =  	v.back(); 	L
	Last element. No range checking.
Iterators (operators apply to both forward and reverse iterators)
iter =  	v.begin(); 	L
	Returns iterator to first element.
iter =  	v.end(); 	L
	Returns iterator to after last element.
riter =  	v.rbegin(); 	L
	Returns iterator to first (in reverse order) element.
riter =  	v.rend(); 	L
	Returns iterator to after last (in reverse order) element.

	++iter; 	L
	Preincrement iter to next element. Use in both forward and reverse iterators normally. Can also postincrement. Returns value.

	--iter; 	L
	Predecrement iter. Can also postincrement. Returns value.
iter2 =  	iter + i; 	
	Iterator i elements after iter. += assigment also defined.
iter2 =  	iter - i; 	
	Iterator i elements before iter -= assignment also defined.
e =  	*iter; 	L
	Dereference the iterator to get the value.

		4.2.6 Iteration


			4.2.6.1 C++ STL: Which method of iteration over a STL container is better? 
This may seem frivolous to some of you, but which of the following 2 methods of iteration over a STL container is better? Why?

class Elem;
typedef vector<Elem> ElemVec;
ElemVec elemVec;

// Method 0
for (ElemVec::iterator i = elemVec.begin(); i != elemVec.end(); ++i)
{
    Elem& e = *i;
    // Do something
}

// Method 1
for (int i = 0; i < elemVec.size(); ++i)
{
    Elem& e = elemVec.at(i);
    // Do something
}

Method 0 seems like cleaner STL, but Method 1 achieves the same with lesser code. Simple iteration over a container is what appears all over the place in any source code. So, I'm inclined to pick Method 1 which seems to reduce visual clutter and code size.


The first version works with any container and so is more useful in template functions that take any container a s a parameter. It is also conceivably slightly more efficient, even for vectors.

The second version only works for vectors and other integer-indexed containers. It'd somewhat more idiomatic for those containers, will be easily understood by newcomers to C++, and is useful if you need to do something else with the index, which is not uncommon.


If you don't mind a (very?) small loss of efficiency, i'd recommend using Boost.Foreach

BOOST_FOREACH( Elem& e, elemVec )
{
    // Your code
}



Some more advantages of method 0:

    if you move from vector to another container the loop remains the same,
    easy to move from iterator to const_iterator if you need,
    when c++0x will arive, auto typing will reduce some of the code clutter.

The main disadvantage is that in many cases you scan two containers, in which case an index is cleaner than keeping two iterators.




			4.2.6.2 std::for_each
function template
<algorithm>
std::for_each
template <class InputIterator, class Function>
   Function for_each (InputIterator first, InputIterator last, Function fn);
Apply function to range
Applies function fn to each of the elements in the range [first,last).

The behavior of this template function is equivalent to:
1
2
3
4
5
6
7
8
9
template<class InputIterator, class Function>
  Function for_each(InputIterator first, InputIterator last, Function fn)
{
  while (first!=last) {
    fn (*first);
    ++first;
  }
  return fn;      // or, since C++11: return move(fn);
}


Parameters
first, last
Input iterators to the initial and final positions in a sequence. The range used is [first,last), which contains all the elements between first and last, including the element pointed by first but not the element pointed by last.
fn
Unary function that accepts an element in the range as argument.
This can either be a function pointer or a move constructible function object.
Its return value, if any, is ignored.

Return value
C++98C++11
Returns fn.

Example
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
// for_each example
#include <iostream>     // std::cout
#include <algorithm>    // std::for_each
#include <vector>       // std::vector

void myfunction (int i) {  // function:
  std::cout << ' ' << i;
}

struct myclass {           // function object type:
  void operator() (int i) {std::cout << ' ' << i;}
} myobject;

int main () {
  std::vector<int> myvector;
  myvector.push_back(10);
  myvector.push_back(20);
  myvector.push_back(30);

  std::cout << "myvector contains:";
  for_each (myvector.begin(), myvector.end(), myfunction);
  std::cout << '\n';

  // or:
  std::cout << "myvector contains:";
  for_each (myvector.begin(), myvector.end(), myobject);
  std::cout << '\n';

  return 0;
}


Output:
myvector contains: 10 20 30
myvector contains: 10 20 30

Complexity
Linear in the distance between first and last: Applies fn to each element.

Data races
The objects in the range [first,last) are accessed (each object is accessed exactly once).
These objects may be modified if InputIterator is a mutable iterator type and fn is not a constant function.

Exceptions
Throws if fn throws or if any of the operations on iterators throws.
Note that invalid arguments cause undefined behavior.

See also
transform
Transform range (function template )
find
Find value in range (function template )
search
Search range for subsequence (function template )
		4.2.7
	4.3 set

		4.3.1 http://www.cplusplus.com/reference/set/set/
std::set
template < class T,                        // set::key_type/value_type
           class Compare = less<T>,        // set::key_compare/value_compare
           class Alloc = allocator<T>      // set::allocator_type
           > class set;
Set
Sets are containers that store unique elements following a specific order.

In a set, the value of an element also identifies it (the value is itself the key, of type T), and each value must be unique. The value of the elements in a set cannot be modified once in the container (the elements are always const), but they can be inserted or removed from the container.

Internally, the elements in a set are always sorted following a specific strict weak ordering criterion indicated by its internal comparison object (of type Compare).

set containers are generally slower than unordered_set containers to access individual elements by their key, but they allow the direct iteration on subsets based on their order.

Sets are typically implemented as binary search trees.

Container properties
Associative
Elements in associative containers are referenced by their key and not by their absolute position in the container.
Ordered
The elements in the container follow a strict order at all times. All inserted elements are given a position in this order.
Set
The value of an element is also the key used to identify it.
Unique keys
No two elements in the container can have equivalent keys.
Allocator-aware
The container uses an allocator object to dynamically handle its storage needs.

Template parameters
T
Type of the elements. Each element in a set container is also uniquely identified by this value (each value is itself also the element's key).
Aliased as member types set::key_type and set::value_type.
Compare
A binary predicate that takes two arguments of the same type as the elements and returns a bool. The expression comp(a,b), where comp is an object of this type and a and b are key values, shall return true if a is considered to go before b in the strict weak ordering the function defines.
The set object uses this expression to determine both the order the elements follow in the container and whether two element keys are equivalent (by comparing them reflexively: they are equivalent if !comp(a,b) && !comp(b,a)). No two elements in a set container can be equivalent.
This can be a function pointer or a function object (see constructor for an example). This defaults to less<T>, which returns the same as applying the less-than operator (a<b).
Aliased as member types set::key_compare and set::value_compare.
Alloc
Type of the allocator object used to define the storage allocation model. By default, the allocator class template is used, which defines the simplest memory allocation model and is value-independent.
Aliased as member type set::allocator_type.

Member types
C++98C++11
member type	definition	notes
key_type	The first template parameter (T)	
value_type	The first template parameter (T)	
key_compare	The second template parameter (Compare)	defaults to: less<key_type>
value_compare	The second template parameter (Compare)	defaults to: less<value_type>
allocator_type	The third template parameter (Alloc)	defaults to: allocator<value_type>
reference	allocator_type::reference	for the default allocator: value_type&
const_reference	allocator_type::const_reference	for the default allocator: const value_type&
pointer	allocator_type::pointer	for the default allocator: value_type*
const_pointer	allocator_type::const_pointer	for the default allocator: const value_type*
iterator	a bidirectional iterator to value_type	convertible to const_iterator
const_iterator	a bidirectional iterator to const value_type	
reverse_iterator	reverse_iterator<iterator>	
const_reverse_iterator	reverse_iterator<const_iterator>	
difference_type	a signed integral type, identical to: iterator_traits<iterator>::difference_type	usually the same as ptrdiff_t
size_type	an unsigned integral type that can represent any non-negative value of difference_type	usually the same as size_t

Member functions
(constructor)
Construct set (public member function )
(destructor)
Set destructor (public member function )
operator=
Copy container content (public member function )

Iterators:
begin
Return iterator to beginning (public member function )
end
Return iterator to end (public member function )
rbegin
Return reverse iterator to reverse beginning (public member function )
rend
Return reverse iterator to reverse end (public member function )
cbegin 
Return const_iterator to beginning (public member function )
cend 
Return const_iterator to end (public member function )
crbegin 
Return const_reverse_iterator to reverse beginning (public member function )
crend 
Return const_reverse_iterator to reverse end (public member function )

Capacity:
empty
Test whether container is empty (public member function )
size
Return container size (public member function )
max_size
Return maximum size (public member function )

Modifiers:
insert
Insert element (public member function )
erase
Erase elements (public member function )
swap
Swap content (public member function )
clear
Clear content (public member function )
emplace 
Construct and insert element (public member function )
emplace_hint 
Construct and insert element with hint (public member function )

Observers:
key_comp
Return comparison object (public member function )
value_comp
Return comparison object (public member function )

Operations:
find
Get iterator to element (public member function )
count
Count elements with a specific value (public member function )
lower_bound
Return iterator to lower bound (public member function )
upper_bound
Return iterator to upper bound (public member function )
equal_range
Get range of equal elements (public member function )

Allocator:
get_allocator
Get allocator (public member function )

		4.3.2 My examples 

			4.3.2.1 Create set from range, iterate set 


/*
 * =====================================================================================
 *
 *       Filename:  set.cpp
 *
 *    Description:  play w/ set
 *
 *        Version:  1.0
 *        Created:  02/25/16 12:19:06
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  YOSI IZAQ
 *   Organization:  
 *
 * =====================================================================================
 */
#include <iostream>
#include <set>
#include <string>

using namespace std;

int main ()
{
	int nums[10] = {1,5,6,1,1,5,9,0,6,9};
	set<int> myset(nums, nums+10);

	cout<<"set: {";
	for (set<int>::const_iterator i = myset.begin(); i != myset.end(); ++i) {
		cout<<*i<<",";
	}
	cout<<"}"<<endl;

}
[yizaq@YIZAQ-M-D1BW:Thu Feb 25:~/Desktop/Work/code/CPP/std:]$ g++ set.cpp -o set
[yizaq@YIZAQ-M-D1BW:Thu Feb 25:~/Desktop/Work/code/CPP/std:]$ ./set 
set: {0,1,5,6,9,}

			4.3.2.2 More set usage, template function takes container as argument 

/*
 * =====================================================================================
 *
 *       Filename:  set.cpp
 *
 *    Description:  play w/ set
 *
 *        Version:  1.0
 *        Created:  02/25/16 12:19:06
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  YOSI IZAQ
 *   Organization:  
 *
 * =====================================================================================
 */
#include <iostream>
#include <set>
#include <string>

using namespace std;

template <typename ContainerT> void printContainer( ContainerT & container)
{

	cout<<"container: {";
	typename ContainerT::const_iterator j= container.begin();
	for (typename ContainerT::const_iterator i = container.begin(); i != container.end(); ++i) {
		
		if ( (++j) != container.end() ) cout<<*i<<",";
		else cout<<*i;
	}
	cout<<"}"<<endl;

	// BTW, to get Container type use ContainerT::value_type 
}

int main ()
{
	int nums[10] = {1,5,6,1,1,5,9,0,6,9};
	set<int> myset(nums, nums+10);
	set<int> myset1; // empty
	set<int> myset2(myset1); // copy ctor


	printContainer<set<int> > (myset);

	if (myset1.empty()) {
		cout<<"myset1 is empty"<<endl;
	}
	cout<<"size of myset "<<myset.size()<<endl;

	myset1.insert(1);
	myset1.insert(1);
	myset1.insert(2);
	myset1.insert(5);
	myset1.insert(3);
	myset1.insert(1);
	myset1.insert(4);
	myset1.insert(4);
	myset1.insert(5);
	myset1.insert(6);

	cout<<"myset1 after inserts: "<<endl;
	printContainer<set<int> > (myset1);

	myset1.erase(3);
	myset1.erase(5);
	cout<<"myset1 after erases: "<<endl;
	printContainer<set<int> > (myset1);
}
[yizaq@YIZAQ-M-D1BW:Thu Feb 25:~/Desktop/Work/code/CPP/std:]$ ./set 
container: {0,1,5,6,9}
myset1 is empty
size of myset 5
myset1 after inserts: 
container: {1,2,3,4,5,6}
myset1 after erases: 
container: {1,2,4,6}

			4.3.2.3
		4.3.3
	4.4 map

	4.5
5. Exception handling

	5.1 Articles against exceptions handling.

		5.1.1 "
EXCEPTION HANDLING:
A FALSE SENSE OF SECURITY
by Tom Cargill

    This article first appeared in C++ Report, Volume 6, Number 9, November-December 1994.


I suspect that most members of the C++ community vastly underestimate the skills needed to program with exceptions and therefore underestimate the true costs of their use. The popular belief is that exceptions provide a straightforward mechanism for adding reliable error handling to our programs. On the contrary, I see exceptions as a mechanism that may cause more ills than it cures. Without extraordinary care, the addition of exceptions to most software is likely to diminish overall reliability and impede the software development process.

This ""extraordinary care"" demanded by exceptions originates in the subtle interactions among language features that can arise in exception handling. Counter-intuitively, the hard part of coding exceptions is not the explicit throws and catches. The really hard part of using exceptions is to write all the intervening code in such a way that an arbitrary exception can propagate from its throw site to its handler, arriving safely and without damaging other parts of the program along the way.

In the October 1993 issue of the C++ Report, David Reed argues in favor of exceptions that: ""Robust reusable types require a robust error handling mechanism that can be used in a consistent way across different reusable class libraries."" While entirely in favor of robust error handling, I have serious doubts that exceptions will engender software that is any more robust than that achieved by other means. I am concerned that exceptions will lull programmers into a false sense of security, believing that their code is handling errors when in reality the exceptions are actually compounding errors and hindering the software.

To illustrate my concerns concretely I will examine the code that appeared in Reed's article. The code (page 42, October 1993) is a Stack class template. To reduce the size of Reed's code for presentation purposes, I have made two changes. First, instead of throwing Exception objects, my version simply throws literal character strings. The detailed encoding of the exception object is irrelevant for my purposes, because we will see no extraction of information from an exception object. Second, to avoid having to break long lines of source text, I have abbreviated the identifier current_index to top. Reed's code follows. Spend a few minutes studying it before reading on. Pay particular attention to its exception handling. [Hint: Look for any of the classic problems associated with delete, such as too few delete operations, too man4ddelete operations or access to memory after its delete.]

template 
class Stack
{
  unsigned nelems;
  int top;
  T* v;
public:
  unsigned count();
  void push(T);
  T pop();

  Stack();
  ~Stack();
  Stack(const Stack&);
  Stack& operator=(const Stack&);
};

template 
Stack::Stack()
{
  top = -1;
  v = new T[nelems=10];
  if( v == 0 )
    throw ""out of memory"";
}

template 
Stack::Stack(const Stack& s)
{
  v = new T[nelems = s.nelems];
  if( v == 0 )
    throw ""out of memory"";
  if( s.top > -1 ){
    for(top = 0; top <= s.top; top++)
      v[top] = s.v[top];

    top--;
  }
}

template 
Stack::~Stack()
{
  delete [] v;
}

template 
void Stack::push(T element)
{
  top++;
  if( top == nelems-1 ){
    T* new_buffer = new T[nelems+=10];
    if( new_buffer == 0 )
      throw ""out of memory"";
    for(int i = 0; i < top; i++)
      new_buffer[i] = v[i];
    delete [] v;
    v = new_buffer;
  }
  v[top] = element;
}

template 
T Stack::pop()
{
  if( top < 0 )
    throw ""pop on empty stack"";
  return v[top--];
}

template 
unsigned Stack::count()
{
  return top+1;
}

template 
Stack&
Stack::operator=(const Stack& s)
{
  delete [] v;
  v = new T[nelems=s.nelems];
  if( v == 0 )
    throw ""out of memory"";
  if( s.top > -1 ){
    for(top = 0; top <= s.top; top++)
      v[top] = s.v[top];
    top--;
  }
  return *this;
}

My examination of the code is in three phases. First, I study the code's behavior along its ""normal,"" exception-free execution paths, those in which no exceptions are thrown. Second, I study the consequences of exceptions thrown explicitly by the member functions of Stack. Third, I study the consequences of exceptions thrown by the T objects that are manipulated by Stack. Of these three phases, it is unquestionably the third that involves the most demanding analysis.

Normal Execution Paths
Consider the following code, which uses assignment to make a copy of an empty stack:

Stack y;
Stack x = y;
assert( y.count() == 0 );
printf( ""%u\n"", x.count() );



17736

The object x should be made empty, since it is copied from an empty master. However, x is not empty according to x.count(); the value 17736 appears because x.top is not set by the copy constructor when copying an empty object. The test that suppresses the copy loop for an empty object also suppresses the setting of top. The value that top assumes is determined by the contents of its memory as left by the last occupant.

Now consider a similar situation with respect to assignment:

Stack a, b;
a.push(0);
a = b;
printf( ""%u\n"", a.count() );



1

Again, the object a should be empty. Again, it isn't. The boundary condition fault seen in the copy constructor also appears in operator=, so the value of a.top is not set to the value of b.top. There is a second bug in operator=. It does nothing to protect itself against self-assignment, that is, where the left-hand and right-hand sides of the assignment are the same object. Such an assignment would cause operator= to attempt to access deleted memory, with undefined results.

Exceptions Thrown by Stack
There are five explicit throw sites in Stack: four report memory exhaustion from operator new, and one reports stack underflow on a pop operation. (Stack assumes that on memory exhaustion operator new returns a null pointer. However, some implementations of operator new throw an exception instead. I will probably address exceptions thrown by operator new in a later column.)

The throw expressions in the default constructor and copy constructor of Stack are benign, by and large. When either of these constructors throws an exception, no Stack object remains and there is little left to say. (The little that does remain is sufficiently subtle that I will defer it to a later column as well.)

The throw from push is more interesting. Clearly, a Stack object that throws from a push operation has rejected the pushed value. However, when rejecting the operation, in what state should push leave its object? On push failure, this stack class takes its object into an inconsistent state, because the increment of top precedes a check to see that any necessary growth can be accomplished. The stack object is in an inconsistent state because the value of top indicates the presence of an element for which there is no corresponding entry in the allocated array.

Of course, the stack class might be documented to indicate that a throw from its push leaves the object in a state in which further member functions (count, push and pop) can no longer be used. However, it is simpler to correct the code. The push member function could be modified so that if an exception is thrown, the object is left in the state that it occupied before the push was attempted. Exceptions do not provide a rationale for an object to enter an inconsistent state, thus requiring clients to know which member functions may be called.

A similar problem arises in operator=, which disposes of the original array before successfully allocating a new one. If x and y are Stack objects and x=y throws the out-of-memory exception from x.operator=, the state of x is inconsistent. The value returned by a.count() does not reflect the number of elements that can be popped off the stack because the array of stacked elements no longer exists.

Exceptions Thrown by T
The member functions of Stack create and copy arbitrary T objects. If T is a built-in type, such as int or double, then operations that copy T objects do not throw exceptions. However, if T is another class type there is no such guarantee. The default constructor, copy constructor and assignment operator of T may throw exceptions just as the corresponding members of Stack do. Even if our program contains no other classes, client code might instantiate Stack>. We must therefore analyze the effect of an operation on a T object that throws an exception when called from a member function of Stack.

The behavior of Stack should be ""exception neutral"" with respect to T. The Stack class must let exceptions propagate correctly through its member functions without causing a failure of Stack. This is much easier said than done.

Consider an exception thrown by the assignment operation in the for loop of the copy constructor:

template 
Stack::Stack(const Stack& s)
{
  v = new T[nelems = s.nelems]; // leak
  if( v == 0 )
    throw ""out of memory"";
  if( s.top > -1 ){
    for(top = 0; top <= s.top; top++)
      v[top] = s.v[top]; // throw 
    top--;
  }
}

Since the copy constructor does not catch it, the exception propagates to the context in which the Stack object is being created. Because the exception came from a constructor, the creating context assumes that no object has been constructed. The destructor for Stack does not execute. Therefore, no attempt is made to delete the array of T objects allocated by the copy constructor. This array has leaked. The memory can never be recovered. Perhaps some programs can tolerate limited memory leaks. Many others cannot. A long-lived system, one that catches and successfully recovers from this exception, may eventually be throttled by the memory leaked in the copy constructor.

A second memory leak can be found in push. An exception thrown from the assignment of T in the for loop in push propagates out of the function, thereby leaking the newly allocated array, to which only new_buffer. points:

template 
void Stack::push(T element)
{
  top++;
  if( top == nelems-1 ){
    T* new_buffer = new T[nelems+=10]; // leak
    if( new_buffer == 0 )
      throw ""out of memory"";
    for(int i = 0; i < top; i++)
      new_buffer[i] = v[i]; // throw
    delete [] v;
    v = new_buffer;
  }
  v[top] = element;
}

The next operation on T we examine is the copy construction of the T object returned from pop:

template 
T Stack::pop()
{
  if( top < 0 )
    throw ""pop on empty stack"";
  return v[top--]; // throw
}

What happens if the copy construction of this object throws an exception? The pop operation fails because the object at the top of the stack cannot be copied (not because the stack is empty). Clearly, the caller does not receive a T object. But what should happen to the state of the stack object on which a pop operation fails in this way? A simple policy would be that if an operation on a stack throws an exception, the state of the stack is unchanged. A caller that removes the exception's cause can then repeat the pop operation, perhaps successfully.

However, pop does change the state of the stack when the copy construction of its result fails. The post-decrement of top appears in an argument expression to the copy constructor for T. Argument expressions are fully evaluated before their function is called. So top is decremented before the copy construction. It is therefore impossible for a caller to recover from this exception and repeat the pop operation to retrieve that element off the stack.

Finally, consider an exception thrown by the default constructor for T during the creation of the dynamic array of T in operator=:

template 
Stack&
Stack::operator=(const Stack& s)
{
  delete [] v;  // v undefined
  v = new T[nelems=s.nelems]; // throw
  if( v == 0 )
    throw ""out of memory"";
  if( s.top > -1 ){
    for(top = 0; top <= s.top; top++)
      v[top] = s.v[top];
    top--;
  }
  return *this;
}

The delete expression in operator= deletes the old array for the object on the left-hand side of the assignment. The delete operator leaves the value of v undefined. Mostimplementations leave v dangling unchanged, still pointing to the old array that has been returned to the heap. Suppose the exception from T::T() is thrown from within this assignment:

{
  Stack x, y;
  y = x;  // throw
} // double delete

As the exception propagates out of y.operator=, y.v is left pointing to the deallocated array. When the destructor for y executes at the end of the block, y.v still points to the deallocated array. The delete in the Stack destructor therefore has undefined results - it is illegal to delete the array twice.

An Invitation
Regular readers of this column might now expect to see a presentation of my version of Stack. In this case, I have no code to offer, at least at present. Although I can see how to correct many of the faults in Reed's Stack, I am not confident that I can produce a exception-correct version. Quite simply, I don't think that I understand all the exception related interactions against which Stack must defend itself. Rather, I invite Reed (or anyone else) to publish an exception-correct version of Stack. This task involves more than just addressing the faults I have enumerated here, because I have chosen not to identify all the problems that I found in Stack. This omission is intended to encourage others to think exhaustively about the issues, and perhaps uncover situations that I have missed. If I did offer all of my analysis, while there is no guarantee of it completeness, it might discourage others from looking further. I don't know for sure how many bugs must be corrected in Stack to make it exception-correct.

" 

		5.1.2. Posted in November 13th, 2007 by Mark in Programming

Exceptions are a necessary part of the C++ language, but for most programmers they are worse than worthless - they are unusable. When exceptions were first added to the language back in the days before standardization, they were seen as a brilliant improvement over the hideous setjmp/longjmp facility from ANSI C. Because exceptions unwind the stack when they are thrown, they call destructors and clean up all of your untidy messes as they go.


It didn't take long for somebody to notice that the emperor had no clothes. In 1994, Tom Cargill published a prescient article in the late C++ Report. Tom pointed out in detail just how difficult it was to write code that actually held up when exceptions were used. Scott Meyers flags this as one of his five Most Important C++ Non-Book Publications...Ever. (Incidentally, Tom is responsible for a piece of wisdom that sounds like a an offhand quip: the ninety-ninety rule. Any project manager who doesn't understand this rule all the way into his or her bones needs to quit. Now.)

The intervening years have not been kind to exceptions. The problems Tom foresaw in 1994 were real, and while they can be managed, writing exception-safe code is still fraught with peril. As a result, exceptions are basically unused by by most C++ programmers. After all, we have to deal with tough problems like writing safe multithreaded apps, understanding template metaprogramming, and dealing with the language's high-maintenance memory management. The last thing we need is to make use of a feature, that while useful, is basically impossible to use correctly.

Naturally, after this rather verbose introduction, you have probably guessed that I'm using this article to tell you about a simple little utility class I use to help me throw informative, easy to build exceptions in my C++ programs. Yes, exceptions are problematic, but there's one place I can use them with impunity: to cause a fatal error that aborts my program.
Fatal Errors Considered Exceptional

If you analyze Tom Cargill's article, or look into any of the additional work that has been done on exceptions up until today, you'll see that most of the nasty side effects are only a problem for a program that tries to keep running in a predictable and safe fashion while throwing and catching exceptions.

The side effects of code that isn't quite exception-safe include memory leaks, partially constructed objects, and invalid containers. All bad things. But the one place they usually don't matter to me is when things have degraded in my program to the point where I'm ready to throw in the towel anyway. That point is when I've encountered a fatal error and am aborting the program. At that point, I throw an exception, which generally percolates all the way up to main(), where it is caught, and error message is printed, and the program exits.

Handling fatal errors this way makes for much cleaner code. I generally assume that every method or function called in my program succeeds, and don't worry about creating special returns with error codes. I blithely march through call after call without checking results, secure in the knowledge that my code is working properly. I know this is the case, because if something went wrong, an exception would have been thrown, and my program would abort.

This error handling strategy is implemented entirely in main(), which generally follows this form in one of my programs:
HILITED HTML
C++:
int main( int argc, char *argv[] ) { try { // // all the work is enclosed in this try block // ... } catch ( const std::exception & e ) std::cout <<"\nFatal error: " <<e.what() <<"\n\n"; std::cout <<"Hit enter to continue..."; std::string temp; std::getline( std::cin, temp ); return -1; } return 0; }

There are a couple of interesting points to note about the error handler you see here. First, because I am catching std::exception, I will catch any errors in the standard library, such as bad_alloc, logic_error, runtime_error, etc. It's a good idea to have a top-level try/catch block for these items anyway, so my use of exceptions for fatal errors forces good hygiene practices.

Second, I'm using the what() method to give human-readable feedback on exactly what happened to send my program off the rails. This method is defined as virtual for the base class std::exception, so all derived classes will support it. There's no requirement that they populate this string with great prose, but we can at least expect implementors to provide something informative here.
My Exception Class

When I first started using exceptions for fatal errors, I kept things simple by just throwing instances of std::runtime_error when I wanted to abort my program. I could pass the constructor of this object a descriptive string as it was constructed, and that same string would be returned when what() was called in the exception handler. Typical usage might look like this:
HILITED HTML
C++:
#include <stdexcept> int main( int argc, char *argv[] ) { try { if ( argc <2 ) throw std::runtime_error( "Usage:\n\n" "add_link_error url\n" );

This code ensures that if the user leaves off the necessary command line argument, the catch() block will print out a usage statement and return an error value to the invoking shell, which is just what we want. I manage to handle faulty input with just one line of code, don't have to set any error variables, no if/then/break clause to print an error and then exit. It's tidy and works well.

Of course, it wasn't long until I ran into situations where I wanted to provide the user a little more information with a fatal error - information that had to be formatted at runtime. I ended up writing a lot of code that looked like this:
HILITED HTML
C++:
FILE *fp = fopen( "database.txt", "r" ); if ( !fp ) { std::stringstream s; s <<"Error opening file, errno value of " <<errno <<" translates to " <<strerror( errno ); throw std::runtime_error( s.str() ); };

This more or less worked, but it added a lot of lines to the code, and as a rule, the fewer lines, the less typing, the more I like it. In this case I have to construct a separate std::stringstream object to hold the formatted error message (or a character buffer if I choose to go old school and use vnsprintf() , a second line to do the formatting, and a third line to construct and throw the exception.

In addition to writing three lines instead of one, I now have to enclose the whole thing in brackets, because the clause following the if statement is multiple lines, which makes the whole thing require five lines of code instead of one!
A Better Way

I needed to find a better way to do this. I first dabbled with a class derived from std::exception that used vnsprintf() to format arguments, C-style. But there were a few disadvantages to this, the primary one being that it made it hard to take advantage of classes that have their own overrides to stream classes. In other words, if I've bothered to create a stream override so I can print the contents of class foo, it's easy to write that to a stream, but not so easy to insert it into a buffer being formatted with vnsprintf().

So I determined that I wanted to have a class that that let me rewrite the code shown above so that it all fits on one line, like this:
HILITED HTML
C++:
FILE *fp = fopen( "database.txt", "r" ); if ( !fp ) throw fatal_error() <<"Error opening file, errno value of " <<errno <<" translates to " <<strerror( error );

My Goal For Use of class fatal_error

My first stab at getting this to work was to create a class that used multiple inheritance to create a class that inherits from both std::exception and std::stringstream:
HILITED HTML
C++:
class fatal_error : public std::exception , public std::stringstream { ...

With this routine I'd just need to override the definition of what() and I would be in business.

But there was a fatal flaw in this problem: the absence of a copy constructor for std::stringstream. I had assumed that the copy constructor wouldn't be needed, as I was catching the exception object by reference. My thought was that the compiler would create a temporary object, pass it along to my catch clause, and all would be well.

No such luck. In this case, the compiler has the right to make a copy, and even if it doesn't make a copy, it has the right to insist on a copy constructor even if it is only considering the possibility of making a copy. Strike one.
This One Works

So I needed to make a version of my fatal_error class that doesn't try to call the copy constructor for std::stringstream. This is accomplished easily enough by using composition instead of inheritance:
HILITED HTML
C++:
class fatal_error : public std::exception { ... private : mutable std::stringstream mStream; };

This solves one problem, but creates another. Because fatal_error is no longer derived from std::stringstream, I've lost the overloaded operators that insert text into the object before it is thrown. In other words, my wished-for code shown above won't compile.

In this case, the solution is simple, I just add a template method to the class:
HILITED HTML
C++:
class fatal_error : public std::exception { public : template<typename T> fatal_error& operator<<( const T& t ) { mStream <<t; return *this; } ... }

Now the template class takes care of routing the stream insertion output into the std::stringstream member I've incorporated into my class. Note also that the overloaded insertion operator returns a reference to the fatal_error object, allowing me to chain insertions.
Almost Done

There only two more issues to deal with in order for this class to be ready for use. First, I need to deal with the possibility of a copy constructor being called as this exception is thrown. Because I can't copy the std::stringstream object from the old object to the new, I have to save off its contents into a mutable std::string member called mWhat. The result looks like this:
PLAIN TEXT
C++:

   a.
      fatal_error::fatal_error( const fatal_error &that )
   b.
      {
   c.
          mWhat += that.mStream.str();
   d.
      }

Finally, I need a good version of what() that conforms to what is expected for std::exception. This is nice and easy:
HILITED HTML
C++:
virtual const char *fatalError::what() const throw() { if ( mStream.str().size() ) { mWhat += mStream.str(); mStream.str( "" ); } return mWhat.c_str(); }

Wrapped Up

With that, I have an exception that I can use to easily generate fatal error exceptions with as much data as I want. I only have to include a single header file in any code that uses the class, and I can create and throw the exception in a single line of code, which adheres to the C ideologoy of minimal typing.

Life is good.

Complete source code from the single file, fatal_error.h, is given below. This code should work in g++ 3.x code, and Visual Studio 2003 and 2005 programs. If you run into problems with different versions of various compilers, please let me know!
HILITED HTML
C++:

// 
//fatal_error.h 
#include <sstream> 
#include <stdexcept> 
#include <string> 
// 
// This class is designed to make it a little easier 
// to throw informative exceptions. It's a little lame, 
// but I do like to be able to write code like this 
// for fatal errors: 
// 
// throw fatal_error() <<"Game over, " 
// <<mHealth 
// <<" health points!"; 
// 
// It works everywhere I've tested it, let's hope that it holds up. 
 class fatal_error : public std::exception 
{ public : 
	fatal_error() {}; 
// 
// Need a copy constructor, because the runtime of the compiler is 
// allowed to insist on it when it throws an object of this type, 
// even if it doesn't actually make a copy. When I make a copy, I 
// need to capture whatever is in the stringstream object. Note: 
// in many cases, attempting to copy an iostream object leads to 
// errors, so the copy constructor here constructs a brand new 
// mstream object. 
 fatal_error( const fatal_error &that ) { mWhat += that.mStream.str(); } 
// 
 Virtual dtor needed? Not really, but here it is anyway. 
 virtual ~fatal_error() throw(){}; 
// 
// When I finally get this object to an exception handler, 
// (hopefully catching by reference) I want to display the error 
// message that I've inserted. To do that, I just chapture 
// whatever is in the mWhat string object concatenated 
// with anything that might be in the stringstring mStream object, 
// and return it. (Odds are that only one of them will contain 
// anything, depending on whether or not the copy constructor 
// was called. 
 virtual const char *what() const throw() { if ( mStream.str().size() ) { mWhat += mStream.str(); mStream.str( "" ); } return mWhat.c_str(); } 
// 
// The template function used to create insertion operators for all 
// of the various types of objects one might insert into this guy. 
 template<typename T> fatal_error& operator<<( const T& t ) { mStream <<t; return *this; } private: mutable std::stringstream mStream; mutable std::string mWhat; };


	5.2

6. Conversions

	6.1 Hex string to integer
	http://www.codeguru.com/forum/showthread.php?t=231054

Q: How to convert a string into a numeric type?

A: There is one thing that you are not allowed to ignore when you convert a string into a numeric type: the conversion might fail because the
string you are converting might not contain a valid representation of a number.

If, for example, you try to convert the string "Hello" to a number, the conversion must fail.

The old C way (deprecated):

Many people use the 'atoi()', 'atof()' and the other functions from this "family". They're easy to use but have a major drawback: they return 0 both on failure and when converting the string "0", thus making a consistent error detection as good as impossible. We give this little sample for the sake of completeness:

Code:

const char* str_int = "777"; const char* str_float = "333.3"; int i = atoi(str_int); float f = atof(str_float);



A better way:

A bit more complicated, but also more consistent way is to use 'sscanf()' in one of it's flavors:

Code:

const char* str_int = "777";
const char* str_float = "333.3";
int i;
float f;
if(EOF == sscanf(str_int, "%d", &i)) 
{
	//error 
}
if(EOF == sscanf(str_float, "%f", &f)) 
{
	//error 
}


Since 'sscanf()' takes a 'const char*' parameter, you can directly use a 'CString' with it:

Code:

CString str_int("777");
if(EOF == sscanf(str_int, '%d', &i)) 
{
	//error 
}


Be very careful with the format specifier (i.e. "%d" in this example). 'sscanf()' has no way to check whether the format specifier and the type of the passed variable match each other. If they don't you will get unexpected
results. Also note that 'sscanf()' is able to extract more than one numerical value from a string with one call. Have a look in e.g. MSDN for details.


The C++ way

Following sample shows a template function that uses Standard C++ classes to complete the task:

Code:

#include <string> 
#include <sstream> 
#include <iostream> 
template <class T> 
bool from_string(T& t, const std::string& s, std::ios_base& (*f)(std::ios_base&)) 
{
	std::istringstream iss(s);
	return !(iss >> f >> t).fail(); 
}

int main() {
	int i;
	float f;
	// the third parameter of from_string() should be 
	// one of std::hex, std::dec or std::oct 
	if(from_string<int>(i, std::string("ff"), std::hex)) {
		std::cout << i << std::endl; 
	}
	else {
		std::cout << "from_string failed" << std::endl; 
	}
	if(from_string<float>(f, std::string("123.456"), std::dec)) {
		std::cout << f << std::endl; 
	} 
	else {
		std::cout << "from_string failed" << std::endl; 
	}
	return 0; 
} /* output: 255 123.456 */


This method is not only elegant but also type safe, because the compiler will pick the proper 'std::istringstream::operator >>()' at compile time, according to the operand type.



7. CPPUnit, Unit tests framework for C++

What is Unit Test?
    ->  Unit Test: A unit can be an operation, a class, a software package, or a subsystem
    ->  Integration Test: Interactions between units
    ->  System Test: System verification and validation as a whole
    ->  Acceptance Test: Testing as a end user; Expected results from system

    Three Principles
    ->  Testing as you go: the earlier a bug is found, the better!  Test can be done once a unit is ready:
    -> Bottom-up testing: with Drivers Top-down testing: with Stubs
    ->  Design test cases systematically: Include boundary values for each feature Make sure every line of code is executed

What can be tested in units?
    ->  A functional requirement 
    ->  Given input that satisfies the precondition, whether the output satisfies the post-condition
    ->  A unit can be a member function, a class, a package or component or a subsystem Â¿
    ->  Automation is the key! Replace user interaction with the scripts, if possible; replace some units with stubs
    ->  A unit tested can still have bugs, but most trivial bugs should have been found

What can not?
    ->  Generally, test can not replace the verification or code review
    ->  Specifically for unit test, interactions between this unit and other units after integration, system and user acceptance are not possible when the system is not ready yet

	7.1 JUnit
	JUnit and Example
 Refer to: http://www.junit.org
 Some concepts or classes:
Fixture: a set of objects against which tests are run
Test Case:
a class which defines the fixture to run multiple tests
- create a subclass of TestCase
- add an instance variable for each part of the fixture
- override setUp() to initialize the variables
- override tearDown() to release any permanent
resource allocated in setUp
setup: a method which sets up the fixture, called before a test is
executed.
teardown: a method to tear down the fixture, called after a test is
executed.
Test Suite: a collection of test cases.
TestRunner: a tool to define the test suite to be run and to display
its results
 A JUnit example (in Eclipse):
source code: junit\samples\money (simplified)
functionality: single currency arithmetic

	7.2 CPP Unit
CppUnit and Example
 Refer to: http://cppunit.sourceforge.net/cgibin/
moin.cgi
 A compiled CppUnit module in CDF
/u/yijun/software/cppunit-1.10.2
 An example of CppUnit
/cppunit-1.10.2/examples/money

8. Configuration file parsing

	8.1  Rick Wagner, Configuration File Reader for C++
	See source code in /cygdrive/c/work/cpp/recipes/Configuration file reader/ConfigFile-2.1.zip
	
9. Memory mangament

	9.1 Pointers, Smart pointers

		9.1.1 Auto Ptr, Using auto_ptr Effectively

This article appeared in C/C++ Users Journal, 17(10), October 1999.

Most people have heard of the standard auto_ptr smart pointer facility, but not everyone uses it daily. That's a shame, because it turns out that auto_ptr neatly solves common C++ design and coding problems, and using it well can lead to more robust code. This article shows how to use auto_ptr correctly to make your code safer--and how to avoid the dangerous but common abuses of auto_ptr that create intermittent and hard-to-diagnose bugs.
Why Call It an "Auto" Pointer?

auto_ptr is just one of a wide array of possible smart pointers. Many commercial libraries provide more sophisticated kinds of smart pointers that can do wild and wonderful things, from managing reference counts to providing advanced proxy services. Think of the Standard C++ auto_ptr as the Ford Escort of smart pointers: A simple general-purpose smart pointer that doesn't have all the gizmos and luxuries of special-purpose or high-performance smart pointers, but that does many common things well and is perfectly suitable for regular daily use.

What auto_ptr does is own a dynamically allocated object and perform automatic cleanup when the object is no longer needed. Here's a simple example of code that's unsafe without auto_ptr:

    // Example 1(a): Original code
    //
    void f()
    {
      T* pt( new T );

      /*...more code...*/

      delete pt;
    }

Most of us write code like this every day. If f() is a three-line function that doesn't do anything exceptional, this may be fine. But if f() never executes the delete statement, either because of an early return or because of an exception thrown during execution of the function body, then the allocated object is not deleted and we have a classic memory leak.

A simple way to make Example 1(a) safe is to wrap the pointer in a "smarter" pointer-like object that owns the pointer and that, when destroyed, deletes the pointed-at object automatically. Because this smart pointer is simply used as an automatic object (that is, one that's destroyed automatically when it goes out of scope), it's reasonably called an "auto" pointer:

    // Example 1(b): Safe code, with auto_ptr
    //
    void f()
    {
      auto_ptr<T> pt( new T );

      /*...more code...*/

    } // cool: pt's destructor is called as it goes out
      // of scope, and the object is deleted automatically

Now the code will not leak the T object, no matter whether the function exits normally or by means of an exception, because pt's destructor will always be called during stack unwinding. The cleanup happens automatically.

Finally, using an auto_ptr is just about as easy as using a built-in pointer, and to "take back" the resource and assume manual ownership again, we just call release():

    // Example 2: Using an auto_ptr
    //
    void g()
    {
      T* pt1 = new T;
      // right now, we own the allocated object

      // pass ownership to an auto_ptr
      auto_ptr<T> pt2( pt1 );

      // use the auto_ptr the same way
      // we'd use a simple pointer
      *pt2 = 12;       // same as "*pt1 = 12;"
      pt2->SomeFunc(); // same as "pt1->SomeFunc();"

      // use get() to see the pointer value
      assert( pt1 == pt2.get() );

      // use release() to take back ownership
      T* pt3 = pt2.release();

      // delete the object ourselves, since now
      // no auto_ptr owns it any more
      delete pt3;

    } // pt2 doesn't own any pointer, and so won't
      // try to delete it... OK, no double delete

Finally, we can use auto_ptr's reset() function to reset the auto_ptr to own a different object. If the auto_ptr already owned an object, though, it first deletes the already-owned object, so calling reset() is much the same as destroying the auto_ptr and creating a new one that owns the new object:

    // Example 3: Using reset()
    //
    void h()
    {
      auto_ptr<T> pt( new T(1) );

      pt.reset( new T(2) );
        // deletes the first T that was
        // allocated with "new T(1)"

    } // finally, pt goes out of scope and
      // the second T is also deleted
Wrapping Pointer Data Members

Similarly, auto_ptr can be used to safely wrap pointer data members. Consider the following common example that uses the Pimpl (or, compiler-firewall) Idiom:[1]

    // Example 4(a): A typical Pimpl
    //

    // file c.h
    //
    class C
    {
    public:
      C();
      ~C();
      /*...*/
    private:
      class CImpl; // forward declaration
      CImpl* pimpl_;
    };

    // file c.cpp
    //
    class C::CImpl { /*...*/ };

    C::C() : pimpl_( new CImpl ) { }
    C::~C() { delete pimpl_; }

In brief, C's private details are split off into a separate implementation object that's hidden behind an opaque pointer. The idea is that C's constructor is responsible for allocating the private helper "Pimpl" object that contains the class's hidden internals, and C's destructor is responsible for deallocating it. Using auto_ptr, however, we find an easier way:

    // Example 4(b): A safer Pimpl, using auto_ptr
    //

    // file c.h
    //
    class C
    {
    public:
      C();
      /*...*/
    private:
      class CImpl; // forward declaration
      auto_ptr<CImpl> pimpl_;
    };

    // file c.cpp
    //
    class C::CImpl { /*...*/ };

    C::C() : pimpl_( new CImpl ) { }

Now the destructor doesn't need to worry about deleting the pimpl_ pointer, because the auto_ptr will handle it automatically. In fact, if there's no other reason for explicitly writing a destructor, we don't need to bother with a custom destructor at all any more. Clearly, this is easier than managing the pointer manually, and it follows the good practice of wrapping resource ownership in objects--a job that auto_ptr is well suited to do. We'll revisit this example again at the end.
Ownership, Sources, and Sinks

This is nifty stuff all by itself, but it gets better: It's also very useful to pass auto_ptrs to and from functions, as function parameters and return values.

To see why, first consider what happens when you copy an auto_ptr: An auto_ptr owns the object that it holds a pointer to, and only one auto_ptr may own an object at a time. When you copy an auto_ptr, you automatically transfer ownership from the source auto_ptr to the target auto_ptr; if the target auto_ptr already owns an object, that object is first freed. After the copy, only the target auto_ptr owns the pointer and will delete it in due time, while the source is set back to a null state and can no longer be used to refer to the owned object.

For example:

    // Example 5: Transferring ownership from
    //            one auto_ptr to another
    //
    void f()
    {
      auto_ptr<T> pt1( new T );
      auto_ptr<T> pt2;

      pt1->DoSomething(); // OK

      pt2 = pt1;  // now pt2 owns the pointer,
                  // and pt1 does not

      pt2->DoSomething(); // OK

    } // as we go out of scope, pt2's destructor
      // deletes the pointer, but pt1's does nothing

But be careful to avoid the pitfall of trying to use a non-owning auto_ptr:

    // Example 6: Never try to do work through
    //            a non-owning auto_ptr
    //
    void f()
    {
      auto_ptr<T> pt1( new T );
      auto_ptr<T> pt2;

      pt2 = pt1;  // now pt2 owns the pointer, and
                  // pt1 does not

      pt1->DoSomething();
                  // error! following a null pointer
    }

With that in mind, we start to see how well auto_ptr works with sources and sinks. A "source" is a function or other operation that creates a new resource, and then typically hands off and relinquishes ownership of the resource. A "sink" is a function that does the reverse, namely that takes ownership of an existing object (and typically disposes of it). Instead of just having sources and sinks return and take bald pointers, though, it's usually better to return or take a smart pointer that owns the resource:

    // Example 7: Sources and sinks
    //

    // A creator function that builds a new
    // resource and then hands off ownership.
    //
    auto_ptr<T> Source()
    {
      return auto_ptr<T>( new T );
    }

    // A disposal function that takes ownership
    // of an existing resource and frees it.
    //
    void Sink( auto_ptr<T> pt )
    {
    }

    // Sample code to exercise the above:
    auto_ptr<T> pt( Source() ); // takes ownership

Note the elegance of what's going on here:

a.       Source() allocates a new object and returns it to the caller in a completely safe way, by letting the caller assume ownership of the pointer. Even if the caller ignores the return value (of course, you would never write code that ignores return values, right?), the allocated object will always be safely deleted.

At the end of this article, I'll demonstrate why returning an auto_ptr is an important idiom. It turns out that returning a result by wrapping it in something like an auto_ptr is sometimes the only way to make a function strongly exception-safe.

b.       Sink() takes an auto_ptr by value and therefore assumes ownership of it. When Sink() is done, the deletion is performed as the local auto_ptr object goes out of scope (as long as Sink() itself hasn't handed off ownership to someone else). The Sink() function as written above doesn't actually do anything with its parameter, so calling "Sink( pt );" is a fancy way of writing "pt.reset(0);", but normally a sink function would do some work with the object before freeing it.
Things Not To Do, and Why Not To Do Them

Beware: Never use auto_ptrs except in one of the ways I just described above. I have seen many programmers try to use auto_ptrs in other ways just as they would use any other object. The problem with this is that auto_ptrs are most assuredly not like any other object. Here's the fundamental issue, and I'll highlight it to make sure it stands out:

For auto_ptr, copies are NOT equivalent.

It turns out that this has important effects when you try to use auto_ptrs with generic code that does make copies and isn't necessarily aware that copies aren't equivalent (after all, usually copies are!).  Consider the following code that I regularly see posted on the C++ newsgroups:

    // Example 8: Danger, Will Robinson!
    //
    vector< auto_ptr<T> > v;

    /* ... */

    sort( v.begin(), v.end() );

It is never safe to put auto_ptrs into standard containers. Some people will tell you that their compiler and library compiles this fine, and others will tell you that they've seen exactly this example recommended in the documentation of a certain popular compiler; don't listen to them.

The problem is that auto_ptr does not quite meet the requirements of a type you can put into containers, because copies of auto_ptrs are not equivalent. For one thing, there's nothing that says a vector can't just decide to up and make an "extra" internal copy of some object it contains. For another, when you call generic functions that will copy elements, like sort() does, the functions have to be able to assume that copies are going to be equivalent. At least one popular sort internally takes a copy of a "pivot" element, and if you try to make it work on auto_ptrs it will merrily take a copy of the pivot auto_ptr object (thereby taking ownership and putting it in a temporary auto_ptr on the side), do the rest of its work on the sequence (including taking further copies of the now-non-owning auto_ptr that was picked as a pivot value), and when the sort is over the pivot is destroyed and you have a problem: At least one auto_ptr in the sequence (the one that was the pivot value) no longer owns the pointer it once held, and in fact the pointer it held has already been deleted!

So the standards committee bent over backwards to do everything it could to help you out: The Standard auto_ptr was deliberately and specifically designed to break if you try to use it with the standard containers (or, at least, to break with most natural implementations of the standard library). To do this, the committee used a trick: auto_ptr's copy constructor and copy assignment operator take references to non-const to the right-hand-side object. The standard containers' single-element insert() functions take a reference to const, and hence won't work with auto_ptrs.
Interlude: The const auto_ptr Idiom

One cute and intentional result of this engineering of auto_ptr is that const auto_ptrs never lose ownership: Copying a const auto_ptr is illegal, and in fact the only things you can do with a const auto_ptr are dereference it with operator*() or operator->() or call get() to inquire about the value of the contained pointer. This means that we have a clear and concise idiom to express that an auto_ptr can never lose ownership:

    // Example 9: The const auto_ptr idiom
    //
    const auto_ptr<T> pt1( new T );
        // making pt1 const guarantees that pt1 can
        // never be copied to another auto_ptr, and
        // so is guaranteed to never lose ownership

    auto_ptr<T> pt2( pt1 ); // illegal
    auto_ptr<T> pt3;
    pt3 = pt1;              // illegal
    pt1.release();          // illegal
    pt1.reset( new T );     // illegal

Now that's what I call const! So if you want to declare to the world that an auto_ptr can never be changed and will always delete what it owns, this is the way to do it. The const auto_ptr idiom is a useful and common technique, and one that you should keep in mind.
auto_ptr and Exception Safety

Finally, auto_ptr is sometimes essential to writing exception-safe code. Consider the following function:

    // Example 10(a): Exception-safe?
    //
    String f()
    {
      String result;
      result = "some value";
      cout << "some output";
      return result;
    }

This function has two visible side effects: It emits some output, and it returns a String. A detailed examination of exception safety is beyond the scope of this article,[2] but the goal we want to achieve is the strong exception-safety guarantee, which boils down to ensuring that the function acts atomically--even if there are exceptions, either all side effects happen or none of them do.

Although the code in Example 10(a) comes pretty close to achieving the strong exception-safety guarantee, there's still one minor quibble, as illustrated by the following client code:

    String theName;
    theName = f();

The String copy constructor is invoked because the result is returned by value, and the copy assignment operator is invoked to copy the result into theName. If either copy fails, then f() has completed all of its work and all of its side effects (good), but the result has been irretrievably lost (oops).

Can we do better, and perhaps avoid the problem by avoiding the copy?  For example, we could let the function take a non-const String reference parameter and place the return value in that:

    // Example 10(b): Better?
    //
    void f( String& result )
    {
      cout << "some output";
      result = "some value";
    }

This may look better, but it isn't, because the assignment to result might still fail which leaves us with one side effect complete and the other incomplete. Bottom line, this attempt doesn't really buy us much.

One way to solve the problem is to return a pointer to a dynamically allocated String, but the best solution is to go a step farther and return the pointer in an auto_ptr:

    // Example 10(c): Correct (finally!)
    //
    auto_ptr<String> f()
    {
      auto_ptr<String> result = new String;
      *result = "some value";
      cout << "some output";
      return result;  // rely on transfer of ownership;
                      // this can't throw
    }

This does the trick, since we have effectively hidden all of the work to construct the second side effect (the return value) while ensuring that it can be safely returned to the caller using only nonthrowing operations after the first side effect has completed (the printing of the message). We know that, once the cout is complete, the returned value will make it successfully into the hands of the caller, and be correctly cleaned up in all cases: If the caller accepts the returned value, the act of accepting a copy of the auto_ptr causes the caller to take ownership; and if the caller does not accept the returned value, say by ignoring the return value, the allocated String will be automatically cleaned up as the temporary auto_ptr holding it is destroyed. The price for this extra safety?  As often happens when implementing strong exception safety, the strong safety comes at the (usually minor) cost of some efficiency--here, the extra dynamic memory allocation. But, when it comes to trading off efficiency for correctness, we usually ought to prefer the latter!

Make a habit of using smart pointers like auto_ptr in your daily work. auto_ptr neatly solves common problems and will make your code safer and more robust, especially when it comes to preventing resource leaks and ensuring strong exception safety. Because it's standard, it's portable across libraries and platforms, and so it will be right there with you wherever you take your code.
Acknowledgments

This article is drawn from material in the new book Exceptional C++: 47 engineering puzzles, programming problems, and exception-safety solutions by Herb Sutter, Â© 2000 Addison Wesley Longman Inc., which contains further detailed treatments of points touched on briefly in this article, including exception safety, the Pimpl (compiler-firewall) Idiom, optimization, const-correctness, namespaces, and other C++ design and programming topics.

	9.2

10. C++ Tutorial, http://www.java2s.com/Tutorial/Cpp/CatalogCpp.htm


11. Compilation Errors FAQs

	11.1 GCC

		11.1.1 undefined vtable
		Example:
/view/yizaq__MAR.int.acs5_0.lx/vob/nm_acs/acs/runtime/infrastructure/stateManager/test/TimerCacheTest.cpp:116: undefined reference to `vtable for TimerCacheTest'

Solution:
That is the most obscure error message the gcc produces, but the reason
is usually simple:

The compiler has to put the vtable into an object file. It puts it into
the object file where the definition of the first non-inline member
function is. If it is missing, you get this rather unhelpful linker
error. Please check the existence of the definitions of your member
functions. For example, commonly absence of defenition of virtual functions (coming from base classes) will result in this error.
In one instance changing signature of DTOR to virtual resolved this error.

		11.1.2 class has virtual functions but non-virtual destructor
- Reason:
The thing is: without the destructor, GCC gives me a bunch of warnings "class has virtual functions but non-virtual destructor", but still compiles and my program works fine

This is an annoying warning in Modern C++, but in old object-style C++ it is generally correct.

The problem is about the way your objects are destructed. A simple test:

#include <iostream>

class Base {};
class Derived: public Base { public: ~Derived() { std::cout << "Aargh\n"; } };

int main() {
  Base* b = new Derived();
  Derived* d = new Derived();

  delete d;
  delete b;
}
This prints:

Aargh
Yep, only once.

The problem is that when you call delete on a variable of type Base*, the Base::~Base() method is called. If it is virtual, then the call is dynamically dispatched to the final method (based on the dynamic type), in this case Derived::~Derived(), but if it is not, then Derived::~Derived() is never called, thus never executed.

Therefore, if you wish to call delete (or use smart pointers which do it for you) on base types, then you need to add virtual ~Base() {} in their class definitions. This is why gcc warns you when you create a polymorphic class without a virtual destructor.


- Fix: define an empty DTOR
or If you insist on doing this, go ahead and pass -Wno-non-virtual-dtor to GCC. This warning doesn't seem to be turned on by default, so you must have enabled it with -Wall or -Weffc++. However, I think it's a useful warning, because in most situations this would be a bug.
ex:
                virtual ~CAD_DIAG() {};

		11.1.3 may be used uninitialized in this function

			11.1.3.1 My example
void f()
{
	if (cond) goto error;

	int * p = NULL;
	p = malloc(..);
	// some code w/ p
	//
error:
	free(p)
}

- Get this warn here since goto may take us to error: scope w/o declaring & Initializing p

			11.1.3.2

		11.1.4 jump into scope of identifier with variably modified type


			11.1.4.1 Example
int test_alloc_stack(int size){
    if(0) goto error; // same issue whatever conditional is used
    int apply[size];
    give_values(apply,size);
    return 1;
    error:
        return 0;
} 

a. The declaration:

int apply[size];
creates a variable length array. When it goes out of scope, the compiler must produce some code that cleans up the allocation for that array. Jumping into the scope of such an object is forbidden I imagine because some implementations might need to arrange for some initialization that the clean up code would require, and if you jump into the scope the initialization would be bypassed.

If you change to a dynamic allocation, the initialization and clean up become your responsibility instead of the compiler's.

b. It is forbidden by the standard:

C99 standard, paragraph 6.8.6.1

Constraints

[...] A goto statement shall not jump from outside the scope of an identiﬁer having a variably modiﬁed type to inside the scope of that identiﬁer.

Which is exactly what your goto is doing, namely, jumping from outside the scope of apply to inside it.

You can use the following workaround to limit the scope of apply:

if(0) goto error;

{
	    int apply[size];
	        give_values(apply,size);
		    return 1;
}

error:
return 0;

c. Your goto makes you skip the line that allocates apply (at runtime).

You can solve the problem in one of four ways:

1: Rewrite your code so you don't use goto.

2: Move the declaration of apply to before the goto.

3: Change the scope so that error: is outside the scope of apply:

int test_alloc_stack(int size){
	    if(0) goto error; // same issue whatever conditional is used
	        {
			        int apply[size];
				        give_values(apply,size);
					        return 1;
						    }
		    error:
		        return 0;
}
4: Change the variable declaration so its size can be determined at compile-time.

			11.1.4.2

		11.1.5 gcc warning" 'will be initialized after'
Make sure the members appear in the initializer list in the same order as they appear in the class

Class C {
   int a;
   int b;
   C():b(1),a(2){} //warning, should be C():a(2),b(1)
}
or you can turn -Wno-reorder

		11.1.6 error: stropts.h: No such file or directory
It is a known issue that modern Linux systems are missing stropts.h file. You will probably have some problems when trying to compile software like pppd, pptp, gftp, etc from sources. Seems to be a strange thing, as you won’t get any errors in previous versions of Linux. Most recent versions of Fedora don’t contain this file, that’s why we need to know what to do if software compilation fails because of missing stropts.h.

Let’s determine when we need to have this file on our machine.When we’re compiling any “old” package from sources, we may receive the following error:

error: stropts.h: No such file or directory

What could be the reason and why isn’t this file included into our Linux distribution?This error means that your system doesn’t support STREAMS.

Linux doesn’t support STREAMS (many years ago it was available as a third party module, but it hasn’t worked for years). stropts.h is part of a POSIX XSR option, which is not supported in modern Linux distributions. Do we really need it in Linux?

This means that software you’re trying to compile, will not use the functions listed under stropts.h as they’re not supported by the operating system. So we will do a simple trick that will let you to compile your software without these functions.

Since the stropts.h is required for a successful compilation, the most simple way to solve the issue is to create a blank file named stropts.h under /usr/include. You may want to put any comments there, this way you won’t forget what was the reason to create this file.

This simple trick will help you to compile pptp (1.7.2),  pppd (2.4.5), and I think that the list will be much bigger. That was just my experience, but the sense remains the same: you need this file for a successful compilation. Just create it and have fun! :)
		11.1.7
12. C language

	12.1 Time
	http://www.acm.uiuc.edu/webmonkeys/book/c_guide/2.15.html
 The time header provides several functions useful for reading and converting the current time and date. Some functions behavior is defined by the LC_TIME category of the location setting.

Macros:

    NULL
    CLOCKS_PER_SEC 

Variables:

    typedef size_t
    typedef clock_t
    typedef size_t
    struct tm 

Functions:

    asctime();
    clock();
    ctime();
    difftime();
    gmtime();
    localtime();
    mktime();
    strftime();
    time(); 

            12.1.1 Variables and Definitions

    NULL is the value of a null pointer constant.
    CLOCKS_PER_SEC is the number of processor clocks per second.

    size_t is the unsigned integer result of the sizeof keyword.
    clock_t is a type suitable for storing the processor time.
    time_t is a type suitable for storing the calendar time.

    struct tm is a structure used to hold the time and date. Its members are as follows:

         int tm_sec;    /* seconds after the minute (0 to 61) */
         int tm_min;    /* minutes after the hour (0 to 59) */
         int tm_hour;   /* hours since midnight (0 to 23) */
         int tm_mday;   /* day of the month (1 to 31) */
         int tm_mon;    /* months since January (0 to 11) */
         int tm_year;   /* years since 1900 */
         int tm_wday;   /* days since Sunday (0 to 6 Sunday=0) */
         int tm_yday;   /* days since January 1 (0 to 365) */
         int tm_isdst;  /* Daylight Savings Time */

If tm_isdst is zero, then Daylight Savings Time is not in effect. If it is a positive value, then Daylight Savings Time is in effect. If it is negative, then the function using it is requested to attempt to calculate whether or not Daylight Savings Time is in effect for the given time.

Note that tm_sec may go as high as 61 to allow for up to two leap seconds.
            12.1.2 asctime

Declaration:

    char *asctime(const struct tm *timeptr); 

Returns a pointer to a string which represents the day and time of the structure timeptr. The string is in the following format:

    DDD MMM dd hh:mm:ss YYYY 

DDD	Day of the week (Sun, Mon, Tue, Wed, Thu, Fri, Sat)
MMM	Month of the year (Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
dd	Day of the month (1,...,31)
hh	Hour (0,...,23)
mm 	Minute (0,...,59)
ss	Second (0,...,59)
YYYY	Year
The string is terminated with a newline character and a null character. The string is always 26 characters long (including the terminating newline and null characters).

A pointer to the string is returned.

Example:

    #include<time.h>
    #include<stdio.h>

    int main(void)
    {
      time_t timer;

      timer=time(NULL);
      printf("The current time is %s.\n",asctime(localtime(&timer)));
      return 0;
    }

            12.1.3 clock

Declaration:

    clock_t clock(void); 

Returns the processor clock time used since the beginning of an implementation-defined era (normally the beginning of the program). The returned value divided by CLOCKS_PER_SEC results in the number of seconds. If the value is unavailable, then -1 is returned.

Example:

    #include<time.h>
    #include<stdio.h>

    int main(void)
    {
      clock_t ticks1, ticks2;

      ticks1=clock();
      ticks2=ticks1;
      while((ticks2/CLOCKS_PER_SEC-ticks1/CLOCKS_PER_SEC)<1)
        ticks2=clock();

      printf("Took %ld ticks to wait one second.\n",ticks2-ticks1);
      printf("This value should be the same as CLOCKS_PER_SEC which is %ld.\n",CLOCKS_PER_SEC);
      return 0;
    }

            12.1.4 ctime

Declaration:

    char *ctime(const time_t *timer); 

Returns a string representing the localtime based on the argument timer. This is equivalent to:

    asctime(locatime(timer)); 

The returned string is in the following format:

    DDD MMM dd hh:mm:ss YYYY 

DDD	Day of the week (Sun, Mon, Tue, Wed, Thu, Fri, Sat)
MMM	Month of the year (Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
dd	Day of the month (1,...,31)
hh	Hour (0,...,23)
mm	Minute (0,...,59)
ss	Second (0,...,59)
YYYY	Year
The string is terminated with a newline character and a null character. The string is always 26 characters long (including the terminating newline and null characters).

A pointer to the string is returned.
            12.1.5 difftime

Declaration:

    double difftime(time_t time1, time_t time2); 

Calculates the difference of seconds between time1 and time2 (time1-time2).

Returns the number of seconds.
            12.1.6 gmtime

Declaration:

    struct tm *gmtime(const time_t *timer); 

The value of timer is broken up into the structure tm and expressed in Coordinated Universal Time (UTC) also known as Greenwich Mean Time (GMT).

A pointer to the structure is returned. A null pointer is returned if UTC is not available.
            12.1.7 localtime

Declaration:

    struct tm *localtime(const time_t *timer); 

The value of timer is broken up into the structure tm and expressed in the local time zone.

A pointer to the structure is returned.

Example:

    #include<time.h>
    #include<stdio.h>

    int main(void)
    {
      time_t timer;

      timer=time(NULL);
      printf("The current time is %s.\n",asctime(localtime(&timer)));
      return 0;
    }

            12.1.8 mktime

Declaration:

    time_t mktime(struct tm *timeptr); 

Converts the structure pointed to by timeptr into a time_t value according to the local time zone. The values in the structure are not limited to their constraints. If they exceed their bounds, then they are adjusted accordingly so that they fit within their bounds. The original values of tm_wday (day of the week) and tm_yday (day of the year) are ignored, but are set correctly after the other values have been constrained. tm_mday (day of the month) is not corrected until after tm_mon and tm_year are corrected.

After adjustment the structure still represents the same time.

The encoded time_t value is returned. If the calendar time cannot be represented, then -1 is returned.

Example:

    #include<time.h>
    #include<stdio.h>

    /* find out what day of the week is January 1, 2001 
      (first day of the 21st century) */

    int main(void)
    {
      struct tm time_struct;
      char days[7][4]={"Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"};

      time_struct.tm_year=2001-1900;
      time_struct.tm_mon=0;
      time_struct.tm_mday=1;
      time_struct.tm_sec=0;
      time_struct.tm_min=0;
      time_struct.tm_hour=0;
      time_struct.tm_isdst=-1;

      if(mktime(&time_struct)==-1)
       {
        printf("Error getting time.\n");
        exit(0);
       }

      printf("January 1, 2001 is a %s.\n",days[time_struct.tm_wday]);
      return 0;
    }

            12.1.9 strftime

Declaration:

    size_t strftime(char *str, size_t maxsize, const char *format, const struct tm *timeptr); 

Formats the time represented in the structure timeptr according to the formatting rules defined in format and stored into str. No more than maxsize characters are stored into str (including the terminating null character).

All characters in the format string are copied to the str string, including the terminating null character, except for conversion characters. A conversion character begins with the % sign and is followed by another character which defines a special value that it is to be replaced by.
Conversion
Character	What it is replaced by
%a	abbreviated weekday name
%A	full weekday name
%b	abbreviated month name
%B	full month name
%c	appropriate date and time representation
%d	day of the month (01-31)
%H	hour of the day (00-23)
%I	hour of the day (01-12)
%j	day of the year (001-366)
%m	month of the year (01-12)
%M	minute of the hour (00-59)
%p	AM/PM designator
%S	second of the minute (00-61)
%U	week number of the year where Sunday is the first day of week 1 (00-53)
%w	weekday where Sunday is day 0 (0-6)
%W	week number of the year where Monday is the first day of week 1 (00-53)
%x	appropriate date representation
%X	appropriate time representation
%y	year without century (00-99)
%Y	year with century
%Z	time zone (possibly abbreviated) or no characters if time zone isunavailable
%%	%
Returns the number of characters stored into str not including the terminating null character. On error zero is returned.
            12.1.10 time

Declaration:

    time_t time(time_t *timer); 

Calculates the current calender time and encodes it into time_t format.

The time_t value is returned. If timer is not a null pointer, then the value is also stored into the object it points to. If the time is unavailable, then -1 is returned. 

	12.2 more time APIs


		12.2.1 std::clock vs. chrono
  C++  Utilities library Date and time utilities C-style date and time utilities 
Defined in header <ctime>
std::clock_t clock();
Returns the approximate processor time used by the process since the beginning of an implementation-defined era related to the program's execution. To convert result value to seconds divide it by CLOCKS_PER_SEC.
Only the difference between two values returned by different calls to std::clock is meaningful, as the beginning of the std::clock era does not have to coincide with the start of the program. std::clock time may advance faster or slower than the wall clock, depending on the execution resources given to the program by the operating system. For example, if the CPU is shared by other processes, std::clock time may advance slower than wall clock. On the other hand, if the current process is multithreaded and more than one execution core is available, std::clock time may advance faster than wall clock.
Parameters
(none)
Return value
Processor time used by the program so far or (clock_t)(-1) if that information is unavailable.
Notes
On POSIX-compatible systems, clock_gettime with clock id CLOCK_PROCESS_CPUTIME_ID offers better resolution.
The value returned by clock() may wrap around on some implementations. For example, on a machine with 32-bit std::clock_t, it wraps after 2147 seconds or 36 minutes.
Example
This example demonstrates the difference between clock() time and real time
#include <iostream>
#include <chrono>
#include <ctime>
#include <thread>
 
// the function f() does some time-consuming work
void f()
{
    volatile double d;
    for(int n=0; n<10000; ++n)
       for(int m=0; m<10000; ++m)
           d += d*n*m;
}
 
int main()
{
    std::clock_t c_start = std::clock();
    auto t_start = std::chrono::high_resolution_clock::now();
    std::thread t1(f); 
    std::thread t2(f); // f() is called on two threads
    t1.join();
    t2.join();
    std::clock_t c_end = std::clock();
    auto t_end = std::chrono::high_resolution_clock::now();
 
    std::cout << "CPU time used: "
              << 1000.0 * (c_end-c_start) / CLOCKS_PER_SEC
              << " ms\n";
    std::cout << "Wall clock time passed: "
              << std::chrono::duration_cast<std::chrono::milliseconds>(t_end - t_start).count()
              << " ms\n";
}
Output:
CPU time used: 1520 ms
Wall clock time passed: 769 ms

		12.2.2 gettimeofday

			12.2.2.1 time.c

 #include <time.h>
#include <sys/time.h>
#include <stdlib.h>
#include <stdio.h>

int main(int argc, char **argv)
{
  if (argc < 2)
    {
      printf("USAGE: %s loop-iterations\n", argv[0]);
      return 1;
    }

  int iterations = atoi(argv[1]);

  struct timeval start, end;

  gettimeofday(&start, NULL);

  for (int i = 0; i < iterations; i++)
    {
    }

  gettimeofday(&end, NULL);

  printf("%ld\n", ((end.tv_sec * 1000000 + end.tv_usec)
		  - (start.tv_sec * 1000000 + start.tv_usec)));

  return 0;
}

			12.2.2.2 GETTIMEOFDAY(2)           Linux Programmer's Manual          GETTIMEOFDAY(2)
NAME         top

       gettimeofday, settimeofday - get / set time
SYNOPSIS         top

       #include <sys/time.h>

       int gettimeofday(struct timeval *tv, struct timezone *tz);

       int settimeofday(const struct timeval *tv, const struct timezone *tz);

   Feature Test Macro Requirements for glibc (see feature_test_macros(7)):

       settimeofday(): _BSD_SOURCE
DESCRIPTION         top

       The functions gettimeofday() and settimeofday() can get and set the
       time as well as a timezone.  The tv argument is a struct timeval (as
       specified in <sys/time.h>):

           struct timeval {
               time_t      tv_sec;     /* seconds */
               suseconds_t tv_usec;    /* microseconds */
           };

       and gives the number of seconds and microseconds since the Epoch (see
       time(2)).  The tz argument is a struct timezone:

           struct timezone {
               int tz_minuteswest;     /* minutes west of Greenwich */
               int tz_dsttime;         /* type of DST correction */
           };

       If either tv or tz is NULL, the corresponding structure is not set or
       returned.  (However, compilation warnings will result if tv is NULL.)

       The use of the timezone structure is obsolete; the tz argument should
       normally be specified as NULL.  (See NOTES below.)

       Under Linux there are some peculiar "warp clock" semantics associated
       with the settimeofday() system call if on the very first call (after
       booting) that has a non-NULL tz argument, the tv argument is NULL and
       the tz_minuteswest field is nonzero.  (The tz_dsttime field should be
       zero for this case.)  In such a case it is assumed that the CMOS
       clock is on local time, and that it has to be incremented by this
       amount to get UTC system time.  No doubt it is a bad idea to use this
       feature.
RETURN VALUE         top

       gettimeofday() and settimeofday() return 0 for success, or -1 for
       failure (in which case errno is set appropriately).
ERRORS         top

       EFAULT One of tv or tz pointed outside the accessible address space.

       EINVAL Timezone (or something else) is invalid.

       EPERM  The calling process has insufficient privilege to call
              settimeofday(); under Linux the CAP_SYS_TIME capability is
              required.
CONFORMING TO         top

       SVr4, 4.3BSD.  POSIX.1-2001 describes gettimeofday() but not
       settimeofday().  POSIX.1-2008 marks gettimeofday() as obsolete,
       recommending the use of clock_gettime(2) instead.
NOTES         top

       The time returned by gettimeofday() is affected by discontinuous
       jumps in the system time (e.g., if the system administrator manually
       changes the system time).  If you need a monotonically increasing
       clock, see clock_gettime(2).

       Macros for operating on timeval structures are described in
       timeradd(3).

       Traditionally, the fields of struct timeval were of type long.

       The tz_dsttime field has never been used under Linux.  Thus, the
       following is purely of historic interest.

       On old systems, the field tz_dsttime contains a symbolic constant
       (values are given below) that indicates in which part of the year
       Daylight Saving Time is in force.  (Note: this value is constant
       throughout the year: it does not indicate that DST is in force, it
       just selects an algorithm.)  The daylight saving time algorithms
       defined are as follows:

           DST_NONE     /* not on DST */
           DST_USA      /* USA style DST */
           DST_AUST     /* Australian style DST */
           DST_WET      /* Western European DST */
           DST_MET      /* Middle European DST */
           DST_EET      /* Eastern European DST */
           DST_CAN      /* Canada */
           DST_GB       /* Great Britain and Eire */
           DST_RUM      /* Romania */
           DST_TUR      /* Turkey */
           DST_AUSTALT  /* Australian style with shift in 1986 */

       Of course it turned out that the period in which Daylight Saving Time
       is in force cannot be given by a simple algorithm, one per country;
       indeed, this period is determined by unpredictable political
       decisions.  So this method of representing timezones has been
       abandoned.
SEE ALSO         top

       date(1), adjtimex(2), clock_gettime(2), time(2), ctime(3), ftime(3),
       timeradd(3), capabilities(7), time(7)

			12.2.2.3
		12.2.3 Print date and time using gettimeofday
gettimeofday: Wall-Clock Time

The gettimeofday system call gets the system's wall-clock time. It takes a pointer to a struct timeval variable. This structure represents a time, in seconds, split into two fields. The tv_sec field contains the integral number of seconds, and the tv_usec field contains an additional number of microseconds. This struct timeval value represents the number of seconds elapsed since the start of the UNIX epoch, on midnight UTC on January 1, 1970. The gettimeofday call also takes a second argument, which should be NULL. Include <sys/time.h> if you use this system call.

The number of seconds in the UNIX epoch isn't usually a very handy way of representing dates. The localtime and strftime library functions help manipulate the return value of gettimeofday. The localtime function takes a pointer to the number of seconds (the tv_sec field of struct timeval) and returns a pointer to a struct tm object. This structure contains more useful fields, which are filled according to the local time zone:

·         tm_hour, tm_min , tm_sec— The time of day, in hours, minutes, and seconds.

·         tm_year, tm_mon , tm_day— The year, month, and date.

·         tm_wday— The day of the week. Zero represents Sunday.

·         tm_yday— The day of the year.

·         tm_isdst— A flag indicating whether daylight savings time is in effect.

The strftime function additionally can produce from the struct tm pointer a customized, formatted string displaying the date and time. The format is specified in a manner similar to printf, as a string with embedded codes indicating which time fields to include. For example, this format string

 
"%Y-%m-%d %H:%M:%S" 
specifies the date and time in this form:

 
2001-01-14 13:09:42 
Pass strftime a character buffer to receive the string, the length of that buffer, the format string, and a pointer to a struct tm variable. See the strftime man page for a complete list of codes that can be used in the format string. Notice that neither localtime nor strftime handles the fractional part of the current time more precise than 1 second (the tv_usec field of struct timeval). If you want this in your formatted time strings, you'll have to include it yourself.

Include <time.h> if you call localtime or strftime.

The function in Listing 8.6 prints the current date and time of day, down to the millisecond.

Listing 8.6 (print-time.c) Print Date and Time

#include <stdio.h> 
#include <sys/time.h> 
#include <time.h> 
#include <unistd.h> 
 
void print_time () 
{
  struct timeval tv; 
  struct tm* ptm; 
  char time_string[40]; 
  long milliseconds; 
 
  /* Obtain the time of day, and convert it to a tm struct. */ 
  gettimeofday (&tv, NULL); 
  ptm = localtime (&tv.tv_sec); 
  /* Format the date and time, down to a single second. */ 
  strftime (time_string, sizeof (time_string), "%Y-%m-%d %H:%M:%S", ptm); 
  /* Compute milliseconds from microseconds. */ 
  milliseconds = tv.tv_usec / 1000; 
  /* Print the formatted time, in seconds, followed by a decimal point 
     and the milliseconds. */ 
  printf ("%s.%03ld\n", time_string, milliseconds); 
} 
 
			12.2.3.1 Getting Current Time with Milliseconds 
When you call gettimeofday it gives you the number of seconds since EPOCH too, so you don't need to call time again. And when you use output of localtime as input of strftime, you may omit the intermediate variable (not a very useful point though). So your code could be written like:

timeval curTime;
gettimeofday(&curTime, NULL);
int milli = curTime.tv_usec / 1000;

char buffer [80];
strftime(buffer, 80, "%Y-%m-%d %H:%M:%S", localtime(&curTime.tv_sec));

char currentTime[84] = "";
sprintf(currentTime, "%s:%d", buffer, milli);
printf("current time: %s \n", currentTime);
an important note to be considered is that functions like localtime are not thread-safe, and you'd better use localtime_r instead.

			12.2.3.2

		12.2.4
	12.3

13. Open source libraries

	13.1 Networking

		13.1.1  Authentication

			13.1.1.1  RADIUS

				13.1.1.1.1  GNU RADIUS
http://www.gnu.org/software/radius/

			13.1.1.2


		13.1.2



	13.2 Security, Cryptography


14. Books
What are the best books I can learn C++ from?

Before going further, I should mention that I am not a C++ programmer myself, and the recommendations listed here are based on positive comments I have heard from others.

The C++ equivalent of K& R2 is "The C++ Programming Language", 3rd Edition, by Bjarne Stroustrup. Experienced C++ programmers love it; however, many beginners seem to find it very hard going indeed. Like K& R2, it assumes basic familiarity with programming concepts and is not really intended for the absolute beginner. It does not assume any previous knowledge of C. http://www.research.att.com/~bs/about_3rd.html

A more accessible book that is intended for beginners is "C++ Primer", 3rd Edition, by Stanley Lippman and JosÃ©e Lajoie. This book is thorough, and conforms to the C++ standard. It is reportedly extremely clear and detailed, and, again, does not assume any previous knowledge of C. http://cseng.aw.com/bookdetail.qry?ISBN=0-201-82470-1& ptype=0

Another text I've seen seen particularly recommended is "C++ - How to Program", 2nd Edition, by H M Deitel and P J Deitel. Again, this text does not assume prior knowledge of C. http://www.deitel.com/products_and_services/publications /cpphtp2.htm

Other texts I have seen recommended a number of times on the C++ newsgroups include the badly-named-though-often-recommended "Teach Yourself C++ in 21 days" by Jesse Liberty, "C++ Primer Plus" by Stephen Prata, and "Thinking in C++" by Bruce Eckel. http://www.libertyassociates.com/book_edit.htm#21 Days http://www.bruceeckel.com/books.html#ThinkingInCPlusPlus

Bruce Eckel has also placed a "beta" of the second edition of his "Thinking in C++" online as well. Do remember that it isn't the final version and that there might remain some as-yet undetected errors. http://www.eckelobjects.com/ThinkingInCPP2e.html The C++ FAQ contains some recommendations for C++ books as well.

15. Operators

	15.1  Bitwise Operators

	C++ provides operators to work with the individual bits in ints. For this to be useful, you must have some idea of how integers are represented in binary. For example the decimal number 3 is represented as 11 in binary and the decimal number 5 is represented as 101 in binary.
	The bitwise operators
	Operator	Name	Description
	a&b	and	1 if both bits are 1. 3 & 5 is 1.
	a|b	or	1 if either bit is 1. 3 | 5 is 7.
	a^b	xor	1 if both bits are different. 3 ^ 5 is 6.
	~a	not	This unary operator inverts the bits. If ints are stored as 32-bit integers, ~3 is 11111111111111111111111111111100.
	n<<p	left shift	shifts the bits of n left p positions. Zero bits are shifted into the low-order positions. 3 << 2 is 12.
	n>>p	right shift	shifts the bits of n right p positions. If n is a 2's complement signed number, the sign bit is shifted into the high-order positions. 5 >> 2 is 1.
	Packing and Unpacking

	A common use of the bitwise operators (shifts with ands to extract values and ors to add values) is to pack multiple values in one int. [Bit-fields are another way to do this.]

	For example, let's say you have the following integer variables: age (range 0-127 requires 7 bits), gender (range 0-1 requires 1 bit), and height (range 0-127 requires 7 bits). These can be packed and unpacked into/from one int by using only the minimum number of bits to represent each variable. The 15 bits that these require could be stored like this (A for age, G for gender, and H for height).

int age, gender, height, packed_info;
    
. . .   // Assign values 

// Pack as AAAAAAA G HHHHHHH using shifts and "or"
packed_info = (age << 8) | (gender << 7) | height;

// Unpack with shifts and masking using "and"
height = packed_info & 0x7F;   // This constant is binary ...01111111
gender = (packed_info >> 7) & 1;
age    = (packed_info >> 8);


If you're using a CPU whose shift speed depends on the distance of the shift, you can use the following nested expression to pack the fields. However, I believe most newer CPUs don't depend on the shift distance.

packed_info = (((age << 1) | gender) << 7) | height;

Setting flag bits

Some library functions take an int that contains bits, each of which represents a true/false (bool) value. This saves a lot of space and can be fast to process. [needs example]
Don't confuse && and &

Don't confuse &&, which is the short-circuit logical and, with &, which is the uncommon bitwise and. They may not produce the same result in a logical expression.
Shift left multiplies by 2; shift right divides by 2

On some older computers is was faster to shift instead of multiply or divide by a power of two. For example, to multiply x by 8 and put it in y,

y = x << 3;  // Assigns 8*x to y.

Flipping between on and off with xor

Sometimes xor is used to flip between 1 and 0.

x = x ^ 1;   // or the more cryptic x ^= 1;

In a loop this will change x alternately between 0 and 1.
Exchanging values with xor

Here's some weird code I ran across once. It uses xor to exchange two values (x and y). Never use it; this is just a curiosity from the museum of bizarre code.

x = x ^ y;
y = x ^ y;
x = x ^ y;

	15.2
16. Design patterns

	16.1 Singelton

		16.1.1 First example


Singleton Pattern & its implementation with C++
Singleton is one of the commonly used patterns in object oriented developments. In this article I am discussing abt this pattern in general and how we can implement this pattern with C++.
Introduction

Suppose we have to use a single object of a class throughout the lifetime of an application. In C++, it is possible to declare a global object, which can be used anywhere inside the program. But a good object oriented design strictly prohibits the use of global variables or methods, since they are against the fundamental principles of object orientation like data encapsulation or data hiding. More over, most latest object oriented programming languages like JAVA or C# do not support global variables or functions.

Another practical solution to get a single object is by declaring a class, which contains only static methods. A static class is loaded into memory when the execution of the program starts and it remains there till the application ends. Remember that for invoking a static method of a class, it is not necessary to create an instance of the class. But remember that a class with only static methods and variables are not a good object oriented design. A class of static methods unfortunately breaks down to a list of functions or utilities.

When we want to create only one instance of a class in a truly object oriented fashion by adhering to the basic principles of object oriented programming, the Singleton patterns are used. The Singleton Pattern comes under that classification of Creational Pattern, which deals with the best ways to create objects. The Singleton Design pattern is used, where only one instance of an object is needed throughout the lifetime of an application. The Singleton class is instantiated at the time of first access and same instance is used thereafter till the application quits.

There are very good non-software examples available in real world for Singleton patterns. The office of the Principal of my college is a Singleton. The University specifies the means by which a principal is selected, limits the term of office, and defines the order of succession. As a result, there can be at most one active principal at any given time. Regardless of the personal identity of the principal, the title, "The Principal" is a global point of access that identifies the person in the office.

The Singletons are often used to control access to resources such as database connections or sockets. Suppose we have a license for only one connection for our database. A Singleton connection object makes sure that only one connection can be made at any time.

It is pretty easy to implement the Singleton Pattern in any object oriented programming languages like C++, JAVA or C#. There are lots of different ways to implement the Singleton Pattern. But by using a private constructor and a static method to create and return an instance of the class is a popular way for implementing Singleton Pattern. The UML representation of a Singleton Pattern is shown below.

C++ Implementation

/*
Creational Pattern: SINGLETON
Author: Rajesh V.S
Language: C++
Email: rajeshvs@msn.com
*/

#include <iostream>


using namespace std;

class Singleton
{
private:
    static bool instanceFlag;
    static Singleton *single;
    Singleton()
    {
        //private constructor

    }
public:
    static Singleton* getInstance();
    void method();
    ~Singleton()
    {
        instanceFlag = false;
    }
};

bool Singleton::instanceFlag = false;
Singleton* Singleton::single = NULL;
Singleton* Singleton::getInstance()
{
    if(! instanceFlag)
    {
        single = new Singleton();
        instanceFlag = true;
        return single;
    }
    else
    {
        return single;
    }
}

void Singleton::method()
{
    cout << "Method of the singleton class" << endl;
}

int main()
{
    Singleton *sc1,*sc2;
    sc1 = Singleton::getInstance();
    sc1->method();
    sc2 = Singleton::getInstance();
    sc2->method();

    return 0;
}


		16.1.2 2nd example
Introduction

In the course of developing software applications, repetitive patterns emerge as the application is developed. As whole software systems are developed, many of these same patterns become evident at scale.

This concept of repetitive pattern is evident in other applications. One such application is automobile manufacturing. Many different automobile models share the same sub-assemblies from the most basic components, such as light bulbs and fasteners, to larger assemblies, such as chassis and engines.

In homebuilding, the repetitive pattern concept applies to screws and nails as well as to whole building electrical distribution systems. Whether a team is assembled to create a new automobile or a new building design, it usually does not have to ponder problems that were solved before. If a team assigned to design and build a house had to rethink and design every single component of the house, the whole process would take much longer than it currently does. Design decisions such as the height of a door or the function of a light switch are well understood. A house designer does not have to redesign and reconstruct a different type of device to deliver and collect water in order to meet a requirement to supply hand washing functionality to different parts of the house: a standard sink, as well as a standard interface of hot and cold water inputs and drain water output, are well understood components of house construction. The repetitive pattern concept can be applied over and over to nearly everything we surround ourselves with, including software.

The automobile and homebuilding examples help visualize some general abstract concepts in software design and construction. The concept of well-defined general purpose units of functionality that are well understood is the motivation for design patterns and the focus of two other design pattern articles, Exploring the Factory Design Pattern and Exploring the Observer Design Pattern. These patterns cover nearly every aspect of object-oriented software design including object creation, object interaction, and object lifetime. For the scope of this article, we are going to discuss the Singleton pattern, which lives in a family of creational patterns.

Creational patterns dictate how and when objects get created. Many instances require special behavior that can only be solved though creational techniques, rather than trying to force a desired behavior after an instance is created. One of the best examples of this type of behavioral requirement is contained in the Singleton pattern. The Singleton pattern was formally defined in the classic reference, Design Patterns: Elements of Reusable Software by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides (also known as the Gang of Four, or GoF). This pattern is one of the least complicated, as well as most popular, in Design Patterns. However, as we will see, there can be problems with implementing this pattern. This article attempts to examine the Singleton pattern from its beginning though various early implementations, as well as how to best use it in MicrosoftÂ® .NET application development.
Singleton Pattern

The intent of the Singleton pattern as defined in Design Patterns is to "ensure a class has only one instance, and provide a global point of access to it".

What problem does this solve, or put another way, what is our motivation to use it? In nearly every application, there is a need to have an area from which to globally access and maintain some type of data. There are also cases in object-oriented (OO) systems where there should be only one class, or a predefined number of instances of a class, running at any given time. For example, when a class is being used to maintain an incremental counter, the simple counter class needs to keep track of an integer value that is being used in multiple areas of an application. The class needs to be able to increment this counter as well as return the current value. For this situation, the desired class behavior would be to have exactly one instance of a class that maintains the integer and nothing more.

At first glance, one might be tempted to create an instance of a counter class as a just a static global variable. This is a common technique but really only solves part of the problem; it solves the problem of global accessibility, but does nothing to ensure that there is only one instance of the class running at any given time. The responsibility of having only one instance of the class should fall on the class itself and not on the user of the class. The users of the class should always be free from having to monitor and control the number of running instances of the class.

What is needed is a way to control how class instances are created and then ensure that only one gets created at any given time. This would give us exactly the behavior we require and free a client from having to know any class details.
Logical Model

The model for a singleton is very straightforward. There is (usually) only one singleton instance. Clients access the singleton instance through one well-known access point. The client in this case is an object that needs access to a sole instance of a singleton. Figure 1 shows this relationship graphically.

Ee817670.singletondespatt01(en-us,PandP.10).gif

Figure 1. Singleton pattern logical model
Physical Model

The physical model for the Singleton pattern is also very simple. However, there are several slightly different ways that singletons have been implemented over time. Let's look at the original GoF singleton implementation. Figure 2 shows a UML model of the original Singleton pattern as defined in Design Patterns.

Ee817670.singletondespatt02(en-us,PandP.10).gif

Figure 2. Singleton pattern physical model from design patterns

What we see is a simple class diagram showing that there is a private static property of a singleton object as well as public method Instance() that returns this same property. This is really the core of what makes a singleton. The other properties and methods are there to show additional operations that may be allowed on the class. For the purpose of this discussion, let's focus on the instance property and method.

Clients access any instance of a singleton only through the Instance method. How the instance gets created is not defined here. What we also want to be able to do is control how and when an instance will get created. In OO development, special object creation behavior is generally best handled in the constructor for a class. This case is no different. What we can do is define when and how we construct a class instance and then keep any client from calling the constructor directly. This is the approach always used for singleton construction. Let's look at the original example from Design Patterns. The C++ Singleton Sample Implementation Code example shown below is generally considered the default implementation for a singleton. This sample has been ported to many other programming languages and generally exists everywhere in very near this same form.
C++ Singleton Sample Implementation Code

// Declaration
class Singleton {
public: 
    static Singleton* Instance();
protected: 
    Singleton();
private:
    static Singleton* _instance;
}

// Implementation 
Singleton* Singleton::_instance = 0;

Singleton* Singleton::Instance() {
    if (_instance == 0) {
        _instance = new Singleton;
    }
    return _instance;
}

Letâs examine this code for a moment. This simple class has one member variable and that is a pointer to itself. Notice that the constructor is protected and that the only public method is the Instance method. In the implementation of the Instance method, there is a control block (if) that checks to see if the member variable has been initialized, and if not creates a new instance. This lazy initialization in the control block means that the Singleton instance is initialized, or created, only on the first call to the Instance() method. For many applications, this approach works just fine. But, for multithreaded applications, this approach proves to have a potentially hazardous side effect. If two threads manage to enter the control block at the same time, two instances of the member variable could be created. To solve this, you might be tempted to merely place a critical section around the control block in order to guarantee thread safety. If you do this, then all calls to the Instance method would be serialized and could have a very negative impact on performance, depending on the application. It is for this reason that another version of this pattern was created that uses something called a double-check mechanism. The next code sample shows an example of a double-check lock using Java syntax.
		16.1.3
	16.2


17. Coding standards

	17.1 C++ Coding Standard,  http://www.possibility.com/Cpp/CppCodingStandard.html
 Contents
To make comments on this page please see the new Disqus comment section. Pferor was also nice enough to make a copy of this document available in pdf format.

|   17.1.1. Introduction
|          * Standardization is Important
|          * Standards Enforcement
|          * Accepting an Idea
|          * 6 Phases of a Project (joke)
|          * Flow Chart of Project Decision Making (joke)
|          * On Leadership 
|   17.1.2. Resources- Take a Look!
|          * General
|          * Book Recommendations 
|   17.1.3. Names
|          * Make Names Fit
|          * Include Units in Names
|          * No All Upper Case Abbreviations
|          * Class Names
|          * Class Library Names
|          * Method Names
|          * Class Attribute Names
|          * Method Argument Names
|          * Variable Names on the Stack
|          * Pointer Variables
|          * Reference Variables and Functions Returning References
|          * Global Variables
|          * Global Constants
|          * Static Variables
|          * Type Names
|          * Enum Names
|          * #define and Macro Names
|          * C Function Names
|          * C++ File Extensions 
|   17.1.4. Documentation
|          * Comments Should Tell a Story
|          * Document Decisions
|          * Use Extractable Headers
|          * Comment All Questions a Programmer May Have When Looking at Your Code
|          * Make Your Code Discoverable by Browsing
|          * Write Comments as You Code
|          * Make Gotchas Explicit
|          * Interface and Implementation Documentation
|          * Directory Documentation
|          * Include Statement Documentation
|          * Block Comments 
|   17.1.5. Complexity Management
|          * Layering
|          * Minimize Dependencies with Abstract Base Classes
|          * Liskov's Substitution Prinicple
|          * Open/Closed Principle
|          * Register/Dispatch Idiom
|          * Delegation
|          * Follow the Law of Demeter
|          * Design by Contract 
|   17.1.6. Classes
|          * Naming Class Files
|          * Class Layout
|          * What should go in public/protected/private?
|          * Prototype Source File
|          * Use Header File Guards
|          * Required Methods for a Class
|          * Method Layout
|          * Formating Methods with Multiple Arguments
|          * Different Accessor Styles
|          * Init Idiom for Initializing Objects
|          * Initialize all Variables
|          * Minimize Inlines
|          * Think About What Work to do in Constructors
|          * Don't Over Use Operators
|          * Thin vs. Thick Class Interfaces
|          * Short Methods
|          * In a Source file Indicate if a Method is Static or Virtual 
|   17.1.7. Process
|          * Use a Design Notation and Process
|          * Using Use Cases
|          * Using Stories
|          * Unified Modeling Language
|          * Code Reviews
|          * Create a Source Code Control System Early and Not Often
|          * Create a Bug Tracking System Early and Not Often
|          * Create a Wiki System Early and Not Often
|          * RCS Keyword, Change Log, and History Policy
|          * Honor Responsibilities
|          * Process Automation
|          * Tools Agreement
|          * Non-Blocking Scheduling
|          * Using Personas
|          * Use a Continuous Build System
|          * Code in the Dominant Style
|          * Run Unit Tests Before Every Check-in 
|   17.1.8. Formatting
|          * Brace {} Policy
|          * Indentation/Tabs/Space Policy
|          * Parens () with Key Words and Functions Policy
|          * A Line Should Not Exceed 78 Characters
|          * If Then Else Formatting
|          * switch Formatting
|          * Use of goto,continue,break and ?:
|          * One Statement Per Line
|          * Alignment of Declaration Blocks
|          * Document Null Statements
|          * Include static and virtual Key Words in Source File 
|   17.1.9. Exceptions
|          * Create One Exception for Each Library
|          * Selecting Between Exceptions And Asserts
|          * Be Careful Throwing Exceptions in Destructors
|          * Working With Libaries Using All Sorts of Different Policies 
|  17.1.10. Templates
|  17.1.11. Namespaces
|          * Create Unique Name Space Names
|          * Don't Globally Define using
|          * Create Shortcut Names 
|  17.1.12. Miscellaneous
|          * Be Const Correct
|          * Placement of the Const Qualifier
|          * Use Streams
|          * No Magic Numbers
|          * Error Return Check Policy
|          * To Use Enums or Not to Use Enums
|          * Macros
|          * Do Not Default If Test to Non-Zero
|          * The Bull of Boolean Types
|          * Usually Avoid Embedded Assignments
|          * Reusing Your Hard Work and the Hard Work of Others
|          * Commenting Out Large Code Blocks
|          * Use #if Not #ifdef
|          * Creating a C Function in C++
|          * Mixing C and C++
|          * No Data Definitions in Header Files
|          * Make Functions Reentrant
|          * Use the Resource Acquisition is Initialization (RAII) Idiom
|          * Remove Trailing Whitespace 
|  17.1.13. Portability
|          * Use Typedefs for Types
|          * Alignment of Class Members
|          * Compiler Dependent Exceptions
|          * Compiler Dependent RTTI 
|  17.1.14. Popular Myths
|          * Promise of OO
|          * You can't use OO and C++ on Embedded Systems 

		17.1.1. Introduction
Standardization is Important
It helps if the standard annoys everyone in some way so everyone feels they are on the same playing field. The proposal here has evolved over many projects, many companies, and literally a total of many weeks spent arguing. It is no particular person's style and is certainly open to local amendments.
Good Points
When a project tries to adhere to common standards a few good things happen:

    * Programmers can go into any code and figure out what's going on.
    * New people can get up to speed quickly.
    * People new to C++ are spared the need to develop a personal style and defend it to the death.
    * People new to C++ are spared making the same mistakes over and over again.
    * People make fewer mistakes in consistent environments.
    * Programmers have a common enemy :-) 

Bad Points
Now the bad:

    * The standard is usually stupid because it was made by someone who doesn't understand C++.
    * The standard is usually stupid because it's not what I do.
    * Standards reduce creativity.
    * Standards are unnecessary as long as people are consistent.
    * Standards enforce too much structure.
    * People ignore standards anyway.
    * Standards can be used as a reason for NIH (not invented here) because the new/borrowed code won't follow the standard. 

Discussion
The experience of many projects leads to the conclusion that using coding standards makes the project go smoother. Are standards necessary for success? Of course not. But they help, and we need all the help we can get! Be honest, most arguments against a particular standard come from the ego. Few decisions in a reasonable standard really can be said to be technically deficient, just matters of taste. So be flexible, control the ego a bit, and remember any project is fundamentally a team effort.

Standards Enforcement
First, any serious concerns about the standard should be brought up and worked out within the group. Maybe the standard is not quite appropriate for your situation. It may have overlooked important issues or maybe someone in power vehemently disagrees with certain issues :-)

In any case, once finalized hopefully people will play the adult and understand that this standard is reasonable, and has been found reasonable by many other programmers, and therefore is worthy of being followed even with personal reservations.

Failing willing cooperation it can be made a requirement that this standard must be followed to pass a code inspection.

Failing that the only solution is a massive tickling party on the offending party.

Accepting an Idea

   |1. It's impossible.
   |2. Maybe it's possible, but it's weak and uninteresting.
   |3. It is true and I told you so.
   |4. I thought of it first.
   |5. How could it be otherwise. 

If you come to objects with a negative preconception please keep an open mind. You may still conclude objects are bunk, but there's a road you must follow to accept something different. Allow yourself to travel it for a while.
6 Phases of a Project

   |1. Enthusiasm
   |2. Disillusionment
   |3. Panic
   |4. A Search for the Guilty
   |5. The Punishment of the Innocent
   |6. Praise and Honor for the Non-Participants 

Flow Chart for Project Decision Making

                       +---------+
                       |  START  | 
                       +---------+
                            |
                            V            
            YES       +------------+      NO
      +---------------|  DOES THE  |---------------+               
      |               | DAMN THING |               |
      V               |    WORK?   |               V    
+------------+        +------------+        +--------------+  NO
| DON'T FUCK |                              | DID YOU FUCK |-----+
| WITH IT    |                              |   WITH IT?   |     |
+------------+                              +--------------+     |
      |                                            |             |
      |                                            | YES         |
      |                                            V             |
      |  +------+     +-------------+       +---------------+    |
      |  | HIDE |  NO | DOES ANYONE |<------| YOU DUMBSHIT! |    |                 
      |  |  IT  |<----|    KNOW?    |       +---------------+    |
      |  +------+     +-------------+                            |
      |      |               |                                   |
      |      |               V                                   |
      |      |        +-------------+       +-------------+      |
      |      |        |   YOU POOR  |  YES  |  WILL YOU   |      |     
      |      |        |   BASTARD   |<------| CATCH HELL? |<-----+
      |      |        +-------------+       +-------------+
      |      |               |                     |
      |      |               |                     | NO
      |      |               V                     V
      |      V        +-------------+       +------------+ 
      +-------------->|    STOP     |<------| SHITCAN IT |
                      +-------------+       +------------+
      
                              

Leadership
I wish i had said this, but it was said by asd@asd.com in comp.software-eng.

Leaders:

   |1. lead by example
   |2. don't ask anything of anyone they wouldn't do themselves
   |3. are called on to make difficult and unpopular decisions
   |4. keep the team focused
   |5. reward/support their team in whatever they do
   |6. keep/clear unnecessary crap out of the way of the team 

Consensus is great. If it lasts for the project lifecycle, consider yourself blessed. I've been on a couple projects where two engineers just blantantly disagreed! They were always:

Programmer #1 says " x = 1"
Programmer #2 says " x != 1"

That's when a Project Leader is required. Unless you want to flip a coin.

Oh yah - one more thing. Project leaders: TAKE the blame when things go wrong and SHARE the credit when things go right.

Ain't easy - but it's the way I try to run my life.

		17.1.2. Resources- Take a Look!
General

    * Code Reviews. If you are interested in coding standards you may also be interested in Code Review Standards I have created at http://www.possibility.com/epowiki/Wiki.jsp?page=CodeReviews.
    * Design Stories
    * OO Info Sources
    * Designing Qt-Style C++ APIs - A good paper on API I design for C++. I don't agree with everything, but it is good.
    * Unified Modeling Language (UML)
    * OO FAQ - All You Wanted to Know About OO
    * C++ FAQ LITE
    * C++ Source Libraries
    * C++ Tutorials
    * ACE C++ Library
    * Collection of Other Standards
    * Design by Contract from Eiffle
    * C++ isn't Perfect, Here are Some Reasons Why
    * Doxygen - is a 'javadoc' like utility that extracts comments and relevant information from your C++/C programs and generates HTML pages from it.
    * Const Correctness - A very nice article on const correctness by Chad Loder.
    * Abraxis Code Check - A program for checking code for coding standard violations and other problems. 

Book Recommendations
What are some good C++ books you can buy for you and your team?

   |1. Koenig/Moo's "Accelerated C++"
   |2. Lippman/Moo's "C++ Primer" 4th Edition
   |3. Bruce Eckel's "Thinking In C++"
   |4. Scott Meyers "Effective C++"
   |5. Dewhurst's "C++ Gotchas"
   |6. Meyers' "Effective STL"
   |7. Josuttis' "The C++ Standard Library"
   |8. Vandevoorde/Josuttis' "C++ Templates"
   |9. Langer/Kreft's "Standard C++ IOStreams and Locales"
  |10. Sutter's "Exceptional C++"
  |11. Sutter's "More Exceptional C++ and Exceptional C++ Style"
  |12. Martin's "Agile Software Development: Principles, Patterns, and Practices" 

		17.1.3. Names

Make Names Fit
Names are the heart of programming. In the past people believed knowing someone's true name gave them magical power over that person. If you can think up the true name for something, you give yourself and the people coming after power over the code. Don't laugh!

A name is the result of a long deep thought process about the ecology it lives in. Only a programmer who understands the system as a whole can create a name that "fits" with the system. If the name is appropriate everything fits together naturally, relationships are clear, meaning is derivable, and reasoning from common human expectations works as expected.

If you find all your names could be Thing and DoIt then you should probably revisit your design.

Class Names

    * Name the class after what it is. If you can't think of what it is that is a clue you have not thought through the design well enough.
    * Compound names of over three words are a clue your design may be confusing various entities in your system. Revisit your design. Try a CRC card session to see if your objects have more responsibilities than they should.
    * Avoid the temptation of bringing the name of the class a class derives from into the derived class's name. A class should stand on its own. It doesn't matter what it derives from.
    * Suffixes are sometimes helpful. For example, if your system uses agents then naming something DownloadAgent conveys real information. 

Method and Function Names

    * Usually every method and function performs an action, so the name should make clear what it does: CheckForErrors() instead of ErrorCheck(), DumpDataToFile() instead of DataFile(). This will also make functions and data objects more distinguishable.

      Classes are often nouns. By making function names verbs and following other naming conventions programs can be read more naturally.

    * Suffixes are sometimes useful:
          o Max - to mean the maximum value something can have.
          o Cnt - the current count of a running count variable.
          o Key - key value. 

      For example: RetryMax to mean the maximum number of retries, RetryCnt to mean the current retry count.

    * Prefixes are sometimes useful:
          o Is - to ask a question about something. Whenever someone sees Is they will know it's a question.
          o Get - get a value.
          o Set - set a value. 

      For example: IsHitRetryLimit.

Include Units in Names
If a variable represents time, weight, or some other unit then include the unit in the name so developers can more easily spot problems. For example:

uint32 mTimeoutMsecs;
uint32 mMyWeightLbs;

Better yet is to make a variable into a class so bad conversions can be caught.

No All Upper Case Abbreviations

    * When confronted with a situation where you could use an all upper case abbreviation instead use an initial upper case letter followed by all lower case letters. No matter what. 

Justification

    * People seem to have very different intuitions when making names containing abbreviations. It's best to settle on one strategy so the names are absolutely predictable.

      Take for example NetworkABCKey. Notice how the C from ABC and K from key are confused. Some people don't mind this and others just hate it so you'll find different policies in different code so you never know what to call something. 

Example

   class FluidOz             // NOT FluidOZ
   class NetworkAbcKey       // NOT NetworkABCKey

Class Names

    * Use upper case letters as word separators, lower case for the rest of a word
    * First character in a name is upper case
    * No underbars ('_') 

Justification

    * Of all the different naming strategies many people found this one the best compromise. 

Example

   class NameOneTwo
  
   class Name

Class Library Names

    * Now that name spaces are becoming more widely implemented, name spaces should be used to prevent class name conflicts among libraries from different vendors and groups.
    * When not using name spaces, it's common to prevent class name clashes by prefixing class names with a unique string. Two characters is sufficient, but a longer length is fine. 

Example
John Johnson's complete data structure library could use JJ as a prefix, so classes would be:

   class JjLinkList
   {
   }

Method Names

    * Use the same rule as for class names. 

Justification

    * Of all the different naming strategies many people found this one the best compromise. 

Example

   class NameOneTwo
   {
   public:
      int                   DoIt();
      void                  HandleError();
   }

Class Attribute Names

    * Attribute names should be prepended with the character 'm'.
    * After the 'm' use the same rules as for class names.
    * 'm' always precedes other name modifiers like 'p' for pointer. 

Justification

    * Prepending 'm' prevents any conflict with method names. Often your methods and attribute names will be similar, especially for accessors. 

Example

   class NameOneTwo
   {
   public:
      int                   VarAbc();
      int                   ErrorNumber();
   private:
      int                   mVarAbc;
      int                   mErrorNumber;
      String*               mpName;
   }

Method Argument Names

    * The first character should be lower case.
    * All word beginnings after the first letter should be upper case as with class names. 

Justification

    * You can always tell which variables are passed in variables.
    * You can use names similar to class names without conflicting with class names. 

Example

   class NameOneTwo
   {
   public:
      int                   StartYourEngines(
                               Engine& rSomeEngine, 
                               Engine& rAnotherEngine);
   }

Variable Names on the Stack

    * use all lower case letters
    * use '_' as the word separator. 

Justification

    * With this approach the scope of the variable is clear in the code.
    * Now all variables look different and are identifiable in the code. 

Example

   int
   NameOneTwo::HandleError(int errorNumber)
   {
      int            error= OsErr();
      Time           time_of_error;
      ErrorProcessor error_processor;
      Time*          p_out_of_time= 0;
   }

The standard pointer notation is not entirely satisfactory because it doesn't look quite right, but it is consistent.

How do you handle statics? There's never a reason to have a static local to a function so there's no reason to invent a syntax for it. But like for most absolute rules, there is an exception, that is when making singletons. Use a "s_" prefix in this case. Take a look at Singleton Pattern for more details.

Pointer Variables

    * pointers should be prepended by a 'p' in most cases
    * place the * close to the pointer type not the variable name 

Justification

    * The idea is that the difference between a pointer, object, and a reference to an object is important for understanding the code, especially in C++ where -> can be overloaded, and casting and copy semantics are important.
    * Pointers really are a change of type so the * belongs near the type. One reservation with this policy relates to declaring multiple variables with the same type on the same line. In C++ the pointer modifier only applies to the closest variable, not all of them, which can be very confusing, especially for newbies. You want to have one declaration per line anyway so you can document each variable. 

Example

  String* pName= new String;

  String* pName, name, address; // note, only pName is a pointer.

Reference Variables and Functions Returning References

    * References should be prepended with 'r'. 

Justification

    * The difference between variable types is clarified.
    * It establishes the difference between a method returning a modifiable object and the same method name returning a non-modifiable object. 

Example

   class Test
   {
   public:
      void               DoSomething(StatusInfo& rStatus);

      StatusInfo&        rStatus();
      const StatusInfo&  Status() const;

   private:
      StatusInfo&        mrStatus;
   }

Global Variables

    * Global variables should be prepended with a 'g'. 

Justification

    * It's important to know the scope of a variable. 

Example

    Logger  gLog;
    Logger* gpLog;

Global Constants

    * Global constants should be all caps with '_' separators. 

Justification
It's tradition for global constants to named this way. You must be careful to not conflict with other global #defines and enum labels.
Example

    const int A_GLOBAL_CONSTANT= 5;

Static Variables

    * Static variables may be prepended with 's'. 

Justification

    * It's important to know the scope of a variable. 

Example

   class Test
   {
   public:
   private:
      static StatusInfo msStatus;
   }

Type Names

    * When possible for types based on native types make a typedef.
    * Typedef names should use the same naming policy as for a class with the word Type appended. 

Justification

    * Of all the different naming strategies many people found this one the best compromise.
    * Types are things so should use upper case letters. Type is appended to make it clear this is not a class. 

Example

   typedef uint16  ModuleType;
   typedef uint32  SystemType;

Enum Names
Labels All Upper Case with '_' Word Separators
This is the standard rule for enum labels.
Example

   enum PinStateType
   {
      PIN_OFF,
      PIN_ON
   };

Enums as Constants without Class Scoping
Sometimes people use enums as constants. When an enum is not embedded in a class make sure you use some sort of differentiating name before the label so as to prevent name clashes.
Example

   enum PinStateType            If PIN was not prepended a conflict 
   {                            would occur as OFF and ON are probably
      PIN_OFF,                  already defined.
      PIN_ON
   };

Enums with Class Scoping
Just name the enum items what you wish and always qualify with the class name: Aclass::PIN_OFF.
Make a Label for an Error State
It's often useful to be able to say an enum is not in any of its valid states. Make a label for an uninitialized or error state. Make it the first label if possible.
Example

enum { STATE_ERR,  STATE_OPEN, STATE_RUNNING, STATE_DYING};

#define and Macro Names

    * Put #defines and macros in all upper using '_' separators. 

Justification
This makes it very clear that the value is not alterable and in the case of macros, makes it clear that you are using a construct that requires care.

Some subtle errors can occur when macro names and enum labels use the same name.
Example

#define MAX(a,b) blah
#define IS_ERR(err) blah

C Function Names

    * In a C++ project there should be very few C functions.
    * For C functions use the GNU convention of all lower case letters with '_' as the word delimiter. 

Justification

    * It makes C functions very different from any C++ related names. 

Example

   int
   some_bloody_function()
   {
   }

C++ File Extensions
In short: Use the .h extension for header files and .cc for source files.

For some reason an odd split occurred in early C++ compilers around what C++ source files should be called. C header files always use the .h and C source files always use the .c extension. What should we use for C++?

The short answer is as long as everyone on your project agrees it doesn't really matter. The build environment should be able to invoke the right compiler for any extension. Historically speaking here have been the options:

    * Header Files: .h, .hh, .hpp
    * Source Files: .C, .cpp, .cc 

Header File Extension Discussion
Using .hh extension is not widely popular but makes a certain kind of sense. C header files use .h file extension and C++ based header files use .hh file extension. The problem is if we consider a header file an interface to a service then we can have a C interface to a service and C++ interface to the service in the same file. Using preprocessor directives this is possible and common. The recommendation is to stick with using the .h extension.

Source File Extension Discussion
The problem with the .C extension is that it is indistinguishable from the .c extensions in operating systems that aren't case sensitive. Yes, this is a UNIX vs. windows issue. Since it is a simple step aiding portability we won't use the .C extension. The .cpp extension is a little wordy. So the .cc extension wins by default.

		17.1.4. Documentation

Comments Should Tell a Story
Consider your comments a story describing the system. Expect your comments to be extracted by a robot and formed into a man page. Class comments are one part of the story, method signature comments are another part of the story, method arguments another part, and method implementation yet another part. All these parts should weave together and inform someone else at another point of time just exactly what you did and why.

Document Decisions
Comments should document decisions. At every point where you had a choice of what to do place a comment describing which choice you made and why. Archeologists will find this the most useful information.

Use Extractable Headers
Use a document extraction system like Doxygen when documenting your code.

These headers are structured in such a way as they can be parsed and extracted. They are not useless like normal headers. So take time to fill them out. If you do it right once no more documentation may be necessary.

As part of your nighlty build system have a step the generates the documentation from the source. Then index the source using a tool like Lucene. Have a front end to the search so developers can do full text searches on nightly builds and for release builds. This is a wonderfully useful feature.

The next step in automation is to front the repository with a web server documentation can directly refer to a source file with a URL.

Comment All Questions a Programmer May Have When Looking at Your Code
At every point in your code think about what questions a programmer may have about the code. It's crucial you answer all those questions somehow, someway. If you don't, as the code writer, answer those questions, who will?

If you think your code is so clear and wonderful that nobody will have any questions then you are lying to yourself. I have never seen a large system with this wonderful self-documenting code feature. I've seen very few small libraries are even a single class that are so wonderfully self-documented.

You have a lot of tools at your disposal to answer questions:

   |1. A brain to think up the questions you should be answering. Why? Who? When? How? What?
   |2. Variable names.
   |3. Class names.
   |4. Class decomposition.
   |5. Method decomposition.
   |6. File names.
   |7. Documentation at all levels: package, class, method, attribute, inline. 

The better you are at orchestrating all these elements together the clearer your code will be to everyone else.

I don't really consider unit tests a question answering device because if you can't understand the code by reading it, reading something else about the code you don't understand won't help you understand it better.

Make Your Code Discoverable by Browsing
Programmers should be able to navigate your code by looking at markers in the code, namely the names and the directory structure. Nothing is more frustrating to than to have to look at pile of code and have no idea what it's organizing principles are.

Have a logicanl directory structure. Have directories called doc, lib, src, bin, test, pkg, install, etc and whatever, so I at least have some idea where stuff is. People use the weirdest names and lump everything together so that it it can be detangles. Clear thought is evidenced from the beginning by a directory stucture.

Don't put more than one class in a file. Otherwise, how will I know its there when I browse your code? Should I really need to use search to find every last thing? Can't I just poke around the code and find it? I can if you organize your code.

Name your files after your classes. I didn't believe this one until I saw it. Why you name a file different than the class? How I am possibly supposed to know what's in the file otherwise?

Write Comments as You Code
You won't every go back later and document your code. You just won't. Don't lie to yourself, the world, and your mother by saying that you will.

So when you do something document it right then and there. When you create a class- document it. When you create a method- document it. And so on. That way when you finish coding you will also be finished documenting.

I advocate simultaneously writing code, writing tests, and writing documentaiton. Which comes first depends on you and the problem. I don't think there is any rule that says which should come first. On the path to getting stuff done I'll take the entrance that seems easiest to me at the time. Once on the path it's easy to follow the entire trail.

Won't this break the flow? No, I think it improves flow because it keeps you mindful of what you are doing, why you are doing, and how it fits in the big picture. My take on TDD (test driven development) is that it's not the tests that are really important, it's that the tests keep you mindful while programming. A test means you are keeping everything in you mind at once you need to remember to successfully code something up. As you can't keep large chunks in your mind then smaller chunks are better. Writing a test forces you to remember what your code is supposed to accomplish. It's forcing you to also think about the use case/story/intent behind why you are writing the code.

The result is a pointed mind that has focussed all its powers on doing one thing. When you can bring that focus to you programming you can be successful. The tests are really secondary. If your system/acceptance tests can't find bugs you are screwed anyway. And I find code written mindfully, one step at a time, has very few bugs. Unit tests are just one definition of a "step." You can use the orignial story you are implementing as a step as well. I use unit tests more as a mental focussing device while developing, like Zen Archery, than for the actual tests. After development unit tests are very useful in making sure code doesn't break. So I am not saying unit tests aren't useful. I just don't think they are the real reason behind why TDD generates working code. With a clear well functioning focussed mind we generate working code. But getting into that state is hard.

Writing comments simultaneously with all other aspects of development deepens your mindfulness because you are thinking about everything at once. All the interconnections are present in your brain because you are explaining the intent behind what you are doing.

There's a saying that you don't know something until you teach it. Comments are teaching what you are doing to someone else. When you are writing comments you must generate the thoughts to teach, to explain to someone else the intent behing what you are doing. It's very difficult to make a coding error when all this context is hot in your mind.

I'll go back and forth between documenting, testing, and coding. I'll let the problem dictate what happens when as I am working my way through solving the problem. Saying testing should always come first is too simple a rule and I think misses the larger point about software development.

Software is ultimately mind stuff. Using our minds better is the real methodology.

Make Gotchas Explicit
Explicitly comment variables changed out of the normal control flow or other code likely to break during maintenance. Embedded keywords are used to point out issues and potential problems. Consider a robot will parse your comments looking for keywords, stripping them out, and making a report so people can make a special effort where needed.

Gotcha Keywords

    * :TODO: topic
      Means there's more to do here, don't forget.

    * :BUG: [bugid] topic
      means there's a Known bug here, explain it and optionally give a bug ID.

    * :KLUDGE:
      When you've done something ugly say so and explain how you would do it differently next time if you had more time.

    * :TRICKY:
      Tells somebody that the following code is very tricky so don't go changing it without thinking.

    * :WARNING:
      Beware of something.

    * :COMPILER:
      Sometimes you need to work around a compiler problem. Document it. The problem may go away eventually.

    * :ATTRIBUTE: value
      The general form of an attribute embedded in a comment. You can make up your own attributes and they'll be extracted.

Gotcha Formatting

    * Make the gotcha keyword the first symbol in the comment.
    * Comments may consist of multiple lines, but the first line should be a self-containing, meaningful summary.
    * The writer's name and the date of the remark should be part of the comment. This information is in the source repository, but it can take a quite a while to find out when and by whom it was added. Often gotchas stick around longer than they should. Embedding date information allows other programmer to make this decision. Embedding who information lets us know who to ask. 

Example

   // :TODO: tmh 960810: possible performance problem
   // We should really use a hash table here but for now we'll
   // use a linear search.

   // :KLUDGE: tmh 960810: possible unsafe type cast
   // We need a cast here to recover the derived type. It should
   // probably use a virtual method or template.

See Also
See Interface and Implementation Documentation for more details on how documentation should be laid out.

Interface and Implementation Documentation
There are two main audiences for documentation:

    * Class Users
    * Class Implementors 

With a little forethought we can extract both types of documentation directly from source code.
Class Users
Class users need class interface information which when structured correctly can be extracted directly from a header file. When filling out the header comment blocks for a class, only include information needed by programmers who use the class. Don't delve into algorithm implementation details unless the details are needed by a user of the class. Consider comments in a header file a man page in waiting.
Class Implementors
Class implementors require in-depth knowledge of how a class is implemented. This comment type is found in the source file(s) implementing a class. Don't worry about interface issues. Header comment blocks in a source file should cover algorithm issues and other design decisions. Comment blocks within a method's implementation should explain even more.

Directory Documentation
Every directory should have a README file that covers:

    * the purpose of the directory and what it contains
    * a one line comment on each file. A comment can usually be extracted from the NAME attribute of the file header.
    * cover build and install directions
    * direct people to related resources:
          o directories of source
          o online documentation
          o paper documentation
          o design documentation 
    * anything else that might help someone 

Consider a new person coming in 6 months after every original person on a project has gone. That lone scared explorer should be able to piece together a picture of the whole project by traversing a source directory tree and reading README files, Makefiles, and source file headers.

Include Statement Documentation
Include statements should be documented, telling the user why a particular file was included. If the file includes a class used by the class then it's useful to specify a class relationship:

    * ISA - this class inherits from the class in the include file.
    * HASA - this class contains, that is has as a member attribute, the class in the include file. This class owns the memory and is responsible for deleting it.
    * USES - this class uses something from the include file.
    * HASA-USES - this class keeps a pointer or reference to the class in the include file, but this class does not own the memory. 

Example

#ifndef XX_h
#define XX_h

// SYSTEM INCLUDES
//
#include                              // standard IO interface
#include                             // HASA string interface
#include                               // USES auto_ptr


Notice how just by reading the include directives the code is starting to tell you a story of why and how it was built.

Block Comments
Use comments on starting and ending a Block:

{  
   // Block1  (meaningful comment about Block1)
  ... some code

  {  
     // Block2  (meaningful comment about Block2)
     ... some code
  }  // End Block2

}  // End Block1

This may make block matching much easier to spot when you don't have an intelligent editor.

		17.1.5. Complexity Management

Layering
Layering is the primary technique for reducing complexity in a system. A system should be divided into layers. Layers should communicate between adjacent layers using well defined interfaces. When a layer uses a non-adjacent layer then a layering violation has occurred.

A layering violation simply means we have dependency between layers that is not controlled by a well defined interface. When one of the layers changes code could break. We don't want code to break so we want layers to work only with other adjacent layers.

Sometimes we need to jump layers for performance reasons. This is fine, but we should know we are doing it and document appropriately.

Minimize Dependencies with Abstract Base Classes
One of the most important strategies in C++ is to remove dependencies among different subsystems. Abstract base classes (ABCs) are a solid technique for dependency removal.

An ABC is an abstraction of a common form such that it can be used to build more specific forms. An ABC is a common interface that is reusable across a broad range of similar classes. By specifying a common interface as long as a class conforming to that interface is used it doesn't really matter what is the type of the derived type. This breaks code dependencies. New classes, conforming to the interface, can be substituted in at will without breaking code. In C++ interfaces are specified by using base classes with virtual methods.

The above is a bit rambling because it's a hard idea to convey. So let's use an example: We are doing a GUI where things jump around on the screen. One approach is to do something like:

   class Frog
   {
   public:
      void Jump();
   }
   class Bean
   {
   public:
      void Jump();
   }

The GUI folks could instantiate each object and call the Jump method of each object. The Jump method of each object contains the implementation of jumping behavior for that type of object. Obviously frogs and beans jump differently even though both can jump.

Unfortunately the owner of Bean didn't like the word Jump so they changed the method name to Leap. This broke the code in the GUI and one whole week was lost.

Then someone wanted to see a horse jump so a Horse class was added:

   class Horse
   {
   public:
      void Jump();
   }

The GUI people had to change their code again to add Horse.

Then someone updated Horse so that its Jump behavior was slightly different. Unfortunately this caused a total recompile of the GUI code and they were pissed.

Someone got the bright idea of trying to remove all the above dependencies using abstract base classes. They made one base class that specified an interface for jumping things:

   class Jumpable
   {
   public:
      virtual void Jump() = 0;
   }

Jumpable is a base class because other classes need to derive from it so they can get Jumpable's interface. It's an abstract base class because one or more of its methods has the = 0 notation which means the method is a pure virtual method. Pure virtual methods must be implemented by derived classes. The compiler checks.

Not all methods in an ABC must be pure virtual, some may have an implementation. This is especially true when creating a base class encapsulating a process common to a lot of objects. For example, devices that must be opened, diagnostics run, booted, executed, and then closed on a certain event may create an ABC called Device that has a method called LifeCycle which calls all other methods in turn thus running through all phases of a device's life. Each device phase would have a pure virtual method in the base class requiring implementation by more specific devices. This way the process of using a device is made common but the specifics of a device are hidden behind a common interface.

Back to Jumpable. All the classes were changed to derive from Jumpable:

   class Frog : public Jumpable
   {
   public:
      virtual void Jump() { ... }
   }

   etc ...

We see an immediate benefit: we know all classes derived from Jumpable must have a Jump method. No one can go changing the name to Leap without the compiler complaining. One dependency broken.

Another benefit is that we can pass Jumpable objects to the GUI, not specific objects like Horse or Frog:

   class Gui
   {
   public:
      void MakeJump(Jumpable*);
   }

   Gui gui;
   Frog* pFrog= new Frog;
  
   gui.MakeJump(pFrog); 

Notice Gui doesn't even know it's making a frog jump, it just has a jumpable thing, that's all it cares about. When Gui calls the Jump method it will get the implementation for Frog's Jump method. Another dependency down. Gui doesn't have to know what kind of objects are jumping.

We also removed the recompile dependency. Because Gui doesn't contain any Frog objects it will not be recompiled when Frog changes.
Downside
Wow! Great stuff! Yes but there are a few downsides:
Overhead for Virtual Methods
Virtual methods have a space and time penalty. It's not huge, but should be considered in design.
Make Everything an ABC!
Sometimes people overdo it, making everything an ABC. The rule is make an ABC when you need one not when you might need one. It takes effort to design a good ABC, throwing in a virtual method doesn't an ABC make. Pick and choose your spots. When some process or some interface can be reused and people will actually make use of the reuse then make an ABC and don't look back.

Liskov's Substitution Principle (LSP)
This principle states:

   All classes derived from a base class should be interchangeable
   when used as a base class.

The idea is users of a class should be able to count on similar behavior from all classes that derive from a base class. No special code should be necessary to qualify an object before using it. If you think about it violating LSP is also violating the Open/Closed principle because the code would have to be modified every time a derived class was added. It's also related to dependency management using abstract base classes.

For example, if the Jump method of a Frog object implementing the Jumpable interface actually makes a call and orders pizza we can say its implementation is not in the spirit of Jump and probably all other objects implementing Jump. Before calling a Jump method a programmer would now have to check for the Frog type so it wouldn't screw up the system. We don't want this in programs. We want to use base classes and feel comfortable we will get consistent behaviour.

LSP is a very restrictive idea. It constrains implementors quite a bit. In general people support LSP and have LSP as a goal.

Open/Closed Principle
The Open/Closed principle states a class must be open and closed where:

    * open means a class has the ability to be extended.
    * closed means a class is closed for modifications other than extension. The idea is once a class has been approved for use having gone through code reviews, unit tests, and other qualifying procedures, you don't want to change the class very much, just extend it. 

The Open/Closed principle is a pitch for stability. A system is extended by adding new code not by changing already working code. Programmers often don't feel comfortable changing old code because it works! This principle just gives you an academic sounding justification for your fears :-)

In practice the Open/Closed principle simply means making good use of our old friends abstraction and polymorphism. Abstraction to factor out common processes and ideas. Inheritance to create an interface that must be adhered to by derived classes. In C++ we are talking about using abstract base classes . A lot.

Register/Dispatch Idiom
Another strategy for reducing dependencies in a system is the Register/Dispatch Idiom (RDI). RDI treats large grained occurrences in a system as events. Events are identified by some unique identifier. Objects in the system register with a dispatch system for events or classes of events it is interested in. Objects that are event sources send events into the dispatch system so the dispatch system can route events to consumers.

RDI separates producers and consumers on a distributed scale. Event producers and consumers don't have to know about each other at all. Consumers can drop out of the event stream by deregistering for events. New consumers can register for events at anytime. Event producers can drop out with no ill effect to event consumers, the consumer just won't get any more events. It is a good idea for producers to have an "I'm going down event" so consumers can react intelligently.

Logically the dispatch system is a central entity. The implementation however can be quite different. For a highly distributed system a truly centralized event dispatcher would be a performance bottleneck and a single point of failure. Think of event dispatchers as being a lot of different processes cast about on various machines for redundancy purposes. Event processors communicate amongst each other to distribute knowledge about event consumers and producers. Much like a routing protocol distributes routing information to its peers.

RDI works equally well in the small, in processes and single workstations. Parts of the system can register as event consumers and event producers making for a very flexible system. Complex decisions in a system are expressed as event registrations and deregistrations. No further level of cooperation required.

More expressive event filters can also be used. The above proposal filters events on some unique ID. Often you want events filtered on more complex criteria, much like a database query. For this to work the system has to understand all data formats. This is easy if you use a common format like attribute value pairs. Otherwise each filter needs code understanding packet formats. Compiling in filter code to each dispatcher is one approach. Creating a downloadable generic stack based filter language has been used with success on other projects, being both simple and efficient.

Delegation
Delegation is the idea of a method using another object's method to do the real work. In some sense the top layer method is a front for the other method. Delegation is a form of dependency breaking. The top layer method never has to change while it's implementation can change at will.

Delegation is an alternative to using inheritance for implementation purposes. One can use inheritance to define an interface and delegation to implement the interface.

Some people feel delegation is a more robust form of OO than using implementation inheritance. Delegation encourages the formation of abstract class interfaces and HASA relationships. Both of which encourage reuse and dependency breaking.
Example

   class TestTaker
   {
   public:
      void WriteDownAnswer()   { mPaidTestTaker.WriteDownAnswer(); } 
   private:
      PaidTestTaker  mPaidTestTaker;
   }

In this example a test taker delegates actually answering the question to a paid test taker. Not ethical but a definite example of delegation!

Follow the Law of Demeter
The Law of Demeter states (Wikipedia): An object A can request a service (call a method) of an object instance B, but object A cannot âreach throughâ object B to access yet another object to request its services. Doing so would mean that object A implicitly requires greater knowledge of object Bâs internal structure. Instead, Bâs class should be modified if necessary so that object A can simply make the request directly of object B, and then let object B propagate the request to any relevant subcomponents. If the law is followed, only object B knows its internal structure.
Justification
The purpose of this law is to break dependencies so implementations can change without breaking code. If an object wishes to remove one of its contained objects it won't be able to do so because some other object is using it. If instead the service was through an interface the object could change its implementation anytime without ill effect.
Caveat
As for most laws the Law of Demeter should be ignored in certain cases. If you have a really high level object that contains a lot of subobjects, like a car contains thousands of parts, it can get absurd to created a method in car for every access to a subobject.
Example

   class SunWorkstation
   {
   public:
      void          UpVolume(int amount) { mSound.Up(amount); }

      SoundCard     mSound;

   private:
      GraphicsCard  mGraphics;
   }

   SunWorksation sun;

   Do   : sun.UpVolume(1);
   Don't: sun.mSound.Up(1);


Design by Contract
The idea of design by contract is strongly related to LSP . A contract is a formal statement of what to expect from another party. In this case the contract is between pieces of code. An object and/or method states that it does X and you are supposed to believe it. For example, when you ask an object for its volume that's what you should get. And because volume is a verifiable attribute of a thing you could run a series of checks to verify volume is correct, that is, it satisfies its contract.

The contract is enforced in languages like Eiffel by pre and post condition statements that are actually part of the language. In other languages a bit of faith is needed.

Design by contract when coupled with language based verification mechanisms is a very powerful idea. It makes programming more like assembling spec'd parts.
Using Design by Contract

   |1. DO NOT PUT "REAL" CODE IN DBC CALLS.. Dbc calls should only test conditions. No code that can't be compiled out should be included in Dbc calls.
   |2. Every method should define its pre and post conditions.
   |3. Every class should define its invariants.
   |4. Callers are responsible for checking preconditions. An object may not and is not required to test for assertion violations.
   |5. Method pre-conditions should be documented in a method's interface documentation.
   |6. Pre-conditions can be weakened by derived classes.
   |7. Post-conditions can be strengthened by derived classes.
   |8. Every Class Should:
         |1. Develop its class invariants.
         |2. Code its invariants and call them in its operations.
         |3. Document its invariants in the class documentation. 
      Yes, this takes a lot of work, but high availibility is the system's __primary goal__, meeting this goal requires a lot of work and effort by each programmer.
   |9. Every Method Should:
         |1. Develop a list of exceptions.
         |2. Develop operation pre-conditions.
         |3. Develop operation post-conditions.
         |4. Code the exceptions, pre, and post conditions.
         |5. Document the exceptions, pre, and post conditions. 
      Yes, this takes a lot of work, but high availibility is the system's __primary goal__, meeting this goal requires a lot of work and effort by each programmer. 

		17.1.6. Classes

Naming Class Files
Class Definition in One File
Each class definition should be in its own file where each file is named directly after the class's name:

   ClassName.h

Implementation in One File
In general each class should be implemented in one source file:

   ClassName.cc   // or whatever the extension is: cpp, c++

But When it Gets Really Big...
If the source file gets too large or you want to avoid compiling templates all the time then add additional files named according to the following rule:

   ClassName_section.C

section is some name that identifies why the code is chunked together. The class name and section name are separated by '_'.

Class Layout
A common class layout is critical from a code comprehension point of view and for automatically generating documentation. C++ programmers, through a new set of tools, can enjoy the same level generated documentation Java programmers take for granted.

Class and Method Documentation
It is recommended a program like Doxygen be used to document C++ classes, method, variables, functions, and macros. The documentation can be extracted and put in places in a common area for all programmers to access. This saves programmers having to read through class headers. Documentation generation should be integrated with the build system where possible.

Template
Please use the following template when creating a new class.

/**  A one line description of the class.  
 *
 * #include "XX.h" <BR>
 * -llib 
 *
 * A longer description.
 *  
 * @see something
 */

#ifndef XX_h
#define XX_h

// SYSTEM INCLUDES
//

// PROJECT INCLUDES
//

// LOCAL INCLUDES
//

// FORWARD REFERENCES
//


class XX
{
public:
// LIFECYCLE

   /** Default constructor.
    */
   XX(void);


   /** Copy constructor.
    * 
    * @param from The value to copy to this object.
    */
   XX(const XX& from);


   /** Destructor.
    */
   ~XX(void);


// OPERATORS

   /** Assignment operator.
    *
    * @param from THe value to assign to this object.
    *
    * @return A reference to this object.
    */
   XX&                     operator=(const XX& from);  

// OPERATIONS                       
// ACCESS
// INQUIRY

protected:
private:
};

// INLINE METHODS
//

// EXTERNAL REFERENCES
//

#endif  // _XX_h_

Required Methods Placeholders
The template has placeholders for required methods . You can delete them or implement them.
Ordering is: public, protected, private
Notice that the public interface is placed first in the class, protected next, and private last. The reasons are:

    * programmers should care about a class's interface more than implementation
    * when programmers need to use a class they need the interface not the implementation 

It makes sense then to have the interface first. Placing implementation, the private section, first is a historical accident as the first examples used the private first layout. Over time emphasis has switched deemphasizing a class's interface over implementation details.
LIFECYCLE
The life cycle section is for methods that control the life cycle of an object. Typically these methods include constructors, destructors, and state machine methods.
OPERATORS
Place all operators in this section.
OPERATIONS
Place the bulk of a class's non access and inquiry method methods here. A programmer will look here for the meat of a class's interface.
ACCESS
Place attribute accessors here.
INQUIRY
These are the Is* methods. Whenever you have a question to ask about an object it can be asked via in Is method. For example: IsOpen() will indicate if the object is open. A good strategy is instead of making a lot of access methods you can turn them around to be questions about the object thus reducing the exposure of internal structure. Without the IsOpen() method we might have had to do: if (STATE_OPEN == State()) which is much uglier.

What should go in public/protected/private?
Public Section
Only put an object's interface in the public section. DO NOT expose any private data items in the public section. At least encapsulate access via access methods. Ideally your method interface should make most access methods unnecessary. Do not put data in the public interface.
Protected and Private Section
What should go into the protected section versus the private section is always a matter of debate.
All Protected
Some say there should be no private section and everything not in the public section should go in the protected section. After all, we should allow all our children to change anything they wish.

All Private
Another camp says by making the public interface virtual any derived class can change behavior without mucking with internals.

Wishy Washy
Rationally decide where elements should go and put them there. Not very helpful.
And the Winner Is...
Keeping everything all private seems the easiest approach. By making the public methods virtual flexibility is preserved.

Prototype Source File

#include "XX.h"  // class implemented


/////////////////////////////// PUBLIC ///////////////////////////////////////

//============================= LIFECYCLE ====================================

XX::XX()
{
}// XX

XX::XX(const XX&)
{
}// XX

XX::~XX()
{
}// ~XX


//============================= OPERATORS ====================================

XX& 
XX::operator=(const XX&);
{
   return *this;

}// =

//============================= OPERATIONS ===================================
//============================= ACESS      ===================================
//============================= INQUIRY    ===================================
/////////////////////////////// PROTECTED  ///////////////////////////////////

/////////////////////////////// PRIVATE    ///////////////////////////////////

Use Header File Guards
Include files should protect against multiple inclusion through the use of macros that "guard" the files.
When Not Using Namespces

#ifndef filename_h
#define filename_h

#endif 


The new line after the endif if is required by some compilers.

When Using Namespaces
If namespaces are used then to be completely safe:

#ifndef namespace_filename_h
#define namespace_filename_h

#endif 

   |1. Replace filename with the name of the file being guarded. This should usually be the name of class contained in the file. Use the exact class name. Some standards say use all upper case. This is a mistake because someone could actually name a class the same as yours but using all upper letters. If the files end up be included together one file will prevent the other from being included and you will be one very confused puppy. It has happened!

   |2. Most standards put a leading _ and trailing _. This is no longer valid as the C++ standard reserves leading _ to compiler writers.

   |3. When the include file is not for a class then the file name should be used as the guard name.

   |4. Compilers differ on how comments are handled on preprocessor directives. Historically many compilers have not accepted comments on preprocessor directives.

   |5. Historically many compilers require a new line after last endif.

Required Methods for a Class
To be good citizens almost all classes should implement the following methods. If you don't have to define and implement any of the "required" methods they should still be represented in your class definition as comments.

    * Default Constructor

      If your class needs a constructor, make sure to provide one. You need one if during the operation of the class it creates something or does something that needs to be undone when the object dies. This includes creating memory, opening file descriptors, opening transactions etc.

      If the default constructor is sufficient add a comment indicating that the compiler-generated version will be used.

      If your default constructor has one or more optional arguments, add a comment indicating that it still functions as the default constructor.

    * Virtual Destructor

      If your class is intended to be derived from by other classes then make the destructor virtual.

    * Copy Constructor

      If your class is copyable, either define a copy constructor and assignment operator or add a comment indicating that the compiler-generated versions will be used.

      If your class objects should not be copied, make the copy constructor and assignment operator private and don't define bodies for them. If you don't know whether the class objects should be copyable, then assume not unless and until the copy operations are needed.

    * Assignment Operator

      If your class is assignable, either define a assignment operator or add a comment indicating that the compiler-generated versions will be used.

      If your objects should not be assigned, make the assignment operator private and don't define bodies for them. If you don't know whether the class objects should be assignable, then assume not. 

Justification

    * Virtual destructors ensure objects will be completely destructed regardless of inheritance depth. You don't have to use a virtual destructor when:
          o You don't expect a class to have descendants.
          o The overhead of virtualness would be too much.
          o An object must have a certain data layout and size. 
    * A default constructor allows an object to be used in an array.
    * The copy constructor and assignment operator ensure an object is always properly constructed. 

The Law of The Big Three
A class with any of (destructor, assignment operator, copy constructor) generally needs all 3. For more information see http://www.parashift.com/c++-faq-lite/coding-standards.html#[25.9].
Example
The default class template with all required methods. An example using default values:

class Planet
{
public:
  /** The following is the default constructor if no arguments are supplied.
   */
  Planet(int radius= 5);
  
  // Use compiler-generated copy constructor, assignment, and destructor.
  // Planet(const Planet&);
  // Planet& operator=(const Planet&);
  // ~Planet();
};

Method Layout
The approach used is to place a comment block before each method that can be extracted by a tool and be made part of the class documentation. Here we'll use Doxygen which supports the Javadoc format. See the Doxygen documentation for a list of attributes supported by the document generator.

Method Header
Every parameter should be documented. Every return code should be documented. All exceptions should be documented. Use complete sentences when describing attributes. Make sure to think about what other resources developers may need and encode them in with the @see attributes.

  /** Assignment operator.
   * 
   *
   * @param val The value to assign to this object.
   * @exception LibaryException The explanation for the exception.
   * @return A reference to this object.
   */
   XX&                     operator=(XX& val);

Additional Sections
In addition to the standard attribute set, the following sections can be included in the documentation:

   |1. PRECONDITION
      Document what must have happened for the object to be in a state where the method can be called.

   |2. WARNING
      Document anything unusual users should know about this method.

   |3. LOCK REQUIRED
      Some methods require a semaphore be acquired before using the method. When this is the case use lock required and specify the name of the lock.

   |4. EXAMPLES
      Include exampes of how to use a method. A picture says a 1000 words, a good example answers a 1000 questions.

For example:

  /** Copy one string to another.
   *
   * PRECONDITION

   * REQUIRE(from != 0)
   * REQUIRE(to != 0)
   *
   * WARNING

   * The to buffer must be long enough to hold
   * the entire from buffer.
   *
   * EXAMPLES

   * 

   * strcpy(somebuf, "test")
   * 


   *
   * @param from The string to copy.
   * @param to The buffer to copy the string to.
   *
   * @return void
   */
   void  strcpy(const char* from, char* to); 

Common Exception Sections
If the same exceptions are being used in a number of methods, then the exceptions can be documented once in the class header and referred to from the method documentation.

		17.1.8. Formatting Methods with Multiple Arguments
We should try and make methods have as few parameters as possible. If you find yourself passing the same variables to every method then that variable should probably be part of the class. When a method does have a lot of parameters format it like this:

   int                     AnyMethod(
                              int   arg1,  
                              int   arg2, 
                              int   arg3,
                              int   arg4);

Different Accessor Styles
Why Accessors?
Access methods provide access to the physical or logical attributes of an object. Accessing an object's attributes directly as we do for C structures is greatly discouraged in C++. We disallow direct access to attributes to break dependencies, the reason we do most things. Directly accessing an attribute exposes implementation details about the object.

To see why ask yourself:

    * What if the object decided to provide the attribute in a way other than physical containment?
    * What if it had to do a database lookup for the attribute?
    * What if a different object now contained the attribute? 

If any of the above changed code would break. An object makes a contract with the user to provide access to a particular attribute; it should not promise how it gets those attributes. Accessing a physical attribute makes such a promise.
Accessors Considered Somewhat Harmful
At least in the public interface having accessors many times is an admission of failure, a failure to make an object's interface complete. At the protected or private level accessors are fine as these are the implementation levels of a class.
Implementing Accessors
There are three major idioms for creating accessors.
Get/Set

   class X
   {
   public:
      int    GetAge() const     { return mAge; }
      void   SetAge(int age)    { mAge= age; }
   private:
      int mAge;
   }

The problem with Get/Set is twofold:

    * It's ugly. Get and Set are strewn throughout the code cluttering it up.
    * It doesn't treat attributes as objects in their own right. An object will have an assignment operator. Why shouldn't age be an object and have its own assignment operator? 

One benefit, that it shares with the One Method Name, is when used with messages the set method can transparently transform from native machine representations to network byte order.
One Method Name

   class X
   {
   public:
      int    Age() const     { return mAge; }
      void   Age(int age)    { mAge= age; }
   private:
      int mAge;
   }

Similar to Get/Set but cleaner. Use this approach when not using the Attributes as Objects approach.
Attributes as Objects

   class X
   {
   public:
      int              Age() const     { return mAge; }
      int&             rAge()          { return mAge; } 

      const String&    Name() const    { return mName; }
      String&          rName()         { return mName; }
   private:
      int              mAge;
      String           mName;
   }

The above two attribute examples shows the strength and weakness of the Attributes as Objects approach.

When using an int type, which is not a real object, the int is set directly because rAge() returns a reference. The object can do no checking of the value or do any representation reformatting. For many simple attributes, however, these are not horrible restrictions. A way around this problem is to use a class wrapper around base types like int.

When an object is returned as reference its = operator is invoked to complete the assignment. For example:

   X x;
   x.rName()= "test";

This approach is also more consistent with the object philosophy: the object should do it. An object's = operator can do all the checks for the assignment and it's done once in one place, in the object, where it belongs. It's also clean from a name perspective.

When possible use this approach to attribute access.

Init Idiom for Initializing Objects

    * Objects with multiple constructors and/or multiple attributes should define a private Init() method to initialize all attributes. If the number of different member variables is small then this idiom may not be a big win and C++'s constructor initialization syntax can/should be used. 

Justification

    * When using C++'s ability to initialize variables in the constructor it's difficult with multiple constructors and/or multiple attributes to make sure all attributes are initialized. When an attribute is added or changed almost invariably we'll miss changing a constructor.

      It's better to define one method, Init(), that initializes all possible attributes. Init() should be called first from every constructor.

    * The Init() idiom cannot be used in two cases where initialization from a constructor is required:
          o constructing a member object
          o initializing a member attribute that is a reference 

Example

   class Test
   {
   public:
      Test()
      {
         Init();   // Call to common object initializer
      }

      Test(int val)
      {
         Init();   // Call to common object initializer
         mVal= val;
      }

   private:
      int      mVal;
      String*  mpName;

      void Init()
      {
         mVal  = 0;
         mpName= 0;
      }
   }

Since the number of member variables is small, this might be better
written as:

   class Test 
   {
   public:
     Test(int val = 0, String* name = 0)
       : mVal(val), mpName(name) {}
   private:
     int         mVal;
     String*     mpName;
   };

Initialize all Variables

    * You shall always initialize variables. Always. Every time. 

Justification

    * More problems than you can believe are eventually traced back to a pointer or variable left uninitialized. C++ tends to encourage this by spreading initialization to each constructor. See Init Idiom for Initializing Objects . 

Minimize Inlines
Minimize inlining in declarations or inlining in general. As soon as you put your C++ code in a shared library which you want to maintain compatibility with in the future, inlined code is a major pain in the butt. It's not worth it, for most cases.

Think About What Work to do in Constructors
Should you do work that can fail in constructors? If you have a compiler that does not support exceptions (or thread safe exceptions if it matters to you) then the answer is definitely no. Go directly to Do Work in Open. If your compiler supports exception then go to Do Work in Constructor. There are still reasons to use an Open method even with exceptions.
Use Open Reasons

   |1. It is difficult to write exception safe code in constructor. It's possible to throw an exception and not destruct objects allocated in the constructor. Use of auto_ptr can help prevent this problem.
   |2. Some compilers do not support thread safe exceptions on all platforms.
   |3. Virtual methods are not available in base classes. If the base class is expecting a virtual method implemented by derived classes to be available during construction then initialization must follow construction. This is common in frameworks.
   |4. Larger scale state machines may dictate when initialization should occur. An object may contain numerous other objects that may have complex initialization conditions. In this case we could wait to construct objects but then we always have to worry about null pointers.
   |5. If deletion is needed to free resources we still may want to keep the state around for debugging or statistics or as a supplier of information for other objects. 

Do Work in Constructor
With exceptions work done in the constructor can signal failure so it is fine to perform real work in the constructor. This is the guru endorced approach as a matter of fact. But there are reasons to still use an open style approach.

The constructor code must still be very careful not to leak resources in the constructor. It's possible to throw an exception and not destruct objects allocated in the constructor.

There is a pattern called Resource Acquisition as Initialization that says all initialization is performed in the constructor and released in the destructor. The idea is that this is a safer approach because it should reduce resource leaks.

Do Work in Open
Do not do any real work in an object's constructor. Inside a constructor initialize variables only and/or do only actions that can't fail.

Create an Open() method for an object which completes construction. Open() should be called after object instantiation.
Example

   class Device
   {
   public:
      Device()    { /* initialize and other stuff */ }
      int Open()  { return FAIL; }
   };

   Device dev;
   if (FAIL == dev.Open()) exit(1);

Don't Over Use Operators
C++ allows the overloading of all kinds of weird operators. Unless you are building a class directly related to math there are very few operators you should override. Only override an operator when the semantics will be clear to users.
Justification

    * Very few people will have the same intuition as you about what a particular operator will do. 

Thin vs. Thick Class Interfaces
How many methods should an object have? The right answer of course is just the right amount, we'll call this the Goldilocks level. But what is the Goldilocks level? It doesn't exist. You need to make the right judgment for your situation, which is really what programmers are for :-)

The two extremes are thin classes versus thick classes. Thin classes are minimalist classes. Thin classes have as few methods as possible. The expectation is users will derive their own class from the thin class adding any needed methods.

While thin classes may seem "clean" they really aren't. You can't do much with a thin class. Its main purpose is setting up a type. Since thin classes have so little functionality many programmers in a project will create derived classes with everyone adding basically the same methods. This leads to code duplication and maintenance problems which is part of the reason we use objects in the first place. The obvious solution is to push methods up to the base class. Push enough methods up to the base class and you get thick classes.

Thick classes have a lot of methods. If you can think of it a thick class will have it. Why is this a problem? It may not be. If the methods are directly related to the class then there's no real problem with the class containing them. The problem is people get lazy and start adding methods to a class that are related to the class in some willow wispy way, but would be better factored out into another class. Judgment comes into play again.

Thick classes have other problems. As classes get larger they may become harder to understand. They also become harder to debug as interactions become less predictable. And when a method is changed that you don't use or care about your code will still have to be recompiled, possibly retested, and rereleased.

Short Methods

    * Methods should limit themselves to a single page of code. 

Justification

    * The idea is that the each method represents a technique for achieving a single objective.
    * Most arguments of inefficiency turn out to be false in the long run.
    * True function calls are slower than not, but there needs to a thought out decision (see premature optimization). 

In a Source file Indicate if a Method is Static or Virtual
In a source file you can't tell a method is static or virtual because this information is in the header file. Knowing this information in a source file is useful and can be communicated using comments:

/*virtual*/ void
Class::method()
{
}

/*static*/ void
Class::method()
{
}

I've only seen this format once in source code, but it is interesting enough that I thought I would include here for your consideration. Notice how the method name sits alone on its own line. This looks more like C code and looks very clean for some reason.

		17.1.7. Process

Use a Design Notation and Process
Programmers need to have a common language for talking about coding, designs, and the software process in general. This is critical to project success.

Any project brings together people of widely varying skills, knowledge, and experience. Even if everyone on a project is a genius you will still fail because people will endlessly talk past each other because there is no common language and processes binding the project together. All you'll get is massive fights, burnout, and little progress. If you send your group to training they may not come back seasoned experts but at least your group will all be on the same page; a team.

There are many popular methodologies out there. The point is to do some research, pick a method, train your people on it, and use it. Take a look at the top of this page for links to various methodologies.

You may find an Agile methodology to your liking. For more information see http://www.possibility.com/epowiki/Wiki.jsp?page=agile.

You may find the CRC (class responsibility cards) approach to teasing out a design useful. Many others have. It is an informal approach encouraging team cooperation and focusing on objects doing things rather than objects having attributes. There's even a whole book on it: Using CRC Cards by Nancy M. Wilkinson.

Using Use Cases
A use case is a generic description of an entire transaction involving several objects. A use case can also describe the behaviour of a set of objects, such as an organization. A use case model thus presents a collection of use cases and is typically used to specify the behavior of a whole application system together with one or more external actors that interact with the system.

An individual use case may have a name (although it is typically not a simple name). Its meaning is often written as an informal text description of the external actors and the sequences of events between objects that make up the transaction. Use cases can include other use cases as part of their behaviour.
Requirements Capture
Use cases attempt to capture the requirements for a system in an understandable form. The idea is by running through a set of use case we can verify that the system is doing what it should be doing.

Have as many use cases as needed to describe what a system needs to accomplish.
The Process

    * Start by understanding the system you are trying to build.
    * Create a set of use cases describing how the system is to be used by all its different audiences.
    * Create a class and object model for the system.
    * Run through all the use cases to make sure your model can handle all the cases. Update your model and create new use cases as necessary. 

Using Stories
A user story consists of just a phrase or a few sentences written down, announcing something the user wants to do. The user story is not used as a requirements specification, but as a marker for a future conversation.

    * User stories are used as tokens in the planning process after assessment of business value and risk. The customer prioritizes the stories and schedules them for implementation.
    * User Story is a story about how the system is supposed to solve a problem. Each UserStory represents a chunk of functionality that is coherent in some way to the customer.
    * User Story is a token that stands in for a conversation whose purpose is roughly equivalent to that of a UseCase. The content of a UserStory is often an abbreviated version of the main success scenario of a UseCase, but it doesn't have to be.
    * User Story is a marker that reminds the customer and developers what to talk about, and also inspires them in exploring some particular area of business value. A UserStory, then, contains whatever the customer thinks is necessary to jog the memories and inspirations of those who will later explore the story. Expertise in the business area will help the customer decide what are the essential "jogs" to record in the initial UserStory marker.
    * Developers should be able to implement a story in 2-4 weeks. The iteration length depends on you project. 

A Story Is

    * Testable -You can write automatic tests to detect the presence of the story.
    * Progress - The customers side of the team is willing to accept the story as a sign of progress toward their larger goal.
    * Bite-sized - The story should be completable within the iteration.
    * Estimatable - The technical side of the team must be able to guess how much of the team's time the story will require to get working. 

How It All Fits Together
There are a lot of entrants in this part of the development process. We have user stories, use cases, task analysis, task cases, usage scenarios, etc and etc.

It seems we need something more detailed than requirements as requirements tend to be fairly high level and are usually not directly useful for development. A requirement will cut across many subsystems and each of the cross-cuts must be identified. Thus requirements need to go through refinement and elaboration to be used in development.

If we get too detailed then we get bogged down in detailed design before we are ready. If we aren't detailed enough then we can't know if our requirements are met. Nor can we convince ourselves that we know how to solve the problem.

User Stories Need to be Fleshed Out
User Stories are symbolic of the stuff that needs to get done. They are like the reminder notes you make to yourself. In the detailed design these can be expanded out to uses cases, to more detailed notes, state machines, etc. Or TestDrivenDesign practices could be used to flesh out the detailed implementation.

For more information see http://www.possibility.com/epowiki/Edit.jsp?page=UserStory.

Unified Modeling Language
The Unified Modeling Language is too large to present here. Fortunately you can see it at Rational's web site. Since you do need a modeling language UML is a safe choice. It combines features from several methods into one unified language. Remember all languages and methods are open to local customization. If their language is too complex then use the parts you and your project feel they need and junk the rest.

Code Reviews
If you can make a formal code review work then my hat is off to you. Code reviews can be very useful. Unfortunately they often degrade into nit picking sessions and endless arguments about silly things. They also tend to take a lot of people's time for a questionable payback.

My god he's questioning code reviews, he's not an engineer!

Not really, it's the form of code reviews and how they fit into normally late chaotic projects is what is being questioned.

First, code reviews are way too late to do much of anything useful. What needs reviewing are requirements and design. This is where you will get more bang for the buck.

Get all relevant people in a room. Lock them in. Go over the class design and requirements until the former is good and the latter is being met. Having all the relevant people in the room makes this process a deep fruitful one as questions can be immediately answered and issues immediately explored. Usually only a couple of such meetings are necessary.

If the above process is done well coding will take care of itself. If you find problems in the code review the best you can usually do is a rewrite after someone has sunk a ton of time and effort into making the code "work."

You will still want to do a code review, just do it offline. Have a couple people you trust read the code in question and simply make comments to the programmer. Then the programmer and reviewers can discuss issues and work them out. Email and quick pointed discussions work well. This approach meets the goals and doesn't take the time of 6 people to do it.

For more information on code reviews please take a look at here. You'll find a lot of information on justifying code reviews if you are having troubles instituting them and lots of suggestions on how to conduct them.

Create a Source Code Control System Early and Not Often
A common build system and source code control system should be put in place as early as possible in a project's lifecycle, preferably before anyone starts coding. Source code control is the structural glue binding a project together. If programmers can't easily use each other's products then you'll never be able to make a good reproducible build and people will piss away a lot of time. It's also hell converting rogue build environments to a standard system. But it seems the right of passage for every project to build their own custom environment that never quite works right.

Some issues to keep in mind:

    * Appoint a buildmaster who is in charge of the build environment and making builds. If you have a tools group so much the better as build environments generally generate a lot of tools.
    * Programmers should generally leave tagging and other advanced operations to the buildmaster.
    * Shared source environments like CVS usually work best in largish projects.
    * Makefiles should be completely templated so developers need no makefile expertise.
    * You will need multiple builds of the same code meaning programmers will want to have the option of building against optimized code versions, debugger code versions, code with the -DDEBUG macro defined and versions without, etc. One way to do this is have everyone check out all code and do a total rebuild. The other better way is for the buildmaster to build all necessary versions of code so programmers can check out only the code which they are modifying. The idea is that each combination of compile flags and macros defines a build.
    * Dependency checking should work!
    * Maintain a cycle of builds. Create a nightly build so problems can be detected early. Create a valid build every week or for every feature set that is guaranteed to be good. Every release to QA or to customers should be tagged and available in the tree. Official builds should be official because they contain a certain set of features that assumably meet a schedule, not because it's a certain date.
    * If you use CVS use a reference tree approach. With this approach a master build tree is kept of various builds. Programmers checkout source against the build they are working on. They only checkout what they need because the make system uses the build for anything not found locally. Using the -I and -L flags makes this system easy to setup. Search locally for any files and libraries then search in the reference build. This approach saves on disk space and build time.
    * Get a lot of disk space. With disk space as cheap it is there is no reason not to keep plenty of builds around and have enough space for programmers to compile.
    * Make simple things simple. It should be dead simple and well documented on how to:
          o check out modules to build
          o how to change files
          o how to setup makefiles
          o how to add new modules into the system
          o how to delete modules and files
          o how to check in changes
          o what are the available libraries and include files
          o how to get the build environment including all compilers and other tools 

      Make a web page or document or whatever. New programmers shouldn't have to go around begging for build secrets from the old timers.
    * Use the idea of services. If using a feature requires linking to 3 libraries think about making a service specifiable in the makefile programmers can use instead of having to know the exact libraries needed. With this approach the libraries making up a service can be changed in a based makefile without requiring changes in all makefiles.
    * On checkins log comments should be useful. These comments should be collected every night and sent to interested parties. 

Source Code Control Systems
Some options for source code control systems are:

   |1. Subversion - a free, popular, and well featured system.
   |2. Perforce - a not free, popular, and very solid system that scales beautifully and just works.
   |3. Clear Case - a not free, popular in larger corporations, and requires a dedicated admin team, yet you can accomplish a lot with it. 

There are many other options out there. It doesn't matter which one you pick as much as it does that you pick one and use it.

Create a Bug Tracking System Early and Not Often
The earlier people get used to using a bug tracking system the better. If you are 3/4 through a project and then install a bug tracking system it won't be used. You need to install a bug tracking system early so people will use it.

Programmers generally resist bug tracking, yet when used correctly it can really help a project:

    * Problems aren't dropped on the floor.
    * Problems are automatically routed to responsible individuals.
    * The lifecycle of a problem is tracked so people can argue back and forth with good information.
    * Managers can make the big schedule and staffing decisions based on the number of and types of bugs in the system.
    * Configuration management has a hope of matching patches back to the problems they fix.
    * QA and technical support have a communication medium with developers. 

Not sexy things, just good solid project improvements.

FYI, it's not a good idea to reward people by the number of bugs they fix :-)

Source code control should be linked to the bug tracking system. During the part of a project where source is frozen before a release only checkins accompanied by a valid bug ID should be accepted. And when code is changed to fix a bug the bug ID should be included in the checkin comments.

Bug Tracking Systems
Some options for bug tracking systems are:

   |1. Jira - a full featured and reliable bug tracking system. It works best when combined with Confluence, their wiki product.
   |2. Bugzilla - a free product that is functional and widely used. 

As for source code control systems there are many available bug tracking systems. It's more important that you use one than which one you use.

RCS Keywords, Change Log, and History Policy
When using RCS directly this policy must change, but when using other source code control systems like CVS that support RCS style keywords:

    * Do not use RCS keywords within files.
    * Do not keep a change history in files.
    * Do not keep author information in files. 

Justification

    * The reasoning is your source control system already keeps all this information. There is no reason to clutter up source files with duplicate information that:
          o makes the files larger
          o makes doing diffs difficult as non source code lines change
          o makes the entry into the file dozens of lines lower in the file which makes a search or jump necessary for each file
          o is easily available from the source code control system and does not need embedding in the file 
    * When files must be sent to other organizations the comments may contain internal details that should not be exposed to outsiders. 

Create a Wiki System Early and Not Often
The heart of software development is information. Where do you put all your documentation? Where do we put your coding guidelines? Where you put all your process documents? Where do you put your design documents? Where do you put all the 1000s of bits of information that hold a project together?

With a strategy information is usually spread like seeds in the wind. Much is in people's heads, in email, in IM, in files on people's file systems, or files on different servers. Nobody can ever find anything they need.

A solution to this mess is to store all your information in a wiki. A Wiki is a web site written by many users. It's very easy for a community of people to create and edit content. The idea is that people can add a page for any topic they want and add to any existing page by simply editing it. Over time we can create a site addressing most of the issues people have about projects, products, development, process, and more.

A wiki is perfect support for software development.

I've written up my hard one advice for using wikis at Getting Your Wiki Adopted.

Honor Responsibilities
Responsibility for software modules is scoped. Modules are either the responsibility of a particular person or are common. Honor this division of responsibility. Don't go changing things that aren't your responsibility to change. Only mistakes and hard feelings will result.

Face it, if you don't own a piece of code you can't possibly be in a position to change it. There's too much context. Assumptions seemingly reasonable to you may be totally wrong. If you need a change simply ask the responsible person to change it. Or ask them if it is OK to make such-n-such a change. If they say OK then go ahead, otherwise holster your editor.

Every rule has exceptions. If it's 3 in the morning and you need to make a change to make a deliverable then you have to do it. If someone is on vacation and no one has been assigned their module then you have to do it. If you make changes in other people's code try and use the same style they have adopted.

Programmers need to mark with comments code that is particularly sensitive to change. If code in one area requires changes to code in an another area then say so. If changing data formats will cause conflicts with persistent stores or remote message sending then say so. If you are trying to minimize memory usage or achieve some other end then say so. Not everyone is as brilliant as you.

The worst sin is to flit through the system changing bits of code to match your coding style. If someone isn't coding to the standards then ask them or ask your manager to ask them to code to the standards. Use common courtesy.

Code with common responsibility should be treated with care. Resist making radical changes as the conflicts will be hard to resolve. Put comments in the file on how the file should be extended so everyone will follow the same rules. Try and use a common structure in all common files so people don't have to guess on where to find things and how to make changes. Checkin changes as soon as possible so conflicts don't build up.

As an aside, module responsibilities must also be assigned for bug tracking purposes.

Process Automation
It's a sad fact of human nature that if you don't measure it or check for it: it won't happen. The implication is you must automate as much of the development process as possible and provide direct feedback to developers on specific issues that they can fix.

Process automation also frees up developers to do real work because they don't have to babysit builds and other project time sinks.

Automated Builds and Error Assignment
Create an automated build system that can create nightly builds, parse the build errors, assign the errors to developers, and email developers their particular errors so they can fix them.

This is the best way to maintain a clean build. Make sure the list of all errors for a build is available for everyone to see so everyone can see everyone elses errors. The goal is replace a blaim culture with a culture that tries to get things right and fixes them when they are wrong. Immediate feedback makes this possible.

Automated Code Checking
As part of the automated build process you can check for coding standard violations and for other problems. If you don't check for it people will naturally do their own thing. Code reviews aren't good enough to keep the code correct. With a tool like Abraxis Code Check you can check the code for a lot of potential problems.

This feature like the automated error assignment makes problems immediately visible and immediately correctable, all without a lot of blame and shame.
Documentation Extraction
Related to this principle is the need to automatically extract documentation from the source code and make it available on line for everyone to use. If you don't do this documentation will be seen as generally useless and developers won't put as much effort into it. Making the documentation visible encourages people to do a better job.
Connect Source Code Control System and Bug Tracking System

   |1. When a check-in of source code fixes a bug then have the check-in automatically tell the bug tracking system that the bug was fixed.
   |2. When a bug fix is built in a build change the state of the bug to BUILT.
   |3. Have a submit tool where people ask judges of they can submit a bug fix on the branch. 

There are lots of things you can do depending on how complicated your environment. The more complicated the environment the more you should think about connecting all systems together.

Tools Agreement
The reality of different tool preferences is something to deal with explicitly and openly. Tools include IDEs, languages, editors, make program, source code control, bug system, debuggers, test framework, etc. Some tool decisions by their nature must be project wide, other decisions can be customized per developer.

A split might also be done by who is performing the build. For example, an IDE should be able to used in local builds, but the make program would be used for nightly and release builds.

Certain things are easy/trivial/useful with one tool, but hard/complicated/stupid with another tool. Unstated tool assumptions can be the source of a lot of confusion. "Get a better editor" is not always a workable response, though sometimes that's all there is to it!

Non-Blocking Scheduling
Schedules are lies. Schedules suck. Yes, yes, yes. But we still need them.

The most effective scheduling rule i've used is to schedule so as to unblock others. The idea is to complete the portions of a feature that will unblock those dependent on you. This way development moves along smoothly because more lines of development can be active at a time. For example, instead of implementing the entire database, implement the simple interface and stub it out. People can work for a very long time this way using that portion of the feature that caused others not to block. Plus it's a form of rapid prototyping because you get immediate feedback on these parts. Don't worry about the quality of implementation because it doesn't matter yet.

Using Personas
Personas are a powerful design tool, especially when combined with responsibility driven design. Cooper's personas are:.

simply pretend users of the system you're building. You describe 
them, in a surprising amount of detail, and then design your 
system for them. 

I have a standard set of personas that i consider when creating a design/architecture that don't seem to be common. When you write code their are a lot of personas looking over your shoulder:

   |1. other programmers using the code
   |2. maintenance
   |3. extension
   |4. documentation group
   |5. training group
   |6. code review
   |7. test and validation
   |8. manufacturing
   |9. field support
  |10. first and second line technical support
  |11. live debugging
  |12. post crash debugging
  |13. build system (documentation generation and automatic testing)
  |14. unit testing
  |15. system testing
  |16. source code control
  |17. code readers
  |18. legal 

You are much more careful and more thorough when you really thing about all the personas, all the different people and all their different roles and purposes.

Use a Continuous Build System
Setup a continuous build system for your group. It should build all new check-ins and run the unit tests for each change. If you have the resources run a smoke test for each build as well.

If there's a failure email should go out to the developer's who made the check-ins.

This policy will allow you to catch errors as early as possible which will make your system more stable over time.

Code in the Dominant Style
Let's say someone invites you into your home as a guest. How do you act? Do you act as you do at home or do you try and fit in with the household in which you are staying? You try to fit in of course.

So when you have to write code for a new codebase do you 1) write code however you want or 2) write code like the code that already exists?

When writing code in a new codebase write code how the code is already written. Don't use your own style. Take some time, look around, and see how the code is written. To come in like a bull in a china shop is the mark of someone who is not a professional developer.

Run Unit Tests Before Every Check-in
Before every check-in developers must run unit tests to verify all unit tests should pass. This prevents letting any errors creep in.

Finding, debugging, and handling errors is a tremendous drain on the development process so we want have a solid working system from the start. The start means your code that you check-in should always work and we know it works by running unit tests and smoke tests if your organization has them.

Formatting

Braces {} Policy
Brace Placement
Of the three major brace placement strategies two are acceptable, with the first one listed being preferable:

    * Place brace under and inline with keywords:

         if (condition)        while (condition)
         {                     {
            ...                   ...
         }                     }

    * Traditional Unix policy of placing the initial brace on the same line as the keyword and the trailing brace inline on its own line with the keyword:

         if (condition) {      while (condition) {
            ...                   ...
         }                     }

Justification

    * Another religious issue of great debate solved by compromise. Either form is acceptable, many people, however, find the first form more pleasant. Why is the topic of many psychological studies.

      There are more reasons than psychological for preferring the first style. If you use an editor (such as vi) that supports brace matching, the first is a much better style. Why? Let's say you have a large block of code and want to know where the block ends. You move to the first brace hit a key and the editor finds the matching brace. Example:

           if (very_long_condition && second_very_long_condition)
           {
              ...
           }
           else if (...)
           {
      	..
           }

      To move from block to block you just need to use cursor down and your brace matching key. No need to move to the end of the line to match a brace then jerk back and forth. 

When Braces are Needed
All if, while and do statements must either have braces or be on a single line.

Always Uses Braces Form
All if, while and do statements require braces even if there is only a single statement within the braces. For example:

if (1 == somevalue)
{
   somevalue = 2;
}

Justification
It ensures that when someone adds a line of code later there are already braces and they don't forget. It provides a more consistent look. This doesn't affect execution speed. It's easy to do.
One Line Form

if (1 == somevalue) somevalue = 2;

Justification
It provides safety when adding new lines while maintainng a compact readable form.
Add Comments to Closing Braces
Adding a comment to closing braces can help when you are reading code because you don't have to find the begin brace to know what is going on.

while(1)
{
   if (valid)
   {
  
   } // if valid
   else
   {
   } // not valid

} // end forever

Consider Screen Size Limits
Some people like blocks to fit within a common screen size so scrolling is not necessary when reading code.

Indentation/Tabs/Space Policy

    * Indent using 3, 4, or 8 spaces for each level.
    * Do not use tabs, use spaces. Most editors can substitute spaces for tabs.
    * Tabs should be fixed at 8 spaces. Don't set tabs to a different spacing, uses spaces instead.
    * Indent as much as needed, but no more. There are no arbitrary rules as to the maximum indenting level. If the indenting level is more than 4 or 5 levels you may think about factoring out code. 

Justification

    * Tabs aren't used because 8 space indentation severely limits the number of indentation levels one can have. The argument that if this is a problem you have too many indentation levels has some force, but real code can often be three or more levels deep. Changing a tab to be less than 8 spaces is a problem because that setting is usually local. When someone prints the source tabs will be 8 characters and the code will look horrible. Same for people using other editors. Which is why we use spaces...
    * When people using different tab settings the code is impossible to read or print, which is why spaces are preferable to tabs.
    * Nobody can ever agree on the correct number of spaces, just be consistent. In general people have found 3 or 4 spaces per indentation level workable.
    * As much as people would like to limit the maximum indentation levels it never seems to work in general. We'll trust that programmers will choose wisely how deep to nest code. 

Example

   void
   func()
   {
      if (something bad)
      {
         if (another thing bad)
         {
            while (more input)
            {
            }
         }
      }
   }

Parens () with Key Words and Functions Policy

    * Do not put parens next to keywords. Put a space between.
    * Do put parens next to function names.
    * Do not use parens in return statements when it's not necessary. 

Justification

    * Keywords are not functions. By putting parens next to keywords keywords and function names are made to look alike. 

Example

    if (condition)
    {
    }

    while (condition)
    {
    }

    strcpy(s, s1);

    return 1;

A Line Should Not Exceed 78 Characters

    * Lines should not exceed 78 characters. 

Justification

    * Even though with big monitors we stretch windows wide our printers can only print so wide. And we still need to print code.
    * The wider the window the fewer windows we can have on a screen. More windows is better than wider windows.
    * We even view and print diff output correctly on all terminals and printers. 

If Then Else Formatting
Layout
It's up to the programmer. Different bracing styles will yield slightly different looks. One common approach is:

   if (condition)                 // Comment
   {
   } 
   else if (condition)            // Comment
   {
   }
   else                           // Comment
   {
   }

If you have else if statements then it is usually a good idea to always have an else block for finding unhandled cases. Maybe put a log message in the else even if there is no corrective action taken.

Condition Format
Always put the constant on the left hand side of an equality/inequality comparison. For example:

if ( 6 == errorNum ) ...

One reason is that if you leave out one of the = signs, the compiler will find the error for you. A second reason is that it puts the value you are looking for right up front where you can find it instead of buried at the end of your expression. It takes a little time to get used to this format, but then it really gets useful.

switch Formatting

    * Falling through a case statement into the next case statement shall be permitted as long as a comment is included.
    * The default case should always be present and trigger an error if it should not be reached, yet is reached.
    * If you need to create variables put all the code in a block. 

Example

   switch (...)
   {
      case 1:
         ...
      // FALL THROUGH

      case 2:
      {        
         int v;
         ...
      }
      break;

      default:
   }

Use of goto,continue,break and ?:
Goto
Goto statements should be used sparingly, as in any well-structured code. The goto debates are boring so we won't go into them here. The main place where they can be usefully employed is to break out of several levels of switch, for, and while nesting, although the need to do such a thing may indicate that the inner constructs should be broken out into a separate function, with a success/failure return code.


   for (...) 
   {
      while (...) 
      {
         ...
         if (disaster)
            goto error;
      }
   }
   ...
error:
   clean up the mess 

When a goto is necessary the accompanying label should be alone on a line and to the left of the code that follows. The goto should be commented (possibly in the block header) as to its utility and purpose.
Continue and Break
Continue and break are really disguised gotos so they are covered here.

Continue and break like goto should be used sparingly as they are magic in code. With a simple spell the reader is beamed to god knows where for some usually undocumented reason.

The two main problems with continue are:

    * It may bypass the test condition
    * It may bypass the increment/decrement expression 

Consider the following example where both problems occur:

while (TRUE) 
{
   ...
   // A lot of code
   ...
   if (/* some condition */) {
      continue;
   }
   ...
   // A lot of code 
   ...
   if ( i++ > STOP_VALUE) break;
}

Note: "A lot of code" is necessary in order that the problem cannot be caught easily by the programmer.

From the above example, a further rule may be given: Mixing continue with break in the same loop is a sure way to disaster.

?:
The trouble is people usually try and stuff too much code in between the ? and :. Here are a couple of clarity rules to follow:

    * Put the condition in parens so as to set it off from other code
    * If possible, the actions for the test should be simple functions.
    * Put the action for the then and else statement on a separate line unless it can be clearly put on one line. 

Example

   (condition) ? funct1() : func2();

   or

   (condition)
      ? long statement
      : another long statement;

One Statement Per Line
There should be only one statement per line unless the statements are very closely related.

The reasons are:

   |1. The code is easier to read. Use some white space too. Nothing better than to read code that is one line after another with no white space or comments. 

One Variable Per Line
Related to this is always define one variable per line:

Not:
char **a, *x;

Do:
char** a= 0;  // add doc
char*  x= 0;  // add doc

The reasons are:

   |1. Documentation can be added for the variable on the line.
   |2. It's clear that the variables are initialized.
   |3. Declarations are clear which reduces the probability of declaring a variable when you actually mean to declare a pointer. 

Alignment of Declaration Blocks

    * Block of declarations should be aligned. 

Justification

    * Clarity.
    * Similarly blocks of initialization of variables should be tabulated.
    * The â&â and â*â tokens should be adjacent to the type, not the name. 

Example

   DWORD       mDword
   DWORD*      mpDword
   char*       mpChar
   char        mChar

   mDword   = 0;
   mpDword  = NULL;
   mpChar   = NULL;
   mChar    = 0;

Include static and virtual Key Words in Source File
If a method is made static or virtual in the header file then also include this information as a short comment in the source file. For example:

In .h file:

class PopcornPopper
{
public:
   virtual void Pop(void);
   static PopcornPopper* Singleton();
};


In .cpp file:

/*virtual*/ void 
PopcornPopper::Pop(void)
{
}// Pop

/*static*/ PopcornPopper* 
PopcornPopper::Singleton()
{
}// Singleton

A source file doesn't contain as much information as the header file because the virtual and static keywords are dropped from method implementations. This is very useful information to have when reading code, so we want to include it in the source file.

Document Null Statements
Always document a null body for a for or while statement so that it is clear that the null body is intentional and not missing code.


   while (*dest++ = *src++)
      ;         // VOID 

		17.1.9. Exceptions

Create One Exception for Each Library
Creating very elaborate exception hierarchies is a waste of time. Nobody ends of caring and all the effort goes to waste. Instead, create one exception per library or namespace and have an exception reason within that exception to indicate the type of the exception.

For example, for your OS encapsulation libary, make an exception called OsencapException.

By using just one exception you make it easy for people using your code to catch your exception. If you have thousand exceptions it is impossible for anyone to handle those. And as exceptions are added you will break existing code that thinks they are handling all your exceptions.

If you think you need to create derived exceptions the derive them from your libraries' base exception class. That allows your library users to still catch the base class exception if they wish.

Most exceptions are things the code can't do anything about anyway, so creating lots of exceptions to express every little thing that can go wrong with a separate class and is time confusing and confusing for the user. It's not necessary.

Make sure to document that an exception is being thrown in you method comment header.

Create a macro for throwing the exception so that you can transparently include __FILE__ and __LINE__ in the exception. This information is usefull when debugging. You can also automatically take a time stamp and get the thread ID.

The exception should take a one or two string arguments so developers can include all the information they need in the exception without having to create a derived exception to add a few more pieces of data.

Include a stack trace of where the exception happened so you can log the stack trace.

Throwing an exception should take only one line of code. Don't uglify your code with tons of exception handling. Make a macro that looks like:

THROW_NAMESPACE_EX_IF(cond, msg1, msg2, reason);

The condition causes the exception to be thrown when true. Msg1 and msg2 are local context. Reason is the specific error code for the exception, if you think you need it.

Don't worry about running out of memory errors. Go ahead and allocate memory in your exception code. If you are running out of memory that should be taken care of in the bad_alloc exception handler.

Selecting Between Exceptions And Asserts
If there is reason to believe that an important test could fail in the released product, it should not be tested with an assert, use an exception instead.

Two useful questions to ask yourself are:

   |1. Should this error ever happen?
   |2. Is the error so unexpected or potentially damaging that the system should failover if it is found? 

When at the boundry of user input we should expect invalid parameters and thus should use an exception instead of DBC.

Exception Definition
There are as many definitions of exception as there are programmers:

The Clean Code Definition

Write a function as if everything worked.
Any error handling that prevents the code from looking
like this is an exception.

The Design by Contract Definition

When an operation is invoked with it's pre-condition
satisfied, yet it cannot return with its post-condition
satisfied.

There are those who say that exceptions should NOT be used to catch things like range errors. Here's why:

Range errors fall into a class of problem that are called Programmer Errors. Programmer errors are things that should NOT occur in a Bug Free Program. Ideally, range type problems are one of those things that should be caught during development. It is for these problems that we have Design By Contract.

You program defensively by putting lots of asserts in to make sure that your program is functioning as expected. Then when you've committed a bug, like not checking user input properly, allowing an invalid index into an array to be derived, the assert macro catches it, and the program does a gracful crash.

Exceptions, on the other hand, should be used to catch problems that would arise even in a Bug Free Program, i.e. Exceptional Circumstances. The most perfect program can still be afflicted by things like shortage of memory and other resources, communications errors, and file problems. When one of these things occurs, an exception should be thrown, and caught at a point where the program can either deal with the problem, or close gracefully.

The real theory behind exceptions is to force the programmer to anticipate things the programmer has no control over. Exceptions support the following kind of scenarios:

   |1. Logic error in the middle of a database transaction. An exception would allow the program a chance to leave the database in a consistent state. A trashed database can be very expensive.
   |2. Logic error in the middle of a program that is using a resource ike a modem and the program runs unattended. Exception handling would give the program a chance to hang up the modem connection, rather than sit there with an connection until it's discovered the next day, running up the phone bill.
   |3. Logic error in the middle of something like a word processor. Consider the user that has been working for a couple of hours with unsaved edits, and your assert message pops up, and the last two hours of work are pretty much lost - causing the user some misery. If you used exception handling, you could at least give the user a chance to salvage the unsaved document in a different file as part of the cleanup. 

Design-by-Contract (DBC)
A design technique developed by Bertrand Meyer for producing "bug free" systems.

Design by Contract (DBC) views the relationship between a class and its clients as formal agreement, expressing each party's rights and obligation. Rights and obligations are determined by a class' specification. Correctness can only be determined in reference to an object's specification. Specifications, in DBC, are expressed through assertions.

Design by Contract is a development approach where a specification is associated with every software element. These specifications (or contracts) govern the interaction of the element with the rest of the world. A contract takes form as a set of preconditions, postconditions, and invariants that are run as the system executes. The contract is published in the comment block of each method.

Assertion
A boolean statement that should never be false and, therefore, will only be false because of a bug. Typically assertions are checked only during debug and are not checked during production execution, although they can be left in when performance and memory size are not issues.

Design by Contract uses three kinds of assertions: post-conditions, pre-conditions, and invariants. Pre-conditions and post-conditions apply to operations. Invariants apply to the class.

Pre-condition
A statement of how we expect the world to be before we execute an operation. We might design a pre-condition of the "square" operation as this >= 0. Such a pre-condition says that it is an error to invoke "square" on a negative number.

Post-condition
A statement of what the world should look like after execution of an operation. For example, if we define the operation "square" on a number, the post-condition would take the form result = this *this. The post-condition is a useful way of saying what we do without saying how we do it- in other words, of separating interface from implementation.

Invariant
An invariant is an assertion about a class. For instance, an Account class may have an invariant that says that balance == sum(entries.amount()). The invariant is always true for all instances of the class. "Always" means whenever the object is available for an operation to be invoked. During an operation invariants may not be satisfied, but invariants must hold when an operation has finished.

Is pop'ing an empty stack an exception?
When using a stack data structure is calling pop on an empty stack an exception? This is the standard use case for the endless discussions on what is and what isn't an exception. The upshot is there is not a "right" answer. In practice, as long as the library designer completely documents their choice the library user shouldn't make a mistake.

Let's apply our definition of exception.

The Clean Code View
If you write your application assuming everything works then is pop returning null something you wouldn't expect? It seems reasonable that if you ask for something it may not be there.

Before calling pop the client can call isEmpty to check if there's anything in the list. It's still possible in a multi-threaded environment for the stack to return null even if isEmpty returns true.

So don't use an exception. Pop returns data so it should return null when empty.

The Design by Contract View
Should the library designer have as a pre-condition that pop shouldn't be called when the stack is empty? From an implementor point of view this could seem reasonable. After all, why should an operation be called when there's nothing there? So, pop could assert.

But, library designers should alway see their clients point-of-view. It's a bit extreme to cause a system crash because pop has an empty stack. There's nothing fundamentally or systemically wrong in this scenario that would justify an assert.

It appears the pre-conditions are satisfied for pop. Would any post-conditions not be satisfied? (this defines an exception in DBC). The stack should still be empty after the operation so no post-conditions would be violated. Thus, by definition an exception should not be thrown.

Be Careful Throwing Exceptions in Destructors
An object is presumably created to do something. Some of the changes made by an object should persist after an object dies (is destructed) and some changes should not. Take an object implementing a SQL query. If a database field is updated via the SQL object then that change should persist after the SQL objects dies. To do its work the SQL object probably created a database connection and allocated a bunch of memory. When the SQL object dies we want to close the database connection and deallocate the memory, otherwise if a lot of SQL objects are created we will run out of database connections and/or memory.

The logic might look like:

Sql::~Sql()
{
   delete connection;
   delete buffer;
}

Let's say an exception is thrown while deleting the database connection. Will the buffer be deleted? No. Exceptions are basically non-local gotos with stack cleanup. The code for deleting the buffer will never be executed creating a gaping resource leak.

Special care must be taken to catch exceptions which may occur during object destruction. Special care must also be taken to fully destruct an object when it throws an exception.

Usign RAII can help prevent many of not most of these type of errors.

Working With Libaries Using All Sorts of Different Policies
On many projects we have to work with C libraries that use error return codes, old C++ libraries that use error return codes, and newer C++ libraries that use exceptions. How should all these different approaches work together?

Ideally exceptions should be used where possible because that's the where all new code is going. But I also see new libraries being forced to use error return codes because the old libraries use them and application maintainers don't want you to use exceptions.

In C++ any method can throw an exception and you can't tell. In Java you know when you are not catching an exception. Not in C++. So what happens is that if a new library comes in and throws an exception, a crticial program may start failing because an exception is not caught. This may make everyone use error codes instead of exceptions.

Don't give into this old timer bias. Error return codes are virtually useless because they are competely ingorable. Instead, an application should just wrap their code in a big try catch block that catches all exceptions. That way an application won't die with prejudice and C++ libarary writers can make use of exceptions in their design.

		17.1.10. Templates
Templates have never come up as an issue on project I've worked on, so my advice on templates isn't very useful.

Keeping templates simple has worked best. Just use templates for what they are good at, making a class work over different types. Not everything needs to be a template or needs to be perfectly generic. Because templates are so complex and so difficult to debug, it's best to use them only when necessary.

Template meta programming is too elite for me so I'll leave that to other people.

		17.1.11. Namespaces

Create Unique Name Space Names
A namespace isn't of much use if it's not globally unique.

On way to make name spaces unique is to root tham at some naming

There are two basic strategies for naming: root that name at some naming authority, like the company name and division name. The Java convention is to use the inverse of the companys domain name for package names.

Personally that always seemed overkill to me, but does work in the large.

For internal packages just pick a short simple descriptive namespace that will likely prevent conflict within a project.

For externally visible code you'll probably need to the full domain style namespace just to be safe.

Don't Globally Define using
Don't place using namespace directive at global scope in a header file. This can cause lots of magic invisible conflicts that are hard to track. Keep using statements to implementation files.

For example, let's say I want to use boost's fabulous gregorian date library. In my class I want to return dates and use dates in methods. So my code ends up looking like:

#include "boost/date_time/gregorian/gregorian.hpp" //include all types plus i/o

 
class Calendar
{
public:
   boost::gregorian::date GetEventDate(void) const;
   void                   SetEventDate(boost::gregorian::date dateOfTheEvent);
};


Clearly these are long names and are noisy and are pain to use. So you are tempted to put at the top of you class file:

using namespace boost::gregorian;  // make namespace global for this file

This would mean you could just use "date" instead of "boost::gregorian::date". That's nice. But you can't do that. If you do you are making the decision for everyone who uses your class as well. They may have a conflict, "date" is a very common name afterall.

So, don't use using in you header file, but you can use it in your source file. Because it's your source file you can make the decision to use using to shorten up the names. This strategy preserves most of the convenience while being a good citizen.

Create Shortcut Names
You can use using to create aliases or shortcuts, that is names that are more convenient to access than long namespace names.

For example:

   namespace alias = a::very::long::namespace;
   class YourClass: public alias::TheirClass 
   { ... }

Clearly this makes code both harder to read and easier to read. The code is harder to read because you as a programmer have to compile the alias directive in your head and know what it means whenever it is used in the code.

The code is easier to read because it is less complex. Complex namespaces are distracting and confusing. Even with the additional cognitive load, using namespace alias make code a lot easier to read.

		17.1.12. Miscellaneous
This section contains some miscellaneous do's and don'ts.

    * Don't use floating-point variables where discrete values are needed. Using a float for a loop counter is a great way to shoot yourself in the foot. Always test floating-point numbers as <= or >=, never use an exact comparison (== or !=).

    * Compilers have bugs. Common trouble spots include structure assignment and bit fields. You cannot generally predict which bugs a compiler has. You could write a program that avoids all constructs that are known broken on all compilers. You won't be able to write anything useful, you might still encounter bugs, and the compiler might get fixed in the meanwhile. Thus, you should write ``around'' compiler bugs only when you are forced to use a particular buggy compiler.

    * Do not rely on automatic beautifiers. The main person who benefits from good program style is the programmer him/herself, and especially in the early design of handwritten algorithms or pseudo-code. Automatic beautifiers can only be applied to complete, syntactically correct programs and hence are not available when the need for attention to white space and indentation is greatest. Programmers can do a better job of making clear the complete visual layout of a function or file, with the normal attention to detail of a careful programmer (in other words, some of the visual layout is dictated by intent rather than syntax and beautifiers cannot read minds). Sloppy programmers should learn to be careful programmers instead of relying on a beautifier to make their code readable. Finally, since beautifiers are non-trivial programs that must parse the source, a sophisticated beautifier is not worth the benefits gained by such a program. Beautifiers are best for gross formatting of machine-generated code.

    * Accidental omission of the second ``='' of the logical compare is a problem. The following is confusing and prone to error.

              if (abool= bbool) { ... }
           

      Does the programmer really mean assignment here? Often yes, but usually no. The solution is to just not do it, an inverse Nike philosophy. Instead use explicit tests and avoid assignment with an implicit test. The recommended form is to do the assignment before doing the test:


             abool= bbool;
             if (abool) { ... }
          

    * Modern compilers will put variables in registers automatically. Use the register sparingly to indicate the variables that you think are most critical. In extreme cases, mark the 2-4 most critical values as register and mark the rest as REGISTER. The latter can be #defined to register on those machines with many registers. 

Be Const Correct
C++ provides the const key word to allow passing as parameters objects that cannot change to indicate when a method doesn't modify its object. Using const in all the right places is called "const correctness."

It's hard at first, but using const really tightens up your coding style. Const correctness grows on you.

If you don't use const correctness from the start it can be nightmare to add it in later because it causes a chain reaction of needing const everywhere. It's better to start being const correct from the start or you probably won't be.

You can always cast aways constness when necessary, but it's better not to.

For more information see Const Correctness in the C++ FAQ.

Placement of the Const Qualifier
When you combine const with pointers it can become quite confusing as to what const means. For example, is "const int * = NULL" an unchangeable pointer or is the int that it points to unchangeable? I know it always confuses me. Reese Anschultz suggested an alternate standard syntax that I've never tried, but it makes sense, so here it is:

int const = constant integer
int const * = pointer to constant integer
int const * const = constant pointer to constant integer
int const * const * = pointer to constant pointer to constant integ

This looks disturbingly different than the more common "const int A_GLOBAL_CONSTANT= 5" syntax we are used to seeing. But, according to the standards, the qualifier modifies everything to its left with the special exception where the qualifier precedes the first type and modifies just that type. Since there is one generalized form that works for all occasions, it is more consistent to always put the qualifier to the right of whatever is qualified.

Use Streams
Programmers transitioning from C to C++ find stream IO strange preferring the familiarity of good old stdio. Printf and gang seem to be more convenient and are well understood.

Type Safety
Stdio is not type safe, which is one of the reasons you are using C++, right? Stream IO is type safe. That's one good reason to use streams.

Standard Interface
When you want to dump an object to a stream there is a standard way of doing it: with the << operator. This is not true of objects and stdio.
Interchangeablity of Streams
One of the more advanced reasons for using streams is that once an object can dump itself to a stream it can dump itself to any stream. One stream may go to the screen, but another stream may be a serial port or network connection. Good stuff.
Streams Got Better
Stream IO is not perfect. It is however a lot better than it used to be. Streams are now standardized, acceptably efficient, more reliable, and now there's lots of documentation on how to use streams.
Check Thread Safety
Some stream implementations are not yet thread safe. Make sure that yours is.
But Not Perfect
For an embedded target tight on memory streams do not make sense. Streams inline a lot of code so you might find the image larger than you wish. Experiment a little. Streams might work on your target.

No Magic Numbers
A magic number is a bare naked number used in source code. It's magic because no-one has a clue what it means including the author inside 3 months. For example:

if      (22 == foo) { start_thermo_nuclear_war(); }
else if (19 == foo) { refund_lotso_money(); }
else if (16 == foo) { infinite_loop(); }
else                { cry_cause_im_lost(); }

In the above example what do 22 and 19 mean? If there was a number change or the numbers were just plain wrong how would you know?

Instead of magic numbers use a real name that means something. You can use #define or constants or enums as names. Which one is a design choice. For example:

#define   PRESIDENT_WENT_CRAZY  (22)
const int WE_GOOFED= 19;
enum 
{
   THEY_DIDNT_PAY= 16
};

if      (PRESIDENT_WENT_CRAZY == foo) { start_thermo_nuclear_war(); }
else if (WE_GOOFED            == foo) { refund_lotso_money(); }
else if (THEY_DIDNT_PAY       == foo) { infinite_loop(); }
else                                  { happy_days_i_know_why_im_here(); }

Now isn't that better? The const and enum options are preferable because when debugging the debugger has enough information to display both the value and the label. The #define option just shows up as a number in the debugger which is very inconvenient. The const option has the downside of allocating memory. Only you know if this matters for your application.

Error Return Check Policy

    * Check every system call for an error return, unless you know you wish to ignore errors. For example, printf returns an error code but rarely would you check for its return code. In which case you can cast the return to (void) if you really care.
    * Include the system error text for every system error message.
    * Check every call to malloc or realloc unless you know your versions of these calls do the right thing. You might want to have your own wrapper for these calls, including new, so you can do the right thing always and developers don't have to make memory checks everywhere. 

To Use Enums or Not to Use Enums
C++ allows constant variables, which should deprecate the use of enums as constants. Unfortunately, in most compilers constants take space. Some compilers will remove constants, but not all. Constants taking space precludes them from being used in tight memory environments like embedded systems. Workstation users should use constants and ignore the rest of this discussion.

In general enums are preferred to #define as enums are understood by the debugger.

Be aware enums are not of a guaranteed size. So if you have a type that can take a known range of values and it is transported in a message you can't use an enum as the type. Use the correct integer size and use constants or #define. Casting between integers and enums is very error prone as you could cast a value not in the enum.
A C++ Workaround
C++ allows static class variables. These variables are available anywhere and only the expected amount of space is taken.
Example

class Variables
{
public:
   static const int   A_VARIABLE;
   static const int   B_VARIABLE;
   static const int   C_VARIABLE;
}

Macros
Don't Turn C++ into Pascal
Don't change syntax via macro substitution. It makes the program unintelligible to all but the perpetrator.
Replace Macros with Inline Functions
In C++ macros are not needed for code efficiency. Use inlines.
Example

#define  MAX(x,y)	(((x) > (y) ? (x) : (y))	// Get the maximum

The macro above can be replaced for integers with the following inline function with no loss of efficiency:

   inline int 
   max(int x, int y)
   {
      return (x > y ? x : y);
   }

Be Careful of Side Effects
Macros should be used with caution because of the potential for error when invoked with an expression that has side effects.
Example

   MAX(f(x),z++);

Always Wrap the Expression in Parenthesis
When putting expressions in macros always wrap the expression in parenthesis to avoid potential communitive operation ambiguity.
Example

#define ADD(x,y) x + y

must be written as 

#define ADD(x,y) ((x) + (y))

Make Macro Names Unique
Like global variables macros can conflict with macros from other packages.

   |1. Prepend macro names with package names.
   |2. Avoid simple and common names like MAX and MIN. 

Do Not Default If Test to Non-Zero
Do not default the test for non-zero, i.e.


   if (FAIL != f()) 

is better than


   if (f()) 

even though FAIL may have the value 0 which C considers to be false. An explicit test will help you out later when somebody decides that a failure return should be -1 instead of 0. Explicit comparison should be used even if the comparison value will never change; e.g., if (!(bufsize % sizeof(int))) should be written instead as if ((bufsize % sizeof(int)) == 0) to reflect the numeric (not boolean) nature of the test. A frequent trouble spot is using strcmp to test for string equality, where the result should never ever be defaulted. The preferred approach is to define a macro STREQ.


   #define STREQ(a, b) (strcmp((a), (b)) == 0) 

Or better yet use an inline method:


   inline bool
   StringEqual(char* a, char* b)
   {
      return strcmp(a, b) == 0;
   }

Note, this is just an example, you should really use the standard library string type for doing the comparison.

The non-zero test is often defaulted for predicates and other functions or expressions which meet the following restrictions:

    * Returns 0 for false, nothing else.
    * Is named so that the meaning of (say) a true return is absolutely obvious. Call a predicate IsValid(), not CheckValid(). 

The Bull of Boolean Types
Any project using source code from many sources knows the pain of multiple conflicting boolean types. The new C++ standard defines a native boolean type. Until all compilers support bool, and existing code is changed to use it, we must still deal with the cruel world.

The form of boolean most accurately matching the new standard is:


   typedef int     bool;
   #define TRUE    1
   #define FALSE   0

or

   const int TRUE  = 1;
   const int FALSE = 0;

Note, the standard defines the names true and false not TRUE and FALSE. The all caps versions are used to not clash if the standard versions are available.

Even with these declarations, do not check a boolean value for equality with 1 (TRUE, YES, etc.); instead test for inequality with 0 (FALSE, NO, etc.). Most functions are guaranteed to return 0 if false, but only non-zero if true. Thus,


   if (TRUE == func()) { ... 

must be written


   if (FALSE != func()) { ... 

Usually Avoid Embedded Assignments
There is a time and a place for embedded assignment statements. In some constructs there is no better way to accomplish the results without making the code bulkier and less readable.


   while (EOF != (c = getchar())) 
   {
      process the character
   }

The ++ and -- operators count as assignment statements. So, for many purposes, do functions with side effects. Using embedded assignment statements to improve run-time performance is also possible. However, one should consider the tradeoff between increased speed and decreased maintainability that results when embedded assignments are used in artificial places. For example,


   a = b + c;
   d = a + r; 

should not be replaced by


   d = (a = b + c) + r; 

even though the latter may save one cycle. In the long run the time difference between the two will decrease as the optimizer gains maturity, while the difference in ease of maintenance will increase as the human memory of what's going on in the latter piece of code begins to fade.

Reusing Your Hard Work and the Hard Work of Others
Reuse across projects is almost impossible without a common framework in place. Objects conform to the services available to them. Different projects have different service environments making object reuse difficult.

Developing a common framework takes a lot of up front design effort. When this effort is not made, for whatever reasons, there are several techniques one can use to encourage reuse:

Ask! Email a Broadcast Request to the Group
This simple technique is rarely done. For some reason programmers feel it makes them seem less capable if they ask others for help. This is silly! Do new interesting work. Don't reinvent the same stuff over and over again.

If you need a piece of code email to the group asking if someone has already done it. The results can be surprising.

In most large groups individuals have no idea what other people are doing. You may even find someone is looking for something to do and will volunteer to do the code for you. There's always a gold mine out there if people work together.
Tell! When You do Something Tell Everyone
Let other people know if you have done something reusable. Don't be shy. And don't hide your work to protect your pride. Once people get in the habit of sharing work everyone gets better.
Don't be Afraid of Small Libraries
One common enemy of reuse is people not making libraries out of their code. A reusable class may be hiding in a program directory and will never have the thrill of being shared because the programmer won't factor the class or classes into a library.

One reason for this is because people don't like making small libraries. There's something about small libraries that doesn't feel right. Get over it. The computer doesn't care how many libraries you have.

If you have code that can be reused and can't be placed in an existing library then make a new library. Libraries don't stay small for long if people are really thinking about reuse.

If you are afraid of having to update makefiles when libraries are recomposed or added then don't include libraries in your makefiles, include the idea of services. Base level makefiles define services that are each composed of a set of libraries. Higher level makefiles specify the services they want. When the libraries for a service change only the lower level makefiles will have to change.

Keep a Repository
Most companies have no idea what code they have. And most programmers still don't communicate what they have done or ask for what currently exists. The solution is to keep a repository of what's available.

In an ideal world a programmer could go to a web page, browse or search a list of packaged libraries, taking what they need. If you can set up such a system where programmers voluntarily maintain such a system, great. If you have a librarian in charge of detecting reusability, even better.

Another approach is to automatically generate a repository from the source code. This is done by using common class, method, library, and subsystem headers that can double as man pages and repository entries.

Commenting Out Large Code Blocks
Sometimes large blocks of code need to be commented out for testing.
Using #if 0
The easiest way to do this is with an #if 0 block:

   void 
   example()
   {
      great looking code

      #if 0
      lots of code
      #endif
    
      more code
    }

You can't use /**/ style comments because comments can't contain comments and surely a large block of your code will contain a comment, won't it?

Don't use #ifdef as someone can unknowingly trigger ifdefs from the compiler command line.
Use Descriptive Macro Names Instead of 0
The problem with #if 0 is that even day later you or anyone else has no idea why this code is commented out. Is it because a feature has been dropped? Is it because it was buggy? It didn't compile? Can it be added back? It's a mystery.
Use Descriptive Macro Names Instead of #if 0

#if NOT_YET_IMPLEMENTED  

#if OBSOLETE

#if TEMP_DISABLED 

Add a Comment to Document Why
Add a short comment explaining why it is not implemented, obsolete or temporarily disabled.

Use #if Not #ifdef
Use #if MACRO not #ifdef MACRO. Someone might write code like:

#ifdef DEBUG
        temporary_debugger_break();
#endif

Someone else might compile the code with turned-of debug info like:

cc -c lurker.cpp -DDEBUG=0

Alway use #if, if you have to use the preprocessor. This works fine, and does the right thing, even if DEBUG is not defined at all (!)

#if DEBUG
        temporary_debugger_break();
#endif

If you really need to test whether a symbol is defined or not, test it with the defined() construct, which allows you to add more things later to the conditional without editing text that's already in the program:

#if !defined(USER_NAME)
 #define USER_NAME "john smith"
#endif

Creating a C Function in C++

extern "C" void
a_c_function_in_cplusplus(int a)
{
}

__cplusplus Preprocessor Directive
If you have code that must compile in a C and C++ environment then you must use the __cplusplus preprocessor directive. For example:

#ifdef __cplusplus

extern "C" some_function();

#else

extern some_function();

#endif

Mixing C and C++
In order to be backward compatible with dumb linkers C++'s link time type safety is implemented by encoding type information in link symbols, a process called name mangling. This creates a problem when linking to C code as C function names are not mangled. When calling a C function from C++ the function name will be mangled unless you turn it off. Name mangling is turned off with the extern "C" syntax. If you want to create a C function in C++ you must wrap it with the above syntax. If you want to call a C function in a C library from C++ you must wrap in the above syntax. Here are some examples:

Calling C Functions from C++

extern "C" int strncpy(...);
extern "C" int my_great_function();
extern "C"
{
   int strncpy(...);
   int my_great_function();
};

No Data Definitions in Header Files
Do not put data definitions in header files. for example:

/* 
 * aheader.h 
 */
int x = 0;

   |1. It's bad magic to have space consuming code silently inserted through the innocent use of header files.
   |2. It's not common practice to define variables in the header file so it will not occur to devellopers to look for this when there are problems.
   |3. Consider defining the variable once in a .cpp file and use an extern statement to reference it.
   |4. Consider using a singleton for access to the data. 

Make Functions Reentrant
Functions should not keep static variables that prevent a function from being reentrant. Functions can declare variables static. Some C library functions in the past, for example, kept a static buffer to use a temporary work area. Problems happen when the function is called one or more times at the same time. This can happen when multiple tasks are used or say from a signal handler. Using the static buffer caused results to overlap and become corrupted.

The moral is make your functions reentrant by not using static variables in a function. Besides, every machine has 128MB of RAM now so we don't worry about buffer space any more :-)

Use the Resource Acquisition is Initialization (RAII) Idiom
RAII is a pattern useful in making sure allocated resources get freed. What kind of resources? Memory usually. Could be file descriptors or locks too. Anything that is allocated at one point and needs to be deleted at another point in your code.

C++ can help make this painless because of a feature I miss a lot in Java, that your destructor is always called when an object leaves scope. This feature has caused the creation of the Guard idiom. A Guard can be wrapped around any resource so has to free the resource when the guard goes out of scope.

If you think you are always so careful to pair new and deletes that you don't need to use one of those pattern thingies then I am sure I'll be sitting beside you someday, like I have dozens of times before, searching for resource leaks in your code.

The acquisition phase happens at construction. You are supposed to do all the initialization in the constructor so you can do all the cleaning up in the destructor. And if you can guarantee through some different means that the destructor is always called then you can be pretty sure you won't leak.

Some intialization sequences can't be done in the constructor, particularly those using message driven state machines, but pretty much everything else can. And for those things use RAII. The justification is that it will save your butt from the many memory links that haunt large software products written in C++.

The key is to make sure the destructor is always called. The easiest way is to use a stack variable. That way you know the destructor will be called when leaving scope.

For pointers you can use one of the many smart pointer variants like auto_ptr. These will make sure your pointers are deleted when memory ownership is transferred or the scope is exited. You can even use them as member variables so you don't have to write code in the destructor.

If you can't use exceptions then this idiom isn't for you. As you are doing a lot of work in the constructor you can have errors and you'll want throw an exception.

See http://www.hackcraft.net/raii/ for a better explanation of RAII.

Remove Trailing Whitespace
Avoid trailing whitespace in source code as it causes source control systems that show diffs to show unecessary diffs that overwhelm the poor programmers ability to care.

		17.1.13. Portability

Use Typedefs for Types
It's a good idea to typedef int8, int16, int32, int64, float32, float64, uint8, uint16, uint32, uint64, etc., instead of assuming it'll be done with int, long, float, and short.

Alignment of Class Members
There seems to be disagreement on how to align class data members. Be aware that different platforms have different alignment rules and it can be an issue. Alignment may also be an issue when using shared memory and shared libraries.

The real thing to remember when it comes to alignment is to put the biggest data members first, and smaller members later, and to pad with char[] so that the same structure would be used no matter whether the compiler was in "naturally aligned" or "packed" mode.

For the Mac there's no blanket "always on four byte boundaries" rule -- rather, the rule is "alignment is natural, but never bigger than 4 bytes, unless the member is a double and first in the struct in which case it is 8". And that rule was inherited from PowerOpen/AIX.

Compiler Dependent Exceptions
Using exceptions across the shared library boundary could cause some problems if the shared library and the client module are compiled by different compiler vendors.

Compiler Dependent RTTI
Different compilers are not guaranteed to name types the same.

		17.1.14. Popular Myths

Promise of OO
OO has been hyped to the extent you'd figure it would solve world hunger and usher in a new era of world peace. Not! OO is an approach, a philosophy, it's not a recipe which blindly followed yields quality.

Robert Martin put OO in perspective:

    * OO, when properly employed, does enhance the reusability of software. But it does so at the cost of complexity and design time. Reusable code is more complex and takes longer to design and implement. Furthermore, it often takes two or more tries to create something that is even marginally reusable.
    * OO, when properly employed, does enhance the software's resilience to change. But it does so at the cost of complexity and design time. This trade off is almost always a win, but it is hard to swallow sometimes.
    * OO does not necessarily make anything easier to understand. There is no magical mapping between the software concepts and every human's map of the real world. Every person is different. What one person percieves to be a simple and elegant design, another will perceive as convoluted and opaque.
    * If a team has been able, by applying point 1 above, to create a repository of reusable items, then development times can begin to shrink significantly due to reuse.
    * If a team has been able, by applying point 2 above, to create software that is resilient to change, then maintenance of that software will be much simpler and much less error prone. 

You can't use OO and C++ on Embedded Systems
Oh yes you can. I've used C++ on several embedded systems as have many others. And if you can't why not? Please don't give in to vague feelings and prejudice. An attitude best shown with a short exchange:

Rube: Our packet driver is slow. We're only getting 100 packets per second.
Me  : Good thing you didn't do it in C++ huh?
Rube: Oh yah, it would have been really slow then!
Me  : (smiled secretly to myself)

My initial response was prompted by a general unacceptance of C++ in the project and blaming C++ for all problems. Of course all the parts written in C and assembly had no problems :-) Embedded systems shops tend to be hardware driven companies and tend not to know much about software development, thus any new fangled concepts like OO and C++ are ridiculed without verbally accessible reasons. Counter arguments like code that is fast and small and reusable don't make a dent. Examples like improving the speed of a driver by inlining certain methods and not hacking the code to death gently roll into the bit bucket.

Techniques
Of course C++ can be a disaster for an embedded system when used incorrectly, which of course is true of any tool. Here's some ideas to use C++ safely in an embedded system:

    * Get Some Training!

      If people don't know C++ and OO then they will likely fail and blame their tools. A good craftsperson doesn't blame their tools. Get training. Hire at least one experienced person as guide/mentor.

    * Be Careful Using Streams

      The streams library is large and slow. You are better off making a "fake" streams library by overloading the << operator. If you have a lot of memory then use streams, they are convenient and useful.

    * Be Careful Using Templates

      Code using templates can suffer from extreme code bloat. This is pretty much a function of your compiler as templates can be efficiently used when done correctly. Test your compiler for it how handles templates. If it doesn't make a copy per file for each template then you are in business. Templates have good time efficiency so they would be nice to use.

      You can fix the template code bloat problem by using explicit instantiation. Actually, even if the compiler generates one copy per source file. This, however, is often too much programmer work to expect on a large project, so be careful. Many linkers are smart enough to strip away all but one of the copies.

      Another issue to consider is template complexity. Templates can be complex for those new to C++. Bugs in templates are very hard to find and may overwhelm the patience of users.

    * Exceptions Beware

      Embedded applications are usually interrupt driven and multi-threaded. Test that exceptions are thread safe. Many compilers support exceptions, but not thread safe exceptions. And you probably don't want to call code in an interrupt that throws exceptions.

    * Use Polymorphic Interfaces to Make Frameworks

      When you think through your design and come up with good abstractions you will be shocked at how little code and how little time it takes to implement new features.

    * Make an OS Encapsulation Library

      Don't use your embedded OSs features directly. Create a layer that encapsulates OS functions and use those encapsulations. Most feature like tasks, interrupts, semaphores, message queues, messages, etc. are common to all systems. With good encapsulations it's quite possible to have the same code compile for Solaris, VxWorks, Windows, and other systems. It just takes a little thought.

    * ROM Beware

      A lot of systems create a ROM and download code later over the network that is linked against the ROM. Something to remember is linkers will try and include only code that is used. So your ROM may not contain code that loaded code expects to be there. You need to include all functions in your ROM.

    * Multiple Interface Levels

      Most embedded systems have a command line interface which usually requires C linkage, then they may have an SNMP interface, and they may have some sort of other friendly interface. Design this up front to be common across all code. It will make your life much easier. C functions require access to global pointers so they can use objects. The singleton pattern makes this easier.

      Come up with common naming conventions. A decent one is:
          o Make up a module abbreviation that can be prefixed to all calls. For example: log for the logging module.
          o Encode an action after the prefix. For example: logHelp which prints help for the logging module.
          o Require a certain set of functions for each sub system: For example:
                + moduleHelp - prints help for the module
                + modulePrint - prints the current state of the module
                + moduleStart - start a module
                + moduleStop - stop a module
                + moduleSetDebug - set the debug level for a module. It's very nice to set debug levels on a module by module basis. 

    * Debug and Error System First

      Make your debug and error system first so everyone writing code will use it. It's very hard to retrofit code with debug output and intelligent use of error codes. If you have some way to write system assert errors to NVRAM, disk, or some other form of persistent storage so you can recover it on the next reboot.

    * Think About Memory

      Think how you'll share memory buffers between ISR code and task level code. Think how fast your default memory allocator is, it is probably slow. Think if your processor supports purify! Think how you'll track memory corruption and leakage.

    * Think About System Integrity

      You need to design up front how you are going to handle watchdog functions and test that the system is still running and not corrupted.

    * Remember to Use Volatile

      When using memory mapped I/O make sure that you declare the input port variables as volatile, (some compilers do this automatically), since the value can change without notice, and the optimizer could eliminate what looks like a redundant access to that variable. Not using volatile leads to some very obscure bugs. If you suspect problems in this area take a look at the generated code to make sure read-only assumptions are being made.

      Sometimes the keyword volatile is ifdef'd out for portability reasons. Check that what you think is volatile is really declared as volatile. 

Comments (View)
Loading comments...
 
Problems loading Disqus?
Like Dislike

    * 1 person liked this.

	Community 	
Disqus

    *
      Login options
          o
          o
          o
          o
          o
          o
    * About Disqus

Glad you liked it. Would you like to share?

Facebook

Twitter

Share No thanks

Sharing this page ...

Thanks! Close
Add New Comment
Post as â¦
Showing 63 comments
Sort by   Subscribe by email   Subscribe by RSS

    *
      	
      Sagar Ranglani [Moderator] 2 years ago
      This is extreamly comprehensive... No doubt...The above things are comming out of a highly experienced programmers' brain. Extreamly usefull...
      Thanx ...
      Flag
      1 person liked this. Like Reply Reply
    *
      	
      buy youtube views [Moderator] 1 month ago
      I think weâre making some progress now. TurboGears 2 and Pylons use something weâre calling âWSGI Componentsâ which are not pure WSGI middleware in the sense you mean it. Routes for example has a pretty standard API to work with, but itâs (or something implementing that API) is definitely required for Pylons to work.
      Flag
      Like Reply Reply
    *
      	
      SUNDAY [Moderator] 2 months ago
      HOW CAN I GET CODES FOR ALREADY DESIGN PROGRAM IN C++
      Flag
      Like Reply Reply
    *
      	
      SUNDAY [Moderator] 2 months ago
      HOW CAN I GET A COMPLETE PROGRAM CODE FOR SERIES OF SOFTWARE AND DESIGN PROCEDURE
      Flag
      Like Reply Reply
    *
      	
      Mike [Moderator] 3 months ago
      "Continue and break like goto should be used sparingly as they are magic in code. With a simple spell the reader is beamed to god knows where for some usually undocumented reason."

      I'm sorry, Mr. Hoff, but this makes you look stupid. Regardless of how clearly or not the loop is written, the change in program flow after a continue or break is very well defined; if you think you've been "beamed to god knows where," you just don't know what you're doing, and should consider a career in retail. If, on the other hand, you think that this kind of hyperbole is amusing, well... you do your readers a disservice by discouraging them away from these useful constructs.

      Properly used, continue and break within loops enhance clarity. The key issue in the problematic case you describe is not the continue and break, but the "lot of code" issue. Long blocks of code, regardless of the control structures contained therein, are prone to bugs. Additionally, the loop in your particular example was written poorly: the test should have been incorporated into the while loop itself: "while (i++ > STOP_VALUE) {...}".

      I further suspect that, as presented in your example, the use of post-increment rather than a pre-increment, located at the end of the loop, was also a bug, but that would depend on the initialization and use of 'i' before and within the loop. If in fact that was the correct behavior, replacing the while() with a do/while() would have been the preferred construct.

      I have not yet found in your document whether you also discourage the use of multiple exit points from a function using early 'return' statements. There was a while when this was also discouraged, but the current thinking is that early exits also contribute to clarity, especially when used at the beginning of a function to check for e.g. error conditions before proceeding with the true logic of the function.
      Flag
      Like Reply Reply
    *
      	
      toddhoff [Moderator] 3 months ago in reply to Mike
      Maybe I just don't look stupid? While I don't agree with every point in the standard, I do agree strongly with this one. My personal style has always been to rely heavily on early exits. Create a function that is very narrow in scope, return when you find something interesting, and the end say nothing interesting was found. This means below a return statement you know there's no interaction. Very easy to understand. It also works beautifully with RAII. Nothing similar an be said about continues/breaks/and gotos (beyond their traditional uses in switch/loops). When you come upon code in the wild that is pages long and is filled with control flow jumps the only way to understand it is to execute the code in your head, which is much harder than a syntactic scan, which is what you want from code. You are of course more than free to disagree and do differently. I would say that many bugs, especially resource exhaustion bugs, are found in code with heavy control flow manipulation.
      Flag
      Like Reply Reply
    *
      	
      Mike [Moderator] 4 months ago
      "Until all compilers support bool" -- huh? Do you know of any C++ implementation that has never supported bool fully? And if you're talking only about C, then you should not be encouraging people to define a type called "bool" because of potential conflicts if their code is used by a C++ compiler.

      As for this bit of wisdom:
      "if (TRUE == func()) { ... must be written if (FALSE != func()) { ... "

      Neither form is best. If the function returns 0 for the false condition, then a simple "if (func())" to detect true is correct, always , in C or C++, and more readable.
      If, on the other hand, the function returns 0 for "no error" and an error code for error, then you'd want to use "if (func() == NO_ERROR)" -- NO_ERROR, not FALSE. It may be acceptable in the scope of a project to accept the idiom of !func() => "no error," but that's not too intuitive: "not" does not imply "success." Compare this to using if (!ptr) to test for a NULL pointer, which is intuitive as well as readable.
      Flag
      Like Reply Reply
    *
      	
      Mike [Moderator] 4 months ago
      "Block of declarations should be aligned."
      No, they should not. If you have a block of declarations with a bunch of short types and then later need to add a longer type, this technique requires changing all the whitespace in that block just to accommodate this rule. Columnar alignment has its uses, particularly in lines of calculation that are similar so as to point out the differences. This rule is misguided.
      Flag
      Like Reply Reply
    *
      	
      Wolf [Moderator] 4 months ago in reply to Mike
      Yes mike, this is an important point! I'm discussing this strange kind of beauty for years.
      Do you know a place in the web, where a standard for C++ could be elaborated
      and it's elements get discussed constructively? I'm very interested in this topic.
      Please let me read the link here. or there:
      http://www.possibility.com/Cpp/CppCodingStandar...

      Thanks in advance!
      Flag
      1 person liked this. Like Reply Reply
    *
      	
      Mike [Moderator] 4 months ago
      "It's a good idea to typedef int8, int16, int32, int64, float32, float64, uint8, uint16, uint32, uint64"
      In C99, <stdint.h> defines int8_t, int16_t, uint32_t, etc. These types have not yet made it into the C++ standard, but they are defined in boost::cstdint with those same names. The shorter versions, however nice and clean they are, should be deprecated in favor of the standard names.
      Flag
      Like Reply Reply
    *
      	
      Recruit0 [Moderator] 4 months ago
      Very nice.

      EDIT: Didn't realize there was a PDF of this and links to sections. Lots of information here.
      Flag
      Like Reply Reply
    *
      	
      Wolf [Moderator] 4 months ago
      I have (at least) one question concerning your C++ coding standard.
      It's about padding within parentheses. I'm not sure whether to like or dislike it,
      I practised both in my programming. As I read, you seem to favor no padding.
      The Java coding standard shares your favor. Would you tell me (or best of all:
      the future readers of your standard) good reasons for doing so?
      Please do not misconceive me: Currently I like the style you discribe.
      But I have no found a really competitive reason against "visual clarity" of the padded version.

      With best regards
      Flag
      Like Reply Reply
    *
      	
      toddhoff [Moderator] 4 months ago in reply to Wolf
      I don't think there are any really any truly convincing reasons when it comes to these sorts of choices. The point here I think is ease of code reading. The space separating everything approach makes everything look a like, which in a functional language is probably sensible, but in C++ we have if, while, do, etc and these should stand out when scanning. They stand out less when everything has a space. YMMV.
      Flag
      Like Reply Reply
    *
      	
      Wolf [Moderator] 4 months ago in reply to toddhoff
      Since this is about C++, isn't it a good idea to add some these considerations
      to the section at http://www.possibility.com/Cpp/CppCodingStandar... ?
      the ease for scanning source code provided by spaces after keywords is certainly
      limited by padding spaces within parentheses.

      Your reason seems "convincing" to me, even if maybe not "truly convincing" to everybody. ;-)
      Flag
      Like Reply Reply
    *
      	
      Ð¢Ð¸Ð¿Ð¾Ð³ÑÐ°ÑÐ¸Ñ [Moderator] 4 months ago
      Thanks. It`s good
      Flag
      Like Reply Reply
    *
      	
      Electronic Cigarette Girl [Moderator] 4 months ago
      Im new at coding so a lot of this is over my head but useful as I keep learning. Every time I visit this article it makes more and more sense to me.

      -Bella :)
      Flag
      Like Reply Reply
    *
      	
      1465 [Moderator] 5 months ago
      give another information about topic in turoo c
      Flag
      Like Reply Reply
    *
      	
      martindesjardins [Moderator] 6 months ago
      Hi !

      Nice coding standard. I agree with most of it and fit with observations i gather through my 12 years of professional programming. I wouldnt be afraid to take it as a whole and applying it in the company where i work.

      Good job !

      Martin Desjardins ing.
      Flag
      Like Reply Reply
    *
      	
      Manifestsilence [Moderator] 7 months ago
      Thank you for a wonderful read. I'm quite new to serious programming - I'm a long time dabbler in Basic for Conway-esque simulations and the like, and now teaching myself C++. This page is by far the best guidance I have found for the scope of the language, what constitutes good habits, and what the heck kind of mess I'm getting into here. Made me smile a lot too. I read the whole dang thing in one sitting at 2am even though I'm very new to the details of the language so much of my understanding was fuzzy at best. That it made as much sense as it did to me is a testament to your clarity.
      Flag
      Like Reply Reply
    *
      	
      toddh [Moderator] 7 months ago in reply to Manifestsilence
      Great, I'm glad you found it helpful. Now get some sleep :-)
      Flag
      Like Reply Reply
    *
      	
      MartinBell [Moderator] 10 months ago
      Hello. I have a question concerning your standard. Iâm using a very similar naming convention in my own project. Itâs based on the convention from my previous company with some changes but is quite close to your one. Unfortunately with this convention I sometimes get clashes between class and member names. For example.

      class Widget
      {
      ...
      };

      class WidgetContainer
      {
      Public:
      Const Widget& GetMeTheWidgetMethod(){return mWidget;}

      Private:
      Widget mWidget;
      };

      The question is what would you call GetMeTheWidgetMethod? I would like to call it simply Widget so you can call it as so:

      const Widget& widget=container->Widget();

      Obviously you cannot do this C++. You could call it GetWidget() or even TheWidget(). The problem is its then inconsistent with the rest of the code. At my old company we prefixed all class names with C in the same way as MFC does which is a solution but Iâd rather not go there.

      Thank you.
      Flag
      Like Reply Reply
    *
      	
      MartinBell [Moderator] 10 months ago in reply to MartinBell
      Iâve sort of solved my own problem. You just need to prefix the word class then using a Widget inside WidgetContainer. Iâm sure there is a better naming convention but this at least works. It would certainly confuse people so I wouldnât use it on a big project.

      class WidgetContainer
      {
      Public:
      Const class Widget& Widget(){return mWidget;}

      Private:
      class Widget mWidget;
      };
      Flag
      Like Reply Reply
    *
      	
      hotmail email [Moderator] 10 months ago
      Wow.. thanks your information about coding is awsome thanks a lot..
      Flag
      Like Reply Reply
    *
      	
      sanzilla [Moderator] 10 months ago
      nice article sir ,
      keep this up.
      Flag
      Like Reply Reply
    *
      	
      Thomas [Moderator] 1 year ago
      is this THE coding standard? are there any other coding standards which are spread in big software-companies?
      till now i had my "own coding standard" but now i will use a wide spread standard.... i think this document will be very useful :-)

      last question: is it possible to add pagenumbers to the pdf-document?
      Flag
      Like Reply Reply
    *
      	
      angel_tsankov [Moderator] 1 year ago
      What is the rationale behind including system headers first, then project headers, and finally local ones? Why not include them in the reverse order?
      That could help us catch missing includes in local files.
      Flag
      Like Reply Reply
    *
      	
      toddh [Moderator] 1 year ago in reply to angel_tsankov
      I think an order is the important thing and makes the code easier to
      scan and understand. Which order doesn't matter unless you are trying to
      define forwardly referenced classes. There usually develops a pattern.
      System files exist in low layer encaps and higher level application code
      includes those so system files shouldn't be all that common anyway.
      Flag
      Like Reply Reply
    *
      	
      littleprogrammer [Moderator] 1 year ago
      Hello ! I enjoyed your article and it seems great to me. I like it, and I think it's really usefull. I can say that I'd undersnat something very important today. Keep programming, guy ! :)
      Flag
      Like Reply Reply
    *
      	
      mrtecnolog [Moderator] 1 year ago in reply to littleprogrammer
      hei littleprogrammer, It seems like we are of the same kind,hey dude i like dealing with programming that much.Today i saw one ATM system and notice some many bugs which need to be dealt with.in my time im gonna develop a system...yah!!! keep on working hard bra!!
      Flag
      Like Reply Reply
    *
      	
      littleprogrammer [Moderator] 1 year ago in reply to mrtecnolog
      Good luck with your project guy, and me patient. I think it will "grow" great, and it's probably awesome ;) !


      This day I wanna implemet a calculator for the big numbers (over 500 digits). I learn how to make operations with this and I think it's really cool. I like big numbers. More about me: I'm studding algorithms and make problems for the Informatics Olimpycs in Romania, I'm form Romania ....

      See ya, let's start programming. :D
      Flag
      Like Reply Reply
    *
      	
      Name [Moderator] 1 year ago
      Very nice page. But I am confused in one aspect:
      How should I name boost::shared_ptr?
      Should I use "pMyName" because it is holding a pointer and provides pointer syntax
      or "my_name" because it is allocated on the stack?
      Flag
      Like Reply Reply
    *
      	
      cool986 [Moderator] 1 year ago
      Pretty cool set of resources...thanks
      http://www.mpos.net/s/p4.asp
      http://fashionshow99.spaces.live.com
      Flag
      Like Reply Reply
    *
      	
      Muhammad alaa [Moderator] 1 year ago
      this is awsome. thanks guys so much
      Flag
      Like Reply Reply
    *
      	
      LUTHANDO [Moderator] 1 year ago
      Hi, i just wanna thank you for supporting us with a such full resource like this, my dream for future is to become a recognised software engineerer again thank you.
      Flag
      Like Reply Reply
    *
      	
      season [Moderator] 1 year ago
      Very comprehensive...but it's would be great to have some files put all these rules together
      I am saying that with the files readers could use as templates
      Flag
      Like Reply Reply
    *
      	
      Lestaizezima [Moderator] 1 year ago
      Anything you can tell me on how to make hacks cuz im new in this stuff i need to make a hack for this game for my friend it deals with Getting by a security system GameGaurd and beable to track people characters movement to be able to hit them (the game is Soldier Front from ijji)
      Flag
      Like Reply Reply
    *
      	
      learn.hypnosis [Moderator] 1 year ago
      Great job .............. Keep going......................
      Flag
      Like Reply Reply
    *
      	
      pratik [Moderator] 1 year ago
      gr8 one..thankz a lot
      Flag
      Like Reply Reply
    *
      	
      FloridaHealthInsurance [Moderator] 1 year ago
      thanks for sharing the useful resources. no doubt the person is highly experienced. thanks .
      Flag
      Like Reply Reply
    *
      	
      FloridaHealthInsuranceQuotes [Moderator] 1 year ago
      The /* (slash, asterisk) characters, followed by any sequence of characters (including new lines), followed by the */ characters. This syntax is the same as ANSI C.
      Flag
      Like Reply Reply
    *
      	
      Jeremy [Moderator] 1 year ago
      I suggest removing the "Flow Chart for Project Decision Making" due to the foul language. I am trying to convince my employer of the need to adopt a coding standard. I really like the content here but the "joke" at the beginning is undermining the effectiveness of the article.
      Flag
      Like Reply Reply
    *
      	
      todd [Moderator] 1 year ago in reply to Jeremy
      What people usually do is make a copy and delete what they find objectionable and add their local changes. Feel free to do the same.
      Flag
      Like Reply Reply
    *
      	
      Mike [Moderator] 4 months ago in reply to todd
      It's not just the foul language; it's the smarmy side comments and sardonic tone that pervades the article that make it difficult to recommend. Like, in the "one statement per line" section, you write "Nothing better than to read code that is one line after another with no white space or comments." In fact you mean something more like "It is painful to read code..." There are people reading this whose first language isn't English; forcing them to deal with your sarcasm is even more counterproductive than the foul language.

      And as for the little dialog between you and the "rube" -- are we supposed to be impressed that you look down your nose at someone? That you "smile secretly to yourself"? You undermine the useful information by treating its presentation as a lark, and because these little bits are sprinkled throughout, it requires someone who wants to make "local changes" towards a more professional tone to be a very diligent copy editor.
      Flag
      Like Reply Reply
    *
      	
      toddhoff [Moderator] 4 months ago in reply to Mike
      I got it Mike. You don't like me or the standard. But I do appreciate the more substantial comments you have made elsewhere and hopefully they'll give others something to think about when writing their own take on a standard.
      Flag
      Like Reply Reply
    *
      	
      Piyush Aggarwala [Moderator] 1 year ago
      Simply KILLER documentation. My cousin showed me this information and even though I don't write in C/C++ (I'm a VBA and newbie to VB.NET), I am picking up some cool ideas with my coding.
      Flag
      Like Reply Reply
    *
      	
      shahri [Moderator] 1 year ago
      I'd like to write something special, but I can just ACK the things the other commenters wrote: Very helpful!
      Flag
      Like Reply Reply
    *
      	
      fiancee visa [Moderator] 1 year ago
      The /* (slash, asterisk) characters, followed by any sequence of characters (including new lines), followed by the */ characters. This syntax is the same as ANSI C.
      Flag
      Like Reply Reply
    *
      	
      fiancee visa [Moderator] 1 year ago
      Really a very helpful information. Thanks for sharing with us. Like your way of view.
      Flag
      Like Reply Reply
    *
      	
      purushottam [Moderator] 1 year ago
      i want a table of 2 in c++ codeing
      Flag
      Like Reply Reply
    *
      	
      Fabio Locati [Moderator] 1 year ago
      Is there a PDF version of this?
      Flag
      Like Reply Reply
    *
      	
      todd [Moderator] 1 year ago in reply to Fabio Locati
      Sorry, no. Just html.
      Flag
      Like Reply Reply
    *
      	
      Jonathon Ogden [Moderator] 1 year ago
      Superb documentation. Whilst it contains your own thoughts you use many other sources so you aren't implying that you are only right and everyone else is wrong. Very balanced view of the different subjects since any aspect that you covered can be a source for arguments. One instance for me was that in a small team I worked with, 2 members argued for 8 hours solid on whether to use the prefix 'm' for member variables or 'm_typename' e.g bool m_boolGenderIsMale or bool mGenderIsMale.

      Anyway, your documentation is brilliant and I have to agree with Sagar, certainly comes from a highly experienced programmers' mind, one that is especially balanced regarding these subjects. I hope you continue to develop this documentation if the need arises.
      Flag
      Like Reply Reply
    *
      	
      todd [Moderator] 1 year ago in reply to Jonathon Ogden
      Spending eight hours on such a seemingly trivial distinction sounds very familiar :-) Do that on several projects and you get this standard. I'm glad people have found it useful.
      Flag
      Like Reply Reply
    *
      	
      visitor [Moderator] 1 year ago
      great Stuff! Thanks
      Flag
      Like Reply Reply
    *
      	
      Chris [Moderator] 1 year ago
      love the Flow Chart for Project Decision Making thing. that really cracked me up laughing.
      Flag
      Like Reply Reply
    *
      	
      Niki [Moderator] 2 years ago
      Thanks.
      Flag
      Like Reply Reply
    *
      	
      Puppy[CN] [Moderator] 2 years ago
      Thanks very much for the great suggestions in the doc ~~ they're really useful in my coding practice.
      Flag
      Like Reply Reply
    *
      	
      Pascal [Moderator] 2 years ago
      Wow. This is the largest coding standard list I've found so far.

      Programming Language Questions & review
      Flag
      Like Reply Reply
    *
      	
      ranjankumar [Moderator] 2 years ago
      Thanx Toddh for nice document.
      We have taken this for as the standards practice for coding in C++ at CDAC Mumbai, India.
      http://cdacmumbai.in
      Flag
      Like Reply Reply
    *
      	
      toddh [Moderator] 2 years ago
      Thanks Sagar for the kind words. And thanks for being my first Disqus comment!
      Flag
      Like Reply Reply
    *
      	
      toddh [Moderator] 2 years ago
      test
      Flag
      Like Reply Reply
    *
      	
      rock [Moderator] 1 year ago in reply to toddh
      Can u tell me how many functions a class should hold as per coding standards
      Flag
      Like Reply Reply
    *
      	
      toddh [Moderator] 1 year ago in reply to rock
      I could but I would be lying. It's the nastiest of all things, a judgment call. Sure, if there were more than X then I might be concerned. X maybe 30 or pick some other number. What matters to me are does it meet design rules like high cohesion, loose coupling, single responsibility, unit tested, clear naming, well documented etc. If there are 20 convenience accessors I would worry about it. If there were 20 methods that look like they belong to another class than I would worry.
      Flag
      Like Reply Reply

Trackback URL 
blog comments powered by Disqus

Â© Copyright 1995-2008. Todd Hoff. All rights reserved.
	


	17.2 Const correctness 

"const-correctness" is a key concept in large scale software projects. Yet, to implement it thoroughly, one has to fully understand what const actually means. Oddly enough, this keyword has no less than three different meanings in C++. In this article I will explain each meaning and provide cues for coping with the baffling syntax. This discussion serves as the basis for future articles that will address const-correctness.
const objects

Declaring an object as const is a commitment made by the programmer that the program doesn't alter it subsequently. (Note that I'm using the term object in its wider sense, namely class objects and data variables.) A const definition (as opposed to a const declaration) must include a proper initializer. For example,

const int MAX_LINE=25;
const std::string address="203.178.156.66";
const char signage[15]="fire alarm";
const double in2cm = 2.54; 

const pointers

The second type of const refers to pointers. Declaring a pointer as const ensures that the program doesn't assign a new address to it afterwards. The object bound to such a pointer may be modified, though. For example,

int r=10, s=0;
int *const pci = &s; // pci is a const pointer to int
pci++; // error, can't modify a const pointer
pci= &r; // error
*pci=9; //OK 

const Member Functions

In addition to const objects and const pointers (which were originally introduced in C), C++ has a third type of const, namely const member functions. A class object's state consists of the values of its non-static data members. Declaring a member function as const ensures that that function doesn't change its object's state. You do that by appending const after the function's parameter list. For example,

class Student
{
public:
 double getAvg() const {return average;} //const member function
private:
 double average;
//...
};

Trying to modify a data member inside a const member function is an error:

int Student::getAvg() const
{
 average += 0.5; // compilation error
 return average; 
}

Complex Declarations

Because const can apply to both objects and pointers, and because its exact position in a declaration is flexible, even experienced programmers find const declarations of compound types confusing.

Consider the following example. Can you tell what the types of x and y are?

const char * x= "test";
char const * y= "another one";

x and y actually have the same type, namely "pointer to const char", in spite of the variation in the position of const. const may appear before or after a type name, without changing the declaration's meaning.

This free ordering rule isn't unique to const. Consider the position of the keywords long and unsigned in the following example:

int long n;
long int m; //same as above
unsigned long o;
long unsigned r; //same as above

Now consider the following const declaration:

char * const z= "test";

This time, the type of z is "const pointer to char". How does the compiler know that z is a const pointer, whereas x and y are not? More importantly, how can you distinguish between const pointers and pointers to const variables?

The secret lies in the location of const with respect to the asterisk. The sequence "* const" always indicates a const pointer. If, however, the const appears before the asterisk, then the object bound to the pointer is const. This brings us to yet another complexity.
const pointers of const objects

It's possible to combine const objects and const pointers in a single declaration. The result is a const pointer to a const object:

const int n=1;
const int * const p= &n; // const pointer to const int

Let's parse it together. p is a const pointer because its declaration contains the sequence "* const". It points to const int because declaration contains another const before the asterisk.

Is it possible to combine the three types of const in one declaration? Certainly:

class A
{
//...
const int * const get_scores(int id) const;
};

get_scores() is a const member function that returns a const pointer to const int.
operator const_cast<>

The operator const_cast<> removes the const quality of an object. Note that removing const-ness this doesn't mean that you can modify the resulting object. Consider:

const char *msg= "hello world";
int main() 
{
 char * s = const_cast <char *> (msg); // get rid of const
 strcpy(s, "bad idea!"); //undefined behavior
}

Any attempt to overwrite s will result in undefined behavior. The problem is that const objects may be stored in the system's read-only memory. A brute-force removal of const allows you to treat the object as if it weren't const, say passing it as an argument to a function that takes char *, but not to modify it.

const_cast<> performs the opposite operation as well, namely convert a non-const object to const. For example:

char s[]= "fasten your seatbelt";
size=strlen(const_cast<const char *> (s));// more explicit

You will rarely see such uses of const_cast<> though. C++ automatically converts non-const objects to const in a context that requires a const object. Therefore, using const_cast<> to make an object const is never mandatory, although it documents the programmer's intention explicitly.
Summary

The syntactic intricacies often cause programmers to give up the use of const, thereby producing code that is less secure and less readable. While the difference between pointers to const objects and const pointers is rather subtle, checking the position of the const qualifier with respect to the asterisk should resolve the ambiguity. const member functions are easily recognized by the presence of const after the parameter list.
Sample Chapters

"Object Engineering Techniques" By Richard Due is a sample chapter from Mentoring Object Technology Projects. This chapter discusses some of the common object-oriented design methods such as use case modeling and class-responsibility-collaboration (CRC) modeling.
Safari Books

Modern C++ Design: Generic Programming and Design Patterns Applied by Andrei Alexandrescu is an excellent guide to state-of-the-art C++ design. The books discusses powerful syntactic features such as partial template specialization along with guidelines for effective generic class design. 


	17.3

18. Nuts and bolts, odds and ends

	18.1 templates

		18.1.1 Push the limits of the meta compiler
This code:
template <int i > 
class A: A<i+1>
{

};

int main(){

A<1> a;

return 0;
}

Will provoke this compilation error:
/users/yizaq/stam.cpp:3:   instantiated from `A<14>'
/users/yizaq/stam.cpp:3:   instantiated from `A<13>'
/users/yizaq/stam.cpp:3:   instantiated from `A<12>'
/users/yizaq/stam.cpp:3:   instantiated from `A<11>'
/users/yizaq/stam.cpp:3:   instantiated from `A<10>'
/users/yizaq/stam.cpp:3:   instantiated from `A<9>'
/users/yizaq/stam.cpp:3:   instantiated from `A<8>'
/users/yizaq/stam.cpp:3:   instantiated from `A<7>'
/users/yizaq/stam.cpp:3:   instantiated from `A<6>'
/users/yizaq/stam.cpp:3:   instantiated from `A<5>'
/users/yizaq/stam.cpp:3:   instantiated from `A<4>'
/users/yizaq/stam.cpp:3:   instantiated from `A<3>'
/users/yizaq/stam.cpp:3:   instantiated from `A<2>'
/users/yizaq/stam.cpp:3:   instantiated from `A<1>'
/users/yizaq/stam.cpp:9:   instantiated from here

/users/yizaq/stam.cpp:3: error: invalid use of undefined type `class A<501>'
/users/yizaq/stam.cpp:3: error: declaration of `class A<501>'


	18.2 Limits

	climits (limits.h)
header
Sizes of integral types

This header defines constants with the limits of integral types for the specific system and compiler implemetation used.

The following panel shows the different constants and their guaranteed minimal magnitudes (positive numbers may be greater in value, and negative numbers may be less in value). Any particular compiler implementation may define integral types with greater magnitudes than those shown here:

name	expresses	min. magnitude*
CHAR_BIT	Number of bits for a char object (byte)	8
SCHAR_MIN	Minimum value for an object of type signed char	-127
SCHAR_MAX	Maximum value for an object of type signed char	127
UCHAR_MAX	Maximum value for an object of type unsigned char	255
CHAR_MIN	Minimum value for an object of type char	either SCHAR_MIN or 0
CHAR_MAX	Maximum value for an object of type char	either SCHAR_MAX or UCHAR_MAX
MB_LEN_MAX	Maximum number of bytes in a multibyte character, for any locale	1
SHRT_MIN	Minimum value for an object of type short int	-32767
SHRT_MAX	Maximum value for an object of type short int	32767
USHRT_MAX	Maximum value for an object of type unsigned short int	65535
INT_MIN	Minimum value for an object of type int	-32767
INT_MAX	Maximum value for an object of type int	32767
UINT_MAX	Maximum value for an object of type unsigned int	65535
LONG_MIN	Minimum value for an object of type long int	-2147483647
LONG_MAX	Maximum value for an object of type long int	2147483647
ULONG_MAX	Maximum value for an object of type unsigned long int	4294967295

* This is not necessarily the actual value of the constant in any particular compiler or system, it may be equal or greater in magnitude than this.	


	18.3
19. Program Library HOWTO
http://tldp.org/HOWTO/Program-Library-HOWTO/index.html

	19.1 Introduction

This HOWTO for programmers discusses how to create and use program libraries on Linux using the GNU toolset. A ``program library'' is simply a file containing compiled code (and data) that is to be incorporated later into a program; program libraries allow programs to be more modular, faster to recompile, and easier to update. Program libraries can be divided into three types: static libraries, shared libraries, and dynamically loaded (DL) libraries.

This paper first discusses static libraries, which are installed into a program executable before the program can be run. It then discusses shared libraries, which are loaded at program start-up and shared between programs. Finally, it discusses dynamically loaded (DL) libraries, which can be loaded and used at any time while a program is running. DL libraries aren't really a different kind of library format (both static and shared libraries can be used as DL libraries); instead, the difference is in how DL libraries are used by programmers. The HOWTO wraps up with a section with more examples and a section with references to other sources of information.

Most developers who are developing libraries should create shared libraries, since these allow users to update their libraries separately from the applications that use the libraries. Dynamically loaded (DL) libraries are useful, but they require a little more work to use and many programs don't need the flexibility they offer. Conversely, static libraries make upgrading libraries far more troublesome, so for general-purpose use they're hard to recommend. Still, each have their advantages, and the advantages of each type are described in the section discussing that type. Developers using C++ and dynamically loaded (DL) libraries should also consult the ``C++ dlopen mini-HOWTO''.

It's worth noting that some people use the term dynamically linked libraries (DLLs) to refer to shared libraries, some use the term DLL to mean any library that is used as a DL library, and some use the term DLL to mean a library meeting either condition. No matter which meaning you pick, this HOWTO covers DLLs on Linux.

This HOWTO discusses only the Executable and Linking Format (ELF) format for executables and libraries, the format used by nearly all Linux distributions today. The GNU gcc toolset can actually handle library formats other than ELF; in particular, most Linux distributions can still use the obsolete a.out format. However, these formats are outside the scope of this paper.

If you're building an application that should port to many systems, you might consider using GNU libtool to build and install libraries instead of using the Linux tools directly. GNU libtool is a generic library support script that hides the complexity of using shared libraries (e.g., creating and installing them) behind a consistent, portable interface. On Linux, GNU libtool is built on top of the tools and conventions described in this HOWTO. For a portable interface to dynamically loaded libraries, you can use various portability wrappers. GNU libtool includes such a wrapper, called ``libltdl''. Alternatively, you could use the glib library (not to be confused with glibc) with its portable support for Dynamic Loading of Modules. You can learn more about glib at http://developer.gnome.org/doc/API/glib/glib-dynamic-loading-of-modules.html. Again, on Linux this functionality is implemented using the constructs described in this HOWTO. If you're actually developing or debugging the code on Linux, you'll probably still want the information in this HOWTO.

This HOWTO's master location is http://www.dwheeler.com/program-library, and it has been contributed to the Linux Documentation Project (http://www.linuxdoc.org). It is Copyright (C) 2000 David A. Wheeler and is licensed through the General Public License (GPL); see the last section for more information.

	19.2 Static Libraries

Static libraries are simply a collection of ordinary object files; conventionally, static libraries end with the ``.a'' suffix. This collection is created using the ar (archiver) program. Static libraries aren't used as often as they once were, because of the advantages of shared libraries (described below). Still, they're sometimes created, they existed first historically, and they're simpler to explain.

Static libraries permit users to link to programs without having to recompile its code, saving recompilation time. Note that recompilation time is less important given today's faster compilers, so this reason is not as strong as it once was. Static libraries are often useful for developers if they wish to permit programmers to link to their library, but don't want to give the library source code (which is an advantage to the library vendor, but obviously not an advantage to the programmer trying to use the library). In theory, code in static ELF libraries that is linked into an executable should run slightly faster (by 1-5%) than a shared library or a dynamically loaded library, but in practice this rarely seems to be the case due to other confounding factors.

To create a static library, or to add additional object files to an existing static library, use a command like this:

ar rcs my_library.a file1.o file2.o
This sample command adds the object files file1.o and file2.o to the static library my_library.a, creating my_library.a if it doesn't already exist. For more information on creating static libraries, see ar(1).

Once you've created a static library, you'll want to use it. You can use a static library by invoking it as part of the compilation and linking process when creating a program executable. If you're using gcc(1) to generate your executable, you can use the -l option to specify the library; see info:gcc for more information.

Be careful about the order of the parameters when using gcc; the -l option is a linker option, and thus needs to be placed AFTER the name of the file to be compiled. This is quite different from the normal option syntax. If you place the -l option before the filename, it may fail to link at all, and you can end up with mysterious errors.

You can also use the linker ld(1) directly, using its -l and -L options; however, in most cases it's better to use gcc(1) since the interface of ld(1) is more likely to change.


	19.3 Shared Libraries

Shared libraries are libraries that are loaded by programs when they start. When a shared library is installed properly, all programs that start afterwards automatically use the new shared library. It's actually much more flexible and sophisticated than this, because the approach used by Linux permits you to:

update libraries and still support programs that want to use older, non-backward-compatible versions of those libraries;

override specific libraries or even specific functions in a library when executing a particular program.

do all this while programs are running using existing libraries.

		19.3.1 Conventions

For shared libraries to support all of these desired properties, a number of conventions and guidelines must be followed. You need to understand the difference between a library's names, in particular its ``soname'' and ``real name'' (and how they interact). You also need to understand where they should be placed in the filesystem.

			19.3.1.1 Shared Library Names

Every shared library has a special name called the ``soname''. The soname has the prefix ``lib'', the name of the library, the phrase ``.so'', followed by a period and a version number that is incremented whenever the interface changes (as a special exception, the lowest-level C libraries don't start with ``lib''). A fully-qualified soname includes as a prefix the directory it's in; on a working system a fully-qualified soname is simply a symbolic link to the shared library's ``real name''.

Every shared library also has a ``real name'', which is the filename containing the actual library code. The real name adds to the soname a period, a minor number, another period, and the release number. The last period and release number are optional. The minor number and release number support configuration control by letting you know exactly what version(s) of the library are installed. Note that these numbers might not be the same as the numbers used to describe the library in documentation, although that does make things easier.

In addition, there's the name that the compiler uses when requesting a library, (I'll call it the ``linker name''), which is simply the soname without any version number.

The key to managing shared libraries is the separation of these names. Programs, when they internally list the shared libraries they need, should only list the soname they need. Conversely, when you create a shared library, you only create the library with a specific filename (with more detailed version information). When you install a new version of a library, you install it in one of a few special directories and then run the program ldconfig(8). ldconfig examines the existing files and creates the sonames as symbolic links to the real names, as well as setting up the cache file /etc/ld.so.cache (described in a moment).

ldconfig doesn't set up the linker names; typically this is done during library installation, and the linker name is simply created as a symbolic link to the ``latest'' soname or the latest real name. I would recommend having the linker name be a symbolic link to the soname, since in most cases if you update the library you'd like to automatically use it when linking. I asked H. J. Lu why ldconfig doesn't automatically set up the linker names. His explanation was basically that you might want to run code using the latest version of a library, but might instead want development to link against an old (possibly incompatible) library. Therefore, ldconfig makes no assumptions about what you want programs to link to, so installers must specifically modify symbolic links to update what the linker will use for a library.

Thus, /usr/lib/libreadline.so.3 is a fully-qualified soname, which ldconfig would set to be a symbolic link to some realname like /usr/lib/libreadline.so.3.0. There should also be a linker name, /usr/lib/libreadline.so which could be a symbolic link referring to /usr/lib/libreadline.so.3.

			19.3.1.2 Filesystem Placement

Shared libraries must be placed somewhere in the filesystem. Most open source software tends to follow the GNU standards; for more information see the info file documentation at info:standards#Directory_Variables. The GNU standards recommend installing by default all libraries in /usr/local/lib when distributing source code (and all commands should go into /usr/local/bin). They also define the convention for overriding these defaults and for invoking the installation routines.

The Filesystem Hierarchy Standard (FHS) discusses what should go where in a distribution (see http://www.pathname.com/fhs). According to the FHS, most libraries should be installed in /usr/lib, but libraries required for startup should be in /lib and libraries that are not part of the system should be in /usr/local/lib.

There isn't really a conflict between these two documents; the GNU standards recommend the default for developers of source code, while the FHS recommends the default for distributors (who selectively override the source code defaults, usually via the system's package management system). In practice this works nicely: the ``latest'' (possibly buggy!) source code that you download automatically installs itself in the ``local'' directory (/usr/local), and once that code has matured the package managers can trivially override the default to place the code in the standard place for distributions. Note that if your library calls programs that can only be called via libraries, you should place those programs in /usr/local/libexec (which becomes /usr/libexec in a distribution). One complication is that Red Hat-derived systems don't include /usr/local/lib by default in their search for libraries; see the discussion below about /etc/ld.so.conf. Other standard library locations include /usr/X11R6/lib for X-windows. Note that /lib/security is used for PAM modules, but those are usually loaded as DL libraries (also discussed below).

		19.3.2 How Libraries are Used

On GNU glibc-based systems, including all Linux systems, starting up an ELF binary executable automatically causes the program loader to be loaded and run. On Linux systems, this loader is named /lib/ld-linux.so.X (where X is a version number). This loader, in turn, finds and loads all other shared libraries used by the program.

The list of directories to be searched is stored in the file /etc/ld.so.conf. Many Red Hat-derived distributions don't normally include /usr/local/lib in the file /etc/ld.so.conf. I consider this a bug, and adding /usr/local/lib to /etc/ld.so.conf is a common ``fix'' required to run many programs on Red Hat-derived systems.

If you want to just override a few functions in a library, but keep the rest of the library, you can enter the names of overriding libraries (.o files) in /etc/ld.so.preload; these ``preloading'' libraries will take precedence over the standard set. This preloading file is typically used for emergency patches; a distribution usually won't include such a file when delivered.

Searching all of these directories at program start-up would be grossly inefficient, so a caching arrangement is actually used. The program ldconfig(8) by default reads in the file /etc/ld.so.conf, sets up the appropriate symbolic links in the dynamic link directories (so they'll follow the standard conventions), and then writes a cache to /etc/ld.so.cache that's then used by other programs. This greatly speeds up access to libraries. The implication is that ldconfig must be run whenever a DLL is added, when a DLL is removed, or when the set of DLL directories changes; running ldconfig is often one of the steps performed by package managers when installing a library. On start-up, then, the dynamic loader actually uses the file /etc/ld.so.cache and then loads the libraries it needs.

By the way, FreeBSD uses slightly different filenames for this cache. In FreeBSD, the ELF cache is /var/run/ld-elf.so.hints and the a.out cache is /var/run/ld.so.hints. These are still updated by ldconfig(8), so this difference in location should only matter in a few exotic situations.

		19.3.3 Environment Variables

Various environment variables can control this process, and there are environment variables that permit you to override this process.

			19.3.3.1 LD_LIBRARY_PATH

You can temporarily substitute a different library for this particular execution. In Linux, the environment variable LD_LIBRARY_PATH is a colon-separated set of directories where libraries should be searched for first, before the standard set of directories; this is useful when debugging a new library or using a nonstandard library for special purposes. The environment variable LD_PRELOAD lists shared libraries with functions that override the standard set, just as /etc/ld.so.preload does. These are implemented by the loader /lib/ld-linux.so. I should note that, while LD_LIBRARY_PATH works on many Unix-like systems, it doesn't work on all; for example, this functionality is available on HP-UX but as the environment variable SHLIB_PATH, and on AIX this functionality is through the variable LIBPATH (with the same syntax, a colon-separated list).

LD_LIBRARY_PATH is handy for development and testing, but shouldn't be modified by an installation process for normal use by normal users; see ``Why LD_LIBRARY_PATH is Bad'' at http://www.visi.com/~barr/ldpath.html for an explanation of why. But it's still useful for development or testing, and for working around problems that can't be worked around otherwise. If you don't want to set the LD_LIBRARY_PATH environment variable, on Linux you can even invoke the program loader directly and pass it arguments. For example, the following will use the given PATH instead of the content of the environment variable LD_LIBRARY_PATH, and run the given executable:
  /lib/ld-linux.so.2 --library-path PATH EXECUTABLE
Just executing ld-linux.so without arguments will give you more help on using this, but again, don't use this for normal use - these are all intended for debugging.

			19.3.3.2 LD_DEBUG

Another useful environment variable in the GNU C loader is LD_DEBUG. This triggers the dl* functions so that they give quite verbose information on what they are doing. For example:
  export LD_DEBUG=files
  command_to_run
displays the processing of files and libraries when handling libraries, telling you what dependencies are detected and which SOs are loaded in what order. Setting LD_DEBUG to ``bindings'' displays information about symbol binding, setting it to ``libs'' displays the library search paths, and setting ti to ``versions'' displays the version depdendencies.

Setting LD_DEBUG to ``help'' and then trying to run a program will list the possible options. Again, LD_DEBUG isn't intended for normal use, but it can be handy when debugging and testing.

			19.3.3.3 Other Environment Variables

There are actually a number of other environment variables that control the loading process; their names begin with LD_ or RTLD_. Most of the others are for low-level debugging of the loader process or for implementing specialized capabilities. Most of them aren't well-documented; if you need to know about them, the best way to learn about them is to read the source code of the loader (part of gcc).

Permitting user control over dynamically linked libraries would be disastrous for setuid/setgid programs if special measures weren't taken. Therefore, in the GNU loader (which loads the rest of the program on program start-up), if the program is setuid or setgid these variables (and other similar variables) are ignored or greatly limited in what they can do. The loader determines if a program is setuid or setgid by checking the program's credentials; if the uid and euid differ, or the gid and the egid differ, the loader presumes the program is setuid/setgid (or descended from one) and therefore greatly limits its abilities to control linking. If you read the GNU glibc library source code, you can see this; see especially the files elf/rtld.c and sysdeps/generic/dl-sysdep.c. This means that if you cause the uid and gid to equal the euid and egid, and then call a program, these variables will have full effect. Other Unix-like systems handle the situation differently but for the same reason: a setuid/setgid program should not be unduly affected by the environment variables set.

		19.3.4 Creating a Shared Library

Creating a shared library is easy. First, create the object files that will go into the shared library using the gcc -fPIC or -fpic flag. The -fPIC and -fpic options enable ``position independent code'' generation, a requirement for shared libraries; see below for the differences. You pass the soname using the -Wl gcc option. The -Wl option passes options along to the linker (in this case the -soname linker option) - the commas after -Wl are not a typo, and you must not include unescaped whitespace in the option. Then create the shared library using this format:

gcc -shared -Wl,-soname,your_soname \
    -o library_name file_list library_list
Here's an example, which creates two object files (a.o and b.o) and then creates a shared library that contains both of them. Note that this compilation includes debugging information (-g) and will generate warnings (-Wall), which aren't required for shared libraries but are recommended. The compilation generates object files (using -c), and includes the required -fPIC option:

gcc -fPIC -g -c -Wall a.c
gcc -fPIC -g -c -Wall b.c
gcc -shared -Wl,-soname,libmystuff.so.1 \
    -o libmystuff.so.1.0.1 a.o b.o -lc
Here are a few points worth noting:

Don't strip the resulting library, and don't use the compiler option -fomit-frame-pointer unless you really have to. The resulting library will work, but these actions make debuggers mostly useless.

Use -fPIC or -fpic to generate code. Whether to use -fPIC or -fpic to generate code is target-dependent. The -fPIC choice always works, but may produce larger code than -fpic (mnenomic to remember this is that PIC is in a larger case, so it may produce larger amounts of code). Using -fpic option usually generates smaller and faster code, but will have platform-dependent limitations, such as the number of globally visible symbols or the size of the code. The linker will tell you whether it fits when you create the shared library. When in doubt, I choose -fPIC, because it always works.

In some cases, the call to gcc to create the object file will also need to include the option ``-Wl,-export-dynamic''. Normally, the dynamic symbol table contains only symbols which are used by a dynamic object. This option (when creating an ELF file) adds all symbols to the dynamic symbol table (see ld(1) for more information). You need to use this option when there are 'reverse dependencies', i.e., a DL library has unresolved symbols that by convention must be defined in the programs that intend to load these libraries. For ``reverse dependencies'' to work, the master program must make its symbols dynamically available. Note that you could say ``-rdynamic'' instead of ``-Wl,export-dynamic'' if you only work with Linux systems, but according to the ELF documentation the ``-rdynamic'' flag doesn't always work for gcc on non-Linux systems.

During development, there's the potential problem of modifying a library that's also used by many other programs -- and you don't want the other programs to use the ``developmental''library, only a particular application that you're testing against it. One link option you might use is ld's ``rpath'' option, which specifies the runtime library search path of that particular program being compiled. From gcc, you can invoke the rpath option by specifying it this way:
 -Wl,-rpath,$(DEFAULT_LIB_INSTALL_PATH)
If you use this option when building the library client program, you don't need to bother with LD_LIBRARY_PATH (described next) other than to ensure it's not conflicting, or using other techniques to hide the library.

		19.3.5 Installing and Using a Shared Library

Once you've created a shared library, you'll want to install it. The simple approach is simply to copy the library into one of the standard directories (e.g., /usr/lib) and run ldconfig(8).

First, you'll need to create the shared libraries somewhere. Then, you'll need to set up the necessary symbolic links, in particular a link from a soname to the real name (as well as from a versionless soname, that is, a soname that ends in ``.so'' for users who don't specify a version at all). The simplest approach is to run:
 ldconfig -n directory_with_shared_libraries

Finally, when you compile your programs, you'll need to tell the linker about any static and shared libraries that you're using. Use the -l and -L options for this.

If you can't or don't want to install a library in a standard place (e.g., you don't have the right to modify /usr/lib), then you'll need to change your approach. In that case, you'll need to install it somewhere, and then give your program enough information so the program can find the library... and there are several ways to do that. You can use gcc's -L flag in simple cases. You can use the ``rpath'' approach (described above), particularly if you only have a specific program to use the library being placed in a ``non-standard'' place. You can also use environment variables to control things. In particular, you can set LD_LIBRARY_PATH, which is a colon-separated list of directories in which to search for shared libraries before the usual places. If you're using bash, you could invoke my_program this way using:

LD_LIBRARY_PATH=.:$LD_LIBRARY_PATH  my_program
If you want to override just a few selected functions, you can do this by creating an overriding object file and setting LD_PRELOAD; the functions in this object file will override just those functions (leaving others as they were).

Usually you can update libraries without concern; if there was an API change, the library creator is supposed to change the soname. That way, multiple libraries can be on a single system, and the right one is selected for each program. However, if a program breaks on an update to a library that kept the same soname, you can force it to use the older library version by copying the old library back somewhere, renaming the program (say to the old name plus ``.orig''), and then create a small ``wrapper'' script that resets the library to use and calls the real (renamed) program. You could place the old library in its own special area, if you like, though the numbering conventions do permit multiple versions to live in the same directory. The wrapper script could look something like this:
  #!/bin/sh
  export LD_LIBRARY_PATH=/usr/local/my_lib:$LD_LIBRARY_PATH
  exec /usr/bin/my_program.orig $*
Please don't depend on this when you write your own programs; try to make sure that your libraries are either backwards-compatible or that you've incremented the version number in the soname every time you make an incompatible change. This is just an ``emergency'' approach to deal with worst-case problems.

You can see the list of the shared libraries used by a program using ldd(1). So, for example, you can see the shared libraries used by ls by typing:
  ldd /bin/ls
Generally you'll see a list of the sonames being depended on, along with the directory that those names resolve to. In practically all cases you'll have at least two dependencies:

/lib/ld-linux.so.N (where N is 1 or more, usually at least 2). This is the library that loads all other libraries.

libc.so.N (where N is 6 or more). This is the C library. Even other languages tend to use the C library (at least to implement their own libraries), so most programs at least include this one.

Beware: do not run ldd on a program you don't trust. As is clearly stated in the ldd(1) manual, ldd works by (in certain cases) by setting a special environment variable (for ELF objects, LD_TRACE_LOADED_OBJECTS) and then executing the program. It may be possible for an untrusted program to force the ldd user to run arbitrary code (instead of simply showing the ldd information). So, for safety's sake, don't use ldd on programs you don't trust to execute.

		19.3.6 Incompatible Libraries

When a new version of a library is binary-incompatible with the old one the soname needs to change. In C, there are four basic reasons that a library would cease to be binary compatible:

The behavior of a function changes so that it no longer meets its original specification,

Exported data items change (exception: adding optional items to the ends of structures is okay, as long as those structures are only allocated within the library).

An exported function is removed.

The interface of an exported function changes.

If you can avoid these reasons, you can keep your libraries binary-compatible. Said another way, you can keep your Application Binary Interface (ABI) compatible if you avoid such changes. For example, you might want to add new functions but not delete the old ones. You can add items to structures but only if you can make sure that old programs won't be sensitive to such changes by adding items only to the end of the structure, only allowing the library (and not the application) to allocate the structure, making the extra items optional (or having the library fill them in), and so on. Watch out - you probably can't expand structures if users are using them in arrays.

For C++ (and other languages supporting compiled-in templates and/or compiled dispatched methods), the situation is trickier. All of the above issues apply, plus many more issues. The reason is that some information is implemented ``under the covers'' in the compiled code, resulting in dependencies that may not be obvious if you don't know how C++ is typically implemented. Strictly speaking, they aren't ``new'' issues, it's just that compiled C++ code invokes them in ways that may be surprising to you. The following is a (probably incomplete) list of things that you cannot do in C++ and retain binary compatibility, as reported by Troll Tech's Technical FAQ:

add reimplementations of virtual functions (unless it it safe for older binaries to call the original implementation), because the compiler evaluates SuperClass::virtualFunction() calls at compile-time (not link-time).

add or remove virtual member functions, because this would change the size and layout of the vtbl of every subclass.

change the type of any data members or move any data members that can be accessed via inline member functions.

change the class hierarchy, except to add new leaves.

add or remove private data members, because this would change the size and layout of every subclass.

remove public or protected member functions unless they are inline.

make a public or protected member function inline.

change what an inline function does, unless the old version continues working.

change the access rights (i.e. public, protected or private) of a member function in a portable program, because some compilers mangle the access rights into the function name.

Given this lengthy list, developers of C++ libraries in particular must plan for more than occasional updates that break binary compatibility. Fortunately, on Unix-like systems (including Linux) you can have multiple versions of a library loaded at the same time, so while there is some disk space loss, users can still run ``old'' programs needing old libraries.


	19.4 Dynamically Loaded (DL) Libraries

Dynamically loaded (DL) libraries are libraries that are loaded at times other than during the startup of a program. They're particularly useful for implementing plugins or modules, because they permit waiting to load the plugin until it's needed. For example, the Pluggable Authentication Modules (PAM) system uses DL libraries to permit administrators to configure and reconfigure authentication. They're also useful for implementing interpreters that wish to occasionally compile their code into machine code and use the compiled version for efficiency purposes, all without stopping. For example, this approach can be useful in implementing a just-in-time compiler or multi-user dungeon (MUD).

In Linux, DL libraries aren't actually special from the point-of-view of their format; they are built as standard object files or standard shared libraries as discussed above. The main difference is that the libraries aren't automatically loaded at program link time or start-up; instead, there is an API for opening a library, looking up symbols, handling errors, and closing the library. C users will need to include the header file <dlfcn.h> to use this API.

The interface used by Linux is essentially the same as that used in Solaris, which I'll call the ``dlopen()'' API. However, this same interface is not supported by all platforms; HP-UX uses the different shl_load() mechanism, and Windows platforms use DLLs with a completely different interface. If your goal is wide portability, you probably ought to consider using some wrapping library that hides differences between platforms. One approach is the glib library with its support for Dynamic Loading of Modules; it uses the underlying dynamic loading routines of the platform to implement a portable interface to these functions. You can learn more about glib at http://developer.gnome.org/doc/API/glib/glib-dynamic-loading-of-modules.html. Since the glib interface is well-explained in its documentation, I won't discuss it further here. Another approach is to use libltdl, which is part of GNU libtool. If you want much more functionality than this, you might want to look into a CORBA Object Request Broker (ORB). If you're still interested in directly using the interface supported by Linux and Solaris, read on.

Developers using C++ and dynamically loaded (DL) libraries should also consult the ``C++ dlopen mini-HOWTO''.

		19.4.1 dlopen()

The dlopen(3) function opens a library and prepares it for use. In C its prototype is:
  void * dlopen(const char *filename, int flag);
If filename begins with ``/'' (i.e., it's an absolute path), dlopen() will just try to use it (it won't search for a library). Otherwise, dlopen() will search for the library in the following order:

A colon-separated list of directories in the user's LD_LIBRARY_PATH environment variable.

The list of libraries specified in /etc/ld.so.cache (which is generated from /etc/ld.so.conf).

/lib, followed by /usr/lib. Note the order here; this is the reverse of the order used by the old a.out loader. The old a.out loader, when loading a program, first searched /usr/lib, then /lib (see the man page ld.so(8)). This shouldn't normally matter, since a library should only be in one or the other directory (never both), and different libraries with the same name are a disaster waiting to happen.

In dlopen(), the value of flag must be either RTLD_LAZY, meaning ``resolve undefined symbols as code from the dynamic library is executed'', or RTLD_NOW, meaning ``resolve all undefined symbols before dlopen() returns and fail if this cannot be done''. RTLD_GLOBAL may be optionally or'ed with either value in flag, meaning that the external symbols defined in the library will be made available to subsequently loaded libraries. While you're debugging, you'll probably want to use RTLD_NOW; using RTLD_LAZY can create inscrutable errors if there are unresolved references. Using RTLD_NOW makes opening the library take slightly longer (but it speeds up lookups later); if this causes a user interface problem you can switch to RTLD_LAZY later.
If the libraries depend on each other (e.g., X depends on Y), then you need to load the dependees first (in this example, load Y first, and then X).

The return value of dlopen() is a ``handle'' that should be considered an opaque value to be used by the other DL library routines. dlopen() will return NULL if the attempt to load does not succeed, and you need to check for this. If the same library is loaded more than once with dlopen(), the same file handle is returned.

In older systems, if the library exports a routine named _init, then that code is executed before dlopen() returns. You can use this fact in your own libraries to implement initialization routines. However, libraries should not export routines named _init or _fini. Those mechanisms are obsolete, and may result in undesired behavior. Instead, libraries should export routines using the __attribute__((constructor)) and __attribute__((destructor)) function attributes (presuming you're using gcc). See Section 5.2 for more information.

		19.4.2 dlerror()

Errors can be reported by calling dlerror(), which returns a string describing the error from the last call to dlopen(), dlsym(), or dlclose(). One oddity is that after calling dlerror(), future calls to dlerror() will return NULL until another error has been encountered.

		19.4.3 dlsym()

There's no point in loading a DL library if you can't use it. The main routine for using a DL library is dlsym(3), which looks up the value of a symbol in a given (opened) library. This function is defined as:
 void * dlsym(void *handle, char *symbol);
the handle is the value returned from dlopen, and symbol is a NIL-terminated string. If you can avoid it, don't store the result of dlsym() into a void* pointer, because then you'll have to cast it each time you use it (and you'll give less information to other people trying to maintain the program).

dlsym() will return a NULL result if the symbol wasn't found. If you know that the symbol could never have the value of NULL or zero, that may be fine, but there's a potential ambiguity otherwise: if you got a NULL, does that mean there is no such symbol, or that NULL is the value of the symbol? The standard solution is to call dlerror() first (to clear any error condition that may have existed), then call dlsym() to request a symbol, then call dlerror() again to see if an error occurred. A code snippet would look like this:
 dlerror(); /* clear error code */
 s = (actual_type) dlsym(handle, symbol_being_searched_for);
 if ((err = dlerror()) != NULL) {
  /* handle error, the symbol wasn't found */
 } else {
  /* symbol found, its value is in s */
 }

		19.4.4 dlclose()

The converse of dlopen() is dlclose(), which closes a DL library. The dl library maintains link counts for dynamic file handles, so a dynamic library is not actually deallocated until dlclose has been called on it as many times as dlopen has succeeded on it. Thus, it's not a problem for the same program to load the same library multiple times. If a library is deallocated, its function _fini is called (if it exists) in older libraries, but _fini is an obsolete mechanism and shouldn't be relied on. Instead, libraries should export routines using the __attribute__((constructor)) and __attribute__((destructor)) function attributes. See Section 5.2 for more information. Note: dlclose() returns 0 on success, and non-zero on error; some Linux manual pages don't mention this.

		19.4.5 DL Library Example

Here's an example from the man page of dlopen(3). This example loads the math library and prints the cosine of 2.0, and it checks for errors at every step (recommended):

    #include <stdlib.h>
    #include <stdio.h>
    #include <dlfcn.h>

    int main(int argc, char **argv) {
        void *handle;
        double (*cosine)(double);
        char *error;

        handle = dlopen ("/lib/libm.so.6", RTLD_LAZY);
        if (!handle) {
            fputs (dlerror(), stderr);
            exit(1);
        }

        cosine = dlsym(handle, "cos");
        if ((error = dlerror()) != NULL)  {
            fputs(error, stderr);
            exit(1);
        }

        printf ("%f\n", (*cosine)(2.0));
        dlclose(handle);
    }

If this program were in a file named "foo.c", you would build the program with the following command:
    gcc -o foo foo.c -ldl

	19.5 Miscellaneous

		19.5.1 nm command

			19.5.1.1  Description


The nm(1) command can report the list of symbols in a given library. It works on both static and shared libraries. For a given library nm(1) can list the symbol names defined, each symbol's value, and the symbol's type. It can also identify where the symbol was defined in the source code (by filename and line number), if that information is available in the library (see the -l option).

The symbol type requires a little more explanation. The type is displayed as a letter; lowercase means that the symbol is local, while uppercase means that the symbol is global (external). Typical symbol types include T (a normal definition in the code section), D (initialized data section), B (uninitialized data section), U (undefined; the symbol is used by the library but not defined by the library), and W (weak; if another library also defines this symbol, that definition overrides this one).

If you know the name of a function, but you truly can't remember what library it was defined in, you can use nm's ``-o'' option (which prefixes the filename in each line) along with grep to find the library name. From a Bourne shell, you can search all the libraries in /lib, /usr/lib, direct subdirectories of /usr/lib, and /usr/local/lib for ``cos'' as follows:
nm -o /lib/* /usr/lib/* /usr/lib/*/* \
      /usr/local/lib/* 2> /dev/null | grep 'cos$' 

Much more information about nm can be found in the nm ``info'' documentation locally installed at info:binutils#nm.


*/

			19.5.1.2 nm(1) - Linux man page

Name

nm - list symbols from object files

Synopsis


 
nm [-a|--debug-syms] [-g|--extern-only][--plugin name] [-B] [-C|--demangle[=style]] [-D|--dynamic] [-S|--print-size] [-s|--print-armap] [-A|-o|--print-file-name][--special-syms] [-n|-v|--numeric-sort] [-p|--no-sort] [-r|--reverse-sort] [--size-sort] [-u|--undefined-only] [-t radix|--radix=radix] [-P|--portability] [--target=bfdname] [-fformat|--format=format] [--defined-only] [-l|--line-numbers] [--no-demangle] [-V|--version] [-X 32_64] [--help] [objfile...]

Description

GNU nm lists the symbols from object files objfile.... If no object files are listed as arguments, nm assumes the file a.out.

For each symbol, nm shows:

• The symbol value, in the radix selected by options (see below), or hexadecimal by default.
• The symbol type. At least the following types are used; others are, as well, depending on the object file format. If lowercase, the symbol is local; if uppercase, the symbol is global (external).

"A"
The symbol's value is absolute, and will not be changed by further linking.

"B"

"b"

The symbol is in the uninitialized data section (known as BSS ).

"C"

The symbol is common. Common symbols are uninitialized data. When linking, multiple common symbols may appear with the same name. If the symbol is defined anywhere, the common symbols are treated as undefined references.

"D"

"d"

The symbol is in the initialized data section.

"G"

"g"

The symbol is in an initialized data section for small objects. Some object file formats permit more efficient access to small data objects, such as a global int variable as opposed to a large global array.

"i"

For PE format files this indicates that the symbol is in a section specific to the implementation of DLLs. For ELF format files this indicates that the symbol is an indirect function. This is a GNU extension to the standard set of ELF symbol types. It indicates a symbol which if referenced by a relocation does not evaluate to its address, but instead must be invoked at runtime. The runtime execution will then return the value to be used in the relocation.

"N"

The symbol is a debugging symbol.

"p"

The symbols is in a stack unwind section.

"R"

"r"

The symbol is in a read only data section.

"S"

"s"

The symbol is in an uninitialized data section for small objects.

"T"

"t"

The symbol is in the text (code) section.

"U"

The symbol is undefined.

"u"

The symbol is a unique global symbol. This is a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use.

"V"

"v"

The symbol is a weak object. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the weak symbol becomes zero with no error. On some systems, uppercase indicates that a default value has been specified.

"W"

"w"

The symbol is a weak symbol that has not been specifically tagged as a weak object symbol. When a weak defined symbol is linked with a normal defined symbol, the normal defined symbol is used with no error. When a weak undefined symbol is linked and the symbol is not defined, the value of the symbol is determined in a system-specific manner without error. On some systems, uppercase indicates that a default value has been specified.

"-"

The symbol is a stabs symbol in an a.out object file. In this case, the next values printed are the stabs other field, the stabs desc field, and the stab type. Stabs symbols are used to hold debugging information.

"?"

The symbol type is unknown, or object file format specific.

• The symbol name.

Options

The long and short forms of options, shown here as alternatives, are equivalent.

-A
-o

--print-file-name
Precede each symbol by the name of the input file (or archive member) in which it was found, rather than identifying the input file once only, before all of its symbols.
-a
--debug-syms
Display all symbols, even debugger-only symbols; normally these are not listed.
-B
The same as --format=bsd (for compatibility with the MIPS nm).

-C

--demangle[=style]
Decode (demangle) low-level symbol names into user-level names. Besides removing any initial underscore prepended by the system, this makes C ++ function names readable. Different compilers have different mangling styles. The optional demangling style argument can be used to choose an appropriate demangling style for your compiler.
--no-demangle
Do not demangle low-level symbol names. This is the default.
-D
--dynamic
Display the dynamic symbols rather than the normal symbols. This is only meaningful for dynamic objects, such as certain types of shared libraries.
-f format
--format=format
Use the output format format, which can be "bsd", "sysv", or "posix". The default is "bsd". Only the first character of format is significant; it can be either upper or lower case.
-g
--extern-only
Display only external symbols.
--plugin name
Load the plugin called name to add support for extra target types. This option is only available if the toolchain has been built with plugin support enabled.
-l
--line-numbers
For each symbol, use debugging information to try to find a filename and line number. For a defined symbol, look for the line number of the address of the symbol. For an undefined symbol, look for the line number of a relocation entry which refers to the symbol. If line number information can be found, print it after the other symbol information.
-n
-v

--numeric-sort
Sort symbols numerically by their addresses, rather than alphabetically by their names.
-p
--no-sort
Do not bother to sort the symbols in any order; print them in the order encountered.
-P
--portability
Use the POSIX .2 standard output format instead of the default format. Equivalent to -f posix.
-S
--print-size
Print both value and size of defined symbols for the "bsd" output style. This option has no effect for object formats that do not record symbol sizes, unless --size-sort is also used in which case a calculated size is displayed.
-s
--print-armap
When listing symbols from archive members, include the index: a mapping (stored in the archive by ar or ranlib) of which modules contain definitions for which names.
-r
--reverse-sort
Reverse the order of the sort (whether numeric or alphabetic); let the last come first.
--size-sort
Sort symbols by size. The size is computed as the difference between the value of the symbol and the value of the symbol with the next higher value. If the "bsd" output format is used the size of the symbol is printed, rather than the value, and -S must be used in order both size and value to be printed.
--special-syms
Display symbols which have a target-specific special meaning. These symbols are usually used by the target for some special processing and are not normally helpful when included included in the normal symbol lists. For example for ARM targets this option would skip the mapping symbols used to mark transitions between ARM code, THUMB code and data.
-t radix
--radix=radix
Use radix as the radix for printing the symbol values. It must be d for decimal, o for octal, or x for hexadecimal.
--target=bfdname
Specify an object code format other than your system's default format.
-u
--undefined-only
Display only undefined symbols (those external to each object file).
--defined-only
Display only defined symbols for each object file.
-V
--version
Show the version number of nm and exit.
-X
This option is ignored for compatibility with the AIX version of nm. It takes one parameter which must be the string 32_64. The default mode of AIX nm corresponds to -X 32, which is not supported by GNU nm.

--help
Show a summary of the options to nm and exit.
@file
Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed.
Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively.

See Also

ar(1), objdump(1), ranlib(1), and the Info entries for binutils.

Copyright

Copyright © 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.

Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, with no Front-Cover Texts, and with no Back-Cover Texts. A copy of the license is included in the section entitled " GNU Free Documentation License".

Referenced By

dstat(1), i686-pc-mingw32-ld(1), ld(1), llvm-nm(1), pstack(1), rpmelfsym(1), strings(1), xtensa-linux-gnu-ar(1), xtensa-linux-gnu-ld(1), xtensa-linux-gnu-objdump(1), xtensa-linux-gnu-ranlib(1), xtensa-linux-gnu-strings(1)



			19.5.1.3 Short explanation 

void foo();

int main(int argc, char* argv[]) {
    foo();
}

void foo() {
   printf("Foo bar baz!");
}
I ran `gcc -c foo.c` on that code. Here is what `nm foo.o` showed:
000000000000001b T foo
0000000000000000 T main
                 U printf
For this example I am running Ubuntu Linux 64-bit; that is why the 8 digit hex you see is 16 digit here. :-)

The hex digit you see is the address of the code in question within the object file relative to the beginning of the .text. section. (assuming we address sections of the object file beginning at 0x0). If you run objdump -td foo.o, you'll see the following in the output:

Disassembly of section .text:

0000000000000000 :
   0:   55                      push   %rbp
   1:   48 89 e5                mov    %rsp,%rbp
   4:   48 83 ec 10             sub    $0x10,%rsp
   8:   89 7d fc                mov    %edi,-0x4(%rbp)
   b:   48 89 75 f0             mov    %rsi,-0x10(%rbp)
   f:   b8 00 00 00 00          mov    $0x0,%eax
  14:   e8 00 00 00 00          callq  19 
  19:   c9                      leaveq
  1a:   c3                      retq

000000000000001b :
  1b:   55                      push   %rbp
  1c:   48 89 e5                mov    %rsp,%rbp
  1f:   b8 00 00 00 00          mov    $0x0,%eax
  24:   48 89 c7                mov    %rax,%rdi
  27:   b8 00 00 00 00          mov    $0x0,%eax
  2c:   e8 00 00 00 00          callq  31 
  31:   c9                      leaveq
  32:   c3                      retq
Notice that these two symbols line right up with the entries we saw in the symbol table from nm. Bare in mind, these addresses may change if you link this object file to other object files. Also, bare in mind that callq at 0x2c will change when you link this file to whatever libc your system provides, since that is currently an incomplete call to printf (it doesn't know where it is right now).

As for your mylib.a, there is more going on here. The file you have is an archive; it contains multiple object files, each one of which with it's own text segment. As an example, here is part of an nm against /usr/lib/libm.a on my box here

e_sinh.o:
0000000000000000 r .LC0
0000000000000008 r .LC1
0000000000000010 r .LC2
0000000000000018 r .LC3
0000000000000000 r .LC4
                 U __expm1
                 U __ieee754_exp
0000000000000000 T __ieee754_sinh

e_sqrt.o:
0000000000000000 T __ieee754_sqrt

e_gamma_r.o:
0000000000000000 r .LC0
                 U __ieee754_exp
0000000000000000 T __ieee754_gamma_r
                 U __ieee754_lgamma_r
                 U __rint
You'll see that multiple text segment entires -- indicated by the T in the second column rest at address 0x0, but each individual file has only one text segment symbol at 0x0.

As for individual files having multiple symbols resting at the same address, it seems like it would be possible perhaps. After all, it is just an entry in a table used to determine the location and size of a chunk of data. But I don't know for certain. I have never seen multiple symbols referencing the same part of a section before. Anyone with more knowledge on this than me can chime in. :-)

Hope this helps some.

			19.5.1.4
		19.5.2 Library constructor and destructor functions

Libraries should export initialization and cleanup routines using the gcc __attribute__((constructor)) and __attribute__((destructor)) function attributes. See the gcc info pages for information on these. Constructor routines are executed before dlopen returns (or before main() is started if the library is loaded at load time). Destructor routines are executed before dlclose returns (or after exit() or completion of main() if the library is loaded at load time). The C prototypes for these functions are:
  void __attribute__ ((constructor)) my_init(void);
  void __attribute__ ((destructor)) my_fini(void);

Shared libraries must not be compiled with the gcc arguments ``-nostartfiles'' or ``-nostdlib''. If those arguments are used, the constructor/destructor routines will not be executed (unless special measures are taken).

			19.5.2.1 Special functions _init and _fini (OBSOLETE/DANGEROUS)

Historically there have been two special functions, _init and _fini that can be used to control constructors and destructors. However, they are obsolete, and their use can lead to unpredicatable results. Your libraries should not use these; use the function attributes constructor and destructor above instead.

If you must work with old systems or code that used _init or _fini, here's how they worked. Two special functions were defined for initializing and finalizing a module: _init and _fini. If a function ``_init'' is exported in a library, then it is called when the library is first opened (via dlopen() or simply as a shared library). In a C program, this just means that you defined some function named _init. There is a corresponding function called _fini, which is called whenever a client finishes using the library (via a call dlclose() that brings its reference count to zero, or on normal exit of the program). The C prototypes for these functions are:
  void _init(void);
  void _fini(void);

In this case, when compiling the file into a ``.o'' file in gcc, be sure to add the gcc option ``-nostartfiles''. This keeps the C compiler from linking the system startup libraries against the .so file. Otherwise, you'll get a ``multiple-definition'' error. Note that this is completely different than compiling modules using the recommended function attributes. My thanks to Jim Mischel and Tim Gentry for their suggestion to add this discussion of _init and _fini, as well as help in creating it.

		19.5.3 Shared Libraries Can Be Scripts

It's worth noting that the GNU loader permits shared libraries to be text files using a specialized scripting language instead of the usual library format. This is useful for indirectly combining other libraries. For example, here's the listing of /usr/lib/libc.so on one of my systems:
/* GNU ld script
   Use the shared library, but some functions are only in
   the static library, so try that secondarily.  */
GROUP ( /lib/libc.so.6 /usr/lib/libc_nonshared.a )

For more information about this, see the texinfo documentation on ld linker scripts (ld command language). General information is at info:ld#Options and info:ld#Commands, with likely commands discussed in info:ld#Option Commands.

		19.5.4 Symbol Versioning and Version Scripts

Typically references to external functions are bound on an as-needed basis, and are not all bound when the application starts up. If a shared library is out of date, a required interface may be missing; when the application tries to use that interface, it may suddenly and unexpectedly fail.

A solution to this problem are symbol versioning coupled with version scripts. With symbol versioning, the user can get a warning when they start their program if the libraries being used with the application are too old. You can learn more about this from ld manual's descussion of version scripts at http://www.gnu.org/manual/ld-2.9.1/html_node/ld_25.html.

		19.5.5 GNU libtool

If you're building an application that should port to many systems, you might consider using GNU libtool to build and install libraries. GNU libtool is a generic library support script. Libtool hides the complexity of using shared libraries behind a consistent, portable interface. Libtool provides portable interfaces to create object files, link libraries (static and shared), link executables, debug executables, install libraries, install executables. It also includes libltdl, a portability wrapper for dynamically loading programs. For more information, see its documentation at http://www.gnu.org/software/libtool/manual.html

		19.5.6 Removing symbols for space

All the symbols included in generated files are useful for debugging, but take up space. If you need space, you can eliminate some of it.

The best approach is to first generate the object files normally, and do all your debugging and testing first (debugging and testing is much easier with them). Afterwards, once you've tested the program thoroughly, use strip(1) to remove the symbols. The strip(1) command gives you a good deal of control over what symbols to eliminate; see its documentation for details.

Another approach is to use the GNU ld options ``-S'' and ``-s''; ``-S'' omits debugger symbol information (but not all symbols) from the output file, while ``-s'' omits all symbol information from the output file. You can invoke these options through gcc as ``-Wl,-S'' and ``-Wl,-s''. If you always strip the symbols and these options are sufficient, feel free, but this is a less flexible approach.

		19.5.7 Extremely small executables

You might find the paper Whirlwind Tutorial on Creating Really Teensy ELF Executables for Linux useful. It describes how to make a truly tiny program executable. Frankly, you shouldn't use most of these tricks under normal circumstances, but they're quite instructive in showing how ELF really works.

		19.5.8 C++ vs. C

It's worth noting that if you're writing a C++ program, and you're calling a C library function, in your C++ code you'll need to define the C function as extern "C". Otherwise, the linker won't be able to locate the C function. Internally, C++ compilers ``mangle'' the names of C++ functions (e.g., for typing purposes), and they need to be told that a given function should be called as a C function (and thus, not have its name mangled).

If you're writing a program library that could be called from C or C++, it's recommended that you include 'extern "C"' commands right in your header files so that you do this automatically for your users. When combined with the usual #ifndef at the top of a file to skip re-executing header files, this means that a typical header file usable by either C or C++ for some header file foobar.h would look like this:
/* Explain here what foobar does */

#ifndef FOOBAR_H
#define FOOBAR_H

#ifdef __cplusplus
extern "C" {
#endif

 ... header code for foobar goes here ...

#ifdef  __cplusplus
}
#endif
#endif

		19.5.9 Speeding up C++ initialization

The KDE developers have noticed that large GUI C++ applications can take a long time to start up, in part due to its needing to do many relocations. There are several solutions to this. See Making C++ ready for the desktop (by Waldo Bastian) for more information.

		19.5.10 Linux Standard Base (LSB)

The goal of the Linux Standard Base (LSB) project is to develop and promote a set of standards that will increase compatibility among Linux distributions and enable software applications to run on any compliant Linux system. The project's home page is at http://www.linuxbase.org.

A nice article that summarizes how to develop LSB-compliant applications was published in October 2002, Developing LSB-certified applications: Five steps to binary-compatible Linux applications by George Kraft IV (Senior software engineer, IBM's Linux Technology Center). Of course, you need to write code that only accesses the standardized portability layer if you want your code to be portable. In addition, the LSB provides some tools so that application writers of C/C++ programs can check for LSB compliance; these tools use some capabilities of the linker and special libraries to do these checks. Obviously, you'll need to install the tools to do these checks; you can get them from the LSB website. Then, simply use the "lsbcc" compiler as your C/C++ compiler (lsbcc internally creates a linking environment that will complain if certain LSB rules aren't followed):
 $ CC=lsbcc make myapplication
  (or)
 $ CC=lsbcc ./configure; make myapplication 
You can then use the lsbappchk program to ensure that the program only uses functions standardized by the LSB:
 $ lsbappchk myapplication
You also need to follow the LSB packaging guidelines (e.g., use RPM v3, use LSB-conforming package names, and for add-on software must install in /opt by default). See the article and LSB website for more information.

	19.6 More Examples

The following are more examples of all three approaches (static, shared, and dynamically loaded libraries). File libhello.c is a trivial library, with libhello.h as its header. File demo_use.c is a trivial caller of the library. This is followed by commented scripts (script_static and script_dynamic) showing how to use the library as a static and shared library. This is followed by demo_dynamic.c and script_dynamic, which show how to use the shared library as a dynamically loaded library.

		19.6.1 File libhello.c

/* libhello.c - demonstrate library use. */

#include <stdio.h>

void hello(void) {
  printf("Hello, library world.\n");
}

		19.6.2 File libhello.h

/* libhello.h - demonstrate library use. */


void hello(void);

		19.6.3 File demo_use.c

/* demo_use.c -- demonstrate direct use of the "hello" routine */

#include "libhello.h"

int main(void) {
 hello();
 return 0;
}

		19.6.4 File script_static

#!/bin/sh
# Static library demo

# Create static library's object file, libhello-static.o.
# I'm using the name libhello-static to clearly
# differentiate the static library from the
# dynamic library examples, but you don't need to use
# "-static" in the names of your
# object files or static libraries.

gcc -Wall -g -c -o libhello-static.o libhello.c

# Create static library.

ar rcs libhello-static.a libhello-static.o

# At this point we could just copy libhello-static.a
# somewhere else to use it.
# For demo purposes, we'll just keep the library
# in the current directory.

# Compile demo_use program file.

gcc -Wall -g -c demo_use.c -o demo_use.o

# Create demo_use program; -L. causes "." to be searched during
# creation of the program.  Note that this command causes
# the relevant object file in libhello-static.a to be
# incorporated into file demo_use_static.

gcc -g -o demo_use_static demo_use.o -L. -lhello-static

# Execute the program.

./demo_use_static

		19.6.5 File script_shared

#!/bin/sh
# Shared library demo

# Create shared library's object file, libhello.o.

gcc -fPIC -Wall -g -c libhello.c

# Create shared library.
# Use -lc to link it against C library, since libhello
# depends on the C library.

gcc -g -shared -Wl,-soname,libhello.so.0 \
    -o libhello.so.0.0 libhello.o -lc

# At this point we could just copy libhello.so.0.0 into
# some directory, say /usr/local/lib.

# Now we need to call ldconfig to fix up the symbolic links.
 
# Set up the soname.  We could just execute:
# ln -sf libhello.so.0.0 libhello.so.0
# but let's let ldconfig figure it out.

/sbin/ldconfig -n .

# Set up the linker name.
# In a more sophisticated setting, we'd need to make
# sure that if there was an existing linker name,
# and if so, check if it should stay or not.

ln -sf libhello.so.0 libhello.so

# Compile demo_use program file.

gcc -Wall -g -c demo_use.c -o demo_use.o

# Create program demo_use.
# The -L. causes "." to be searched during creation
# of the program; note that this does NOT mean that "."
# will be searched when the program is executed.

gcc -g -o demo_use demo_use.o -L. -lhello

# Execute the program.  Note that we need to tell the program
# where the shared library is, using LD_LIBRARY_PATH.

LD_LIBRARY_PATH="." ./demo_use

		19.6.6 File demo_dynamic.c

/* demo_dynamic.c -- demonstrate dynamic loading and
   use of the "hello" routine */


/* Need dlfcn.h for the routines to
   dynamically load libraries */
#include <dlfcn.h>

#include <stdlib.h>
#include <stdio.h>

/* Note that we don't have to include "libhello.h".
   However, we do need to specify something related;
   we need to specify a type that will hold the value
   we're going to get from dlsym(). */

/* The type "simple_demo_function" describes a function that
   takes no arguments, and returns no value: */

typedef void (*simple_demo_function)(void);


int main(void) {
 const char *error;
 void *module;
 simple_demo_function demo_function;

 /* Load dynamically loaded library */
 module = dlopen("libhello.so", RTLD_LAZY);
 if (!module) {
   fprintf(stderr, "Couldn't open libhello.so: %s\n",
           dlerror());
   exit(1);
 }

 /* Get symbol */
 dlerror();
 demo_function = dlsym(module, "hello");
 if ((error = dlerror())) {
   fprintf(stderr, "Couldn't find hello: %s\n", error);
   exit(1);
 }

 /* Now call the function in the DL library */
 (*demo_function)();

 /* All done, close things cleanly */
 dlclose(module);
 return 0;
}

		19.6.7 File script_dynamic

#!/bin/sh
# Dynamically loaded library demo

# Presume that libhello.so and friends have
# been created (see dynamic example).

# Compile demo_dynamic program file into an object file.

gcc -Wall -g -c demo_dynamic.c

# Create program demo_use.
# Note that we don't have to tell it where to search for DL libraries,
# since the only special library this program uses won't be
# loaded until after the program starts up.
# However, we DO need the option -ldl to include the library
# that loads the DL libraries.

gcc -g -o demo_dynamic demo_dynamic.o -ldl

# Execute the program.  Note that we need to tell the
# program where get the dynamically loaded library,
# using LD_LIBRARY_PATH.

LD_LIBRARY_PATH="." ./demo_dynamic

	19.7 Other Information Sources

Particularly useful sources of information about libraries include the following:

``The GCC HOWTO'' by Daniel Barlow. In particular, this HOWTO discusses compiler options for creating libraries and how to query libraries. It covers information not covered here, and vice versa. This HOWTO is available through the Linux Documentation Project at http://www.linuxdoc.org.

``Executable and Linkable Format (ELF)'' by the Tool Interface Standards (TIS) committee (this is actually one chapter of the Portable Formats Specification Version 1.1 by the same committee). This provides information about the ELF format (it isn't specific to Linux or GNU gcc), and provides a great deal of detail on the ELF format. See ftp://tsx-11.mit.edu/pub/linux/packages/GCC/ELF.doc.tar.gz If you get the file from MIT, note that the format is unusual; after gunzipping and untarring, you'll get an ``hps'' file; just strip off the top and bottom lines, rename it to a ``ps'' file, and you'll get a printable Postscript file with the usual filename.

``ELF: From the Programmer's Perspective'' by Hongjui Lu. This gives Linux and GNU gcc-specific information on ELF, and is available at ftp://tsx-11.mit.edu/pub/linux/packages/GCC/elf.ps.gz.

The ld documentation ``Using LD, the GNU Linker'' describes ld in far more detail. It is available at http://www.gnu.org/manual/ld-2.9.1.

		19.7.1  Linux Commands For Shared Library Management & Debugging Problem
		http://www.cyberciti.biz/tips/linux-shared-library-management.html



by nixCraft on January 6, 2011 · 12 comments· Last updated March 21, 2012

If you are a developer, you will re-use code provided by others. Usually /lib, /lib64, /usr/local/lib, and other directories stores various shared libraries. You can write your own program using these shared libraries. As a sys admin you need to manage and install these shared libraries. Use the following commands for shared libraries management, security, and debugging problems.
What is a Library In Linux or UNIX?

In Linux or UNIX like operating system, a library is noting but a collection of resources such as subroutines / functions, classes, values or type specifications. There are two types of libraries:

    Static libraries - All lib*.a fills are included into executables that use their functions. For example you can run a sendmail binary in chrooted jail using statically liked libs.
    Dynamic libraries or linking [ also known as DSO (dynamic shared object)] - All lib*.so* files are not copied into executables. The executable will automatically load the libraries using ld.so or ld-linux.so.

Linux Library Management Commands

    ldconfig : Updates the necessary links for the run time link bindings.
    ldd : Tells what libraries a given program needs to run.
    ltrace : A library call tracer.
    ld.so/ld-linux.so: Dynamic linker/loader.

Important Files

As a sys admin you should be aware of important files related to shared libraries:

    /lib/ld-linux.so.* : Execution time linker/loader.
    /etc/ld.so.conf : File containing a list of colon, space, tab, newline, or comma separated directories in which to search for libraries.
    /etc/ld.so.cache : File containing an ordered list of libraries found in the directories specified in /etc/ld.so.conf. This file is not in human readable format, and is not intended to be edited. This file is created by ldconfig command.
    lib*.so.version : Shared libraries stores in /lib, /usr/lib, /usr/lib64, /lib64, /usr/local/lib directories.

#1: ldconfig command

You need to use the ldconfig command to create, update, and remove the necessary links and cache (for use by the run-time linker, ld.so) to the most recent shared libraries found in the directories specified on the command line, in the file /etc/ld.so.conf, and in the trusted directories (/usr/lib, /lib64 and /lib). The ldconfig command checks the header and file names of the libraries it encounters when determining which versions should have their links updated. This command also creates a file called /etc/ld.so.cache which is used to speed up linking.
Examples

In this example, you've installed a new set of shared libraries at /usr/local/lib/:
$ ls -l /usr/local/lib/
Sample outputs:

-rw-r--r-- 1 root root 878738 Jun 16  2010 libGeoIP.a
-rwxr-xr-x 1 root root    799 Jun 16  2010 libGeoIP.la
lrwxrwxrwx 1 root root     17 Jun 16  2010 libGeoIP.so -> libGeoIP.so.1.4.6
lrwxrwxrwx 1 root root     17 Jun 16  2010 libGeoIP.so.1 -> libGeoIP.so.1.4.6
-rwxr-xr-x 1 root root 322776 Jun 16  2010 libGeoIP.so.1.4.6
-rw-r--r-- 1 root root  72172 Jun 16  2010 libGeoIPUpdate.a
-rwxr-xr-x 1 root root    872 Jun 16  2010 libGeoIPUpdate.la
lrwxrwxrwx 1 root root     23 Jun 16  2010 libGeoIPUpdate.so -> libGeoIPUpdate.so.0.0.0
lrwxrwxrwx 1 root root     23 Jun 16  2010 libGeoIPUpdate.so.0 -> libGeoIPUpdate.so.0.0.0
-rwxr-xr-x 1 root root  55003 Jun 16  2010 libGeoIPUpdate.so.0.0.0

Now when you run an app related to libGeoIP.so, you will get an error about missing library. You need to run ldconfig command manually to link libraries by passing them as command line arguments with the -l switch:
# ldconfig -l /path/to/lib/our.new.lib.so
Another recommended options for sys admin is to create a file called /etc/ld.so.conf.d/geoip.conf as follows:

/usr/local/lib

Now just run ldconfig to update the cache:
# ldconfig
To verify new libs or to look for a linked library, enter:
# ldconfig -v
# ldconfig -v | grep -i geoip
Sample outputs:

	libGeoIP.so.1 -> libGeoIP.so.1.4.6
	libGeoIPUpdate.so.0 -> libGeoIPUpdate.so.0.0.0

Troubleshooting Chrooted Jails

You can print the current cache with the -p option:
# ldconfig -p
Putting web server such as Apache / Nginx / Lighttpd in a chroot jail minimizes the damage done by a potential break-in by isolating the web server to a small section of the filesystem. It is also necessary to copy all files required by Apache inside the filesystem rooted at /jail/ directory , including web server binaries, shared Libraries, modules, configuration files, and php/perl/html web pages. You need to also copy /etc/{ld.so.cache,ld.so.conf} files and /etc/ld.so.conf.d/ directory to /jail/etc/ directory. Use the ldconfig command to update, print and troubleshoot chrooted jail problems:

### chroot to jail bash
chroot /jail /bin/bash
###  now update the cache in /jail ###
ldconfig
###  print the cache in /jail ###
ldconfig -p
### copy missing libs ###
cp /path/to/some.lib /jail/path/to/some.lib
ldconfig
ldconfig -v | grep some.lib
### get out of jail ###
exit
### may be delete bash and ldconfig to increase security (NOTE path carefully) ###
cd /jail
rm sbin/ldconfig bin/bash
### now start nginx jail ###
chroot /jail /usr/local/nginx/sbin/nginx
 

Rootkits

A rootkit is a program (or combination of several programs) designed to take fundamental control of a computer system, without authorization by the system's owners and legitimate managers. Usually, rootkit use /lib, /lib64, /usr/local/lib directories to hide itself from real root users. You can use ldconfig command to view all the cache of all shared libraries and unwanted programs:
# /sbin/ldconfig -p | less
You can also use various tools to detect rootkits under Linux.
Common errors

You may see the errors as follows:

    Dynamic linker error in foo
    Can't map cache file cache-file
    Cache file cache-file foo

All of the above errors means the linker cache file /etc/ld.so.cache is corrupt or does not exists. To fix these errors simply run the ldconfig command as follows:
# ldconfig
Can't find library xyz Error

The executable required a dynamically linked library that ld.so or ld-linux.so cannot find. It means a library called xyz needed by the program called foo not installed or path is not set. To fix this problem install xyz library and set path in /etc/ld.so.conf file or create a file in /etc/ld.so.conf.d/ directory.
#2: ldd command

ldd (List Dynamic Dependencies) is a Unix and Linux program to display the shared libraries required by each program. This tools is required to build and run various server programs in a chroot jail. A typical example is as follows to list the Apache server shared libraries, enter:
# ldd /usr/sbin/httpd
Sample outputs:

	libm.so.6 => /lib64/libm.so.6 (0x00002aff52a0c000)
	libpcre.so.0 => /lib64/libpcre.so.0 (0x00002aff52c8f000)
	libselinux.so.1 => /lib64/libselinux.so.1 (0x00002aff52eab000)
	libaprutil-1.so.0 => /usr/lib64/libaprutil-1.so.0 (0x00002aff530c4000)
	libcrypt.so.1 => /lib64/libcrypt.so.1 (0x00002aff532de000)
	libldap-2.3.so.0 => /usr/lib64/libldap-2.3.so.0 (0x00002aff53516000)
	liblber-2.3.so.0 => /usr/lib64/liblber-2.3.so.0 (0x00002aff53751000)
	libdb-4.3.so => /lib64/libdb-4.3.so (0x00002aff5395f000)
	libexpat.so.0 => /lib64/libexpat.so.0 (0x00002aff53c55000)
	libapr-1.so.0 => /usr/lib64/libapr-1.so.0 (0x00002aff53e78000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x00002aff5409f000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00002aff542ba000)
	libc.so.6 => /lib64/libc.so.6 (0x00002aff544bf000)
	libsepol.so.1 => /lib64/libsepol.so.1 (0x00002aff54816000)
	/lib64/ld-linux-x86-64.so.2 (0x00002aff527ef000)
	libuuid.so.1 => /lib64/libuuid.so.1 (0x00002aff54a5c000)
	libresolv.so.2 => /lib64/libresolv.so.2 (0x00002aff54c61000)
	libsasl2.so.2 => /usr/lib64/libsasl2.so.2 (0x00002aff54e76000)
	libssl.so.6 => /lib64/libssl.so.6 (0x00002aff5508f000)
	libcrypto.so.6 => /lib64/libcrypto.so.6 (0x00002aff552dc000)
	libgssapi_krb5.so.2 => /usr/lib64/libgssapi_krb5.so.2 (0x00002aff5562d000)
	libkrb5.so.3 => /usr/lib64/libkrb5.so.3 (0x00002aff5585c000)
	libcom_err.so.2 => /lib64/libcom_err.so.2 (0x00002aff55af1000)
	libk5crypto.so.3 => /usr/lib64/libk5crypto.so.3 (0x00002aff55cf3000)
	libz.so.1 => /usr/lib64/libz.so.1 (0x00002aff55f19000)
	libkrb5support.so.0 => /usr/lib64/libkrb5support.so.0 (0x00002aff5612d000)
	libkeyutils.so.1 => /lib64/libkeyutils.so.1 (0x00002aff56335000)

Now, you can copy all those libs one by one to /jail directory

# mkdir /jail/lib
# cp  /lib64/libm.so.6 /jail/lib
# cp /lib64/libkeyutils.so.1 /jail/lib

You can write a bash script to automate the entire procedure:

cp_support_shared_libs(){
        local d="$1"            # JAIL ROOT
        local pFILE="$2"        # copy bin file libs
        local files=""
	## use ldd to get shared libs list ###
        files="$(ldd $pFILE |  awk '{ print $3 }' | sed  '/^$/d')"
 
        for i in $files
        do
          dcc="${i%/*}" # get dirname only
          [ ! -d ${d}${dcc} ] && mkdir -p ${d}${dcc}
          ${_cp} -f $i ${d}${dcc}
        done
 
        # Works with 32 and 64 bit ld-linux
        sldl="$(ldd $pFILE | grep 'ld-linux' | awk '{ print $1}')"
        sldlsubdir="${sldl%/*}"
        [ ! -f ${d}${sldl} ] && ${_cp} -f ${sldl} ${d}${sldlsubdir}
}

Call cp_support_shared_libs() it as follows:

cp_support_shared_libs "/jail" "/usr/local/nginx/sbin/nginx"

Report Missing Functions

Type the following command:
$ ldd -d /path/to/executable
Report Missing Objects

Type the following command:
$ ldd -r /path/to/executable
Determine If Particular Feature Supported Or Not

TCP Wrapper is a host-based Networking ACL system, used to filter network access to Internet. TCP wrappers was original written to monitor and stop cracking activities on the UNIX / Linux systems. To determine whether a given executable daemon supports TCP Wrapper or not, run the following command:
$ ldd /usr/sbin/sshd | grep libwrap
Sample outputs:

	libwrap.so.0 => /lib64/libwrap.so.0 (0x00002abd70cbc000)

The output indicates that the OpenSSH (sshd) daemon supports TCP Wrapper.
Other usage of ldd command

You can use the ldd command when an executable is failing because of a missing dependency. Once you found a missing dependency, you can install it or update the cache with the ldconfig command as mentioned above.
#3: ltrace command

The ltrace command simply runs the specified command until it exits. It intercepts and records the dynamic library calls which are called by the executed process and the signals which are received by that process. It can also intercept and print the system calls executed by the program. Its use is very similar to strace command.
# ltrace /usr/sbin/httpd
# ltrace /sbin/chroot /usr/sbin/httpd
# ltrace /bin/ls
Sample outputs:

__libc_start_main(0x804fae0, 1, 0xbfbd6544, 0x805bce0, 0x805bcd0 
strrchr("/bin/ls", '/')                                                                                                                            = "/ls"
setlocale(6, "")                                                                                                                                   = "en_IN.utf8"
bindtextdomain("coreutils", "/usr/share/locale")                                                                                                   = "/usr/share/locale"
textdomain("coreutils")                                                                                                                            = "coreutils"
__cxa_atexit(0x8052d10, 0, 0, 0xbfbd6544, 0xbfbd6498)                                                                                              = 0
isatty(1)                                                                                                                                          = 1
getenv("QUOTING_STYLE")                                                                                                                            = NULL
getenv("LS_BLOCK_SIZE")                                                                                                                            = NULL
getenv("BLOCK_SIZE")                                                                                                                               = NULL
getenv("BLOCKSIZE")                                                                                                                                = NULL
getenv("POSIXLY_CORRECT")                                                                                                                          = NULL
getenv("BLOCK_SIZE")                                                                                                                               = NULL
getenv("COLUMNS")                                                                                                                                  = NULL
ioctl(1, 21523, 0xbfbd6470)                                                                                                                        = 0
getenv("TABSIZE")                                                                                                                                  = NULL
getopt_long(1, 0xbfbd6544, "abcdfghiklmnopqrstuvw:xABCDFGHI:"..., 0x0805ea40, -1)                                                                  = -1
__errno_location()                                                                                                                                 = 0xb76b8694
malloc(40)                                                                                                                                         = 0x08c8e3e0
memcpy(0x08c8e3e0, "", 40)                                                                                                                         = 0x08c8e3e0
....
....
.....
..
output truncated
free(0x08c8e498)                                                                                                                                   = 
free(NULL)                                                                                                                                         = 
free(0x08c8e480)                                                                                                                                   = 
exit(0 
__fpending(0xb78334e0, 0xbfbd6334, 0xb78876a3, 0xb78968f8, 0)                                                                                      = 0
fclose(0xb78334e0)                                                                                                                                 = 0
__fpending(0xb7833580, 0xbfbd6334, 0xb78876a3, 0xb78968f8, 0)                                                                                      = 0
fclose(0xb7833580)                                                                                                                                 = 0
+++ exited (status 0) +++

The ltrace command is a perfect debugging utility in Linux:

    To monitor the library calls used by a program and all the signals it receives.
    For tracking the execution of processes.
    It can also show system calls, used by a program.

ltrace Command Examples

Consider the following c program:

 
#include <stdio.h>
int main(){
	printf("Hello world\n");
	return 0;
}
 

Compile and run it as follows:
$ cc hello.c -o hello
$ ./hello
Now use the ltrace command to tracking the execution of processes:
$ ltrace -S -tt ./hello
Sample outputs:

15:20:38.561616 SYS_brk(NULL)                                                                                                                      = 0x08f42000
15:20:38.561845 SYS_access("/etc/ld.so.nohwcap", 00)                                                                                               = -2
15:20:38.562009 SYS_mmap2(0, 8192, 3, 34, -1)                                                                                                      = 0xb7708000
15:20:38.562155 SYS_access("/etc/ld.so.preload", 04)                                                                                               = -2
15:20:38.562336 SYS_open("/etc/ld.so.cache", 0, 00)                                                                                                = 3
15:20:38.562502 SYS_fstat64(3, 0xbfaafe20, 0xb7726ff4, 0xb772787c, 3)                                                                              = 0
15:20:38.562629 SYS_mmap2(0, 76469, 1, 2, 3)                                                                                                       = 0xb76f5000
15:20:38.562755 SYS_close(3)                                                                                                                       = 0
15:20:38.564204 SYS_access("/etc/ld.so.nohwcap", 00)                                                                                               = -2
15:20:38.564372 SYS_open("/lib/tls/i686/cmov/libc.so.6", 0, 00)                                                                                    = 3
15:20:38.564561 SYS_read(3, "\177ELF\001\001\001", 512)                                                                                            = 512
15:20:38.564694 SYS_fstat64(3, 0xbfaafe6c, 0xb7726ff4, 0xb7705796, 0x8048234)                                                                      = 0
15:20:38.564822 SYS_mmap2(0, 0x1599a8, 5, 2050, 3)                                                                                                 = 0xb759b000
15:20:38.565076 SYS_mprotect(0xb76ee000, 4096, 0)                                                                                                  = 0
15:20:38.565209 SYS_mmap2(0xb76ef000, 12288, 3, 2066, 3)                                                                                           = 0xb76ef000
15:20:38.565454 SYS_mmap2(0xb76f2000, 10664, 3, 50, -1)                                                                                            = 0xb76f2000
15:20:38.565604 SYS_close(3)                                                                                                                       = 0
15:20:38.565709 SYS_mmap2(0, 4096, 3, 34, -1)                                                                                                      = 0xb759a000
15:20:38.565842 SYS_set_thread_area(0xbfab030c, 0xb7726ff4, 0xb759a6c0, 1, 0)                                                                      = 0
15:20:38.566070 SYS_mprotect(0xb76ef000, 8192, 1)                                                                                                  = 0
15:20:38.566185 SYS_mprotect(0x08049000, 4096, 1)                                                                                                  = 0
15:20:38.566288 SYS_mprotect(0xb7726000, 4096, 1)                                                                                                  = 0
15:20:38.566381 SYS_munmap(0xb76f5000, 76469)                                                                                                      = 0
15:20:38.566522 __libc_start_main(0x80483e4, 1, 0xbfab04e4, 0x8048410, 0x8048400 
15:20:38.566667 puts("Hello world" 
15:20:38.566811 SYS_fstat64(1, 0xbfab0310, 0xb76f0ff4, 0xb76f14e0, 0x80484c0)                                                                      = 0
15:20:38.566936 SYS_mmap2(0, 4096, 3, 34, -1)                                                                                                      = 0xb7707000
15:20:38.567126 SYS_write(1, "Hello world\n", 12Hello world
)                                                                                                  = 12
15:20:38.567282 <... puts resumed> )                                                                                                               = 12
15:20:38.567348 SYS_exit_group(0 
15:20:38.567454 +++ exited (status 0) +++

You need to carefully monitor the order and arguments of selected functions such as open() [used to open and possibly create a file or device] or chown() [used to change ownership of a file] so that you can spot simple kinds of race conditions or security related problems. This is quite useful for evaluating the security of binary programs to find out what kind of changes made to the system.
ltrace: Debugging Memory & I/O Usage For HA Based Cluster Computers

The ltrace command can be used to trace memory usage of the malloc() and free() functions in C program. You can calculate the amount of memory allocated as follows:
[node303 ~]$ ltrace -e malloc,free ./simulator arg1 agr2 arg3
The ltrace will start ./simulator program and it will trace the malloc() and free() functions. You can find out I/O problems as follows:
[node303 ~]$ ltrace -e fopen,fread,fwrite,fclose ./simulator arg1 agr2 arg3
You may need to change function names as your programming languages or UNIX platform may use different memory allocation functions.
#4: ld.so/ld-linux.so Command

The ld.so or / ld-linux.so used as follows by Linux:

    To load the shared libraries needed by a program.
    To prepare the program to run, and then runs it.

List All Dependencies and How They Are Resolved

Type the following command:
# cd /lib
For 64 bit systems:
# cd /lib64
Pass the --list option, enter:
# ./ld-2.5.so --list /path/to/executable
Other options

From the man page:

  --verify                   verify that given object really is a dynamically linked object we can handle
  --library-path PATH   use given PATH instead of content of the environment variable LD_LIBRARY_PATH
  --inhibit-rpath LIST    ignore RUNPATH and RPATH information in object names in LIST

Environment Variables

The LD_LIBRARY_PATH can be used to set a library path for finding dynamic libraries using LD_LIBRARY_PATH, in the standard colon seperated format:
$ export LD_LIBRARY_PATH=/opt/simulator/lib:/usr/local/lib
The LD_PRELOAD allow an extra library not specified in the executable to be loaded:
$ export LD_PRELOAD=/home/vivek/dirhard/libdiehard.so

		19.7.2 Anatomy of Linux dynamic libraries
Libraries were designed to package similar functionality in a single unit. These units could then be shared with other developers and permitted what came to be called modular programming—that is, building programs from modules. Linux supports two types of libraries, each with its own advantages and disadvantages. The static library contains functionality that is bound to a program statically at compile time. This differs from dynamic libraries, which are loaded when an application is loaded and binding occurs at run time. Figure 1 shows the library hierarchy in Linux.

Figure 1. Library hierarchy in Linux
Library hierarchy in Linux.

You can use shared libraries in a couple of ways: either linked dynamically at run time or dynamically loaded and used under program control. This article explores both of these methods.

Static libraries can be beneficial in small programs where minimal functionality is needed. For programs that require multiple libraries, shared libraries can reduce the memory footprint of the program (both on disk and in memory at run time). This is because multiple programs can use a shared library simultaneously; therefore, only one copy of the library is needed in memory at a time. With a static library, every running program has its own copy of the library.

GNU/Linux provides two ways to deal with shared libraries (each method originating from Sun Solaris). You can dynamically link your program with the shared library and have Linux load the library upon execution (unless it's already in memory). An alternative is for the program to selectively call functions with the library in a process called dynamic loading. With dynamic loading, a program can load a specific library (unless already loaded), and then call a particular function within that library. (Figure 2 shows these two methods.) This is a common usage pattern in building applications that support plugins. I explore this application program interface (API) and demonstrate it later in the article.

Figure 2. Static vs. dynamic linking
Static vs. dynamic linking

Dynamic linking with Linux

Now, let's dig into the process of using dynamically linked shared libraries in Linux. When users start an application, they're invoking an Executable and Linking Format (ELF) image. The kernel begins with the process of loading the ELF image into user space virtual memory. The kernel notices an ELF section called .interp, which indicates the dynamic linker to be used (/lib/ld-linux.so), shown in Listing 1. This is similar to the interpreter definition for script files in UNIX® (#!/bin/sh): It's just used in a different context.

Listing 1. Using readelf to show program headers


mtj@camus:~/dl$ readelf -l dl

Elf file type is EXEC (Executable file)
Entry point 0x8048618
There are 7 program headers, starting at offset 52

Program Headers:
  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
  PHDR           0x000034 0x08048034 0x08048034 0x000e0 0x000e0 R E 0x4
  INTERP         0x000114 0x08048114 0x08048114 0x00013 0x00013 R   0x1
      [Requesting program interpreter: /lib/ld-linux.so.2]
  LOAD           0x000000 0x08048000 0x08048000 0x00958 0x00958 R E 0x1000
  LOAD           0x000958 0x08049958 0x08049958 0x00120 0x00128 RW  0x1000
  DYNAMIC        0x00096c 0x0804996c 0x0804996c 0x000d0 0x000d0 RW  0x4
  NOTE           0x000128 0x08048128 0x08048128 0x00020 0x00020 R   0x4
  GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RW  0x4

  ...

mtj@camus:~dl$


Note that ld-linux.so is itself an ELF shared library, but it is statically compiled and has no shared library dependencies. When dynamic linking is needed, the kernel bootstraps the dynamic linker (ELF interpreter), which initializes itself, and then loads the specified shared objects (unless already loaded). It then performs the necessary relocations, including the shared objects that the target shared object uses. The LD_LIBRARY_PATH environment variable defines where to look for the available shared objects. When done, control is transferred back to the original program to begin its execution.

Relocation is handled through an indirection mechanism called the Global Offset Table (GOT) and the Procedure Linkage Table (PLT). These tables provide the addresses of external functions and data, which ld-linux.so loads during the relocation process. This means that the code that requires the indirection (that is, uses the tables) needs no changes: only the tables require adjustment. Relocation can occur immediately upon load or whenever a given function is needed. (See more on this difference later in Dynamic loading with Linux.)

When the relocations are complete, the dynamic linker allows any loaded shared object to execute optional initialization code. This functionality allows the library to initialize internal data and prepare for use. This code is defined in the .init section of the ELF image. When the library is unloaded, it may also call a termination function (defined as the .fini section in the image). When the initialization functions have been called, the dynamic linker relinquishes control to the original image being loaded.

Back to top

Dynamic loading with Linux

Instead of Linux automatically loading and linking libraries for a given program, it's possible to share this control with the application itself. In this case, the process is called dynamic loading. With dynamic loading, the application can specify a particular library to load, and then use this library as an executable (that is, call the functions within it). But as you learned earlier, the shared library used for dynamic loading is no different than that of a standard shared library (an ELF shared object). In fact, the ld-linux dynamic linker remains involved in this process as the ELF loader and interpreter.

The Dynamic Loading (DL) API exists for dynamic loading and allows a shared library to be available to a user-space program. Although small, the API provides everything needed, with much of the hard work done behind the scenes. The full API is shown in Table 1.

Table 1. The Dl API
Function	Description
dlopen	Makes an object file accessible to a program
dlsym	Obtains the address of a symbol within a dlopened object file
dlerror	Returns a string error of the last error that occurred
dlclose	Closes an object file

The process begins with a call to dlopen, providing the file object to access and a mode. The result of the dlopen call is a handle to the object that will be used later. The mode argument tells the dynamic linker when to perform relocations. There are two possible values. The first, RTLD_NOW, indicates that the dynamic linker will complete all necessary relocations at the dlopen call time. The second and alternative mode, RTLD_LAZY, says to perform relocations only when they're needed. This is done internally by redirecting all requests that are yet to be relocated through the dynamic linker. In this way, the dynamic linker knows at request time when a new reference is occurring, and relocation occurs normally. Subsequent calls do not require a repeat of the relocation.

Two other mode options are available that may be bitwise ORed into the mode argument. RTLD_LOCAL indicates that the symbols of the shared object being loaded won't be made available for relocation processing by any other object. If this is what you want (for example, so that the shared object can invoke symbols in the original process image), use RTLD_GLOBAL.

The dlopen function also automatically resolves dependencies in shared libraries. In this way, if you open an object that is dependent upon other shared libraries, it automatically loads them. The function returns a handle that is used in subsequent calls to the API. The prototype for dlopen is:

#include <dlfcn.h>

void *dlopen( const char *file, int mode );


With a handle to the ELF object, you can identify addresses to symbols within this object using the dlsym call. This function takes a symbol name, such as the name of a function contained within the object. The return value is a resolved address to the symbol within the object:

void *dlsym( void *restrict handle, const char *restrict name );


If an error occurs during a call with this API, you can use the dlerror function to return a human-readable string representing the error. This function has no arguments and returns a string if a prior error occurred or returns NULL if no error occurred:

char *dlerror();


Finally, when no additional calls to the shared object are necessary, the application can call dlclose to inform the operating system that the handle and object references are no longer necessary. This is properly reference-counted, so that multiple users of a shared object do not conflict with one another (it remains in memory as long as there is a user for it). Any symbols resolved through dlsym for the closed object will no longer be available.

char *dlclose( void *handle );


Back to top

Dynamic loading example

Now that you've seen the API, let's look at an example of the DL API. In this application, you basically implement a shell that allows the operator to specify a library, a function, and an argument. In other words, the user can specify a library and call an arbitrary function within that library (that wasn't previously linked to this application). You resolve the function within the library using the DL API, and then call it with the user-defined argument (emitting the result). The complete application is shown in Listing 2.

Listing 2. Shell for using the DL API

#include <stdio.h>
#include <dlfcn.h>
#include <string.h>

#define MAX_STRING      80


void invoke_method( char *lib, char *method, float argument )
{
  void *dl_handle;
  float (*func)(float);
  char *error;

  /* Open the shared object */
  dl_handle = dlopen( lib, RTLD_LAZY );
  if (!dl_handle) {
    printf( "!!! %s\n", dlerror() );
    return;
  }

  /* Resolve the symbol (method) from the object */
  func = dlsym( dl_handle, method );
    error = dlerror();
  if (error != NULL) {
    printf( "!!! %s\n", error );
    return;
  }

  /* Call the resolved method and print the result */
  printf("  %f\n", (*func)(argument) );

  /* Close the object */
  dlclose( dl_handle );

  return;
}


int main( int argc, char *argv[] )
{
  char line[MAX_STRING+1];
  char lib[MAX_STRING+1];
  char method[MAX_STRING+1];
  float argument;

  while (1) {

    printf("> ");

    line[0]=0;
    fgets( line, MAX_STRING, stdin);

    if (!strncmp(line, "bye", 3)) break;

    sscanf( line, "%s %s %f", lib, method, &argument);

    invoke_method( lib, method, argument );

  }

}


To build this application, use the following compile line with the GNU Compiler Collection (GCC). The option -rdynamic is used to tell the linker to add all symbols to the dynamic symbol table (to permit backtraces with the use of dlopen). The -ldl indicates that the dllib should be linked to this program.

gcc -rdynamic -o dl dl.c -ldl


Back to Listing 2, the main function simply acts as the interpreter, parsing three arguments from the input line (library name, function name, floating-point argument). If bye is present, the application exits. Otherwise, the three arguments are passed to the invoke_method function, which uses the DL API.

You start with a call to dlopen to gain access to the object file. If a NULL handle is returned, the object could not be found and the process ends. Otherwise, you have a handle to the object that can be further interrogated. Using the dlsym API function, attempt to resolve the symbol within the newly opened object file. You'll get either a valid pointer to the symbol or a NULL and return an error.

With the symbol resolved in the ELF object, the next step is simply to call the function. Note the difference between this code and the previous discussion of dynamic linking. In this example, you coerce the address of the symbol in the object file to a function pointer, and then call it. The previous example used the object's name as a function, and the dynamic linker ensures that the symbol points to the proper location. Although the dynamic linker can do all the dirty work for you, this approach allows you to build very dynamic applications that can be extended at run time.

After you've called your target function in the ELF object, close access to it through a call to dlclose.

An example of how to use this test program is shown in Listing 3. In this example, you compile and then execute the program. Then, you invoke a few functions within the math library (libm.so). From this demonstration, the program is able to call arbitrary functions within a shared object (library) using dynamic loading. This is a powerful capability and permits the extension of programs with new functionality.

Listing 3. Using the simple program to invoke library functions


mtj@camus:~/dl$ gcc -rdynamic -o dl dl.c -ldl
mtj@camus:~/dl$ ./dl
> libm.so cosf 0.0
  1.000000
> libm.so sinf 0.0
  0.000000
> libm.so tanf 1.0
  1.557408
> bye
mtj@camus:~/dl$


Back to top

Tools

Linux provides a variety of tools for viewing and parsing ELF objects (including shared libraries). One of the most useful is the ldd command, which you use to emit shared library dependencies. For example, using the ldd command on your dl application shows the following:

mtj@camus:~/dl$ ldd dl
        linux-gate.so.1 =>  (0xffffe000)
        libdl.so.2 => /lib/tls/i686/cmov/libdl.so.2 (0xb7fdb000)
        libc.so.6 => /lib/tls/i686/cmov/libc.so.6 (0xb7eac000)
        /lib/ld-linux.so.2 (0xb7fe7000)
mtj@camus:~/dl$


What ldd is telling you is that this ELF image is dependent upon linux-gate.so (a special shared object that handles system calls and has no associated file in the file system), libdl.so (the DL API), the GNU C library (libc.so), and finally the Linux dynamic loader (as there are shared library dependencies).

The readelf command is a feature-rich utility that allows you to parse and read ELF objects. One interesting use of readelf is to identify the relocatable items within an object. For our simple program (shown in Listing 2), you can see the symbols that require relocation as:

mtj@camus:~/dl$ readelf -r dl

Relocation section '.rel.dyn' at offset 0x520 contains 2 entries:
 Offset     Info    Type            Sym.Value  Sym. Name
08049a3c  00001806 R_386_GLOB_DAT    00000000   __gmon_start__
08049a78  00001405 R_386_COPY        08049a78   stdin

Relocation section '.rel.plt' at offset 0x530 contains 8 entries:
 Offset     Info    Type            Sym.Value  Sym. Name
08049a4c  00000207 R_386_JUMP_SLOT   00000000   dlsym
08049a50  00000607 R_386_JUMP_SLOT   00000000   fgets
08049a54  00000b07 R_386_JUMP_SLOT   00000000   dlerror
08049a58  00000c07 R_386_JUMP_SLOT   00000000   __libc_start_main
08049a5c  00000e07 R_386_JUMP_SLOT   00000000   printf
08049a60  00001007 R_386_JUMP_SLOT   00000000   dlclose
08049a64  00001107 R_386_JUMP_SLOT   00000000   sscanf
08049a68  00001907 R_386_JUMP_SLOT   00000000   dlopen
mtj@camus:~/dl$


From this list, you can see the various C library calls that require relocation (to libc.so), including calls to the DL API (libdl.so). The function __libc_start_main is a C library function that is called prior to the main function of your program (a shell that provides necessary initialization).

Other utilities that operate on object files include objdump, which displays information about object files, and nm, which lists the symbols from object files (including debug information). It's also possible to invoke the Linux dynamic linker directly with the ELF program as its argument to manually start the image:

mtj@camus:~/dl$ /lib/ld-linux.so.2 ./dl
> libm.so expf 0.0
  1.000000
>


Additionally, you can use ld-linux.so to list the dependencies of an ELF image (identically to the ldd command) by using the --list option. Remember, it's just a user-space program that's bootstrapped by the kernel when needed.

Back to top

Going further

This article scratched the surface of some of the capabilities of the dynamic linker. In the Resources below, you'll find more detailed introductions to the ELF image format and the process or symbol relocation. And, as is always the case with Linux, you can download the source to the dynamic linker (see Resources) to dig into its internals.
		19.7.3
	19.8 Visiblity

		19.8.1 gcc 
http://gcc.gnu.org/wiki/Visibility
Why is the new C++ visibility support so useful?

Put simply, it hides most of the ELF symbols which would have previously (and unnecessarily) been public. This means:

It very substantially improves load times of your DSO (Dynamic Shared Object). For example, a huge C++ template-based library which was tested (the TnFOX Boost.Python bindings library) now loads in eight seconds rather than over six minutes!
It lets the optimiser produce better code. PLT indirections (when a function call or variable access must be looked up via the Global Offset Table such as in PIC code) can be completely avoided, thus substantially avoiding pipeline stalls on modern processors and thus much faster code. Furthermore when most of the symbols are bound locally, they can be safely elided (removed) completely through the entire DSO. This gives greater latitude especially to the inliner which no longer needs to keep an entry point around "just in case".
It reduces the size of your DSO by 5-20%. ELF's exported symbol table format is quite a space hog, giving the complete mangled symbol name which with heavy template usage can average around 1000 bytes. C++ templates spew out a huge amount of symbols and a typical C++ library can easily surpass 30,000 symbols which is around 5-6Mb! Therefore if you cut out the 60-80% of unnecessary symbols, your DSO can be megabytes smaller!
Much lower chance of symbol collision. The old woe of two libraries internally using the same symbol for different things is finally behind us with this patch. Hallelujah!
Although the library quoted above is an extreme case, the new visibility support reduced the exported symbol table from > 200,000 symbols to less than 18,000. Some 21Mb was knocked off the binary size as well!

Some people may suggest that GNU linker version scripts can do just as well. Perhaps for C programs this is true, but for C++ it cannot be true - unless you laboriously specify each and every symbol to make public (and the complex mangled name of it), you must use wildcards which tend to let a lot of spurious symbols through. And you have to update the linker script if you decide to change names to the classes or the functions. In the case of the library above, the author couldn't get the symbol table below 40,000 symbols using version scripts. Furthermore, using linker version scripts doesn't permit GCC to better optimise the code.

Windows compatibility

For anyone who has worked on any sizeable portable application on both Windows and POSIX, you'll know the sense of frustration that non-Windows builds of GCC don't offer an equivalent to __declspec(dllexport) i.e. the ability to mark your C/C++ interface as being that of the shared library. Frustration because good DSO interface design is just as important for healthy coding as good class design, or correctly opaquing internal data structures.

While the semantics can't be the same with Windows DLL's and ELF DSO's, almost all Windows-based code uses a macro to compile-time select whether dllimport or dllexport is being used. This mechanism can be easily reused with this patch so adding support to anything already able to be compiled as a Windows DLL is literally a five minute operation.

Note: The semantics are not the same between Windows and this GCC feature - for example, __declspec(dllexport) void (*foo)(void) and void (__declspec(dllexport) *foo)(void) mean quite different things whereas this generates a warning about not being able to apply attributes to non-types on GCC.

Still not convinced?

A further reading on the subject of good DSO design is this article by Ulrich Drepper (lead maintainer of GNU glibc).

How to use the new C++ visibility support

In your header files, wherever you want an interface or API made public outside the current DSO, place __attribute__ ((visibility ("default"))) in struct, class and function declarations you wish to make public (it's easier if you define a macro as this). You don't need to specify it in the definition. Then, alter your make system to pass -fvisibility=hidden to each call of GCC compiling a source file. If you are throwing exceptions across shared object boundaries see the section "Problems with C++ exceptions" below. Use nm -C -D on the outputted DSO to compare before and after to see the difference it makes.

Some examples of the syntax:


#if defined _WIN32 || defined __CYGWIN__
  #ifdef BUILDING_DLL
    #ifdef __GNUC__
      #define DLL_PUBLIC __attribute__ ((dllexport))
    #else
      #define DLL_PUBLIC __declspec(dllexport) // Note: actually gcc seems to also supports this syntax.
    #endif
  #else
    #ifdef __GNUC__
      #define DLL_PUBLIC __attribute__ ((dllimport))
    #else
      #define DLL_PUBLIC __declspec(dllimport) // Note: actually gcc seems to also supports this syntax.
    #endif
  #endif
  #define DLL_LOCAL
#else
  #if __GNUC__ >= 4
    #define DLL_PUBLIC __attribute__ ((visibility ("default")))
    #define DLL_LOCAL  __attribute__ ((visibility ("hidden")))
  #else
    #define DLL_PUBLIC
    #define DLL_LOCAL
  #endif
#endif

extern "C" DLL_PUBLIC void function(int a);
class DLL_PUBLIC SomeClass
{
   int c;
   DLL_LOCAL void privateMethod();  // Only for use within this DSO
public:
   Person(int _c) : c(_c) { }
   static void foo(int a);
};
This also helps producing more optimised code: when you declare something defined outside the current compilation unit, GCC cannot know if that symbol resides inside or outside the DSO in which the current compilation unit will eventually end up; so, GCC must assume the worst and route everything through the GOT (Global Offset Table) which carries overhead both in code space and extra (costly) relocations for the dynamic linker to perform. To tell GCC a class, struct, function or variable is defined within the current DSO you must specify hidden visibility manually within its header file declaration (using the example above, you declare such things with DLLLOCAL). This causes GCC to generate optimal code.

But this is of course cumbersome: this is why -fvisibility was added. With -fvisibility=hidden, you are telling GCC that every declaration not explicitly marked with a visibility attribute has a hidden visibility. And like in the example above, even for classes marked as visible (exported from the DSO), you may still want to mark e.g. private members as hidden, so that optimal code will be produced when calling them (from within the DSO).

To aid you converting old code to use the new system, GCC now supports also a #pragma GCC visibility command:


extern void foo(int);
#pragma GCC visibility push(hidden)
extern void someprivatefunct(int);
#pragma GCC visibility pop
#pragma GCC visibility is stronger than -fvisibility; it affects extern declarations as well. -fvisibility only affects definitions, so that existing code can be recompiled with minimal changes. This is more true for C than C++; C++ interfaces tend use classes, which are affected by -fvisibility.

Lastly, there's one other new command line switch: -fvisibility-inlines-hidden. This causes all inlined class member functions to have hidden visibility, causing significant export symbol table size & binary size reductions though not as much as using -fvisibility=hidden. However, -fvisibility-inlines-hidden can be used with no source alterations, unless you need to override it for inlines where address identity is important either for the function itself or any function local static data.

Problems with C++ exceptions (please read!)

Exception catching of a user defined type in a binary other than the one which threw the exception requires a typeinfo lookup. Go back and read that last statement again. When exceptions start mysteriously malfunctioning, the cause is exactly this one!

Just like functions and variables, types that are thrown between multiple shared objects are public interfaces and must have default visibility. The obvious first step is to mark all types throwable across shared object boundaries always as default visibility. You must do this because even if (e.g.) the exception type's implementation code lives in DLL A, when DLL B throws an instance of that type, the catch handler in DLL C will look for the typeinfo in DLL B.

However, this isn't the full story - it gets harder. Symbol visibility is "default" by default but if the linker encounters just one definition with it hidden - just one - that typeinfo symbol becomes permanently hidden (remember the C++ standard's ODR - one definition rule). This is true for all symbols, but is more likely to affect you with typeinfos; typeinfo symbols for classes without a vtable are defined on demand within each object file that uses the class for EH and are defined weakly so the definitions get merged at link time into one copy.

The upshot of this is that if you forget your preprocessor defines in just one object file, or if at any time a throwable type is not declared explicitly public, the -fvisibility=hidden will cause it to be marked hidden in that object file, which overrides all the other definitions with default visibility and causes the typeinfo to vanish in the outputted binary (which then causes any throws of that type to cause terminate() to be called in the catching binary). Your binaries will link perfectly and appear to work correctly, even though they don't.

While it would be lovely to have a warning for this, there are plenty of legitimate reasons to keep throwable types out of public view. And until whole program optimisation is added to GCC, the compiler can't know which throws are caught locally.

The same issue can arise with other vague linkage entities such as static data members of a class template. If the class has hidden visibility, the data member can be instantiated in multiple DSOs and referenced separately, causing havoc.

This issue also shows up with classes used as the operand of dynamic_cast. Make sure to export all such classes.

Step-by-step guide

The following instructions are how to add full support to your library, yielding the highest quality code with the greatest reductions in binary size, load times and link times. All new code should have this support from the beginning! And it's worth your while especially in speed critical libraries to spend the few days required to implement it fully - it's a once off investment of time with nothing but good resulting forever more. You can however add basic support to your library in far less time though it is not recommended that you do so.

Place something along the lines of the following code in your master header file (or a specific header that you will include everywhere). This code is taken from the aforementioned TnFOX library:

// Generic helper definitions for shared library support
#if defined _WIN32 || defined __CYGWIN__
  #define FOX_HELPER_DLL_IMPORT __declspec(dllimport)
  #define FOX_HELPER_DLL_EXPORT __declspec(dllexport)
  #define FOX_HELPER_DLL_LOCAL
#else
  #if __GNUC__ >= 4
    #define FOX_HELPER_DLL_IMPORT __attribute__ ((visibility ("default")))
    #define FOX_HELPER_DLL_EXPORT __attribute__ ((visibility ("default")))
    #define FOX_HELPER_DLL_LOCAL  __attribute__ ((visibility ("hidden")))
  #else
    #define FOX_HELPER_DLL_IMPORT
    #define FOX_HELPER_DLL_EXPORT
    #define FOX_HELPER_DLL_LOCAL
  #endif
#endif

// Now we use the generic helper definitions above to define FOX_API and FOX_LOCAL.
// FOX_API is used for the public API symbols. It either DLL imports or DLL exports (or does nothing for static build)
// FOX_LOCAL is used for non-api symbols.

#ifdef FOX_DLL // defined if FOX is compiled as a DLL
  #ifdef FOX_DLL_EXPORTS // defined if we are building the FOX DLL (instead of using it)
    #define FOX_API FOX_HELPER_DLL_EXPORT
  #else
    #define FOX_API FOX_HELPER_DLL_IMPORT
  #endif // FOX_DLL_EXPORTS
  #define FOX_LOCAL FOX_HELPER_DLL_LOCAL
#else // FOX_DLL is not defined: this means FOX is a static lib.
  #define FX_API
  #define FOX_LOCAL
#endif // FOX_DLL
Obviously, you may wish to replace the FOX with a prefix suiting your library, and for projects also supporting Win32, you'll find a lot of the above familiar (you can reuse most of your Win32 macro machinery to also support GCC). To explain:
If _WIN32 is defined (as is automatic when building for Windows, even for 64-bit systems):
If FOX_DLL_EXPORTS is defined, we are building our library and symbols should be exported. So you would define FOX_DLL_EXPORTS in the build system that builds the FOX DLL. Something ending with _EXPORTS is defined by MSVC by default in all IDE projects (dito CMake default, see CMake Wiki BuildingWinDLL).
If FOX_DLL_EXPORTS is not defined (as is the case for clients using the library), we are importing the library and symbols should be imported.
If _WIN32 is not defined (as is the case when building for Unix with GCC):
If __GNUC__ >= 4 is true, then it means the compiler is GCC version 4.0 or later, and hence supports the new features.
For every non-templated non-static function definition in your library (both headers and source files), decide if it is publicly used or internally used:
If it is publicly used, mark with FOX_API like this: extern FOX_API PublicFunc()
If it is only internally used, mark with FOX_LOCAL like this: extern FOX_LOCAL PublicFunc() Remember, static functions need no demarcation, nor does anything which is templated.
For every non-templated class definition in your library (both headers and source files), decide if it is publicly used or internally used:
If it is publicly used, mark with FOX_API like this: class FOX_API PublicClass
If it is only internally used, mark with FOX_LOCAL like this: class FOX_LOCAL PublicClass
Individual member functions of an exported class that are not part of the interface, in particular ones which are private, and are not used by friend code, should be marked individually with FOX_LOCAL.
In your build system (Makefile etc), you will probably wish to add the -fvisibility=hidden and -fvisibility-inlines-hidden options to the command line arguments of every GCC invocation. Remember to test your library thoroughly afterwards, including that all exceptions correctly traverse shared object boundaries.
If you want to see before and after results, use the command nm -C -D <library>.so which lists all exported symbols in demangled form.


		19.8.2
	19.9
20. FAQ, Cookbook

	20.1 How to parse a simple text file

		20.1.1 my example

/*
 * =====================================================================================
 *
 *       Filename:  parseSimpleFile.cpp
 *
 *    Description:  parse simple text file - diskQuotas.cfg example
 *
 *        Version:  1.0
 *        Created:  01/10/12 14:24:06
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  Yosi Izaq (), yizaq@cisco.com
 *        Company:  CISCO
 *
 * =====================================================================================
 */
#include <iostream>
#include <fstream>
#include <string>
#include <vector>

using namespace std;


//split for single length 1 delimiter
int split( vector<string> & theStringVector,  /* Altered/returned value */ const  string  & theString, const  string  & theDelimiter )
{
  assert( (theDelimiter.size() > 0 ) &&  "Delimiter must be longer than 0" ); 

  size_t  start = 0, end = 0;

  while ( end != string::npos )
  {
    end = theString.find( theDelimiter, start );

      // If at end, use length=maxLength.  Else use length=end-start.
    theStringVector.push_back( theString.substr( start,
                   (end == string::npos) ? string::npos : end - start ) );

      // If at end, use start=maxSize.  Else use start=end+delimiter.
    start = (   ( end > (string::npos - theDelimiter.size()) )
              ?  string::npos  :  end + theDelimiter.size()    );
  }
}

/* 
//--------------------------------------------------------------------------------
//tokenizer for multiple delimiters, like all whitespace
//Header file
class Tokenizer 
{
    public:
        static const std::string DELIMITERS;
        Tokenizer(const std::string& str);
        Tokenizer(const std::string& str, const std::string& delimiters);
        bool NextToken();
        bool NextToken(const std::string& delimiters);
        const std::string GetToken() const;
        void Reset();
    protected:
        size_t m_offset;
        const std::string m_string;
        std::string m_token;
        std::string m_delimiters;
}

//CPP file
const string Tokenizer::DELIMITERS(" \t\n\r");

Tokenizer::Tokenizer(const std::string& s) :
    m_string(s), 
    m_offset(0), 
    m_delimiters(DELIMITERS) {}

Tokenizer::Tokenizer(const std::string& s, const std::string& delimiters) :
    m_string(s), 
    m_offset(0), 
    m_delimiters(delimiters) {}

bool Tokenizer::NextToken() 
{
    return NextToken(m_delimiters);
}

bool Tokenizer::NextToken(const std::string& delimiters) 
{
    size_t i = m_string.find_first_not_of(delimiters, m_offset);
    if (string::npos == i) 
    {
        m_offset = m_string.length();
        return false;
    }

    size_t j = m_string.find_first_of(delimiters, i);
    if (string::npos == j) 
    {
        m_token = m_string.substr(i);
        m_offset = m_string.length();
        return true;
    }

    m_token = m_string.substr(i, j - i);
    m_offset = j;
    return true;
}

//--------------------------------------------------------------------------------
 */

int main()
{
	cout << "Starting Parser\n";
	const string fname = "diskQuotas.cfg";
	string word1, word2, line;
	int num;
	//
  //check to see if the file is opened:
	ifstream myfile(fname.c_str());
  if (myfile.is_open())
  {
    //while there are still lines in the
    //file, keep reading:
    while (! myfile.eof() )
    {
      //place the line from myfile into the
      //line variable:
      getline (myfile,line);

      if (line[0] == '#') // ~='^#'
      {
	      cout <<"found comment line: "<<endl<<line<<endl;
      }
      else
      {

	//ToDo, if not start # then sscanf %s %s %d
      	//display the line we gathered:
      	cout << line << endl;

	 vector<string> v;

	 // using split - work 4 single space
	  //split( v, line , " " );

//      //using tokenizer
//	Tokenizer s(line);
//	while (s.NextToken())
//	{
//		v.push_back(s.GetToken());
//	}
//
//
//#define SHOW(I,X)   cout << "[" << (I) << "]\t " # X " = \"" << (X) << "\"" << endl
//	  for( unsigned int i = 0;  i < v.size();   i++ )
//	    SHOW( i, v[i] );

	 int length = 0;
	 char buffer[256];
	 int token_num = 0;
	 string LOCAL_STORE_KEYWORD="local-store";
	 length = line.copy(buffer, line.length());
	char *p = strtok(buffer, " \t\n\r");
	if ( ! LOCAL_STORE_KEYWORD.compare(p) )
	{
		printf ("Found local store configuration line");

		while (p) {
		    printf ("Token: %s\n", p);
		    token_num++;
		    if (token_num == 3){
			    printf ("Local store quota is %d \n", atoi(p));
		    }
		    p = strtok(NULL, " ");
		}
	}

// Print all words in all lines
//	while (p) {
//	    printf ("Token: %s\n", p);
//	    p = strtok(NULL, " ");
//	}
      }
    }

    //close the stream:
    myfile.close();
  }

  else cout << "Unable to open file";

	//ifstream ifs(fname.c_str());
	/*
	if (!ifs){
		cout<< "can't open file "<< fname <<" \n";
		return 1;
	}

	// read a line using the extraction operator
	if(ifs >> word1 >> word2 >> num) {
		cout << "reading content line\n";

		cout << "[ "
		<< word1 << ' '
		<< word2 << ' '
		<< num << " ]"
		<< endl;
	}
	else {

		char line_s [255];
		cout << "reading line\n";
		ifs.getline(line_s, 255) ;
		if (ifs) cout << "[ " << line_s << " ]" << endl;
	
	}
	// discard whitespace
	//ifs.ignore(10000,'\n');
	// read a line using getline
	if(getline(ifs,line)) {
		cout << "[ " << line << " ]" << endl;
	}
  */
	return 0;
}

running output:

[yizaq@yizaq-WS:Sun Jan 15:/cygdrive/c/work/code/CPP:]$ a.exe 
Starting Parser
found comment line: 
#File type,     The limit ( of disk size) or Fix, The actual limit
ade-log Fix 50
monit-log Fix 55
mgmt-audit-log 0.015 55
mgmt-log 0.281 1000
apache-log Fix 55
rt-log 0.281 1000
rt-config-cache Fix 1000
rt-core Fix 2000
local-store 26.74 95000
Found local store configuration lineToken: local-store
Token: 26.74
Token: 950000
Local store quota is 950000 
acs-db Fix 3000
acs-db-log Fix 100
acs-db-err-log Fix 100
view-log Fix 155
view-db 42.23 150000
view-db-log Fix 100
centrify-system Fix 50
ad-agent-log Fix 55
backup 29.562 105000
backup-log Fix 50
backup-success-log Fix 50
patch Fix 1000
upgrade-log Fix 55

		20.1.2

	20.2 Compilation errors

		20.2.1  stray '\xxx' in program
[yizaq@yizaq-WS:Wed Oct 10:/cygdrive/c/work/code/CPP/secure:]$ g++ buffer_overflow.cpp 
buffer_overflow.cpp:1: error: stray '\239' in program
buffer_overflow.cpp:1: error: stray '\187' in program
buffer_overflow.cpp:1: error: stray '\191' in program

xxx is decimal value. 
convert to hex (239 -> ef) and search & remove in hex editor
Transform vim into a hex editor by doing [escape] :%!xxd
you need to do switch back to ASCII using ´:%!xxd -r´ before you save

didn't work for me. I used hexedit, TAB to go to ascii, overwrite the (windows Notepad inserted UTF-8) three bytes w/ spaces. F2, ctrl-x

	20.3 Initializing private static members

in header put declaration:
static string               m_hostname; 

in cpp put initialization:
string LdapSslContext::m_hostname = "";

	20.4 Is there a GCC preprocessor directive to check if the code is being compiled on a 64 bit machine?
 10 down vote favorite
3
	

I am trying to do something like the following;

#ifdef 64-bit
    #define DECIMAL_FORMAT %ld
#else
    #define DECIMAL_FORMAT %d
#endif
.
intptr_t d;  
.
printf(“Some message with DECIMAL_FORMAT in the middle of it\n”, d);

The variable 'd' being of the type 'intptr_t' needs '%d' format specifier on 32 bit machines and format specifier '%ld' on 64 bit machines. I am looking a solution to be able to compile the code on both 32 bit machines and 64 bit machines without making changes to the GCC command line or the source code.

-------------                 ---------------    -----------------------
I think __LP64__ might be what you're looking for. See http://gcc.gnu.org/onlinedocs/gcc-4.1.2/cpp/Common-Predefined-Macros.html

Maybe a better way to go, though, is to use the %p specifier to printf() instead of %ld or %d. Then you don't even have to worry what your pointer size is.

-------------                 ---------------    -----------------------
 6 down vote
	

You want to use the PRI* macros defined in inttypes.h. You enable them by defining __STDC\_FORMAT\_MACROS. You can then use

 intptr_t d = ... ;
 printf("This is an intptr_t: %" PRIxPTR "\n", d);

The PRIxPTR macro will expand to llx if __WORDSIZE == 64, and lx or x otherwise.
share|improve this answer
	
edited Oct 8 '11 at 12:18
TonyK
6,845830
	
answered Mar 25 '09 at 22:05
JesperE
27.4k260117
	
	
+1 really cool. However, the results on my x86-64 Debian system are slightly different. "echo __WORDSIZE | g++ -xc++ -include limits.h -P -E -" returns 64. "echo PRIxPTR | g++ -xc++ -D__STDC_FORMAT_MACROS -include inttypes.h -E - | tail -1" returns "l" "x". – sigjuice Mar 26 '09 at 8:41

-------------                 ---------------    -----------------------

	20.5 list .so symbols
The standard tool for listing symbols is nm, you can use it simply like this:

nm -g yourLib.so
If you want to see symbols of a C++ library, add the "-C" option which demangle the symbols (it's far more readable demangled).

nm -gC yourLib.so
If your .so file is in elf format, you will have to use readelf program to extract symbol information from the binary.

readelf -Ws /usr/lib/libexample.so
You only should extract those that are defined in this .so file, not in the libraries referenced by it. Seventh column should contain a number in this case. You can extract the corresponding lines with awk:

readelf -Ws /usr/lib/libstdc++.so.6 | awk '{print $8}';

	20.6 Link/Load errors

		20.6.1 error while loading shared libraries
[yizaq@cow1:Tue Jun 25:1115:147:/view/yizaq__yizaq.int.pbis.lx/vob/nm_acs/pbis/cisco/CiscoAD]$ diag_test 
diag_test: error while loading shared libraries: libCiscoAD.so: cannot open shared object file: No such file or directory
[yizaq@cow1:Tue Jun 25:1116:148:/view/yizaq__yizaq.int.pbis.lx/vob/nm_acs/pbis/cisco/CiscoAD]$ ldd diag_test
        libCiscoAD.so => not found
        libstdc++.so.6 => /usr/lib64/libstdc++.so.6 (0x0000003c6b600000)
        libm.so.6 => /lib64/libm.so.6 (0x0000003c6ba00000)
        libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x0000003ef7c00000)
        libc.so.6 => /lib64/libc.so.6 (0x0000003ee6e00000)
        /lib64/ld-linux-x86-64.so.2 (0x0000003ee6a00000)

Fix, export LD_LIBRARY_PATH value so that ld sees it
ex: export LD_LIBRARY_PATH=".:/usr/local/lib:/usr/X11R6/lib:"
		20.6.2

	20.7 popen2 
#include <sys/types.h>
#include <unistd.h>

struct popen2 {
    pid_t child_pid;
    int   from_child, to_child;
};

int popen2(const char *cmdline, struct popen2 *childinfo) {
    pid_t p;
    int pipe_stdin[2], pipe_stdout[2];

    if(pipe(pipe_stdin)) return -1;
    if(pipe(pipe_stdout)) return -1;

    printf("pipe_stdin[0] = %d, pipe_stdin[1] = %d\n", pipe_stdin[0], pipe_stdin[1]);
    printf("pipe_stdout[0] = %d, pipe_stdout[1] = %d\n", pipe_stdout[0], pipe_stdout[1]);

    p = fork();
    if(p < 0) return p; /* Fork failed */
    if(p == 0) { /* child */
        close(pipe_stdin[1]);
        dup2(pipe_stdin[0], 0);
        close(pipe_stdout[0]);
        dup2(pipe_stdout[1], 1);
        execl("/bin/sh", "sh", "-c", cmdline, 0);
        perror("execl"); exit(99);
    }
    childinfo->child_pid = p;
    childinfo->to_child = pipe_stdin[1];
    childinfo->from_child = pipe_stdout[0];
    return 0; 
}

#define TESTING
#ifdef TESTING
int main(void) {
    char buf[1000];
    struct popen2 kid;
    popen2("tr a-z A-Z", &kid);
    write(kid.to_child, "testing\n", 8);
    close(kid.to_child);
    memset(buf, 0, 1000);
    read(kid.from_child, buf, 1000);
    printf("kill(%d, 0) -> %d\n", kid.child_pid, kill(kid.child_pid, 0)); 
    printf("from child: %s", buf); 
    printf("waitpid() -> %d\n", waitpid(kid.child_pid, NULL, 0));
    printf("kill(%d, 0) -> %d\n", kid.child_pid, kill(kid.child_pid, 0)); 
    return 0;
}
#endif

	20.8 What's the scope of the “using” declaration in C++?
I'm using the 'using' declaration in C++ to add std::string and std::vector to the local namespace (to save typing unnecessary 'std::'s).

using std::string;
using std::vector;

class Foo { /*...*/ };
What is the scope on this declaration? If I do this in a header, will it inject these 'using' declarations into every cpp file that includes the header?


When you #include a header file in C++, it places the whole contents of the header file into the spot that you included it in the source file. So including a file that has a using declaration has the exact same effect of placing the using declaration at the top of each file that includes that header file.

Just in case it's not clear from the other answers here: - Do not put a using declaration (or using directive) at file scope in an include file/header! That will cause headaches for users of the header

But if you put the using declaration inside a namespace it's limited to the scope of that namespace, so is generally OK (with the usual caveats on your particular needs and style)
There's nothing special about header files that would keep the using declaration out. It's a simple text substitution before the compilation even starts.

You can limit a using declaration to a scope:

void myFunction()
{
   using namespace std; // only applies to the function's scope
   vector<int> myVector;
}
	20.9 Why “using namespace X;” is not allowed inside class/struct level?
Because the C++ standard explicitly forbids it. From C++03 §7.3.4 [namespace.udir]:

using-directive:
    using namespace ::opt nested-name-specifieropt namespace-name ;
A using-directive shall not appear in class scope, but may appear in namespace scope or in block scope. [Note: when looking up a namespace-name in a using-directive, only namespace names are considered, see 3.4.6. ]

I believe that the rationale is that it would probably be confusing. Currently, while processing a class level identifier, lookup will first search in the class scope and then in the enclosing namespace. Allowing the using namespace at class level would have quite some side effects on how the lookup is now performed. In particular, it would have to be performed sometime between checking that particular class scope and checking the enclosing namespace. That is: 1) merge the class level and used namespace level lookups, 2) lookup the used namespace after the class scope but before any other class scope, 3) lookup the used namespace right before the enclosing namespace. 4) lookup merged with the enclosing namespace.

This would make a big difference, where an identifier at class level would shadow any identifier in the enclosing namespace, but it would not shadow a used namespace. The effect would be strange, in that access to the used namespace from a class in a different namespace and from the same namespace would differ:
.

namespace A {
   void foo() {}
   struct B {
      struct foo {};
      void f() {
         foo();      // value initialize a A::B::foo object (current behavior)
      }
   };
}
struct C {
   using namespace A;
   struct foo {};
   void f() {
      foo();         // call A::foo
   }
};
Lookup right after this class scope. This would have the strange effect of shadowing base classes' members. The current lookup does not mix class and namespace level lookups, and when performing class lookup it will go all the way to the base classes before considering the enclosing namespace. The behavior would be surprising in that it would not consider the namespace in a similar level to the enclosing namespace. Again, the used namespace would be prioritized over the enclosing namespace.
.

namespace A {
   void foo() {}
}
void bar() {}
struct base {
   void foo();
   void bar();
};
struct test : base {
   using namespace A;
   void f() {
      foo();           // A::foo()
      bar();           // base::bar()
   }
};
Lookup right before the enclosing namespace. The problem with this approach is again that it would be surprising to many. Consider that the namespace is defined in a different translation unit, so that the following code cannot be seen all at once:
.

namespace A {
   void foo( int ) { std::cout << "int"; }
}
void foo( double ) { std::cout << "double"; }
struct test {
   using namespace A;
   void f() {
      foo( 5.0 );          // would print "int" if A is checked *before* the
                           // enclosing namespace
   }
};
Merge with the enclosing namespace. This would have the exact same effect that applying the using declaration at the namespace level. It would not add any new value to that, but will on the other hand complicate lookup for compiler implementors. Namespace identifier lookup is now independent from where in the code the lookup is triggered. When inside a class, if lookup does not find the identifier at class scope it will fall back to namespace lookup, but that is exactly the same namespace lookup that is used in a function definition, there is no need to maintain new state. When the using declaration is found at namespace level, the contents of the used namespace are brought into that namespace for all lookups involving the namespace. If using namespace was allowed at class level, there would be different outcomes for namespace lookup of the exact same namespace depending on where the lookup was triggered from, and that would make the implementation of the lookup much more complex for no additional value.
Anyway, my recommendation is not to employ the using namespace declaration at all. It makes code simpler to reason with without having to keep all namespaces' contents in mind.

	20.10 Why do you use typedef when declaring an enum in C++? 
I haven't written any C++ in years and now I'm trying to get back into it. I then ran across this and thought about giving up:

typedef enum TokenType
{
    blah1   = 0x00000000,
    blah2   = 0X01000000,
    blah3   = 0X02000000
} TokenType;
What is this? Why is the typedef keyword used here? Why does the name TokenType appear twice in this declaration? How are the semantics different from this:

enum TokenType
{
    blah1 = 0x00000000,
    blah2=0x01000000,
    blah3=0x02000000
};

----------------------------------------------------------------------------------------------------

In C, declaring your enum the first way allows you to use it like so:

TokenType my_type;
If you use the second style, you'll be forced to declare your variable like this:

enum TokenType my_type;
As mentioned by others, this doesn't make a difference in C++. My guess is that either the person who wrote this is a C programmer at heart, or you're compiling C code as C++. Either way, it won't affect the behaviour of your code.
----------------------------------------------------------------------------------------------------
It's a C heritage, in C, if you do :

enum TokenType
{
    blah1   = 0x00000000,
    blah2   = 0X01000000,
    blah3   = 0X02000000
};
you'll have to use it doing something like :

enum TokenType foo;
But if you do this :

typedef enum e_TokenType
{
    blah1   = 0x00000000,
    blah2   = 0X01000000,
    blah3   = 0X02000000
} TokenType;
You'll be able to declare :

TokenType foo;
But in C++, you can use only the former definition and use it as if it were in a C typedef.
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
	20.11 Class members function pointers

		20.11.1  My example
- declaration:
typedef int (CAD_DNS_DIAG::*dns_testfunc)(const CAD_Test_Params & test_params, CAD_Test_Results & test_res);
typedef std::map<std::string, dns_testfunc> DNS_Test_Func_Map;
/*
 * =====================================================================================
 *        Class:  CAD_Diag_Tests
 *  Description:  AD Domain DNS relates tests and queries provider
 * =====================================================================================
 */
class CAD_Diag_Tests : public CAD_DIAG
{
        public:
                /* ====================  LIFECYCLE     ======================================= */

                ~CAD_Diag_Tests ()                             /* desstructor */
                {
                        m_pInstance = NULL;
                }
                /* ====================  ACCESSORS     ======================================= */
                static CAD_Diag_Tests * getInstance() ;

                /* ====================  MUTATORS      ======================================= */

                /* ====================  OPERATORS     ======================================= */
                virtual int init();
                virtual int shutdown();
                virtual CTS_Vec  getListOfTests();
                virtual CTR_Vec doTests(const CTP_Vec & tests);
                virtual CAD_Test_Results doTest(const CAD_Test_Params & test);

        protected:
                /* ====================  METHODS       ======================================= */

                /* ====================  DATA MEMBERS  ======================================= */

        private:
                /* ====================  METHODS       ======================================= */

                CAD_Diag_Tests ();                             /* constructor */

                /* ====================  DATA MEMBERS  ======================================= */
                static CAD_Diag_Tests *m_pInstance ;
                DNS_Test_Func_Map m_dns_tests_map;

}; /* -----  end of class CAD_Diag_Tests  ----- */

- Init map
int CAD_Diag_Tests::init()
{
        CAD_DNS_DIAG::getInstance()->init();
        m_dns_tests_map["DNS_A_REC_DEF_CFG"] =  &CAD_DNS_DIAG::queryDomainArecordInAllNS;
        m_dns_tests_map["DNS_RES_Q_A_REC_DEF_CFG"] =  &CAD_DNS_DIAG::res_queryDomainArecordInAllNS;
}

- Usage:
        string s_dns_pref = "DNS";
        if (test_params.s_testname.substr(0,s_dns_pref.size()) == s_dns_pref )
        {
                printf ("CAD_Diag_Tests::doTest() - Performing test %s of DNS test suite\n", test_params.s_testname.c_str() );

                dns_testfunc p_dns_testfunc  = m_dns_tests_map[test_params.s_testname]; 
                (CAD_DNS_DIAG::getInstance()->*p_dns_testfunc)(test_params, test_res);
                printf ("CAD_Diag_Tests::doTest() - Completed running test %s\n", test_params.s_testname.c_str() );

	20.12 c++ simple command line parser

		20.12.1 boost::program_options 

			20.12.1.1 Tutorial
Tutorial

Getting Started
Option Details
Multiple Sources
In this section, we'll take a look at the most common usage scenarios of the program_options library, starting with the simplest one. The examples show only the interesting code parts, but the complete programs can be found in the "BOOST_ROOT/libs/program_options/example" directory. Through all the examples, we'll assume that the following namespace alias is in effect:

namespace po = boost::program_options;
Getting Started
The first example is the simplest possible: it only handles two options. Here's the source code (the full program is in "example/first.cpp"):

// Declare the supported options.
po::options_description desc("Allowed options");
desc.add_options()
    ("help", "produce help message")
    ("compression", po::value<int>(), "set compression level")
;

po::variables_map vm;
po::store(po::parse_command_line(ac, av, desc), vm);
po::notify(vm);    

if (vm.count("help")) {
    cout << desc << "\n";
    return 1;
}

if (vm.count("compression")) {
    cout << "Compression level was set to " 
 << vm["compression"].as<int>() << ".\n";
} else {
    cout << "Compression level was not set.\n";
}
We start by declaring all allowed options using the options_description class. The add_options method of that class returns a special proxy object that defines operator(). Calls to that operator actually declare options. The parameters are option name, information about value, and option description. In this example, the first option has no value, and the second one has a value of type int.

After that, an object of class variables_map is declared. That class is intended to store values of options, and can store values of arbitrary types. Next, the calls to store, parse_command_line and notify functions cause vm to contain all the options found on the command line.

And now, finally, we can use the options as we like. The variables_map class can be used just like std::map, except that values stored there must be retrieved with the as method shown above. (If the type specified in the call to the as method is different from the actually stored type, an exception is thrown.)

It's now a good time to try compiling the code yourself, but if you're not yet ready, here's an example session:

$ bin/gcc/debug/first
Compression level was not set.
$ bin/gcc/debug/first --help
Allowed options:
  --help                 : produce help message
  --compression arg      : set compression level
$ bin/gcc/debug/first --compression 10
Compression level was set to 10.
    
Option Details
An option value, surely, can have other types than int, and can have other interesting properties, which we'll discuss right now. The complete version of the code snipped below can be found in example/options_description.cpp.

Imagine we're writing a compiler. It should take the optimization level, a number of include paths, and a number of input files, and perform some interesting work. Let's describe the options:

int opt;
po::options_description desc("Allowed options");
desc.add_options()
    ("help", "produce help message")
    ("optimization", po::value<int>(&opt)->default_value(10), 
  "optimization level")
    ("include-path,I", po::value< vector<string> >(), 
  "include path")
    ("input-file", po::value< vector<string> >(), "input file")
;
The "help" option should be familiar from the previous example. It's a good idea to have this option in all cases.

The "optimization" option shows two new features. First, we specify the address of the variable(&opt). After storing values, that variable will have the value of the option. Second, we specify a default value of 10, which will be used if no value is specified by the user.

The "include-path" option is an example of the only case where the interface of the options_description class serves only one source -- the command line. Users typically like to use short option names for common options, and the "include-path,I" name specifies that short option name is "I". So, both "--include-path" and "-I" can be used.

Note also that the type of the "include-path" option is std::vector. The library provides special support for vectors -- it will be possible to specify the option several times, and all specified values will be collected in one vector.

The "input-file" option specifies the list of files to process. That's okay for a start, but, of course, writing something like:

compiler --input-file=a.cpp
    
is a little non-standard, compared with

compiler a.cpp
    
We'll address this in a moment.

The command line tokens which have no option name, as above, are called "positional options" by this library. They can be handled too. With a little help from the user, the library can decide that "a.cpp" really means the same as "--input-file=a.cpp". Here's the additional code we need:

po::positional_options_description p;
p.add("input-file", -1);

po::variables_map vm;
po::store(po::command_line_parser(ac, av).
          options(desc).positional(p).run(), vm);
po::notify(vm);
    
The first two lines say that all positional options should be translated into "input-file" options. Also note that we use the command_line_parser class to parse the command line, not the parse_command_line function. The latter is a convenient wrapper for simple cases, but now we need to pass additional information.

By now, all options are described and parsed. We'll save ourselves the trouble of implementing the rest of the compiler logic and only print the options:

if (vm.count("include-path"))
{
    cout << "Include paths are: " 
         << vm["include-path"].as< vector<string> >() << "\n";
}

if (vm.count("input-file"))
{
    cout << "Input files are: " 
         << vm["input-file"].as< vector<string> >() << "\n";
}

cout << "Optimization level is " << opt << "\n";                
Here's an example session:

$ bin/gcc/debug/options_description --help
Usage: options_description [options]
Allowed options:
  --help                 : produce help message
  --optimization arg     : optimization level
  -I [ --include-path ] arg : include path
  --input-file arg       : input file
$ bin/gcc/debug/options_description
Optimization level is 10
$ bin/gcc/debug/options_description --optimization 4 -I foo a.cpp
Include paths are: foo
Input files are: a.cpp
Optimization level is 4
Oops, there's a slight problem. It's still possible to specify the "--input-file" option, and usage message says so, which can be confusing for the user. It would be nice to hide this information, but let's wait for the next example.

Multiple Sources
It's quite likely that specifying all options to our compiler on the command line will annoy users. What if a user installs a new library and wants to always pass an additional command line element? What if he has made some choices which should be applied on every run? It's desirable to create a config file with common settings which will be used together with the command line.

Of course, there will be a need to combine the values from command line and config file. For example, the optimization level specified on the command line should override the value from the config file. On the other hand, include paths should be combined.

Let's see the code now. The complete program is in "examples/multiple_sources.cpp". The option definition has two interesting details. First, we declare several instances of the options_description class. The reason is that, in general, not all options are alike. Some options, like "input-file" above, should not be presented in an automatic help message. Some options make sense only in the config file. Finally, it's nice to have some structure in the help message, not just a long list of options. Let's declare several option groups:

// Declare a group of options that will be 
// allowed only on command line
po::options_description generic("Generic options");
generic.add_options()
    ("version,v", "print version string")
    ("help", "produce help message")    
    ;
    
// Declare a group of options that will be 
// allowed both on command line and in
// config file
po::options_description config("Configuration");
config.add_options()
    ("optimization", po::value<int>(&opt)->default_value(10), 
          "optimization level")
    ("include-path,I", 
         po::value< vector<string> >()->composing(), 
         "include path")
    ;

// Hidden options, will be allowed both on command line and
// in config file, but will not be shown to the user.
po::options_description hidden("Hidden options");
hidden.add_options()
    ("input-file", po::value< vector<string> >(), "input file")
    ;        
Note the call to the composing method in the declaration of the "include-path" option. It tells the library that values from different sources should be composed together, as we'll see shortly.

The add method of the options_description class can be used to further group the options:

po::options_description cmdline_options;
cmdline_options.add(generic).add(config).add(hidden);

po::options_description config_file_options;
config_file_options.add(config).add(hidden);

po::options_description visible("Allowed options");
visible.add(generic).add(config);
      
The parsing and storing of values follows the usual pattern, except that we additionally call parse_config_file, and call the store function twice. But what happens if the same value is specified both on the command line and in config file? Usually, the value stored first is preferred. This is what happens for the "--optimization" option. For "composing" options, like "include-file", the values are merged.

Here's an example session:

$ bin/gcc/debug/multiple_sources
Include paths are: /opt
Optimization level is 1
$ bin/gcc/debug/multiple_sources --help
Allows options:

Generic options:
  -v [ --version ]       : print version string
  --help                 : produce help message

Configuration:
  --optimization n       : optimization level
  -I [ --include-path ] path : include path

$ bin/gcc/debug/multiple_sources --optimization=4 -I foo a.cpp b.cpp
Include paths are: foo /opt
Input files are: a.cpp b.cpp
Optimization level is 4
The first invocation uses values from the configuration file. The second invocation also uses values from command line. As we see, the include paths on the command line and in the configuration file are merged, while optimization is taken from the command line.

			20.12.1.2 first.cpp
// Copyright Vladimir Prus 2002-2004.
// Distributed under the Boost Software License, Version 1.0.
// (See accompanying file LICENSE_1_0.txt
// or copy at http://www.boost.org/LICENSE_1_0.txt)

/* The simplest usage of the library.
 */

#include <boost/program_options.hpp>
namespace po = boost::program_options;

#include <iostream>
#include <iterator>
using namespace std;

int main(int ac, char* av[])
{
    try {

        po::options_description desc("Allowed options");
        desc.add_options()
            ("help", "produce help message")
            ("compression", po::value<int>(), "set compression level")
        ;

        po::variables_map vm;        
        po::store(po::parse_command_line(ac, av, desc), vm);
        po::notify(vm);    

        if (vm.count("help")) {
            cout << desc << "\n";
            return 1;
        }

        if (vm.count("compression")) {
            cout << "Compression level was set to " 
                 << vm["compression"].as<int>() << ".\n";
        } else {
            cout << "Compression level was not set.\n";
        }
    }
    catch(exception& e) {
        cerr << "error: " << e.what() << "\n";
        return 1;
    }
    catch(...) {
        cerr << "Exception of unknown type!\n";
    }

    return 0;
} 

			20.12.1.3 My example
- To link:
-lboost_program_options
int main ( int ac, char *av[] )
{
    po::options_description desc("Allowed options");
    StrVec v_tests , v_params;
    string s_domain;

    desc.add_options()
        ("help,h", "produce help message")
        ("domain,d", po::value< string >( &s_domain), "Domain to test")
        ("tests,t", po::value< vector<string> >( &v_tests), "One or more test names, choose one of all/dns/ldap/kerb to run all or full suite. Use multiple times for multiple tests")
        ("params,p", po::value<  vector <string > >( &v_params), "Test parameters, in name-value pairs. Use multiple times for multiple params")
    ;
    
    stringstream ss_desc;
    ss_desc << desc << endl;

    po::variables_map vm;
    po::store(po::parse_command_line(ac, av, desc), vm);
    po::notify(vm);    
    
    if (vm.count("help")) {
        printf("%s\n", ss_desc.str().c_str());
        return 1;
    }
    //if (vm.count("tests"))
    if (v_tests.size() > 0)
    {
            //= vm["test"].as< vector<string> >(); 
            printf ("test/s are: \n" );
            for ( StrVec::iterator i = v_tests.begin(); i != v_tests.end() ; ++i) {
                    printf("%s; ", (*i).c_str());
            }
            printf ("\n" );
    }
    if (v_params.size() > 0)
    {
            printf ("Param/s are: \n" );
            for ( StrVec::iterator i = v_params.begin(); i != v_params.end() ; ++i) {
                    printf("%s; ", (*i).c_str());
            }
            printf ("\n" );
    }
        printf("Domain is %s\n", s_domain.c_str()); 

			20.12.1.4 http://www.radmangames.com/programming/how-to-use-boost-program_options

If it so happens that you’re writing a console application, then chances are you will (or should) want to pass it some parameters at the command line. By default C++ has only the argc and argv parameters to the main function to facilitate this and I can assure you that working with them directly is less than fun. If you have worked with any number of command line programs you would be well aware of a common form that they take and that users expect. To get this expected behavior you should use another favourite boost library of mine: Program options.

Quite simply, Boost.Program_options is the way to do industry standard command line processing in C++, if you’re trying to implement command line arguments in your application then you should be using this library. This tutorial will take you through how to get set up and productive using boost program options with a minimum of fuss.

Obtaining, compiling and linking to boost is not covered.

Application Template

So you have an program that you want to be able to accept command line parameters? Then replace (or merge) the contents of your main.cpp with the code below. This code forms the foundation of the rest of the tutorial and is boiler plate that you will find yourself writing every time you create a new command line application.

Note: the rest of the examples reference the names of objects in the code below.

 
#include "boost/program_options.hpp" 
 
#include <iostream> 
#include <string> 
 
namespace 
{ 
  const size_t ERROR_IN_COMMAND_LINE = 1; 
  const size_t SUCCESS = 0; 
  const size_t ERROR_UNHANDLED_EXCEPTION = 2; 
 
} // namespace 
 
int main(int argc, char** argv) 
{ 
  try 
  { 
    /** Define and parse the program options 
     */ 
    namespace po = boost::program_options; 
    po::options_description desc("Options"); 
    desc.add_options() 
      ("help", "Print help messages") 
      ("add", "additional options") 
      ("like", "this"); 
 
    po::variables_map vm; 
    try 
    { 
      po::store(po::parse_command_line(argc, argv, desc),  
                vm); // can throw 
 
      /** --help option 
       */ 
      if ( vm.count("help")  ) 
      { 
        std::cout << "Basic Command Line Parameter App" << std::endl 
                  << desc << std::endl; 
        return SUCCESS; 
      } 
 
      po::notify(vm); // throws on error, so do after help in case 
                      // there are any problems 
    } 
    catch(po::error& e) 
    { 
      std::cerr << "ERROR: " << e.what() << std::endl << std::endl; 
      std::cerr << desc << std::endl; 
      return ERROR_IN_COMMAND_LINE; 
    } 
 
    // application code here // 
 
  } 
  catch(std::exception& e) 
  { 
    std::cerr << "Unhandled Exception reached the top of main: " 
              << e.what() << ", application will now exit" << std::endl; 
    return ERROR_UNHANDLED_EXCEPTION; 
 
  } 
 
  return SUCCESS; 
 
} // main 
Basic option configuration

All of the below options should be added as additional lines in the desc.add_options() call in the application template.
Add the most simple of options
--option

 
("option", "Info message about option") 
Add a shorthand for an option
--option or -o

 
("option,o", "Info message about option") // can use -o 
Add an option with shorthand only
-o

 
(",o", "Info message about option") // must use -o 
Add an option that has an associated value
--option <value>

 
("option", po::value<arg_type>(), "Info message about option") 
Specify that an option is required
The call to po::notify(vm) will throw if the option is not specified.
 
("option", po::value<arg_type>()->required(), "Info message") 
Specify an option that can be specified multiple times
--option <value1> --option <value2> --option <value3>

 
("option", po::value<std::vector<arg_type> >(), "a list of values") 
Accessing option values

Have the option set directly into an existing variable
I find this to be the most convenient method to use

 
("option", po::value<arg_type>(&existingVariable), "info message") 
Check if an option was passed in the command line
 
if ( vm.count("option") ) 
To extract the value for an option manually
 
vm["option"].as<arg_type>() 
Specifying Positional Options

A positional option is a value given on the command line that is not preceded by an option switch like -o or --option. An example is the following:

user@computer:$ g++ -o main main.cpp
In this case main.cpp is the positional option, and as you can see it is not associated with any option explicitly specified. Instead of being identified by an option switch (like --option) they are identified by the lack of one. When multiple positional options are available the option the value is assigned to is designated by the order in which the values appear in the command line.

user@computer:$ hg help commit -v
In this case 'help' is the first positional option and 'commit' is the second. The command will print help info for the commit subcommand. Now if the order were to be reversed:

user@computer:$ hg commit help -v
The position of the options is now reversed and the command will now try to 'commit' the location 'help'. Again the order in which values are specified determines which positional option the value is assigned to.

Example code for positional options
To specify these with boost program options add a po::positional_options_description object and specify the names of the options that you want to parse as positional. Add the following code block directly below the last option in the desc.add_options() call:
 
po::positional_options_description positionalOptions; 
positionalOptions.add("option_name_1", <num_occurrences>); 
positionalOptions.add("option_name_2", <num_occurrences>); 
The option name specified as the first parameter must correspond to the name of an option already specified in the regular options description. The second parameter specifies the number of values to be associated with the option, in the simple case you will always set this to 1. The positional order of options is implied by the order in which they are added to the description, in this case 'option_name_1' is first and 'option_name_2' is second.

Next you need to make sure that the positional options are parsed along with the others and stored in the variable map. Change the po::store() call to the following:
 
po::store(po::command_line_parser(argc, argv).options(desc) 
            .positional(positionalOptions).run(), 
          vm); 
Putting it all together

With just the information above you can create quite sophisticated command line applications, but sometimes knowing the parts does not give a good enough picture of what can be achieved. Check out below for a full example of the options implemented in a demo application. This should help to give you an idea of how things look when it’s all put together. Be aware that I have implemented some custom parsing for printing the available options in posix style which I include as part of the source package for the example application and an example of that usage output is shown immediately below. The information is parsed generically from the specified options and this prevents you from having to manually update help text when you update options (which is pretty awesome).

Best of luck, and please let me know if you have any issues.

Please not you will need version 1.50.0 of boost to compile the extended example

Usage Output
user@computer:$ ./test_bed --help
This is just a template app that should be modified and added to in order to create a useful command line application

USAGE: test_bed [-hvt] [-w ARG] [-m ARG] -n ARG add like 

-- Option Descriptions --

Positional arguments:
add "additional options"
like "this"

Option Arguments:
-h [ --help ] Print help messages
-v [ --verbose ] print words with verbosity
-w [ --word ] words for the sentence, specify multiple times
-t just a temp option that does very little
-n [ --necessary ] give me anything
-m [ --manual ] extract value manually
Example Application
 
#include "PrettyOptionPrinter.hpp" 
 
#include "boost/program_options.hpp" 
#include "boost/filesystem.hpp" 
 
#include <iostream> 
#include <string> 
 
namespace 
{ 
  const size_t ERROR_IN_COMMAND_LINE = 1; 
  const size_t SUCCESS = 0; 
  const size_t ERROR_UNHANDLED_EXCEPTION = 2; 
 
} // namespace 
 
//------------------------------------------------------------------------ 
int main(int argc, char** argv) 
{ 
  try 
  { 
    std::string appName = boost::filesystem::basename(argv[0]); 
    int add = 0; 
    int like = 0; 
    std::vector<std::string> sentence; 
 
    /** Define and parse the program options 
     */ 
    namespace po = boost::program_options; 
    po::options_description desc("Options"); 
    desc.add_options() 
      ("help,h", "Print help messages") 
      ("verbose,v", "print words with verbosity") 
      ("word,w", po::value<std::vector<std::string> >(&sentence), 
       "words for the sentence, specify multiple times") 
      (",t", "just a temp option that does very little") 
      ("necessary,n", po::value<std::string>()->required(), "necessary!") 
      ("manual,m", po::value<std::string>(), "extract value manually") 
      ("add", po::value<int>(&add)->required(), "additional options") 
      ("like", po::value<int>(&like)->required(), "this"); 
 
    po::positional_options_description positionalOptions; 
    positionalOptions.add("add", 1); 
    positionalOptions.add("like", 1); 
 
    po::variables_map vm; 
 
    try 
    { 
      po::store(po::command_line_parser(argc, argv).options(desc) 
                  .positional(positionalOptions).run(), 
                vm); // throws on error 
 
      /** --help option 
       */ 
      if ( vm.count("help")  ) 
      { 
        std::cout << "This is just a template app that should be modified" 
                  << " and added to in order to create a useful command" 
                  << " line application" << std::endl << std::endl; 
        rad::OptionPrinter::printStandardAppDesc(appName, 
                                                 std::cout, 
                                                 desc, 
                                                 &positionalOptions); 
        return SUCCESS; 
      } 
 
      po::notify(vm); // throws on error, so do after help in case 
                      // there are any problems 
    } 
    catch(boost::program_options::required_option& e) 
    { 
      rad::OptionPrinter::formatRequiredOptionError(e); 
      std::cerr << "ERROR: " << e.what() << std::endl << std::endl; 
      rad::OptionPrinter::printStandardAppDesc(appName, 
                                               std::cout, 
                                               desc, 
                                               &positionalOptions); 
      return ERROR_IN_COMMAND_LINE; 
    } 
    catch(boost::program_options::error& e) 
    { 
      std::cerr << "ERROR: " << e.what() << std::endl << std::endl; 
      rad::OptionPrinter::printStandardAppDesc(appName, 
                                               std::cout, 
                                               desc, 
                                               &positionalOptions); 
      return ERROR_IN_COMMAND_LINE; 
    } 
 
    // can do this without fear because it is required to be present 
    std::cout << "Necessary = " 
              << vm["necessary"].as<std::string>() << std::endl; 
 
    if ( vm.count("verbose") ) 
    { 
      std::cout << "VERBOSE PRINTING" << std::endl; 
    } 
    if (vm.count("verbose") && vm.count("t")) 
    { 
      std::cout << "heeeeyahhhhh" << std::endl; 
    } 
 
    std::cout << "Required Positional, add: " << add 
              << " like: " << like << std::endl; 
 
    if ( sentence.size() > 0 ) 
    { 
      std::cout << "The specified words: "; 
      std::string separator = " "; 
      if (vm.count("verbose")) 
      { 
        separator = "__**__"; 
      } 
      for(size_t i=0; i<sentence.size(); ++i) 
      { 
        std::cout << sentence[i] << separator; 
      } 
      std::cout << std::endl; 
 
    } 
 
    if ( vm.count("manual") ) 
    { 
      std::cout << "Manually extracted value: " 
                << vm["manual"].as<std::string>() << std::endl; 
    } 
 
  } 
  catch(std::exception& e) 
  { 
    std::cerr << "Unhandled Exception reached the top of main: " 
              << e.what() << ", application will now exit" << std::endl; 
    return ERROR_UNHANDLED_EXCEPTION; 
 
  } 
 
  return SUCCESS; 
 
} // main 
 
//------------------------------------------------------------------------ 
 
			20.12.1.5
		20.12.2

	20.13 c++ print source file name and line
__FILE__ , __LINE_ 
A C/C++ feature that helped me to log better
I read an article some time ago where it claims that you take at least 10 years to learn C/C++ entirely. I don’t remember if was Bjarne Stroustrup or someone else that said that but I completely agree!

I program professionally for about 8 years and most of my career was developing in C/C++, still I don’t consider I know everything about this terrific language. One prove is that I found an interesting feature available regarding #define macros!

 

Let’s LOG

One important thing of every program is log. It’s used to trace program’s flow or even debug on some cases where you cannot use GDB/DBX.

That being said, one important thing to put on your logs is the file name and line number where the it occurs. On my early days I though to have found a smart way to do it!

Well, I created a log function that here I’ll simplify it a little:

#include
#include 
 
void log(const char* fileName, int line, const char* msg, ...)
{
    va_list args;
    va_start(args, msg);
 
    fprintf(stdout, "%s, %d:", fileName, line);
    vfprintf(stdout, msg, args);
    fprintf(stdout, "n");
 
    va_end(args);
}
Now I can use this just like a simple printf:


int var = 50;
log("MyFile.cpp", 11, "Hello var: %d", var);
The problem with this, show up when I add couple lines before it:


// trace var value
int var = 50;
 
log("MyFile.cpp", 11, "Hello var: %d", var);
This time the output of this will still be:


MyFile.cpp, 11: Hello var: 50
The problem is this line is wrong now! And imagine fixing all the logs of a 1000 LOC file if you just add an include?

How to solve this?

Standard Predefined Macros

If you check The GNU C Preprocessor page that talks about Standard Predefined Macros you’ll find two interesting macros that solve our problem:

__FILE__ – This macro expands to the name of the current input file, in the form of a C string constant.
__LINE__ – This macro expands to the current input line number, in the form of a decimal integer constant.
Well, now if we use our log function with this macros we’re safe:


// trace var value
int var = 50;
 
log(__FILE__, __LINE__, "Hello var: %d", var);
This time the output of this will be:


MyFile.cpp, 13: Hello var: 50
Cool right?

Yes but if you start working with a bunch of people you’ll realize that use this standard macros might confuse some folks and others tend to use plain printf just because they don’t know how to use it.

Now, how to solve THIS problem?

#define Macros to save us

It turns out there is a feature on standard C called Variadic Macros that I didn’t know before this week that simply solve this issue and make log functions elegant and efficient. I’ll point you again to the The GNU C Preprocessor on the Variadic Macros page so you can read the details, but in a glimpse here is its syntax:


#define MACRO_NAME(arg, ...) somefunc(arg, __VA_ARGS__)
One thing to notice though is that with this syntax you must pass at least one argument as variable arguments due the comma on your macro definition. But don’t look to this post with this face! There is a second syntax of Variadic Macros that will calm you down:


#define MACRO_NAME(arg, ...) somefunc(arg, ##__VA_ARGS__)
With those double pounds before the __VA_ARGS\__ keyword, the C preprocessor will know if you don’t add variable arguments and will take the comma out.

Now, how this will help us on our log function?

Easy, we create this macro:


#define LOG(msg, ...) log(__FILE__, __LINE__, msg, ##__VA_ARGS__)
Now our code snippet can be re-writen to use this new macro:


// trace var value
int var = 50;
 
LOG("Hello var: %d", var);
As I said: cleaner and more elegant ;-) !

	20.14 initialization list question, with emphasis on std vector
 how do I initialise a std::vector?

Is this the way, ie just putting a 0 in brackets? My header:

class Blade;
class Postpro {
   public:
     Postpro(string fName) : theFileName(fName),
                             blade(NULL),
                             sizes(10),
                             t(std::vector<double>(0){};
     ~Postpro(){};
     void test();

   private:
     string theFileName;
     Blade* blade;
     int sizes;
     std::vector<double> t;
}
And then in the cpp I just resize the vector if I want to use it?

void Postpro::test() {
    blade = new Blade;
    t.resize(37);
}


----------------------------------------------------------------------------------------------------
It does not take that much time to type, because you have typed too much:

Instead of

t(std::vector<double>(0))
you could write

t(0)
which should be the same as

t()
The warning might be a bit too pedantic. Classes with a default constructor will be automatically initialized anyway. A warning flag to alert you only of uninitialized POD members would seem more valuable (otherwise you get too much noise).

May-be the use is that it shows the reader that you indeed meant to use the default constructor to initialize that member.
----------------------------------------------------------------------------------------------------

	20.15 boost regex 
- Source:
/Users/yizaq/Desktop/Work/code/CPP/tests/string/regexp.cpp


/*
 * =====================================================================================
 *
 *       Filename:  regexp.cpp
 *
 *    Description:  
 *  email: I’m thinking of putting in place a simple workaround. 
 *  email: Check for offending user name (regexp:  .*@.*\.\..* Or .*@.*\.$) ; if match make ISE drop the auth. 
 *  email: I plan to put the check and set auth res. To drop in AD ID store.*
 *        Version:  1.0
 *        Created:  02/24/2014 10:41:12
 *       Revision:  none
 *       Compiler:  gcc
 *       [yizaq@yizaq-mac:Mon Feb 24:~/Desktop/Work/code/CPP/tests/string:]$ g++ -L/usr/local/Cellar/boost/1.55.0/lib -lboost_regex-mt -lboost_filesystem-mt -lboost_thread-mt    regexp.cpp 
 *
 *         Author:  Yosi Izaq
 *   Organization:  
 *
 * =====================================================================================
 */
#include <stdlib.h>
#include <stdio.h>
#include <string>
#include <iostream>
#include <boost/regex.hpp>

using namespace std;
using namespace boost;

int main(int argc, const char *argv[])
{
	string inp1 = "yosi@cisco..com";	
	string inp2 = "yosi@cisco.com.";	
	string inp3 = "";	

	const regex re1(  ".*\\@.*\\.\\..*" );
	const regex re2(  ".*\\@.*\\.$" );

	cout<<"Please enter pattern"<<endl;
	cin>>inp3;
	cout<<"You entered pattern "<<inp3<<endl;

	if (regex_match(inp1,re1)) {
	    cout<<inp1<<" match pattern 1"<<endl;
	}
	else {
	    cout<<inp1<<" does not match pattern 1"<<endl;
		
	}
	if (regex_match(inp1,re2)) {
	    cout<<inp1<<" match pattern 2"<<endl;
	}
	else {
	    cout<<inp1<<" does not match pattern 2"<<endl;
		
	}

	if (regex_match(inp2,re1)) {
	    cout<<inp2<<" match pattern 1"<<endl;
	}
	else {
	    cout<<inp2<<" does not match pattern 1"<<endl;
		
	}
	if (regex_match(inp2,re2)) {
	    cout<<inp2<<" match pattern 2"<<endl;
	}
	else {
	    cout<<inp2<<" does not match pattern 2"<<endl;
		
	}

	if (regex_match(inp3,re1)) {
	    cout<<inp3<<" match pattern 1"<<endl;
	}
	else {
	    cout<<inp3<<" does not match pattern 1"<<endl;
		
	}
	if (regex_match(inp3,re2)) {
	    cout<<inp3<<" match pattern 2"<<endl;
	}
	else {
	    cout<<inp3<<" does not match pattern 2"<<endl;
		
	}

	return 0;
}
- Ex:
[yizaq@yizaq-mac:Mon Feb 24:~/Desktop/Work/code/CPP/tests/string:]$ g++ -L/usr/local/Cellar/boost/1.55.0/lib -lboost_regex-mt -lboost_filesystem-mt -lboost_thread-mt    regexp.cpp 
[yizaq@yizaq-mac:Mon Feb 24:~/Desktop/Work/code/CPP/tests/string:]$ a.out
Please enter pattern
y@a.b.
You entered pattern y@a.b.
yosi@cisco..com match pattern 1
yosi@cisco..com does not match pattern 2
yosi@cisco.com. does not match pattern 1
yosi@cisco.com. match pattern 2
y@a.b. does not match pattern 1
y@a.b. match pattern 2
[yizaq@yizaq-mac:Mon Feb 24:~/Desktop/Work/code/CPP/tests/string:]$ a.out
Please enter pattern
y@a..b
You entered pattern y@a..b
yosi@cisco..com match pattern 1
yosi@cisco..com does not match pattern 2
yosi@cisco.com. does not match pattern 1
yosi@cisco.com. match pattern 2
y@a..b match pattern 1
y@a..b does not match pattern 2


		20.15.1 


	20.16 Translate IPv6 address from string to binary and back to string (normalizing it on the way)
r ~/Desktop/Work/code/CPP/networking/normalizeIPv6Addr.cpp
/*
 * =====================================================================================
 *
 *       Filename:  normalizeIPv6Addr.cpp
 *
 *    Description:  
 *
 *
 *        Version:  1.0
 *        Created:  08/06/15 13:58:52
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  YOSI IZAQ
 *   Organization:  
 *
 * =====================================================================================
 */

#include <arpa/inet.h>
#include <stdio.h>
#include <stdlib.h>
#include <iostream>
#include <string>

using namespace std;

int normalizeIPV6Addr(const string & ipv6addr, string & normalizedaddr )
{
	cout<<"Got address "<<ipv6addr <<endl;
	unsigned char buf[sizeof(struct in6_addr)];
	int res;
	inet_pton(AF_INET6, ipv6addr.c_str(), buf);
	char str[INET6_ADDRSTRLEN];
	normalizedaddr = "";
	if (res <=0) 
	{
	    if (res == 0 ) 
	    {
	    	cout<<"Address not in presentation format"<<endl;
	    }
	    else
	    {
		    perror("inet_pton");
	    }
	}
	else
	{
		cout<<"Address trandlated to binary"<<endl;
	}

	if (inet_ntop(AF_INET6, buf, str, INET6_ADDRSTRLEN) == NULL ) 
	{
            perror("inet_ntop");
	}

	string sTemp(str);
	normalizedaddr = sTemp;
        cout<<"Normalized address: " << normalizedaddr << " res: "<< res<<endl; 
	return res;
}

int main(int argc, const char *argv[])
{
	string saddr, snormaddr;
	cout<<"Please enter address in IPV6 format"<<endl;
	cin>>saddr;
	cout<<"Got address in IPV6 format:"<<saddr<<endl;

	if ( normalizeIPV6Addr(saddr , snormaddr )  > 0)
	{
           cout<<"Normalized address: " << snormaddr << endl; 
	}
	return 0;
}

[yizaq@YIZAQ-M-D1BW:Thu Aug 06:~/Desktop/Work/code/CPP/networking:]$ g++ normalizeIPv6Addr.cpp -o normalizeIPv6Addr
[yizaq@YIZAQ-M-D1BW:Thu Aug 06:~/Desktop/Work/code/CPP/networking:]$ ./normalizeIPv6Addr 
Please enter address in IPV6 format
2001:0db8:0000:0000:1111:2222:3333:4444
Got address in IPV6 format:2001:0db8:0000:0000:1111:2222:3333:4444
Got address 2001:0db8:0000:0000:1111:2222:3333:4444
Address trandlated to binary
Normalized address: 2001:db8::1111:2222:3333:4444 res: 32767
Normalized address: 2001:db8::1111:2222:3333:4444


	20.17
21. Multithreading

	21.1 POSIX thread (pthread) libraries
http://www.yolinux.com/TUTORIALS/LinuxTutorialPosixThreads.html

Yolinux.com Linux logo 	
POSIX thread (pthread) libraries

The POSIX thread libraries are a standards based thread API for C/C++. It allows one to spawn a new concurrent process flow. It is most effective on multi-processor or multi-core systems where the process flow can be scheduled to run on another processor thus gaining speed through parallel or distributed processing. Threads require less overhead than "forking" or spawning a new process because the system does not initialize a new system virtual memory space and environment for the process. While most effective on a multiprocessor system, gains are also found on uniprocessor systems which exploit latency in I/O and other system functions which may halt process execution. (One thread may execute while another is waiting for I/O or some other system latency.) Parallel programming technologies such as MPI and PVM are used in a distributed computing environment while threads are limited to a single computer system. All threads within a process share the same address space. A thread is spawned by defining a function and its arguments which will be processed in the thread. The purpose of using the POSIX thread library in your software is to execute software faster.

Table of Contents:

    # Thread Basics
    # Thread Creation and Termination
    # Thread Synchronization
    # Thread Scheduling
    # Thread Pitfalls
    # Thread Debugging
    # Thread Man Pages
    # Links
    # Books

		21.1.1 Thread Basics:

    Thread operations include thread creation, termination, synchronization (joins,blocking), scheduling, data management and process interaction.
    A thread does not maintain a list of created threads, nor does it know the thread that created it.
    All threads within a process share the same address space.
    Threads in the same process share:
        Process instructions
        Most data
        open files (descriptors)
        signals and signal handlers
        current working directory
        User and group id
    Each thread has a unique:
        Thread ID
        set of registers, stack pointer
        stack for local variables, return addresses
        signal mask
        priority
        Return value: errno
    pthread functions return "0" if OK.

		21.1.2 Thread Creation and Termination:

Example: pthread1.c

    01	#include <stdio.h>
    02	#include <stdlib.h>
    03	#include <pthread.h>
    04	 
    05	void *print_message_function( void *ptr );
    06	 
    07	main()
    08	{
    09	     pthread_t thread1, thread2;
    10	     char *message1 = "Thread 1";
    11	     char *message2 = "Thread 2";
    12	     int  iret1, iret2;
    13	 
    14	    /* Create independent threads each of which will execute function */
    15	 
    16	     iret1 = pthread_create( &thread1, NULL, print_message_function, (void*) message1);
    17	     iret2 = pthread_create( &thread2, NULL, print_message_function, (void*) message2);
    18	 
    19	     /* Wait till threads are complete before main continues. Unless we  */
    20	     /* wait we run the risk of executing an exit which will terminate   */
    21	     /* the process and all threads before the threads have completed.   */
    22	 
    23	     pthread_join( thread1, NULL);
    24	     pthread_join( thread2, NULL);
    25	 
    26	     printf("Thread 1 returns: %d\n",iret1);
    27	     printf("Thread 2 returns: %d\n",iret2);
    28	     exit(0);
    29	}
    30	 
    31	void *print_message_function( void *ptr )
    32	{
    33	     char *message;
    34	     message = (char *) ptr;
    35	     printf("%s \n", message);
    36	}

Compile:

    C compiler: cc -lpthread pthread1.c
    or
    C++ compiler: g++ -lpthread pthread1.c


Run: ./a.out
Results:

    Thread 1
    Thread 2
    Thread 1 returns: 0
    Thread 2 returns: 0

Details:

    In this example the same function is used in each thread. The arguments are different. The functions need not be the same.

    Threads terminate by explicitly calling pthread_exit, by letting the function return, or by a call to the function exit which will terminate the process including any threads.

    Function call: pthread_create - create a new thread

        int pthread_create(pthread_t * thread, 
                           const pthread_attr_t * attr,
                           void * (*start_routine)(void *), 
                           void *arg);

    Arguments:
        thread - returns the thread id. (unsigned long int defined in bits/pthreadtypes.h)
        attr - Set to NULL if default thread attributes are used. (else define members of the struct pthread_attr_t defined in bits/pthreadtypes.h) Attributes include:
            detached state (joinable? Default: PTHREAD_CREATE_JOINABLE. Other option: PTHREAD_CREATE_DETACHED)
            scheduling policy (real-time? PTHREAD_INHERIT_SCHED,PTHREAD_EXPLICIT_SCHED,SCHED_OTHER)
            scheduling parameter
            inheritsched attribute (Default: PTHREAD_EXPLICIT_SCHED Inherit from parent thread: PTHREAD_INHERIT_SCHED)
            scope (Kernel threads: PTHREAD_SCOPE_SYSTEM User threads: PTHREAD_SCOPE_PROCESS Pick one or the other not both.)
            guard size
            stack address (See unistd.h and bits/posix_opt.h _POSIX_THREAD_ATTR_STACKADDR)
            stack size (default minimum PTHREAD_STACK_SIZE set in pthread.h),
        void * (*start_routine) - pointer to the function to be threaded. Function has a single argument: pointer to void.
        *arg - pointer to argument of function. To pass multiple arguments, send a pointer to a structure.

    Function call: pthread_join - wait for termination of another thread

        int pthread_join(pthread_t th, void **thread_return);

    Arguments:
        th - thread suspended until the thread identified by th terminates, either by calling pthread_exit() or by being cancelled.
        thread_return - If thread_return is not NULL, the return value of th is stored in the location pointed to by thread_return.

    Function call: pthread_exit - terminate the calling thread

        void pthread_exit(void *retval);

    Arguments:
        retval - Return value of thread.

    This routine kills the thread. The pthread_exit function never returns. If the thread is not detached, the thread id and return value may be examined from another thread by using pthread_join.
    Note: the return pointer *retval, must not be of local scope otherwise it would cease to exist once the thread terminates.

    [C++ pitfalls]: The above sample program will compile with the GNU C and C++ compiler g++. The following function pointer representation below will work for C but not C++. Note the subtle differences and avoid the pitfall below:

        1	void print_message_function( void *ptr );
        2	...
        3	...
        4	iret1 = pthread_create( &thread1, NULL, (void*)&print_message_function, (void*) message1);
        5	...
        6	...

		21.1.3 Thread Synchronization:

The threads library provides three synchronization mechanisms:

    mutexes - Mutual exclusion lock: Block access to variables by other threads. This enforces exclusive access by a thread to a variable or set of variables.
    joins - Make a thread wait till others are complete (terminated).
    condition variables - data type pthread_cond_t

Mutexes:
Mutexes are used to prevent data inconsistencies due to operations by multiple threads upon the same memory area performed at the same time or to prevent race conditions where an order of operation upon the memory is expected. A contention or race condition often occurs when two or more threads need to perform operations on the same memory area, but the results of computations depends on the order in which these operations are performed. Mutexes are used for serializing shared resources such as memory. Anytime a global resource is accessed by more than one thread the resource should have a Mutex associated with it. One can apply a mutex to protect a segment of memory ("critical region") from other threads. Mutexes can be applied only to threads in a single process and do not work between processes as do semaphores.

Example threaded function:

    Without Mutex 	With Mutex
    1	int counter=0;
    2	 
    3	/* Function C */
    4	void functionC()
    5	{
    6	 
    7	   counter++
    8	 
    9	}
    	
    01	/* Note scope of variable and mutex are the same */
    02	pthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;
    03	int counter=0;
    04	 
    05	/* Function C */
    06	void functionC()
    07	{
    08	   pthread_mutex_lock( &mutex1 );
    09	   counter++
    10	   pthread_mutex_unlock( &mutex1 );
    11	}
    Possible execution sequence
    Thread 1 	Thread 2 	Thread 1 	Thread 2
    counter = 0 	counter = 0 	counter = 0 	counter = 0
    counter = 1 	counter = 1 	counter = 1 	Thread 2 locked out.
    Thread 1 has exclusive use of variable counter

    	
    	
    	counter = 2

If register load and store operations for the incrementing of variable counter occurs with unfortunate timing, it is theoretically possible to have each thread increment and overwrite the same variable with the same value. Another possibility is that thread two would first increment counter locking out thread one until complete and then thread one would increment it to 2.

    Sequence 	Thread 1 	Thread 2
    1 	counter = 0 	counter=0
    2 	Thread 1 locked out.
    Thread 2 has exclusive use of variable counter 	counter = 1
    3 	counter = 2 	

Code listing: mutex1.c

    01	#include <stdio.h>
    02	#include <stdlib.h>
    03	#include <pthread.h>
    04	 
    05	void *functionC();
    06	pthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;
    07	int  counter = 0;
    08	 
    09	main()
    10	{
    11	   int rc1, rc2;
    12	   pthread_t thread1, thread2;
    13	 
    14	   /* Create independent threads each of which will execute functionC */
    15	 
    16	   if( (rc1=pthread_create( &thread1, NULL, &functionC, NULL)) )
    17	   {
    18	      printf("Thread creation failed: %d\n", rc1);
    19	   }
    20	 
    21	   if( (rc2=pthread_create( &thread2, NULL, &functionC, NULL)) )
    22	   {
    23	      printf("Thread creation failed: %d\n", rc2);
    24	   }
    25	 
    26	   /* Wait till threads are complete before main continues. Unless we  */
    27	   /* wait we run the risk of executing an exit which will terminate   */
    28	   /* the process and all threads before the threads have completed.   */
    29	 
    30	   pthread_join( thread1, NULL);
    31	   pthread_join( thread2, NULL);
    32	 
    33	   exit(0);
    34	}
    35	 
    36	void *functionC()
    37	{
    38	   pthread_mutex_lock( &mutex1 );
    39	   counter++;
    40	   printf("Counter value: %d\n",counter);
    41	   pthread_mutex_unlock( &mutex1 );
    42	}

Compile: cc -lpthread mutex1.c
Run: ./a.out
Results:

    Counter value: 1
    Counter value: 2

When a mutex lock is attempted against a mutex which is held by another thread, the thread is blocked until the mutex is unlocked. When a thread terminates, the mutex does not unless explicitly unlocked. Nothing happens by default.
Man Pages:

    pthread_mutex_lock() - acquire a lock on the specified mutex variable. If the mutex is already locked by another thread, this call will block the calling thread until the mutex is unlocked.
    pthread_mutex_unlock() - unlock a mutex variable. An error is returned if mutex is already unlocked or owned by another thread.
    pthread_mutex_trylock() - attempt to lock a mutex or will return error code if busy. Useful for preventing deadlock conditions.

Joins:
A join is performed when one wants to wait for a thread to finish. A thread calling routine may launch multiple threads then wait for them to finish to get the results. One waits for the completion of the threads with a join.

Sample code: join1.c

    01	#include <stdio.h>
    02	#include <pthread.h>
    03	 
    04	#define NTHREADS 10
    05	void *thread_function(void *);
    06	pthread_mutex_t mutex1 = PTHREAD_MUTEX_INITIALIZER;
    07	int  counter = 0;
    08	 
    09	main()
    10	{
    11	   pthread_t thread_id[NTHREADS];
    12	   int i, j;
    13	 
    14	   for(i=0; i < NTHREADS; i++)
    15	   {
    16	      pthread_create( &thread_id[i], NULL, thread_function, NULL );
    17	   }
    18	 
    19	   for(j=0; j < NTHREADS; j++)
    20	   {
    21	      pthread_join( thread_id[j], NULL);
    22	   }
    23	   
    24	   /* Now that all threads are complete I can print the final result.     */
    25	   /* Without the join I could be printing a value before all the threads */
    26	   /* have been completed.                                                */
    27	 
    28	   printf("Final counter value: %d\n", counter);
    29	}
    30	 
    31	void *thread_function(void *dummyPtr)
    32	{
    33	   printf("Thread number %ld\n", pthread_self());
    34	   pthread_mutex_lock( &mutex1 );
    35	   counter++;
    36	   pthread_mutex_unlock( &mutex1 );
    37	}

Compile: cc -lpthread join1.c
Run: ./a.out
Results:

    Thread number 1026
    Thread number 2051
    Thread number 3076
    Thread number 4101
    Thread number 5126
    Thread number 6151
    Thread number 7176
    Thread number 8201
    Thread number 9226
    Thread number 10251
    Final counter value: 10

Man Pages:

    pthread_create() - create a new thread
    pthread_join() - wait for termination of another thread
    pthread_self() - return identifier of current thread

Condition Variables:

A condition variable is a variable of type pthread_cond_t and is used with the appropriate functions for waiting and later, process continuation. The condition variable mechanism allows threads to suspend execution and relinquish the processor until some condition is true. A condition variable must always be associated with a mutex to avoid a race condition created by one thread preparing to wait and another thread which may signal the condition before the first thread actually waits on it resulting in a deadlock. The thread will be perpetually waiting for a signal that is never sent. Any mutex can be used, there is no explicit link between the mutex and the condition variable.

Man pages of functions used in conjunction with the condition variable:

    Creating/Destroying:
        pthread_cond_init
        pthread_cond_t cond = PTHREAD_COND_INITIALIZER;
        pthread_cond_destroy
    Waiting on condition:
        pthread_cond_wait - unlocks the mutex and waits for the condition variable cond to be signaled.
        pthread_cond_timedwait - place limit on how long it will block.
    Waking thread based on condition:
        pthread_cond_signal - restarts one of the threads that are waiting on the condition variable cond.
        pthread_cond_broadcast - wake up all threads blocked by the specified condition variable.

Example code: cond1.c

    01	#include <stdio.h>
    02	#include <stdlib.h>
    03	#include <pthread.h>
    04	 
    05	pthread_mutex_t count_mutex     = PTHREAD_MUTEX_INITIALIZER;
    06	pthread_cond_t  condition_var   = PTHREAD_COND_INITIALIZER;
    07	 
    08	void *functionCount1();
    09	void *functionCount2();
    10	int  count = 0;
    11	#define COUNT_DONE  10
    12	#define COUNT_HALT1  3
    13	#define COUNT_HALT2  6
    14	 
    15	main()
    16	{
    17	   pthread_t thread1, thread2;
    18	 
    19	   pthread_create( &thread1, NULL, &functionCount1, NULL);
    20	   pthread_create( &thread2, NULL, &functionCount2, NULL);
    21	 
    22	   pthread_join( thread1, NULL);
    23	   pthread_join( thread2, NULL);
    24	 
    25	   printf("Final count: %d\n",count);
    26	 
    27	   exit(0);
    28	}
    29	 
    30	// Write numbers 1-3 and 8-10 as permitted by functionCount2()
    31	 
    32	void *functionCount1()
    33	{
    34	   for(;;)
    35	   {
    36	      // Lock mutex and then wait for signal to relase mutex
    37	      pthread_mutex_lock( &count_mutex );
    38	 
    39	      // Wait while functionCount2() operates on count
    40	      // mutex unlocked if condition varialbe in functionCount2() signaled.
    41	      pthread_cond_wait( &condition_var, &count_mutex );
    42	      count++;
    43	      printf("Counter value functionCount1: %d\n",count);
    44	 
    45	      pthread_mutex_unlock( &count_mutex );
    46	 
    47	      if(count >= COUNT_DONE) return(NULL);
    48	    }
    49	}
    50	 
    51	// Write numbers 4-7
    52	 
    53	void *functionCount2()
    54	{
    55	    for(;;)
    56	    {
    57	       pthread_mutex_lock( &count_mutex );
    58	 
    59	       if( count < COUNT_HALT1 || count > COUNT_HALT2 )
    60	       {
    61	          // Condition of if statement has been met.
    62	          // Signal to free waiting thread by freeing the mutex.
    63	          // Note: functionCount1() is now permitted to modify "count".
    64	          pthread_cond_signal( &condition_var );
    65	       }
    66	       else
    67	       {
    68	          count++;
    69	          printf("Counter value functionCount2: %d\n",count);
    70	       }
    71	 
    72	       pthread_mutex_unlock( &count_mutex );
    73	 
    74	       if(count >= COUNT_DONE) return(NULL);
    75	    }
    76	 
    77	}

Compile: cc -lpthread cond1.c
Run: ./a.out
Results:

    Counter value functionCount1: 1
    Counter value functionCount1: 2
    Counter value functionCount1: 3
    Counter value functionCount2: 4
    Counter value functionCount2: 5
    Counter value functionCount2: 6
    Counter value functionCount2: 7
    Counter value functionCount1: 8
    Counter value functionCount1: 9
    Counter value functionCount1: 10
    Final count: 10

Note that functionCount1() was halted while count was between the values COUNT_HALT1 and COUNT_HALT2. The only thing that has been ensures is that functionCount2 will increment the count between the values COUNT_HALT1 and COUNT_HALT2. Everything else is random.

The logic conditions (the "if" and "while" statements) must be chosen to insure that the "signal" is executed if the "wait" is ever processed. Poor software logic can also lead to a deadlock condition.

Note: Race conditions abound with this example because count is used as the condition and can't be locked in the while statement without causing deadlock.

		21.1.4 Thread Scheduling:

When this option is enabled, each thread may have its own scheduling properties. Scheduling attributes may be specified:

    during thread creation
    by dynamically by changing the attributes of a thread already created
    by defining the effect of a mutex on the thread's scheduling when creating a mutex
    by dynamically changing the scheduling of a thread during synchronization operations.

The threads library provides default values that are sufficient for most cases.

		21.1.5 Thread Pitfalls:

    Race conditions: While the code may appear on the screen in the order you wish the code to execute, threads are scheduled by the operating system and are executed at random. It cannot be assumed that threads are executed in the order they are created. They may also execute at different speeds. When threads are executing (racing to complete) they may give unexpected results (race condition). Mutexes and joins must be utilized to achieve a predictable execution order and outcome.

    Thread safe code: The threaded routines must call functions which are "thread safe". This means that there are no static or global variables which other threads may clobber or read assuming single threaded operation. If static or global variables are used then mutexes must be applied or the functions must be re-written to avoid the use of these variables. In C, local variables are dynamically allocated on the stack. Therefore, any function that does not use static data or other shared resources is thread-safe. Thread-unsafe functions may be used by only one thread at a time in a program and the uniqueness of the thread must be ensured. Many non-reentrant functions return a pointer to static data. This can be avoided by returning dynamically allocated data or using caller-provided storage. An example of a non-thread safe function is strtok which is also not re-entrant. The "thread safe" version is the re-entrant version strtok_r.

    Mutex Deadlock: This condition occurs when a mutex is applied but then not "unlocked". This causes program execution to halt indefinitely. It can also be caused by poor application of mutexes or joins. Be careful when applying two or more mutexes to a section of code. If the first pthread_mutex_lock is applied and the second pthread_mutex_lock fails due to another thread applying a mutex, the first mutex may eventually lock all other threads from accessing data including the thread which holds the second mutex. The threads may wait indefinitely for the resource to become free causing a deadlock. It is best to test and if failure occurs, free the resources and stall before retrying.
    01	...
    02	pthread_mutex_lock(&mutex_1);
    03	while ( pthread_mutex_trylock(&mutex_2) )  /* Test if already locked   */
    04	{
    05	   pthread_mutex_unlock(&mutex_1);  /* Free resource to avoid deadlock */
    06	   ...
    07	   /* stall here   */
    08	   ...
    09	   pthread_mutex_lock(&mutex_1);
    10	}
    11	count++;
    12	pthread_mutex_unlock(&mutex_1);
    13	pthread_mutex_unlock(&mutex_2);
    14	...

    The order of applying the mutex is also important. The following code segment illustrates a potential for deadlock:
    01	void *function1()
    02	{
    03	   ...
    04	   pthread_mutex_lock(&lock1);           // Execution step 1
    05	   pthread_mutex_lock(&lock2);           // Execution step 3 DEADLOCK!!!
    06	   ...
    07	   ...
    08	   pthread_mutex_lock(&lock2);
    09	   pthread_mutex_lock(&lock1);
    10	   ...
    11	}
    12	 
    13	void *function2()
    14	{
    15	   ...
    16	   pthread_mutex_lock(&lock2);           // Execution step 2
    17	   pthread_mutex_lock(&lock1);
    18	   ...
    19	   ...
    20	   pthread_mutex_lock(&lock1);
    21	   pthread_mutex_lock(&lock2);
    22	   ...
    23	}
    24	 
    25	main()
    26	{
    27	   ...
    28	   pthread_create(&thread1, NULL, function1, NULL);
    29	   pthread_create(&thread2, NULL, function2, NULL);
    30	   ...
    31	}
    If function1 acquires the first mutex and function2 acquires the second, all resources are tied up and locked.

    Condition Variable Deadlock: The logic conditions (the "if" and "while" statements) must be chosen to insure that the "signal" is executed if the "wait" is ever processed.

		21.1.6 Thread Debugging:

    GDB:

			21.1.6.1 Debugging Programs with Multiple Threads

Next: Forks, Previous: Inferiors and Programs, Up: Running
4.10 Debugging Programs with Multiple Threads

In some operating systems, such as HP-UX and Solaris, a single program may have more than one thread of execution. The precise semantics of threads differ from one operating system to another, but in general the threads of a single program are akin to multiple processesexcept that they share one address space (that is, they can all examine and modify the same variables). On the other hand, each thread has its own registers and execution stack, and perhaps private memory.

gdb provides these facilities for debugging multi-thread programs:

    automatic notification of new threads
    `thread threadno', a command to switch among threads
    `info threads', a command to inquire about existing threads
    `thread apply [threadno] [all] args', a command to apply a command to a list of threads
    thread-specific breakpoints
    `set print thread-events', which controls printing of messages on thread start and exit.
    `set libthread-db-search-path path', which lets the user specify which libthread_db to use if the default choice isn't compatible with the program. 

    Warning: These facilities are not yet available on every gdb configuration where the operating system supports threads. If your gdb does not support threads, these commands have no effect. For example, a system without thread support shows no output from `info threads', and always rejects the thread command, like this:

              (gdb) info threads
              (gdb) thread 1
              Thread ID 1 not known.  Use the "info threads" command to
              see the IDs of currently known threads.
         

The gdb thread debugging facility allows you to observe all threads while your program runsbut whenever gdb takes control, one thread in particular is always the focus of debugging. This thread is called the current thread. Debugging commands show program information from the perspective of the current thread.

Whenever gdb detects a new thread in your program, it displays the target system's identification for the thread with a message in the form `[New systag]'. systag is a thread identifier whose form varies depending on the particular system. For example, on gnu/Linux, you might see

     [New Thread 0x41e02940 (LWP 25582)]

when gdb notices a new thread. In contrast, on an SGI system, the systag is simply something like `process 368', with no further qualifier.

For debugging purposes, gdb associates its own thread numberalways a single integerwith each thread in your program.

info threads [id...]
    Display a summary of all threads currently in your program. Optional argument id... is one or more thread ids separated by spaces, and means to print information only about the specified thread or threads. gdb displays for each thread (in this order):

        the thread number assigned by gdb
        the target system's thread identifier (systag)
        the thread's name, if one is known. A thread can either be named by the user (see thread name, below), or, in some cases, by the program itself.
        the current stack frame summary for that thread 

    An asterisk `*' to the left of the gdb thread number indicates the current thread.

    For example, 

     (gdb) info threads
       Id   Target Id         Frame
       3    process 35 thread 27  0x34e5 in sigpause ()
       2    process 35 thread 23  0x34e5 in sigpause ()
     * 1    process 35 thread 13  main (argc=1, argv=0x7ffffff8)
         at threadtest.c:68

On Solaris, you can display more information about user threads with a Solaris-specific command:

maint info sol-threads
    Display info on Solaris user threads. 

thread threadno
    Make thread number threadno the current thread. The command argument threadno is the internal gdb thread number, as shown in the first field of the `info threads' display. gdb responds by displaying the system identifier of the thread you selected, and its current stack frame summary:

              (gdb) thread 2
              [Switching to thread 2 (Thread 0xb7fdab70 (LWP 12747))]
              #0  some_function (ignore=0x0) at example.c:8
              8	    printf ("hello\n");
         

    As with the `[New ...]' message, the form of the text after `Switching to' depends on your system's conventions for identifying threads.

    The debugger convenience variable `$_thread' contains the number of the current thread. You may find this useful in writing breakpoint conditional expressions, command scripts, and so forth. See See Convenience Variables, for general information on convenience variables.


thread apply [threadno | all] command
    The thread apply command allows you to apply the named command to one or more threads. Specify the numbers of the threads that you want affected with the command argument threadno. It can be a single thread number, one of the numbers shown in the first field of the `info threads' display; or it could be a range of thread numbers, as in 2-4. To apply a command to all threads, type thread apply all command.


thread name [name]
    This command assigns a name to the current thread. If no argument is given, any existing user-specified name is removed. The thread name appears in the `info threads' display.

    On some systems, such as gnu/Linux, gdb is able to determine the name of the thread as given by the OS. On these systems, a name specified with `thread name' will override the system-give name, and removing the user-specified name will cause gdb to once again display the system-specified name.


thread find [regexp]
    Search for and display thread ids whose name or systag matches the supplied regular expression.

    As well as being the complement to the `thread name' command, this command also allows you to identify a thread by its target systag. For instance, on gnu/Linux, the target systag is the LWP id.

              (gdb) thread find 26688
              Thread 4 has target id 'Thread 0x41e02940 (LWP 26688)'
              (gdb) info thread 4
                Id   Target Id         Frame
                4    Thread 0x41e02940 (LWP 26688) 0x00000031ca6cd372 in select ()
         


set print thread-events
set print thread-events on
set print thread-events off
    The set print thread-events command allows you to enable or disable printing of messages when gdb notices that new threads have started or that threads have exited. By default, these messages will be printed if detection of these events is supported by the target. Note that these messages cannot be disabled on all targets.


show print thread-events
    Show whether messages will be printed when gdb detects that threads have started and exited. 

See Stopping and Starting Multi-thread Programs, for more information about how gdb behaves when you stop and start programs with multiple threads.

See Setting Watchpoints, for information about watchpoints in programs with multiple threads.

set libthread-db-search-path [path]
    If this variable is set, path is a colon-separated list of directories gdb will use to search for libthread_db. If you omit path, `libthread-db-search-path' will be reset to its default value ($sdir:$pdir on gnu/Linux and Solaris systems). Internally, the default value comes from the LIBTHREAD_DB_SEARCH_PATH macro.

    On gnu/Linux and Solaris systems, gdb uses a helper libthread_db library to obtain information about threads in the inferior process. gdb will use `libthread-db-search-path' to find libthread_db. gdb also consults first if inferior specific thread debugging library loading is enabled by `set auto-load libthread-db' (see libthread_db.so.1 file).

    A special entry `$sdir' for `libthread-db-search-path' refers to the default system directories that are normally searched for loading shared libraries. The `$sdir' entry is the only kind not needing to be enabled by `set auto-load libthread-db' (see libthread_db.so.1 file).

    A special entry `$pdir' for `libthread-db-search-path' refers to the directory from which libpthread was loaded in the inferior process.

    For any libthread_db library gdb finds in above directories, gdb attempts to initialize it with the current inferior process. If this initialization fails (which could happen because of a version mismatch between libthread_db and libpthread), gdb will unload libthread_db, and continue with the next directory. If none of libthread_db libraries initialize successfully, gdb will issue a warning and thread debugging will be disabled.

    Setting libthread-db-search-path is currently implemented only on some platforms.


show libthread-db-search-path
    Display current libthread_db search path.


set debug libthread-db
show debug libthread-db
    Turns on or off display of libthread_db-related events. Use 1 to enable, 0 to disable. 

			21.1.6.2 GDB: Stopping and starting multi-thread programs
	http://sources.redhat.com/gdb/current/onlinedocs/gdb/Thread-Stops.html#Thread-Stops

gdb supports debugging programs with multiple threads (see Debugging Programs with Multiple Threads). There are two modes of controlling execution of your program within the debugger. In the default mode, referred to as all-stop mode, when any thread in your program stops (for example, at a breakpoint or while being stepped), all other threads in the program are also stopped by gdb. On some targets, gdb also supports non-stop mode, in which other threads can continue to run freely while you examine the stopped thread in the debugger.

    All-Stop Mode: All threads stop when GDB takes control
    Non-Stop Mode: Other threads continue to execute
    Background Execution: Running your program asynchronously
    Thread-Specific Breakpoints: Controlling breakpoints
    Interrupted System Calls: GDB may interfere with system calls
    Observer Mode: GDB does not alter program behavior 

			21.1.6.3 GDB/MI: Threads commands

			21.1.6.4
    DDD:
        Examining Threads

		21.1.7 Thread Man Pages:

    pthread_atfork - register handlers to be called at fork(2) time
    pthread_attr_destroy [pthread_attr_init] - thread creation attributes
    pthread_attr_getdetachstate [pthread_attr_init] - thread creation attributes
    pthread_attr_getguardsize - get the guardsize attribute in the attr object.
    pthread_attr_getinheritsched [pthread_attr_init] - thread creation attributes
    pthread_attr_getschedparam [pthread_attr_init] - thread creation attributes
    pthread_attr_getschedpolicy [pthread_attr_init] - thread creation attributes
    pthread_attr_getscope [pthread_attr_init] - thread creation attributes
    pthread_attr_getstack - get the thread creation stack attributes stackaddr and stacksize in the attr object.
    pthread_attr_getstackaddr - get the thread creation stackaddr attributes stackaddr attribute in the attr object.
    pthread_attr_getstacksize - get the thread creation stacksize attribute in the attr object.
    pthread_attr_init - thread creation attributes
    pthread_attr_setdetachstate [pthread_attr_init] - thread creation attributes
    pthread_attr_setguardsize - set the guardsize attribute in the attr object.
    pthread_attr_setinheritsched [pthread_attr_init] - thread creation attributes
    pthread_attr_setschedparam [pthread_attr_init] - thread creation attributes
    pthread_attr_setschedpolicy [pthread_attr_init] - thread creation attributes
    pthread_attr_setscope [pthread_attr_init] - thread creation attributes
    pthread_attr_setstack - set the thread creation stack attributes stackaddr and stacksize in the attr object.
    pthread_attr_setstackaddr - set the thread creation stackaddr attributes stackaddr attribute in the attr object.
    pthread_attr_setstacksize - set the thread creation stacksize attribute in the attr object.
    pthread_cancel - thread cancellation
    pthread_cleanup_pop [pthread_cleanup_push] - install and remove cleanup handlers
    pthread_cleanup_pop_restore_np [pthread_cleanup_push] - install and remove cleanup handlers
    pthread_cleanup_push - install and remove cleanup handlers
    pthread_cleanup_push_defer_np [pthread_cleanup_push] - install and remove cleanup handlers
    pthread_condattr_destroy [pthread_condattr_init] - condition creation attributes
    pthread_condattr_init - condition creation attributes
    pthread_cond_broadcast [pthread_cond_init] - operations on conditions
    pthread_cond_destroy [pthread_cond_init] - operations on conditions
    pthread_cond_init - operations on conditions
    pthread_cond_signal [pthread_cond_init] - operations on conditions
    pthread_cond_timedwait [pthread_cond_init] - operations on conditions
    pthread_cond_wait [pthread_cond_init] - operations on conditions
    pthread_create - create a new thread
    pthread_detach - put a running thread in the detached state
    pthread_equal - compare two thread identifiers
    pthread_exit - terminate the calling thread
    pthread_getschedparam [pthread_setschedparam] - control thread scheduling parameters
    pthread_getspecific [pthread_key_create] - management of thread-specific data
    pthread_join - wait for termination of another thread
    pthread_key_create - management of thread-specific data
    pthread_key_delete [pthread_key_create] - management of thread-specific data
    pthread_kill_other_threads_np - terminate all threads in program except calling thread
    pthread_kill [pthread_sigmask] - handling of signals in threads
    pthread_mutexattr_destroy [pthread_mutexattr_init] - mutex creation attributes
    pthread_mutexattr_getkind_np [pthread_mutexattr_init] - mutex creation attributes
    pthread_mutexattr_init - mutex creation attributes
    pthread_mutexattr_setkind_np [pthread_mutexattr_init] - mutex creation attributes
    pthread_mutex_destroy [pthread_mutex_init] - operations on mutexes
    pthread_mutex_init - operations on mutexes
    pthread_mutex_lock [pthread_mutex_init] - operations on mutexes
    pthread_mutex_trylock [pthread_mutex_init] - operations on mutexes
    pthread_mutex_unlock [pthread_mutex_init] - operations on mutexes
    pthread_once - once-only initialization
    pthread_self - return identifier of current thread
    pthread_setcancelstate [pthread_cancel] - thread cancellation
    pthread_setcanceltype [pthread_cancel] - thread cancellation
    pthread_setschedparam - control thread scheduling parameters
    pthread_setspecific [pthread_key_create] - management of thread-specific data
    pthread_sigmask - handling of signals in threads
    pthread_testcancel [pthread_cancel] - thread cancellation

Links:

    Fundamentals Of Multithreading - Paul Mazzucco
    Native Posix Thread Library for Linux
    Posix threads for MS/Win32: [Announcement / description] sourceforge home page
    Introduction to Programming Threads
    Getting Started With POSIX Threads
    ITS: Introduction to Threads
    GNU Portable Threads
    Introduction of threads for Solaris, Linux, and Windows
    Comparison of thread implementations
    comp.programming.threads FAQ
    An in-depth description of PMPthread internal queue functions.
    Examples
    Pthreads tutorial and examples of thread problems - by Andrae Muys
    Valgrind KDE thread checker: Helgrind
    Sun's Multithreaded Programming Guide - Not Linux but a good reference.
    Linux-mag.com: Concurrent Programming Topics - semaphores, condition variables
    Linux-mag.com: The Fibers of Threads - Discussion of how Linux threads work
    Platform independent threads:
        Gnome GLib 2.0 threads - Thread abstraction; including mutexes, conditions and thread private data. [example]
        OmniORB (CORBA) Thread Library
        zThreads
    C++ Thread classes:
        GNU: Common C++ - support for threading, sockets, file access, daemons, persistence, serial I/O, XML parsing and system services
        ACE: Adaptive Communication Environment - C++ interface
            ACE programmers guide: [pdf] (see page 29 for threads)
            Thread management examples using ACE
        Hood - A C++ Threads Library for Multiprogrammed Multiprocessors
        C++ Thread classes - sourceforge
        QpThread

News Groups:

    comp.programming.threads
    comp.unix.solaris

Books:

    	Pthreads Programming A POSIX Standard for Better Multiprocessing
    By Bradford Nichols, Dick Buttlar, Jacqueline Proulx Farrell
    ISBN #1-56592-115-1, O'Reilly

    	Amazon.com
    	Programming with POSIX(R) Threads
    By David R. Butenhof
    ISBN #0201633922, Addison Wesley Pub. Co.

    	Amazon.com
    	C++ Network Programming Volume 1
    By Douglas C. Schmidt, Stephen D. Huston
    ISBN #0201604647, Addison Wesley Pub. Co.

    Covers ACE (ADAPTIVE Communication Environment) open-source framework view of threads and other topics.

    	Amazon.com

	
   

	21.2 posix thread join thread timeout
- Objective: run a thread but wait maximum of X seconds for it to complete

		21.2.1 http://man7.org/linux/man-pages/man3/pthread_tryjoin_np.3.html

       pthread_tryjoin_np,  pthread_timedjoin_np - try to join with a termi‐
       nated thread
SYNOPSIS         top

       #define _GNU_SOURCE             /* See feature_test_macros(7) */
       #include <pthread.h>

       int pthread_tryjoin_np(pthread_t thread, void **retval);

       int pthread_timedjoin_np(pthread_t thread, void **retval,
                                const struct timespec *abstime);

       Compile and link with -pthread.
DESCRIPTION         top

       These functions operate in the same way as pthread_join(3), except
       for the differences described on this page.

       The pthread_tryjoin_np() function performs a nonblocking join with
       the thread thread, returning the exit status of the thread in
       *retval.  If thread has not yet terminated, then instead of blocking,
       as is done by pthread_join(3), the call returns an error.

       The pthread_timedjoin_np() function performs a join-with-timeout.  If
       thread has not yet terminated, then the call blocks until a maximum
       time, specified in abstime.  If the timeout expires before thread
       terminates, the call returns an error.  The abstime argument is a
       structure of the following form, specifying an absolute time measured
       since the Epoch (see time(2)):

           struct timespec {
               time_t tv_sec;     /* seconds */
               long   tv_nsec;    /* nanoseconds */
           };
RETURN VALUE         top

       On success, these functions return 0; on error, they return an error
       number.
ERRORS         top

       These functions can fail with the same errors as pthread_join(3).
       pthread_tryjoin_np() can in addition fail with the following error:

       EBUSY  thread had not yet terminated at the time of the call.

       pthread_timedjoin_np() can in addition fail with the following error:

       ETIMEDOUT
              The call timed out before thread terminated.

       pthread_timedjoin_np() never returns the error EINTR.
VERSIONS         top

       These functions first appeared in glibc in version 2.3.3.
CONFORMING TO         top

       These functions are nonstandard GNU extensions; hence the suffix
       "_np" (nonportable) in the names.
EXAMPLE         top

       The following code waits to join for up to 5 seconds:

           struct timespec ts;
           int s;

           ...

           if (clock_gettime(CLOCK_REALTIME, &ts) == -1) {
            /* Handle error */
           }

           ts.tv_sec += 5;

           s = pthread_timedjoin_np(thread, NULL, &ts);
           if (s != 0) {
               /* Handle error */
           }
SEE ALSO         top

       clock_gettime(2), pthread_exit(3), pthread_join(3), pthreads(7)
		21.2.2
-
	21.3 pthread idioms & FAQ


		21.3.1  Pass member function to thread execution 

			21.3.1.1  Pass member function to thread execution 

				21.3.1.1.1  http://stackoverflow.com/questions/1151582/pthread-function-from-a-class
You can't do it the way you've written it because C++ class member functions have a hidden this parameter passed in.  pthread_create() has no idea what value of this to use, so if you try to get around the compiler by casting the method to a function pointer of the appropriate type, you'll get a segmetnation fault. You have to use a static class method (which has no this parameter), or a plain ordinary function to bootstrap the class:

class C
{
public:
    void *hello(void)
    {
        std::cout << "Hello, world!" << std::endl;
        return 0;
    }

    static void *hello_helper(void *context)
    {
        return ((C *)context)->hello();
    }
};
...
C c;
pthread_t t;
pthread_create(&t, NULL, &C::hello_helper, &c);

				21.3.1.1.2

			21.3.1.2

		21.3.2 Read-Write lock, pthread_rwlock_t   

			21.3.2.1 API


Read/Write Locks in PThreads
Defining a read/write lock variable in Pthreads:
 
   pthread_rwlock_t   x;         
Initializing a read/write lock variable:
After defining the read/write lock variable, you must initialized it using the following function:

 
 int pthread_rwlock_init(pthread_rwlock_t     *rwlock,
			 pthread_rwlockattr_t *attr    );      
rwlock: is the read/write lock that you want to initialize (pass the address !)
attr: is the set of initial property of the read/write lock.
The most common read/write lock is one where the lock is initially in the unlock.

This kind of mutex lock is created using the (default) attribute null:

Example: a read/write lock with an initial unlock state

   pthread_rwlock_init(&x, NULL);  /* Default initialization */    
Read lock a read/write lock:
 
   int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
Example:
   pthread_rwlock_t   x;

   pthread_rwlock_init(&x, NULL);
   ...
   pthread_rwlock_rdlock(&x);         //lock for read, block if locked for write on other thread

NOTE: if a thread already hold a write lock on a read/write lock, and performs a pthread_rwlock_rdlock() on that lock, then the outcome if undefined (in order words: do NOT try !)
NOTE: A thread may hold multiple concurrent read locks on a read/write lock (that is, successfully call the pthread_rwlock_rdlock() function n times). If so, the thread must perform matching unlocks (that is, it must call the pthread_rwlock_unlock() function n times).
Write lock a read/write lock:
 
   int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
Example:
   pthread_rwlock_t   x;

   pthread_rwlock_init(&x, NULL);
   ...
   pthread_rwlock_wrlock(&x);        //lock for write, block if locked for read or write on other thread

			21.3.2.2 Simple Example

#define _MULTI_THREADED
#include <pthread.h>
#include <stdio.h>
#include "check.h"

pthread_rwlock_t       rwlock;

void *rdlockThread(void *arg)
{
  int rc;

  printf("Entered thread, getting read lock\n");
  rc = pthread_rwlock_rdlock(&rwlock);
  checkResults("pthread_rwlock_rdlock()\n", rc);
  printf("got the rwlock read lock\n");

  sleep(5);

  printf("unlock the read lock\n");
  rc = pthread_rwlock_unlock(&rwlock);
  checkResults("pthread_rwlock_unlock()\n", rc);
  printf("Secondary thread unlocked\n");
  return NULL;
}

void *wrlockThread(void *arg)
{
  int rc;

  printf("Entered thread, getting write lock\n");
  rc = pthread_rwlock_wrlock(&rwlock);
  checkResults("pthread_rwlock_wrlock()\n", rc);

  printf("Got the rwlock write lock, now unlock\n");
  rc = pthread_rwlock_unlock(&rwlock);
  checkResults("pthread_rwlock_unlock()\n", rc);
  printf("Secondary thread unlocked\n");
  return NULL;
}

int main(int argc, char **argv)
{
  int                   rc=0;
  pthread_t             thread, thread1;

  printf("Enter Testcase - %s\n", argv[0]);

  printf("Main, initialize the read write lock\n");
  rc = pthread_rwlock_init(&rwlock, NULL);
  checkResults("pthread_rwlock_init()\n", rc);

  printf("Main, grab a read lock\n");
  rc = pthread_rwlock_rdlock(&rwlock);
  checkResults("pthread_rwlock_rdlock()\n",rc);

  printf("Main, grab the same read lock again\n");
  rc = pthread_rwlock_rdlock(&rwlock);
  checkResults("pthread_rwlock_rdlock() second\n", rc);

  printf("Main, create the read lock thread\n");
  rc = pthread_create(&thread, NULL, rdlockThread, NULL);
  checkResults("pthread_create\n", rc);

  printf("Main - unlock the first read lock\n");
  rc = pthread_rwlock_unlock(&rwlock);
  checkResults("pthread_rwlock_unlock()\n", rc);

  printf("Main, create the write lock thread\n");
  rc = pthread_create(&thread1, NULL, wrlockThread, NULL);
  checkResults("pthread_create\n", rc);

  sleep(5);
  printf("Main - unlock the second read lock\n");
  rc = pthread_rwlock_unlock(&rwlock);
  checkResults("pthread_rwlock_unlock()\n", rc);

  printf("Main, wait for the threads\n");
  rc = pthread_join(thread, NULL);
  checkResults("pthread_join\n", rc);

  rc = pthread_join(thread1, NULL);
  checkResults("pthread_join\n", rc);

  rc = pthread_rwlock_destroy(&rwlock);
  checkResults("pthread_rwlock_destroy()\n", rc);

  printf("Main completed\n");
  return 0;
}
Output:

Enter Testcase - QP0WTEST/TPRWLINI0
Main, initialize the read write lock
Main, grab a read lock
Main, grab the same read lock again
Main, create the read lock thread
Main - unlock the first read lock
Main, create the write lock thread
Entered thread, getting read lock
got the rwlock read lock
Entered thread, getting write lock
Main - unlock the second read lock
Main, wait for the threads
unlock the read lock
Secondary thread unlocked
Got the rwlock write lock, now unlock
Secondary thread unlocked
Main completed

			21.3.2.3 Another example, using class ctor/dtor for auto lock/unlock in function scope

cisco/build/stage/opt/pbis/include/lwrwlockguard.h
/*
 * lwrwlockguard.h
 *
 *  Created on: Feb 16, 2014
 *      Author: ashabano
 */

#ifndef LWRWLOCK_H_
#define LWRWLOCK_H_

#include <pthread.h>

class RwLockGuard
{
public:
    RwLockGuard(pthread_rwlock_t& lock, bool writer);
    ~RwLockGuard();

private:
    pthread_rwlock_t& m_lock;
    bool m_writer;
};

#endif /* LWRWLOCK_H_ */

lwadvapi/threaded/lwrwlockguard.cpp

/*
 * lwrwlockguard.cpp
 *
 *  Created on: Feb 16, 2014
 *      Author: ashabano
 */


#include "lwrwlockguard.h"

RwLockGuard::RwLockGuard(pthread_rwlock_t& lock, bool writer) :
    m_lock(lock),
    m_writer(writer)
{
    if (m_writer)
        pthread_rwlock_wrlock(&m_lock);
    else
        pthread_rwlock_rdlock(&m_lock);
}

RwLockGuard::~RwLockGuard()
{
    pthread_rwlock_unlock(&m_lock);
}

			21.3.2.4
		21.3.3


	21.4


23. Advanced Interview questions

	23.1 Advanced C++ and STL interview questions 
Q: How do you link a C++ program to C functions?

A: By using the extern "C" linkage specification around the C function declarations.

Q: Explain the scope resolution operator.

A: It permits a program to reference an identifier in the global scope that has been hidden by another identifier with the same name in the local scope.

Q: What are the differences between a C++ struct and C++ class?

A: The default member and base-class access specifiers are different.

Q: How many ways are there to initialize an int with a constant?

A: Two.

There are two formats for initializers in C++ as shown in the example that follows. The first format uses the traditional C notation. The second format uses constructor notation.

int foo = 123;

int bar (123);

Q: How does throwing and catching exceptions differ from using setjmp and longjmp?

A: The throw operation calls the destructors for automatic objects instantiated since entry to the try block.

Q: What is your reaction to this line of code?

delete this;

A: It’s not a good practice.

Q: What is a default constructor?

A: A constructor that has no arguments.

Q: What is a conversion constructor?

A: A constructor that accepts one argument of a different type.

Q: What is the difference between a copy constructor and an overloaded assignment operator?

A: A copy constructor constructs a new object by using the content of the argument object. An overloaded assignment operator assigns the contents of an existing object to another existing object of the same class.

Q: When should you use multiple inheritance?

A: There are three acceptable answers: "Never," "Rarely," and "When the problem domain cannot be accurately modeled any other way."

Q: What is a virtual destructor?

A: The simple answer is that a virtual destructor is one that is declared with the virtual attribute.

Q: Explain the ISA and HASA class relationships. How would you implement each in a class design?

A: A specialized class "is" a specialization of another class and, therefore, has the ISA relationship with the other class. An Employee ISA Person. This relationship is best implemented with inheritance. Employee is derived from Person. A class may have an instance of another class. For example, an employee "has" a salary, therefore the Employee class has the HASA relationship with the Salary class. This relationship is best implemented by embedding an object of the Salary class in the Employee class.

Q: When is a template a better solution than a base class?

A: When you are designing a generic class to contain or otherwise manage objects of other types, when the format and behavior of those other types are unimportant to their containment or management, and particularly when those other types are unknown (thus, the genericity) to the designer of the container or manager class.

Q: What is a mutable member?

A: One that can be modified by the class even when the object of the class or the member function doing the modification is const.

Q: What is an explicit constructor?

A: A conversion constructor declared with the explicit keyword. The compiler does not use an explicit constructor to implement an implied conversion of types. It’s purpose is reserved explicitly for construction.

Q: What is the Standard Template Library?

A: A library of container templates approved by the ANSI committee for inclusion in the standard C++ specification.

A programmer who then launches into a discussion of the generic programming model, iterators, allocators, algorithms, and such, has a higher than average understanding of the new technology that STL brings to C++ programming.

Q: Describe run-time type identification.

A: The ability to determine at run time the type of an object by using the typeid operator or the dynamic_cast operator.

Q: What problem does the namespace feature solve?

A: Multiple providers of libraries might use common global identifiers causing a name collision when an application tries to link with two or more such libraries. The namespace feature surrounds a library’s external declarations with a unique namespace that eliminates the potential for those collisions.

This solution assumes that two library vendors don’t use the same namespace identifier, of course.

Q: Are there any new intrinsic (built-in) data types?

A: Yes. The ANSI committee added the bool intrinsic type and its true and false value keywords. 

	23.2 http://www.devbistro.com/tech-interview-questions/Cplusplus.jsp
Q: Write a short code using C++ to print out all odd number from 1 to 100 using a for loop(Asked by Intacct.com people)

for( unsigned int i = 1; i < = 100; i++ )
    if( i & 0x00000001 )
        cout << i<<\",\";
ISO layers and what layer is the IP operated from?( Asked by Cisco system people)

Application, Presentation, Session, Transport, Network, Data link and Physical. The IP is operated in the Network layer.

Q: Write a program that ask for user input from 5 to 9 then calculate the average( Asked by Cisco system people)

A.int main()
{
int MAX=4; 
int total =0; 
int average=0; 
int numb;
cout<<"Please enter your input from 5 to 9";
cin>>numb; 
if((numb <5)&&(numb>9)) 
cout<<"please re type your input"; 
else 
for(i=0;i<=MAX; i++)
{
total = total + numb; 
average= total /MAX;
} 
cout<<"The average number is"<<average<<endl;

return 0; 
}

Q: Can you be able to identify between Straight- through and Cross- over cable wiring? and in what case do you use Straight- through and Cross-over? (Asked by Cisco system people)

A. Straight-through is type of wiring that is one to to one connection Cross- over is type of wiring which those wires are got switched

We use Straight-through cable when we connect between NIC Adapter and Hub. Using Cross-over cable when connect between two NIC Adapters or sometime between two hubs.

Q: If you hear the CPU fan is running and the monitor power is still on, but you did not see any thing show up in the monitor screen. What would you do to find out what is going wrong? (Asked by WNI people)

A. I would use the ping command to check whether the machine is still alive(connect to the network) or it is dead.



 How do you write a function that can reverse a linked-list? (Cisco System)

void reverselist(void)
{
	if(head==0)
		return;
	if(head->next==0)
		return;
	if(head->next==tail)
	{
		head->next = 0;
		tail->next = head;
	}
	else
	{
		node* pre = head;
		node* cur = head->next;
		node* curnext = cur->next;
		head->next = 0;
		cur->next = head;
		for(; curnext!=0; )
		{
			cur->next = pre;
			pre = cur;
			cur = curnext;
			curnext = curnext->next;
		}
		curnext->next = cur;
	}
}
What is polymorphism?

Polymorphism is the idea that a base class can be inherited by several classes. A base class pointer can point to its child class and a base class array can store different child class objects.

How do you find out if a linked-list has an end? (i.e. the list is not a cycle)

You can find out by using 2 pointers. One of them goes 2 nodes each time. The second one goes at 1 nodes each time. If there is a cycle, the one that goes 2 nodes each time will eventually meet the one that goes slower. If that is the case, then you will know the linked-list is a cycle.

How can you tell what shell you are running on UNIX system?

You can do the Echo $RANDOM. It will return a undefined variable if you are from the C-Shell, just a return prompt if you are from the Bourne shell, and a 5 digit random numbers if you are from the Korn shell. You could also do a ps -l and look for the shell with the highest PID.

What is Boyce Codd Normal form?

A relation schema R is in BCNF with respect to a set F of functional dependencies if for all functional dependencies in F+ of the form a->b, where a and b is a subset of R, at least one of the following holds:

a->b is a trivial functional dependency (b is a subset of a)
a is a superkey for schema R


Q1: Tell how to check whether a linked list is circular.

A: Create two pointers, each set to the start of the list. Update each as follows:

while (pointer1) {
 pointer1 = pointer1->next;
 pointer2 = pointer2->next; if (pointer2) pointer2=pointer2->next;
 if (pointer1 == pointer2) {
   print (\"circular\n\");
 }
}
Q2: OK, why does this work?
If a list is circular, at some point pointer2 will wrap around and be either at the item just before pointer1, or the item before that. Either way, it’s either 1 or 2 jumps until they meet.

How can you quickly find the number of elements stored in a a) static array b) dynamic array ?

Why is it difficult to store linked list in an array?

How can you find the nodes with repetetive data in a linked list?

Write a prog to accept a given string in any order and flash error if any of the character is different. For example : If abc is the input then abc, bca, cba, cab bac are acceptable but aac or bcd are unacceptable.

This is a C question that I had for an intern position at Microsoft: Write out a function that prints out all the permutations of a string. For example, abc would give you abc, acb, bac, bca, cab, cba. You can assume that all the characters will be unique. After I wrote out my function, he asked me to figure out from the code how many times the printf statement is run, and also questions on optimizing my algorithm.

What’s the output of the following program? Why?

#include <stdio.h>
main()
{
	typedef union
	{
		int a;
		char b[10];
		float c;
	}
	Union;
	
	Union x,y = {100};
	x.a = 50;
	strcpy(x.b,\"hello\");
	x.c = 21.50;
	
	printf(\"Union x : %d %s %f \n\",x.a,x.b,x.c );
	printf(\"Union y :%d %s%f \n\",y.a,y.b,y.c);
}
Given inputs X, Y, Z and operations | and & (meaning bitwise OR and AND, respectively)

What is output equal to in
output = (X & Y) | (X & Z) | (Y & Z)

^Back to Top
++ gamedev interview questions

This set of questions came from a prominent gaming company. As you can see, the answers are not given (the interviews are typically conducted by senior developers), but there’s a set of notes with common mistakes to avoid.

Explain which of the following declarations will compile and what will be constant - a pointer or the value pointed at:
const char *
char const *
char * const
Note: Ask the candidate whether the first declaration is pointing to a string or a single character. Both explanations are correct, but if he says that it’s a single character pointer, ask why a whole string is initialized as char* in C++. If he says this is a string declaration, ask him to declare a pointer to a single character. Competent candidates should not have problems pointing out why const char* can be both a character and a string declaration, incompetent ones will come up with invalid reasons.
You’re given a simple code for the class BankCustomer. Write the following functions:
Copy constructor
= operator overload
== operator overload
+ operator overload (customers’ balances should be added up, as an example of joint account between husband and wife)
Note:Anyone confusing assignment and equality operators should be dismissed from the interview. The applicant might make a mistake of passing by value, not by reference. The candidate might also want to return a pointer, not a new object, from the addition operator. Slightly hint that you’d like the value to be changed outside the function, too, in the first case. Ask him whether the statement customer3 = customer1 + customer2 would work in the second case.

What problems might the following macro bring to the application?
#define sq(x) x*x

Consider the following struct declarations:
struct A { A(){ cout << \"A\"; } };
struct B { B(){ cout << \"B\"; } };
struct C { C(){ cout << \"C\"; } };
struct D { D(){ cout << \"D\"; } };
struct E : D { E(){ cout << \"E\"; } };
struct F : A, B
{
	C c;
	D d;
	E e;
	F() : B(), A(),d(),c(),e() { cout << \"F\"; }
};
What constructors will be called when an instance of F is initialized? Produce the program output when this happens.

Anything wrong with this code?
T *p = new T[10];
delete p;
	
Note: Incorrect replies: “No, everything is correct”, “Only the first element of the array will be deleted”, “The entire array will be deleted, but only the first element destructor will be called”.

Anything wrong with this code?
T *p = 0;
delete p;
Note: Typical wrong answer: Yes, the program will crash in an attempt to delete a null pointer. The candidate does not understand pointers. A very smart candidate will ask whether delete is overloaded for the class T.

Explain virtual inheritance. Draw the diagram explaining the initialization of the base class when virtual inheritance is used.
Note: Typical mistake for applicant is to draw an inheritance diagram, where a single base class is inherited with virtual methods. Explain to the candidate that this is not virtual inheritance. Ask them for the classic definition of virtual inheritance. Such question might be too complex for a beginning or even intermediate developer, but any applicant with advanced C++ experience should be somewhat familiar with the concept, even though he’ll probably say he’d avoid using it in a real project. Moreover, even the experienced developers, who know about virtual inheritance, cannot coherently explain the initialization process. If you find a candidate that knows both the concept and the initialization process well, he’s hired.
What’s potentially wrong with the following code?

long value;
//some stuff
value &= 0xFFFF;
Note: Hint to the candidate about the base platform they’re developing for. If the person still doesn’t find anything wrong with the code, they are not experienced with C++.

What does the following code do and why would anyone write something like that?
void send (int *to, int * from, int count)
{
	int n = (count + 7) / 8;
	switch ( count  %  8)
	{
		case 0: do { *to++ = *from++;
		case 7: *to++ = *from++;
		case 6: *to++ = *from++;
		case 5: *to++ = *from++;
		case 4: *to++ = *from++;
		case 3: *to++ = *from++;
		case 2: *to++ = *from++;
		case 1: *to++ = *from++;
		} while ( --n > 0 );
	}
}
In the H file you see the following declaration:
class Foo {
void Bar( void ) const ;
};
Tell me all you know about the Bar() function.

	23.3 http://www.decompile.com/interview/C%2B%2B_Interview_Questions_Page_02.htm
C++ Language-specific Questions
by Curtis Krauskopf
Language-specific questions typically test your ability to understand why a certain rule exists in the language rather than simply knowing that a rule exists.


Programmers who recently learned C++ using a book such as Teach Yourself C++ in 24 Hours will have difficulty knowing the nuances of the C++ language.

Interviewers are interested in testing candidates for a depth of knowledge in the topic. The interviewer will also expect you to know these topics off the top-of-your-head because these basic facts should form the foundation of your C++ knowledge.

An array is instantiated with the new[] operator. Is it sufficient to delete the array using a delete operator or should a delete[] operator be used? Justify your answer.

Can I drop the [] when deleting an array of some built-in type (char, int, etc)?

What is an example of when a destructor is NOT called at the end of scope?

Explain stack unwinding.

When I write a derived class's destructor, do I need to explicitly call the destructor for my base class?

Explain the difference between a class and an object.

Explain the difference between a struct and a class.

What is difference between malloc/free and new/delete?

	
C++ Language Definition and Acronym Questions
by Curtis Krauskopf
Provide the definitions of each of these words or phrases. For the words that are C++ keywords, describe all of the ways that the keyword could be used.

What is polymorphism?
What is a virtual keyword used for?
What is the mutable keyword used for?
What is the explicit keyword used for?
What is template metaprogramming?
What do the public, private and protected keywords mean? 
What is the static keyword used for?
What is an assignment operator?
What is a dangling pointer?
What is a functor?
Acronyms
There are many common acronyms in the C++ programming language. What is the definition of each of these acronyms?
STL
RAII
VCL (this acronym only applies to developers who are interviewing for a position that will use a Borland C++ compiler) 
Why is C++ called C++?
If you saw a WChar type in a program you didn't write, what would it typically represent?

Efficient C++ Programming
by Curtis Krauskopf
Certain aspects of the C++ language were designed to perform more efficiently than other parts. Knowing which parts are designed to improve speed, reduce storage or improve programming productivity demonstrates your ability to use those techniques in your daily programming.

What executes faster: ++i or i++, where i is an integer variable? 
Which is generally more efficient: a function that returns a value by reference or a function that returns a value without using a reference? 
Describe inline functions and their limitations? 
Why use the STL sort() when we have "good old qsort()"? 
One programmer wants to sort a linked list using recursion; another programmer wants to do it without recursion. Which one has the better answer? 
When is an interface "good"?

Practical C++ Programming
by Curtis Krauskopf
The practical programming questions are the core of most C++ programming interviews. These questions test your knowledge of the C++ language and its features. The purpose of these questions is to eliminate the candidates that have not programmed in C++ recently or who recently learned C++ through a crash-course book.

What language feature is available when a function returns a reference? 
What is name mangling in C++? 
What is overriding? 
Can you assign to a reference? 
What happens if you assign to a reference? 
What is a static_cast and when should it be used? 
What are the names of the other cast operators? 
How do you trap an exception without knowing what exception might be thrown? 
Describe how you design a program. 
Most programming projects involve modifying existing code. What things do you look for when you're tasked with modifying an existing program? 
There is a memory leak in a program. What tools and techniques would you use to isolate, find and fix the memory leak? 
What's the difference between a linked list and an array? 
What is the difference between a vector, a list and a map? 
What is a namespace?
What is an anonymous namespace and how is it different than a regular namespace?

C++ Buzz Phrases
by Curtis Krauskopf
C++ has many buzz phrases. Some of them have arisen from the academic community; others were spawned by trade journals, books and common knowledge. Describe the definitions and concepts expressed in each of these buzz phrases:

Demeter's Law 
Liskov Substitution Principle 
Dependency Inversion 
Visitor Pattern 
Gang of Four 
Bridge Pattern

C++ Problem Solving
by Curtis Krauskopf
Computer programs are designed to solve problems. These programs test your ability to solve problems. The programs are small enough that they can be done on paper with the interviewer.

Find the number of bits in an unsigned integer data type without using the sizeof() function. 
Multiply an integer by 8 without using multiplication or addition. 
Write a function that adds two signed integers and checks for overflow. When an overflow is detected, cause an appropriate exception to be thrown. 
Write a program that counts the number of 'x' characters in an input stream. Assume the stream is binary. 
Write a program that detects if a text file is in Windows format (CR followed by LF) or in Unix/Linux format (CR) or in Mac format (LF). For this problem, it's okay to assume that all lines in the text file terminate the same way.









	
Software Engineering Communication
by Curtis Krauskopf
Communication is an important part of being able to interact with other professionals and with your non-technical coworkers. How well can you communicate about the following issues?

What was your biggest development screw-up? What insight did you learn from that? 
Explain the internet to a young child. 
Explain a database to your grandparents. 
Explain how you learn a new computer language. 
What C++-related magazines or websites do you read on a regular basis? 
Have you ever worked on an open-source project? If you have worked on one, what were the most difficult issues? If you were to work on one, what would you foresee as being some of the difficult issues? 
What are the three most recent computer languages you've learned and why did you learn them?





	
Job Interview Brain Teasers
by Curtis Krauskopf
Riddles seem to be popular amongst some interviewers. The purpose of the riddle is not necessarily to get the right answer -- rather, it's to see how the candidate reacts when faced with a non-standard programming question. Demonstrate your flexibility on-the-job by being able to answer these questions.

The Three Jugs Problem
Two friends who have an eight-quart jug of water wish to share it evenly. They also have two empty jars, one holding five quarts, the other three. How can they each measure exactly 4 quarts of water?

Geometry in real-life
Why is a manhole cover round?

We'll cross that bridge when we get to it
There are 4 women who want to cross a bridge. They all begin on the same side. You have 17 minutes to get all of them across to the other side. It is night. There is one flashlight. A maximum of two people can cross at one time. Any party who crosses, either 1 or 2 people, must have the flashlight with them. The flashlight must be walked back and forth, it cannot be thrown, etc. Each woman walks at a different speed. A pair must walk together at the rate of the slower woman's pace.

Woman 1: 1 minute to cross
Woman 2: 2 minutes to cross
Woman 3: 5 minutes to cross
Woman 4: 10 minutes to cross
For example if Woman 1 and Woman 4 walk across first, 10 minutes have elapsed when they get to the other side of the bridge. If Woman 4 then returns with the flashlight, a total of 20 minutes have passed and you have failed the mission. What is the order required to get all women across in 17 minutes? Now, what's the other way?




	
Job Interview: What's Wrong With this Code?
by Curtis Krauskopf
Good programming problems test more than just the language's syntax. Many programmers are also drawn toward interesting programming puzzles.

Gimpel Software creatively markets their C/C++ Lint tool (called PC-Lint) by publishing a new "Bug of the Month" in every issue of C/C++ User's Journal and Dr. Dobbs Journal. For example, "Bug of the Month" number 750 was published in January of 2006:

The New Year's celebration was marred by the lack of ice for the drinks. The compiler made no complaint. Can you discover the problem?

1    #include <stdio.h>
2
3    #define ON_THE_ROCKS
4
5    const char *ice()
	6    {
		7    #if defined(Shaken)
			8        return "shaken not stirred";
		9    #elif defined(Stirred)
			10       return "stirred not shaken";
		11   #elif defined(ON_THE_R0CKS)
			12       return "on the rocks";
		13   #else
			14       return "";
		15   #endif
			16   }
			17
			18   int main()
	19   {
		20       printf( "Celebrate the New Year " );
		21       printf( "with your drink %s.\n", ice() );
		22       return 0;
		23   }
				
			Output:
			Celebrate the New Year with your drink .


					
			Here are two other programming snippets to puzzle over. Neither one of these was a Gimpel.com "Bug of the Month", but they are typical of the types of programming problems given during C++ job interviews.

#1) What is wrong with this code?


			enum ResponseType { ReturnValues, InvalidInput };

string CreateWebText(string userInput, ResponseType operation) {
	   switch (operation) {
		         case ResponseType.ReturnValues:
				          userInput = "<h1>Values</h1>" + FilterOutBadStuff(userInput);
					           break;
						         case ResponseType.InvalidInput:
						            userInput = "<h1>Invalid</h1>" + FilterOutBadStuff(userInput);
							             break;
								        }
	      return userInput;
}
#2) What is wrong with this code?


struct Fred {
	  Fred(int n): v(n) {}
	    std::vector<int> v;
};

int main() {
	  using namespace std;
	    Fred f(1);
	      f.v[0] = 5;
	        cout << f.v[0] << endl;
		  f = 7;          // is this legal?
		    cout << f.v[0]; // what is output here?
}







	
Showing Skills with Short Programs on a Job Interview
by Curtis Krauskopf
Each of these programming problems should be conducted at a workstation. After thinking about the question for a reasonable timeframe, you should be able to answer the question, "How long will it take you to write this program?". Then prove yourself correct by writing and debugging program within the timeframe you've allotted for yourself.

An array that is instantiated with the new[] operator should also be deleted using the delete[] operator. Write a program that proves that the destructors for an array are not called when the array was instantiated with new [] and the array was deleted with delete (without the delete[] syntax). 
Write a String class that compares its strings by ignoring the case of the characters. 
A comma-delimited file has two columns: timeA and timeB. Both columns are times in the following format: hh:mm [a|p]m

where:
    hh is from 1 to 12.
    mm is from 1 to 60.
    [a|p] is either an 'a' or 'p'.

Example file:
5:57 pm,10:37 am
Write a program that reads the comma-delimited text file. For each line in the text file, report the time that is earlier. Assume all times are in the same time zone and that all times are for the same day.

Sort a linked list using recursion. 
Sort a linked list without using recursion. 
Reverse a single-linked list without using recursion.






	
Language Lawyer in a C++ Job Interview
by Curtis Krauskopf
Language Lawyer questions involve C++ language issues that are typically not seen in day-to-day programming projects. The questions might probe dark corners of the language definition or areas that are supported differently between different popular compilers.

Show an example of a valid C program that fails to compile in C++. 
Show an example of a valid C program that compiles cleanly in C++ but gives a different result. 
Why won't this compile?
for (int i = 0; i < 10; i++) {
  for (int k = 0; k < 10; k++) {
    if (e == 0) goto next_i;
  }
  next_i;
} 

A placement new exists in the C++ language. Is there a "placement delete"?






	
Unfair C++ Job Interview Questions
by Curtis Krauskopf
These questions are beyond the bounds of normal interview questions. I don't know if these questions have actually been asked in a real interview but somebody might think it's a cute question and ask. Being prepared for these out-of-bounds questions will prepare you for other difficult questions. When answering those questions, remember to use the same techniques that you use when practicing these questions.

The interviewer looks up from his newspaper, tosses a pencil at you and says, "Sell me this pencil". The interviewer immediately returns to reading his newspaper. 
The interviewer hands you a black pen and says nothing but "This pen is red." 
Write a program whose output is its own source code. 
Tell me the funniest programming joke you've ever heard.




---------------------------------------------------------------------------------------------------- 
Answers

	
C++ Language-specific Answers
by Curtis Krauskopf
One strategy to use when answering a language issue question is to examine the question from various perspectives. Some perspectives to consider are:

the language author wants to prevent ambiguities
the C++ compiler vendor want to simplify the compiler's implementation
the code writer wants clear rules for implementing a feature
the maintenance programmer needs to understand existing code
legacy code should not be broken by new features
The best answer is one that acknowledges the tradeoffs that were made to accommodate one or more of the above groups. When reviewing your video or audio tape, give yourself extra credit for each group that you mention and their tradeoffs.

Q1) An array is instantiated with the new[] operator. Is it sufficient to delete the array using a delete operator or should a delete[] operator be used? Justify your answer.

A1) The delete[] operator should always be used. This restriction applies for both built-in types (char, int and others) and for aggregate types (structs and classes). This is required by the C++ language definition (the Annotated C++ Reference Manual).

Q2) Can I drop the [] when deleting an array of some built-in type (char, int, etc)?

A2) No. Marshall Cline's C++ FAQ Lite contains a good explanation at parashift.com.

Q3) What is an example of when a destructor is NOT called at the end of scope?

A3) Bjarne Stroustrup's C++ Style and Technique FAQ provides an excellent explanation at att.com. The short answer is that objects that are created on the heap are not automatically destroyed at the end of the scope that created the object.

In addition to Bjarne Stroustrup's answer, I would also add that statically created objects are also not destroyed at the end of the scope.

Q4) Explain stack unwinding.

A4) Stack unwinding occurs when an exception is thrown and control passes from a try block to a handler. Automatic objects are destroyed in the reverse order of their construction. If a destructor throws an exception during the stack unwinding process, terminate is called.

From the Borland C++ Builder help:

When an exception is thrown, the runtime library takes the thrown object, gets the type of the object, and looks upward in the call stack for a handler whose type matches the type of the thrown object. Once a handler is found, the RTL unwinds the stack to the point of the handler, and executes the handler. In the unwind process, the RTL calls destructors for all local objects in the stack frames between where the exception was thrown and where it is caught. If a destructor causes an exception to be raised during stack unwinding and does not handle it, terminate is called. Destructors are called by default, but you can switch off the default by using the -xd compiler option.
Objects that are not allocated on the stack, such as heap allocations, are not automatically released. This can cause memory leaks unless the programmer takes extra precautions to release the allocated memory when an exception is thrown. There are various ways to prevent heap-memory leaks caused by stack unwinding. One way is a user-defined garbage-collection; a second way is to specifically deallocate those resources in the exception handler.

Q5) When I write a derived class's destructor, do I need to explicitly call the destructor for my base class?

A5) Marshall Cline's C++ FAQ Lite answers this question with "No". A more explicit explanation with an example is at parashift.com.

Q6) Explain the difference between a class and an object.

A6) A class is a blueprint for an object. It defines how the object will be created, what data is stored, how the data can be manipulated and how the object will be destroyed. An object is an instantiation of a class. There can be multiple objects instantiated from one class. Every object has one and only one class that it was instantiated from.

Q7) Explain the difference between a struct and a class.

A7) The default members and base classes of a class are private. The default members and base classes of a struct are public.

Other than the default protection, struct and class are equivalent.

An unwritten practice amongst C++ programmers is to define a class for objects that have few or no public data members and to define a struct for objects that have few or no public methods.

Q8) What is difference between malloc()/free() and new/delete?

A8) malloc() and new both allocate space from the heap. free() and delete both release previously allocated heap space. free() should only be used with malloc'd allocations and delete should only be used with new allocations. There are two varieties of new: array allocation through a new[] operator and single object allocation through a new operator. It's the programmer's responsibility to know and track which allocation method was used in order to apply the correct deallocation: free(), delete or array delete (operator delete[]).









	
C++ Language Definition and Acronym Answers
by Curtis Krauskopf
The key to answering a definition-type question is to keep the answer short. Even though you might be an expert on a particular word or phrase, the interviewer is generally not interested in that and they just want a simple explanation that shows you understand what it means.

Some interviewers adopt a more sadistic perspective. Their philosophy is follows the idiom "Give a man enough rope and he'll hang himself". The goal of the sadistic interviewer is to allow you to talk until you've said something that is undeniably incorrect and then point it out to you. Short answers prevent you from rambling on about a topic and then getting yourself into trouble by giving an inaccurate or misleading description.

One way to tell the difference between a language issue and a definition question is to examine the question. A definition-type answer is expected for questions similar to "What is X?". A language-issue type answer is expected for questions that ask how to do something, or why is something defined the way it is.

1) Polymorphism is the ability of a pointer to a derived object to be type-compatible with a pointer to its base class. If the interviewer's follow-up question is, "Huh?", you can answer:

Polymorphism allows two or more classes derived from the same base class to share a common base member function but have different behaviors. Moving to a whiteboard, you can whip up the sample program in Listing A. It uses a pure virtual base member but that's not a requirement. A regular virtual base member would also have been acceptable.

#include <iostream>

using namespace std;

class Vehicle {
public:
  virtual string getFuel() = 0;
};

class Car : public Vehicle {
public:
  virtual string getFuel()
    { return "gasoline"; }
};

class Truck : public Vehicle {
public:
  virtual string getFuel()
    { return "diesel"; }
};

void printFuel(Vehicle &v) {
  cout << v.getFuel() << endl;
}

int main(int, char **) {
  Car car;
  Truck truck;
  printFuel(car);
  printFuel(truck);
  return 0;
}
Listing A: Example of Polymorphism
In Listing A, polymorphism occurs with the Vehicle parameter for the printFuel() function. printFuel() can accept either an instantiation of Car or an instantiation of Truck.

A follow-up question might ask if a Vehicle object could be passed to the printFuel() function. The answer is "no" because Vehicle uses a pure-virtual function and classes with pure-virtual functions can not be instantiated.

2) virtual is a C++ keyword that is used for virtual methods and for virtual base classes.

3) mutable is a storage-class specifier. It allows const-member functions to modify the data member.

4) explicit is used on constructors that have one parameter. It prevents automatic type conversion from changing a candidate parameter into the type used in the constructor.

5) template metaprogramming is an idiom that uses templates to generate source code that calculates an answer at compile-time rather than at run-time.

Follow-up questions would ask about the Curiously Recurring Template Pattern, the Barton-Nackman trick, static polymorphism in template metaprogramming and the benefits and drawbacks of template metaprogramming. See wikipedia.org for a good explanation along with cross reference material.

6) public, private and protected are the access control specifiers in class and struct designs. All three of the keywords are used to control the access to methods and data in base classes and in derived classes. Listing A shows an example of a Car class defining public access to a Vehicle class. The Vehicle class defines public access of the getFuel() pure virtual method.

7) The static keyword is used all over the place in the C++ language. When used inside of a method or function, the static keyword preserves the last value of a variable between method or function calls. Inside of a class definition, a data value can be declared static -- this causes one version of the data to be shared amongst all of the objects of the class. Static member functions can not be virtual because they have external linkage. External linkage means that the function does not have a this pointer and the function can only call other static member functions and access static data.

8) An assignment operator is a simple equal (=) sign for built-in types or the operator=() method for objects. If your first answer only provided one of those assignment operators, a good interviewer would ask something like "is that all?". Written tests can't do that, of course, so be careful when giving what seems like an obvious answer.

9) A dangling pointer can be an unassigned pointer or it can be a pointer to an object that has been destroyed.

10) A functor is short for function object. Function objects are used as callbacks to modify or customize the behavior of an algorithm. Function objects define a member function that provides the glue between an algorithm and the customized behavior. Because functors are full-fledged objects, they have all of the power of an object: state, inheritance, encapsulation and templates. In Listing B, the operator() method of the magnitude structure is a functor. Listing C takes a slightly different approach by using an arbitrary method name, in this case called "isGreaterThan", to attach a customized behavior to an algorithm.

 #include <algorithm>
#include <function>
#include <assert>
#include <iostream>

using namespace std;

// Use the absolute value (magnitude) of the
// number.  For example:  3 < -5 because abs(3) < abs(-5)
struct magnitude {
  bool operator()(const int& x, const int& y)
    const
    { return abs(x) < abs(y); }
};


int main(int, char **) {
  int a[10];
  int i;

  for(i = 0; i < 10; ++i)
    a[i] = i * (i % 2 ? -1 : 1);
  random_shuffle(&a[0], &a[10]);

  // sort into special order:
  sort(&a[0], &a[10], magnitude());

  // Should be: 0,-1,2,-3,4,-5,6,-7,8,-9,
  for(i = 0; i < 10; ++i)
    cout << a[i] << ",";
  cout << endl;

  return 0;
}
Listing B: Functor Example


 #include <algorithm>
#include <iostream>

using namespace std;

// Used to allow for generic implementations of bubble_sort
struct SortOrder {
  virtual bool isGreaterThan(const int x, const int y) const = 0;
};

void bubble_sort(int *first, int *last, SortOrder &compare) {
  int numLaps = last - first - 1;
  for(int lap = 0; lap < numLaps; ++lap) {
    for(int *current = first; current != last; ++current) {
      int *next = current + 1;
      if (next == last)
        continue;
      if (compare.isGreaterThan(*current, *next)) {
        std::swap(*current, *next);
      }
    }
  }
}


// Use the absolute value (magnitude) of the
// number.  For example:  3 < -5 because abs(3) < abs(-5)
struct Magnitude : SortOrder {
  virtual bool isGreaterThan(const int x, const int y) const
    { return abs(x) > abs(y); }
};


int main(int, char **) {
  int a[10];
  int i;

  for(i = 0; i < 10; ++i)
    a[i] = i * (i % 2 ? -1 : 1);
  random_shuffle(&a[0], &a[10]);

  // sort into special order:
  Magnitude sort_by_magnitude;
  bubble_sort(&a[0], &a[10], sort_by_magnitude);

  // Should be: 0,-1,2,-3,4,-5,6,-7,8,-9,
  for(i = 0; i < 10; ++i)
    cout << a[i] << ",";
  cout << endl;

  return 0;
}
Listing C: Another Functor Example

Acronyms
Just like definitions, try to keep the answers to acronyms short.

1) STL: Standard Template Library

2) RAII: Resource Allocation is Initialization. See http://www.hackcraft.net/raii/ for a well-written tutorial on RAII.

3) VCL: Visual Component Library. I'll admit that even though I knew what the VCL was, I didn't know what its acronym stood for until I wrote this article.

4) C++: Quote from Chapter 1 of the C++ Programming Language (Stroustrup)

"The name C++ ... was coined by Rick Mascitti in the summer of 1983. The name signifies the evolutionary nature of the changes from C; "++" is the C increment operator."
See also att.com.
5) A WChar type in a program you didn't write would typically be a wide (16-bit) character type.







	
Efficient C++ Programming Answers
by Curtis Krauskopf
Almost every answer for an efficient programming question can start out with "Well, it depends...". The compiler vendor you use, the optimization settings, the operating system, the speed (and brand) of the CPU, the speed of the RAM memory and dozens of other factors can each affect the outcome of almost every efficiency programming question. The answers here are those that are generally accepted in the industry or can be shown to be true for a wide variety of common C++ compilers.

Q1) What executes faster: ++i or i++, where i is an integer variable?

A1) ++i probably executes faster because i++ would first fetch the value of i, push it on the stack, increment it and then pop the value of i from the stack. In contrast, ++i fetches the value of i, and then increments it. Yes, I'm leaving a lot of detail out and the push/pop cycle can be optimized away for many situations if the optimizer is good enough.

Q2) Which is generally more efficient: a function that returns a reference or a function that does not return a reference?

A2) Functions that don't return a reference are returning the object by value. This is accomplished by using the object's copy constructor. For non-trivial objects, the time and resource cost of copying the object can be easily measured. Functions that return an object by reference only return a pointer to the object. The object the reference points to is not copied.

Q3) What's the deal with inline functions?

A3) The keyword inline is a hint to the compiler that the function should be compiled into the code wherever it is used. This is normally done with a simple function that is called often, such as a getter or setter in a class or struct. The compiler implementer is allowed to ignore the inline hint and substitute a function call instead. Some compilers automatically disable the inlining of functions while debugging.

Q4) Why use the STL sort() when we have "good old qsort()"?

A4) The following answer is quoted from public.research.att.com:

To a novice,
qsort(array,asize,sizeof(elem),compare);
looks pretty weird, and is harder to understand than
sort(vec.begin(),vec.end());
To an expert, the fact that sort() tends to be faster than qsort() for the same elements and the same comparison criteria is often significant. Also, sort() is generic, so that it can be used for any reasonable combination of container type, element type, and comparison criterion. For example:
struct Record {
  string name;
  // ...
};

struct name_compare {	// compare Records using "name" as the key
  bool operator()(const Record& a, const Record& b) const
    { return a.name<b.name; }
};

void f(vector<Record>& vs)
{
  sort(vs.begin(), vs.end(), name_compare());
  // ...
}	
In addition, most people appreciate that sort() is type safe, that no casts are required to use it, and that they don't have to write a compare() function for standard types. The primary reason that sort() tends to outperform qsort() is that the comparison inlines better.
Q5) One programmer wants to sort a linked list using recursion; another programmer wants to do it without recursion. Which one has the better answer?

A5) It depends on the maximum number of items in the linked list. An implementation that uses recursion will eventually run out of stack space if the linked list is long enough. If the number of items in the linked list is relatively small, say around 30 or so, then either solution might be faster but both implementations will be so fast that it's usually not worth optimizing that one little routine. If the number of items in the list could ever be more than 30, then a non-recursive solution would probably be better because it will not run out of stack space when compared with the recursive solution.

Q6) When is an interface "good"?

A6) From parashift.com:

When it provides a simplified view of a chunk of software, and it is expressed in the vocabulary of a user (where a "chunk" is normally a class or a tight group of classes, and a "user" is another developer rather than the ultimate customer). The "simplified view" means unnecessary details are intentionally hidden. This reduces the user's defect-rate. The "vocabulary of users" means users don't need to learn a new set of words and concepts. This reduces the user's learning curve.
Previous Answers		More C++ Answers







	
Practical C++ Programming Answers
by Curtis Krauskopf
Some of the practical programming questions require experience and the answers to some of them can be learned by reading the right books. A core set of books that every professional C++ programmer should read are:
The C++ Programming Language (Stroustrup)
Effective C++ (Meyers)
Design Patterns (Gamma)
The Annotated Reference Manual (Stroustrup & Elis)
C++ Primer (Lippman)
C++ Standard Library (Josuttis)
STL Tutorial (Musser)
C++ Templates (Nico)
Advanced C++ (Coplien)
Q1) What language feature is available when a function returns a reference?

A1) The C++ FAQ-lite at parashift.com answers this question:

The function call can appear on the left hand side of an assignment operator. This ability may seem strange at first. For example, no one thinks the expression f() = 7 makes sense. Yet, if a is an object of class Array, most people think that a[i] = 7 makes sense even though a[i] is really just a function call in disguise (it calls Array::operator[](int), which is the subscript operator for class Array).

class Array {
public:
  int size() const;
  float& operator[] (int index);
  ...
};

int main() {
  Array a;
  for (int i = 0; i < a.size(); ++i)
    a[i] = 7; // invoke Array::operator[](int)
  ...
}

Q2) What is name mangling in C++?

A2) Name mangling encodes the type of the function's parameters into the name in order to create a unique name that is distinguished from identical function names with different parameter types. For example, the parameter int *p might be mangled to "intPtr". A function prototype defined as:


doit(int *p);

could name mangle the doit function into doit_intPtr.

Name mangling is compiler specific. The primary reason why object libraries from one compiler can not be linked with object libraries from another compiler is because each compiler vendor uses a slightly different name mangling scheme.

Q3) What is overriding?

A3) Overriding only occurs in a class hierarchy. An overridden method is one that is hidden from the normal method call hierarchy by a derived class that has a method with the same name, return type and parameter list. When a method is overridden by a subclass's method, the subclass's method is called instead of the parent class's method.

Q4) Can you assign to a reference?

A4) Yes, you can. Here's an example:

int i;
int &j = i;
j = 5;   // changes i to 5
Q5) What happens if you assign to a reference?

A5) From parasoft.com:

You change the state of the referent (the referent is the object to which the reference refers).
Remember: the reference is the referent, so changing the reference changes the state of the referent. In compiler writer lingo, a reference is an "lvalue" (something that can appear on the left hand side of an assignment operator).

Q6) What is a static_cast and when should it be used?

A6) A static_cast<> is the general replacement for the old-style (cast). A static_cast<> is safer than a (cast) because static_cast<> verifies at compile-time that the conversion makes sense.

Q7) What are the names of the other cast operators?

A7) const_cast, reinterpret_cast and dynamic_cast.

Q8) How do you trap an exception without knowing what exception might be thrown?

A8) Use the ... wildcard in the exception handler.

Q9) Describe how you design a program.

A9) Any reasonable answer that you can justify will work for this question. The better answers will include the phrases "top-down", and "bottom-up". Other phrases that could be used are "divide and conquer", "requirements gathering", budgeting, planning, and testing.

A poor answer is along the lines of, "I just sit down and start coding because I get something done right away". Most employers want to know that you spend time designing the program, that you sit at a blank piece of paper or a whiteboard and sketch out even a rough skeleton of how the program will work.

Programmers that design programs using extensive unit testing get extra credit points. If you're an advocate of extreme programming (XP) (www.extremeprogramming.org/), this would be a good time to talk about your experiences with XP and how it makes you a more efficient and better software engineer.

Q10) Most programming projects involve modifying existing code. What things do you look for when you're tasked with modifying an existing program?

A10) The first thing I do when I take over a legacy project is to attempt to compile the project in an isolated environment. I record the compile-time warnings I receive and I pay particular attention to any modules that compile with errors because that's an indication that I have an incomplete or inaccurate development environment. Next, I make a binary comparison between the legacy executable and the newly compiled executable. My goal is to create an executable that is identical to the legacy executable -- at that point I know I have the same environment and settings that the previous developers used.

The next thing I usually look at is any existing documentation. Although many C and C++ programming projects are notorious for having little or no documentation (or even inaccurate documentation!), I have seen projects that had extensive, amazing and accurate documentation -- even to the point where the number of lines of useful comments exceeded the number of lines of code.

Q11) There is a memory leak in a program. What tools and techniques would you use to isolate, find and fix it?

A11) I would first determine how big the memory leak is and look for patterns of when it appears and how quickly it grows. If the memory leak is small or grows slowly and the program terminates soon anyway, then I would say that the problem isn't worth fixing. This isn't out of laziness -- it's a prudent decision that recognizes that some things are too expensive to fix.

If a leak was determined to be worthy of fixing, I would next look for the smallest set of code that reproduces the problem. Can the problem be reproduced by launching and then immediately exiting the program? What's the simplest thing I can do that causes the biggest memory leak quickly?

I would also realize that there may be multiple memory leaks in the program and they might be interacting with each other in strange ways. An example would be a hash table that leaks whenever the hash table's contents are rehashed.

On a Windows system, the primary tool I use to monitor memory usage is the Windows Task Manager. A more aggressive approach is to instrument the malloc/free and new/delete methods to provide a log of memory consumption and releases.

Commercial tools are also available to assist in the detection and eradication of memory leaks. If you've used one before that you've liked, mention it in the interview to earn extra points.

Q12) What's the difference between a linked list and an array?

A12) An array allows random access to the array's elements. A linked list's elements can accessed by dereferencing the head (or tail) pointer and then dereferencing the next (or previous) pointers.

Inserting an element into an array is more difficult than inserting an element into a list. Deleting is similarly more difficult in an array than in a list.

Data is stored sequentially in an array but that is not a requirement for a list. Lists' data can be stored either sequentially or randomly.

Q13) What is the difference between a vector, a list and a map?

A13) All three of them are containers in the STL.

Maps use key/value pairs for the elements. The keys are sorted within the map to allow quick random access. Insertion and deletion are both very quick. Access to any particular element is also quick but each element requires a unique key.

STL vectors and STL lists behave the same as arrays and lists (see Q12).








	
C++ Buzz Phrase Answers
by Curtis Krauskopf
Buzz phrases show how well-read a C++ candidate is. The diversity of knowledge and wisdom embedded in any of these buzz phrases separates the advanced C++ programming candidates from the intermediate or beginner levels. Knowing when to apply these concepts, and equally important, knowing when to break the rules provided by these concepts, shows your ability to handle large C++ design and development projects.

A1) In C++, the Law of Demeter is a guideline for developing class hierarchies. The guideline states that a method inside of an object should only call the methods of:

The object itself
The objects passed as parameters to the method
Objects instantiated within the method
Objects that exist due to has-a relationships within the object
The purpose of the Law of Demeter is to reduce the dependencies between classes. Obeying the law requires the coder to create many wrapper methods that separate callees from callers.

A2) The Liskov Substitution Principle guarantees that code using a pointer to a base class doesn't break when a new class is added to the class hierarchy. One main principle provide this guarantee: the methods for subclasses are substitutable for the methods in the superclasses for instantiated objects.

Violating the principle requires subclasses (or modified superclasses) to check the object's state or the type of the subclass to determine how to dereference a request. Most commonly, this manifests itself in code with switch or if statements similar to:

switch (param.type) {
  case Integer:
    retval = param.toInt();
    break;
  case Double:
    retval = param.toDouble();
...
A3) Dependency Inversion abstracts dependencies into subclasses so that the superclasses become so generic that they no longer have interdependencies.

See Robert Martin's article for more details.

A4) The Visitor Pattern separates an algorithm from an object's structure. It can perform an operation (or groups of operations) on objects that belong to a structure. The objects are not required to have the same interfaces.

A5) The Gang of Four are Erich Gamma, Richard Helm, Ralph Johnson and John Vlissides. They collectively became famous for their seminal book "Design patterns : elements of reusable object-oriented software", Addison-Wesley (ISBN 0201633612 -- no, I don't expect you to memorize the ISBN number -- I'm providing it here in case you want to get the book).

A6) A Bridge Pattern separates an abstraction from its implementation so that they can change independently. Some examples of when a Bridge Pattern can be used are:

A reference counting mechanism that is invisible to the clients being counted.
When changes to a class hierarchy cause an exponential increase in the number of subclasses or superclasses.
When interfacing with a legacy system that can not be touched but must be extended.
Previous Answers		More C++ Answers









C++ Problem Solving
by Curtis Krauskopf
There are usually many ways to solve any programming problem. The solutions provided here are examples and are not necessarily the best -- but they do work.

When creating your solution for any problem-solving type question, remember to test edge-cases -- such as when there are zero, one or an infinite number of possibilities.

Q1) Find the size of an integer data type without using sizeof() function.

A1) Listing D is an example of one solution. What is not mentioned in the question is if the integer data type is signed or unsigned. Does your solution work for both? For edge-case support, we can assume that the integer data type has at least one bit because a 0-bit integer data type is pretty useless. Does your solution work for 1 or 2 bit integers, or did you assume that integers were a multiple of 8 bits?


#include <stdio.h>

template< typename IntType >
int numberOfBits() {
  IntType newValue = 1;
  IntType oldValue = 0;
  int numBits = 0;
  while(oldValue != newValue) {
    ++numBits;
    oldValue = newValue;
    newValue = (newValue << 1) + 1;
  }
  return numBits;
}

int main(int argc, char* argv[]) {
  printf("sizeof(int)  : %d\n", sizeof(int) * 8);
  printf("size of <int>: %d\n", numberOfBits<int>());
  printf("\n");
  printf("sizeof(unsigned int)  : %d\n", sizeof(unsigned int) * 8);
  printf("size of <unsigned int>: %d\n", numberOfBits<unsigned int>());
  printf("\n");
  printf("sizeof(short)  : %d\n", sizeof(short) * 8);
  printf("size of <short>: %d\n", numberOfBits<short>());
  return 0;
}

Listing D: Detect the size of an integer
Update: March 20, 2011
A decompile.com reader, Ján Staník, has submitted the following alternate solution. The solution in Listing D did not assume there are 8 bits per byte but Ján's solution does assume there are 8 bits per byte. However, Ján's solution provides an O(1) solution whereas the solution in Listing D is an O(n) solution.

I think it's useful to examine why his solution works because it makes a clever use of arrays and it calculates the distance between array elements in a template function.

The only change I made to his solution was to format it to stay within the minimum page width of this website.


#include <iostream>

template <typename T>
void SizeOf()
{
  T a[2];
  std::cout << "sizeof() = " << 8 * sizeof(T) << std::endl;
  std::cout << "SizeOf<> = ";
  std::cout << 8 * (((long int)((T*)a+1)) - ((long int)(T*)a));
  std::cout << std::endl;
}

int main( )
{
  SizeOf<unsigned int>();
}

Q2) Multiply an integer by 8 without using multiplication or addition.
A2) The key to the answer to this question is knowing about the shift operator and how it relates to the integer's internal representation. The following code snippet answers this question:


int x = 3;
x = x << 3;











	
	
Software Engineering Communication
by Curtis Krauskopf
Many communication-type questions don't have a specific "right" or "wrong" answer. Almost any reasonable answer will be acceptable as long as it answers the question.

Q1) What was your biggest development screw-up? What insight did you learn from that?

A1) A "wrong" answer to this question would be "I really haven't had any screw-ups -- all of my projects are done perfectly all of the time". If your projects really are like that, then contact me so I can hire you. For the rest of us, we can point out at least one project that could have been done better or wasn't delivered on-time or on-budget.

This question can become a trap for you when you start bad-mouthing a previous employer or your current or ex-coworkers. Keep the criticism self-centered and about how you contributed to the problem. Starting your answer with a sheepish grin (if you can manage that) can disarm the interviewer and give you a little more time to construct your answer.

Even though we would like to forget our screw-ups, it's important to have them ready for an explanation when we're asked about them. This shows that you care about the projects you've worked on, that you try to improve yourself by learning from your past mistakes and that you watch for signs of repeating previous problems. Ending your explanation by explaining all three of these things turns the response from being a low-point in the interview into a high-point -- where your abilities are shown to shine.

Q2) Explain the internet to a young child.

A2) The Internet is a way that computers can talk to each other.

I think the key to this question is keeping the explanation and vocabulary very simple.

Q3) Explain a database to your grandparents.

A3) A database stores information in the same way that a phone book stores information. When you want to search for somebody's phone number, you can easily find it because all of the names are in alphabetical order. Similarly, in a database, all the information is organized in ways that make it easy to find. Unlike a phone book, though, most databases allow new information to be added, old information to be deleted, and changes to be made to existing data.

Using an analogy for this question is appropriate because of the audience.

I picked a phone book because its features are well-understood by everybody.

Q4) Explain how you learn a new computer language.

A4) Just about any reasonable explanation could go here. Some people learn by example. Others learn by reading the definition and rules of the language. Your answer should probably cover how you use small test programs to try features before using them in a real program (you do that, don't you?).

The way I learn a language is to read the language's specification and see how it's similar to one of the languages I already know. I usually buy two books: one that gives the language's definition and a second that shows examples. Using sample programs, I write small test programs to test out features of the language. Then I'll intentionally create problems in those small programs to see how the compiler reacts or how the program blows up at runtime. What happens if a semi-colon is missing? What happens if I use a reserved word for a variable name?

Q5) What C++-related magazines or websites do you read on a regular basis?

A5) Since you're reading this article, you probably read websites that discuss C++ programming!

Some websites that discuss C++ programming issues are:

bcbjournal.com
dreamincode.net
codeproject.com
www.decompile.com/cpp/faq/
Q6) Have you ever worked on an open-source project? If you have worked on one, what were the most difficult issues? If you were to work on one, what would you foresee as being some of the difficult issues?

A6) One of the purposes of this question is to discover if you've ever worked in a team environment and how well you work on that team. Sometimes, large projects are distributed amongst teams of programmers that interact remotely. Your experience on large open-source projects will help you integrate into the company's distributed culture.

A recent slashdot.org article asked readers nearly the same question. The consensus opinions were to:

Find a project you're interested in.
Read the TODO list or find something that is broken or needs to be improved.
Read the discussion message boards and learn the acronyms and terminology that are unique to the project.
Communicate with the core developers to let them know you're interested in volunteering for the project.
Code and test and retest your solution before delivering it.
Deliver your project when you promised to deliver it. This shows that you are reliable and you'll be trusted with larger (and more interesting) assignments.
Don't take it personally if the core developers seem elitist or cliquish. Many open-source projects are run by developers with poor people-skills. If you find one of those projects, don't try to change them or even bother pointing out their behavior. Just move on to another open-source project. There are so many well-run open-source projects that there is inevitably a project that you would enjoy working on.
Q7) What are the three most recent languages you've learned and why did you learn them?

This is another question with no right or wrong answers. Just tell it truthfully without embellishing your answer. A typical follow-up to the question is "How long ago did you learn them?".

The interviewer is looking for your ability to adapt to modern programming conventions and to stay abreast of the industry's technology. The interviewer also wants to know if you're a naturally curious person. Even though it might seem nerdy to a non-professional, learning a language just for the sake of learning it does have merits. If the only language you know is C++, then every problem looks like it can only be solved with C++. Having a variety of languages under your belt (and that you stay current with) shows that you're flexible, well-rounded and professional.








	
Job Interview Brain Teasers
by Curtis Krauskopf
When an interviewer tests you with a brain-teaser, just remain calm. The worst answers are confrontational in which you ask, "How does putting water in a jar relate to the job I'm interviewing for?". Be careful about giving a snap-answer to a question, even if you think you've heard it before. The interviewer is expecting you to think about the problem and engage him with poignant questions. Giving the wrong answer quickly is not the impression you want to give.

Almost as bad as the confrontational answers are flippant answers, such as "I would go to the store and buy a measuring cup". However, you could start your answer that way with a qualification: "Assuming I can't go to the store...". The latter answer shows that you can think outside of the box whereas the first one dismisses the question sarcastically.

The interviewer is also testing to see how you react when you are told you had a wrong answer or when you can't find the answer. Certainly, getting hostile and attacking the question or complaining about how the interviewer didn't explain it well enough does not earn you points even though it might feel good for your damaged ego. Instead, sincerely ask what the answer is and how it is solved. Seem genuinely interested even if you don't care what the answer is -- the interviewer asked the question, so it seems important to him for some reason!

The Three Jugs Problem
Two friends who have an eight-quart jug of water wish to share it evenly. They also have two empty jars, one holding five quarts, the other three. How can they each measure exactly 4 quarts of water?

The Three Jugs Problem Answer
There are many variations on the three jugs problem, with different situations (sometimes sand, sometimes different jug volumes). The goal is generally the same: make a container hold exactly some amount of substance that can't be trivially measured.

Maybe you're blessed to be able to intuitively solve these kinds of problems. If so, just give the answer and impress the interviewer! For the rest of us, we have to solve it using some iterative process.

All of the versions of this problem can be solved by applying state-machine techniques. Starting with an initial condition, what are all of the possible permutations that lead to the next state? From that state, what are all of the possible permutations that lead to the third state and so on? Many of the possibilities might be physically impossible (such as pouring water from an empty jug) and others might undo the previous step. If paper or a whiteboard is available, show your design skills by plotting out the progress of your state-machine until you reach an answer. Most often, though, an interviewer will stop you midway through once it's clear that you're able to solve the problem.

Table 1 shows the initial conditions for the Three Jugs problem. Volume represents the amount of water in the jug in each state. The jugs are arbitrarily labeled A, B and C to easily identify them. Table 2 shows the state transitions in the problem. I've also given each of the transitions a unique number.

 	Jug A	Jug B	Jug C
Volume	8	0	0
Capacity	8	5	3
Table 1: Three Jugs Problem
Initial Conditions


Pour water from	Pour water to	Unique ID
A	B	1
A	C	2
B	A	3
B	C	4
C	A	5
C	B	6
Table 2: Three Jugs Problem
State Transitions
For bookkeeping purposes, you'll want to find a way to discover that you've already visited a previous state. This prevents infinite loops. For the initial conditions in Table 1, notice that the volume row uniquely represents the state. Using the volumes from jugs A, B and C, let's call 800 the initial state (the first digit is for jug A, the second digit is for jug B and the third digit is for jug C).

Now we know how to represent the final condition. That occurs when there are 4 quarts of water in two jugs. Only jugs A and B can contain four quarts of water. So the final condition is 440.

Using your whiteboard or paper, draw the initial condition using the code 800 and show the next state using the permutations in Table 2. Your diagram will look something like Figure A.

 
800 -> 350 (1)


800 -> 503 (2)


Figure A: Three Jugs Problem
First legal moves
The three jugs problem starts with all of the water in Jug A. Figure A shows the first legal moves from Table 2 that are applied to the initial conditions in Table 1. The transition ID number is in parenthesis.

From the initial conditions, there were only two valid transitions. I put the transition ID in parenthesis after the state number to help remember what happened. The next state transition diagram will look something like Figure B.

 
800 -> 350 (1) -> 053 (2)
               -> 800 (3)  X   
               -> 323 (4)
800 -> 503 (2) -> 053 (1)  X
               -> 800 (5)  X
               -> 530 (6)
Figure B: Three Jugs Problem
Next legal moves
The next step in the three jugs problem is to apply the transitions from Table 2 to the states recorded in Figure A. Three of the states are duplicates of a previous state. Those states are culled from further investigation by putting an X next to their transition numbers.

An 'X' is placed next to any state that is previously represented in the diagram, even if it's for another branch in the current state. This happened with 053 in the 800->503 branch because the first transition (A to B and A to C) was already 'discovered'.

By iteratively following this process, you'll either impress (or bore) the interviewer and he'll stop the question or you're arrive at an answer, whichever comes first.

Update: March 22, 2010
A decompile.com reader, Kang Zhao, has graciously provided his solution to the three jugs problem. I'm providing it here in case it makes more sense than the state-machine solution that is provided above.

Kang Zhao writes, "The key is to get 1 quart water. Because 8 - 5 = 3, 5 - 3 = 2, and 8 - 3 = 5, we need to find another way: 6 - 5 = 3 + 3 - 5 = 1".

Initial state:
A(8)	B(5)	C(3)
8
0
0
Solution:
3
5
0
3
2
3
6
2
0
6
0
2
1
5
2
1
4
3
4
4
0
Geometry in real-life
Why is a manhole cover round?

Geometry in Real-Life Answer
Some questions test your ability to think of a solution that doesn't involve programming and instead tests your general knowledge of chemistry, physics, geometry, biology and courses you took that you might have thought you never needed.

As with all brain teaser questions, it's not vitally important that you get the answer because you're being tested on how you solve a problem. One solution is to discuss the merits of a round manhole cover compared to other shapes.

For a humorous transcript of this answer, see Brian Groth's blog at msdn.com.

We'll cross that bridge when we get to it
There are 4 women who want to cross a bridge. They all begin on the same side. You have 17 minutes to get all of them across to the other side. It is night. There is one flashlight. A maximum of two people can cross at one time. Any party who crosses, either 1 or 2 people, must have the flashlight with them. The flashlight must be walked back and forth, it cannot be thrown, etc. Each woman walks at a different speed. A pair must walk together at the rate of the slower woman's pace.

Woman 1: 1 minute to cross
Woman 2: 2 minutes to cross
Woman 3: 5 minutes to cross
Woman 4: 10 minutes to cross
For example if Woman 1 and Woman 4 walk across first, 10 minutes have elapsed when they get to the other side of the bridge. If Woman 4 then returns with the flashlight, a total of 20 minutes have passed and you have failed the mission. What is the order required to get all women across in 17 minutes? Now, what's the other way?

Bridge Answer
The Bridge problem is similar to the Three Jugs problem. In both cases, things need to be transferred from one container to another (a side of a river versus a jug). The same state-machine techniques I described in the Three Jugs problem can be applied to the Bridge problem.

Table 3 shows the problem's initial conditions and Table 4 shows all of the transition states.

 	Woman A	Woman B	Woman C	Woman D
Bank (Left or Right)	L	L	L	L
Travel Time	1	2	5	10
Table 3: Bridge Problem
Initial Conditions


Move from Left bank
to Right bank:

Women	Time	Unique ID
A & B	2	1
A & C	5	2
A & D	10	3
B & C	5	4
B & D	10	5
C & D	10	6
Move from Right bank
to Left bank:

Woman	Time	Unique ID
A	1	7
B	2	8
C	5	9
D	10	10
Table 4: Bridge Problem
State Transitions
The last transition, ID#10, can be omitted because the problem can not be solved in time by having woman D travel from the right side to the left side by herself.

Starting with the initial conditions of ABCD| (in which the letters represent each of the women and the | symbol represents the river bank) the goal is to arrive at |ABCD in 17 or fewer elapsed minutes. Figure C shows the first set of transitions in the problem and Figure D shows the return trips for the first two possibilities in Figure C.

 
ABCD|_ 	-> CD|AB (1) (time: 2)
       	-> BD|AC (2) (time: 5)
       	-> BC|AD (3) (time: 10)
       	-> AD|BC (4) (time: 5)
        -> AC|BD (5) (time: 10)   
        -> AB|CD (6) (time: 10)
Figure C: Bridge Problem
First legal moves
All of the women initially start on the left bank. Figure C shows the first transition from the initial conditions in Table 3 using the states in Table 4.

 
ABCD|_ -> CD|AB (1) (time: 2)
                    -> ACD|B (7)  (elapsed time: 3)
                    -> BCD|A (8)  (elapsed time: 4)
       -> BD|AC (2) (time: 5)
                    -> ABD|C (7)  (elapsed time: 6)
                    -> BCD|A (9)  (elapsed time: 10)
       -> BC|AD (3) (time: 10)
                    -> ABC|D (7)  (elapsed time: 11)
                    -> BCD|A (10) (elapsed time: 20)  X   
       -> AD|BC (4) (time: 5)
                    -> ABD|C (8)  (elapsed time: 7)
                    -> ACD|B (9)  (elapsed time: 10)
       -> AC|BD (5) (time: 10)
                    -> ABC|D (8)  (elapsed time: 12)
                    -> ACD|B (10) (elapsed time: 20)  X
       -> AB|CD (6) (time: 10)
                    -> ABC|D (9)  (elapsed time: 15)
                    -> ABD|C (10) (elapsed time: 20)  X
Figure D: Bridge Problem
Next legal moves
The return trips from Figure C are extrapolated using the transitions from Table 3. Illegal moves (moving a woman who is not on the right bank) have been ignored. Three of the subsequent states exceeded the 17 minute time limit. Those states are marked with an 'X'.

Using this technique, you will find both of the solutions. Don't worry about the proliferation of states in the first few iterations. The 17 minute time limit puts a tight leash on the problem and you'll find the solution pretty quickly.





	
Job Interview: What's Wrong With this Code?
by Curtis Krauskopf
The problem with the Gimpel Software Bug of the Month #750 (repeated in Listing 1 for your convenience) is on line 11. Carefully look at the ON_THE_R0CKS symbol. The O of ROCKS is actually a zero (0). Gimpel's PC-lint tool provides a hint to the problem by reporting that the ON_THE_ROCKS symbol is not used in the program even though it's defined.

 1    #include <stdio.h>
2
3    #define ON_THE_ROCKS
4
5    const char *ice()
6    {
7    #if defined(Shaken)
8        return "shaken not stirred";
9    #elif defined(Stirred)
10       return "stirred not shaken";
11   #elif defined(ON_THE_R0CKS)
12       return "on the rocks";
13   #else
14       return "";
15   #endif
16   }
17
18   int main()
19   {
20       printf( "Celebrate the New Year " );
21       printf( "with your drink %s.\n", ice() );
22       return 0;
23   }
Listing 1: Gimpel Softare Bug Example
The zero in the ON_THE_R0CKS symbol causes the ice() function to compile with one line:


return "";

Many thanks to alert reader ZenJu for correcting my original answer.

The next code sample is actually in C#. You might think that it's not fair to use a C# code sample in a C++ interview. I, as an interviewer, would not do that but I've been in an interview where the interviewer thought that JavaScript and Java were the same thing. If you recognized that the program was in C# and said something to the interviewer in a cordial way, then points for you. Even though you might not have ever programmed in C#, the syntax is close enough that you should be able to provide constructive criticism about the code sample.

Eric Gunnerson's blog on msdn.com provides details about what's wrong with the code from a C# programmer's perspective.

Assuming that I didn't know C# and wasn't familiar with HTML, I would suspect that appending the input string to "<h1>Values</h1>" would cause the input string to be adjacent to the label. For example: ValuesLike this. This is not the case for normal HTML because the </h1> tag forces a new paragraph (caveat: this might be overridable with CSS but I'm not that much of a CSS expert to know).

The point of the first code sample was to provide an example of a program that wasn't C++ but was similar to C++ and to examine it from a C++ coder's perspective.

This is the C# code for your convenience:

 
enum ResponseType { ReturnValues, InvalidInput };

string CreateWebText(string userInput, ResponseType operation) {
   switch (operation) {
      case ResponseType.ReturnValues:
         userInput = "<h1>Values</h1>" + FilterOutBadStuff(userInput);
         break;
      case ResponseType.InvalidInput:
         userInput = "<h1>Invalid</h1>" + FilterOutBadStuff(userInput);
         break;
   }
   return userInput;
}

Listing 2: C# Code Example
The second code sample, shown in Listing 3, asks if a number can be assigned to a structure. The trick in Listing 3 is that the code looks like it's doing one thing when it's really doing something else. When 7 is being assigned to the Fred structure, the compiler looks for a conversion for 7 to the Fred structure. One is available with Fred's constructor. By tracing this code in C++ Builder, you'll be able to see what happens. A std::vector with 7 empty elements is instantiated. The std::vector::operator=() method copies the temporarily instantiated empty vector to f. The value that is written to cout is 0 because the temporary vector was instantiated with 7 empty elements.

 
struct Fred {
  Fred(int n): v(n) {}
  std::vector<int> v;
};

int main() {
  using namespace std;
  Fred f(1);
  f.v[0] = 5;
  cout << f.v[0] << endl;
  f = 7;          // is this legal?
  cout << f.v[0]; // what is output here?
}

Listing 3: Is this code legal?









	
Short C++ Program Answers
by Curtis Krauskopf
Two factors are important with the "Showing Skills" type questions. The first is to create a working program that solves the problem. The second factor is to do the work within the time you've allotted yourself.

Giving an accurate time estimate is a skill that I've had to learn to develop. I practice it daily by challenging myself even on routine matters, such as how long will it take me to debug a problem, or how long will it take me to design a module?

Asking how long a task will take is a reasonable question for an employer or customer because they want to know when a solution will be available and how much the solution will cost.

For yourself, it's part of time management and being able to deliver projects on-time and on-budget.

The solutions for the six "Showing Skills" problems are shown in listings F through K. I've provided the time I took to create the solution. The purpose is to give you a benchmark with which to gauge your productivity. For example, if you estimate 30 minutes for a problem and you're still working on it two hours later, that should tell you something constructive about your organization, coding skills, and debugging skills.

I used all available references for my solutions. When I interview people, I allow them to use references because employers never take away your programming books when they assign you a project. When given a programming assignment, you should feel free to ask about using reference books or the Internet.

Array destruction

An array that is instantiated with the new[] operator should also be deleted using the delete[] operator. Write a program that proves that the destructors for an array are not called when the array was instantiated with new [] and the array was deleted with delete (without the delete[] syntax).
My first version of the array destruction test in Listing F did not use the VCL (a Borland C++ compiler feature) and an access violation was thrown at runtime. I tried to wrap the delete with a try/catch, but the exception still wasn't caught. The debugger told me that an EAccessViolation exception was being thrown and the C++ Builder Help told me that it was defined in the VCL. So I converted the program to use the VCL and tried it again. The VCL version does not cause an access violation at runtime, so I removed the try/catch block in the code.

 
// An array that is instantiated with the new[] operator 
// should also be deleted using the delete[] operator.  
// Write a program that proves that the destructors for 
// an array are not called when the array was instantiated 
// with new [] and the array was deleted with delete 
// (without the delete[] syntax).

// This program took 15 minutes to write and debug.

#include <vcl.h>
#include <iostream>

using namespace std;   // okay for small programs

int g_LiveInstances = 0;

struct Trivial {
  Trivial() {
    cout << "Creating object #" << ++g_LiveInstances << endl;
  }
  virtual ~Trivial() {
    cout << "Deleting an object" << endl;
    --g_LiveInstances;
  }
};

int main(int, char**) {
  Trivial *p = new Trivial[5];
  delete p;

  // This should show:
  //    Number of Trivial instantiations remaining: 4
  cout << "Number of Trivial instantiations remaining: ";
  cout << g_LiveInstances << endl;
  return 0;
}

Listing F: Array Destruction Test
Caseless string comparison

Write a String class that compares its strings by ignoring the case of the characters.
I had two choices when writing the caseless string comparison solution in Listing G. I could either create my own string class that stores a string using a has-a relationship or I could override the compare method in the std::char_traits class. The former would require me to write helper functions for all of the public and protected constructors and methods. I chose the latter solution because its code should be limited to a specialized std::char_traits class.

Notice that I didn't have to write any specialized comparison methods (operator==, operator<, operator>, and others). I used the template supplied by the STL, which calls _Traits::compare(). The static compare() method in CaselessTrait was created by debug-tracing a normal std::string comparison into the char_traits.h file. I copy-pasted the definition of compare() from char_traits into the solution and changed the comparison function from memcpy to strnicmp.

 // Code and debug time:  35 minutes.

#include <iostream>
#include <string>


template <class _CharT>
class CaselessTrait : public std::char_traits<_CharT>
{
public:
  static int _STLP_CALL compare(const char* __s1, 
                                const char* __s2, 
                                size_t __n)
    { return strnicmp(__s1, __s2, __n); }

};


// Not asked for by the problem but I threw it in anyway
std::ostream
&operator<<(std::ostream &os,
            const std::basic_string<char, CaselessTrait<char>, 
            std::allocator<char> > &obj
           )
{
  os << obj.c_str();
  return os;
}


int main(int, char**) {
  typedef std::basic_string<char, CaselessTrait<char> > CaselessString;
  CaselessString test1 = "Hello World";
  CaselessString test2 = "hello world";

  std::cout << test1 << std::endl;
  std::cout << test2 << std::endl;

  if (test1 == test2) {
    std::cout << "Strings are equal" << std::endl;
  }
  else {
    std::cout << "String are not equal" << std::endl;
  }
  return 0;
}
Listing G: Caseless string comparison
Time difference

A comma-delimited file has two columns: timeA and timeB. Both columns are times in the following format: hh:mm [a|p]m

where:
    hh is from 1 to 12.
    mm is from 1 to 60.
    [a|p] is either an 'a' or 'p'.

Example file:
5:57 pm,10:37 am
Write a program that reads the comma-delimited text file. For each line in the text file, report the time that is earlier. Assume all times are in the same time zone and that all times are for the same day.

The time comparison solution in Listing H primarily converts both times into the number of minutes past midnight and then simply compares those two values. I added some code that reports errors, such as when the file can't be opened or when the data format is grossly wrong.

The parsing algorithm in decodeTime() assumes the data is in the right format. The problem doesn't require anything more than this but in a real interview I would ask if the program should check for incorrectly formatted data or invalid data, such as 11:88am. My am/pm detection only checks for "pm" and assumes all other values, including "PM", are "am". I could have easily used stricmp instead of operator==(), but at that point in the parser I was assuming that the data would be correctly formatted. These are the kinds of tradeoffs one makes when keeping the solution simple and staying within the deadline.

 
// Code and debug time:  45 minutes

#include <fstream>
#include <iostream>

// okay for small programs
using namespace std;

// Time converted to the number of minutes past midnight
typedef unsigned int Time;


// Given a data value of the form:
//   hh:mm [a|p]m
// convert the string to the number of
// minutes past midnight.
Time decodeTime(const string text) {
  string::size_type colonPos = text.find(':');
  string::size_type blankPos = text.find(' ');

  int hours = atoi(text.substr(0, colonPos).c_str());
  int mins  = atoi(text.substr(colonPos+1, blankPos-colonPos).c_str());
  string amPm = text.substr(blankPos+1);

  // "midnight" and "noon" are special because we want
  // the number of minutes past midnight... so switch a 12 into
  // a 0 to accomodate the calculation.
  if (hours == 12) hours = 0;

  Time minsPastMidnight = mins;

  if (amPm == "pm")
    minsPastMidnight += (12 + hours) * 60;
  else
    minsPastMidnight += hours * 60;

  return minsPastMidnight;
}


int main(int argc, char* argv[]) {
  ifstream csv("data.csv", ios::in);
  if (!csv) {
    cout << "Can not open data.csv\n";
    return 1;
  }

  string line;   // line from CSV file
  while (getline(csv, line, '\n')) {
    // find the ',' separator
    string::size_type commaPos = line.find(',');
    if (commaPos == string::npos) {
      cout << "Invalid CSV line: " << line << endl;
    }
    else {
      Time firstTime = decodeTime(line.substr(0, commaPos));
      Time secondTime = decodeTime(line.substr(commaPos+1));
      if (firstTime < secondTime)
        cout << line.substr(0, commaPos) << endl;
      else
        cout << line.substr(commaPos+1) << endl;
    }
  }
  return 0;
}

Listing H: Array Destruction Test
Recursive sort

Sort a linked list using recursion.
The recursive sort algorithm in Listing I took a lot longer than I would have expected. My implementation assumes that only the head pointer is available. A flag, sortAgain, is initialized to false and is used to tell Sort() if any of the nodes in the list were swapped. If RecursiveSort() returns with sortAgain still false, the list has been sorted. Otherwise, sortAgain is reset to false and the list is resorted.

To keep the algorithm simple, I didn't make any attempt to keep track of the sorted and unsorted parts of the list. The entire list is sorted every time RecursiveSort is called.

Recursive sort solutions that swap the key values or swap the struct's payload values should be considered failures. Shuffling the data inside of the list defeats the purpose of using a linked list. The main reason for using a linked list is because the data is supposedly large or difficult to copy. If that were not the case, then an array would have been used. List nodes are being used to point to the data. The head pointer and the next pointers are the only parts of the list that need to be modified to sort it.

Don't forget to test your final solution for an empty list and for a list with only one item in it. The first version of my algorithm would have thrown an access violation for an empty list.


// Code and debug time: 1 hour, ten minutes.

#include <stdlib.h>   // for rand()
#include <algorithm>
#include <function>
#include <iostream>

struct List {
  List(int val) : key(val), next(NULL)
  {}
  int key;
  List *next;
};


// Called by Sort(List *) to recursively sort the
// linked list.
//
List * RecursiveSort(List *current, List *prev, bool &sortAgain) {
  List *head = current;

  if (current == NULL || current->next == NULL)
    return current;    // nothing to sort

  if (current->key > current->next->key) {
    if (prev == NULL) {
      head = current->next;
      current->next = head->next;
      head->next = current;
      current = head;
      sortAgain = true;
    }
    else {
      // The unsorted order of the nodes is:
      //    prev, current, node, after
      // The sorted order of the nodes is:
      //    prev, node, current, after
      List *node = current->next;
      List *after = node->next;

      head = current->next;
      prev->next = node;
      current->next = after;
      node->next = current;

      sortAgain = true;
    }
  }

  if (current->next != NULL) {
    RecursiveSort(current->next, current, sortAgain);
  }

  return head;
}



// Sort the single-linked list.
List * Sort(List *head) {
  // Keep sorting the list until the entire
  // list is sorted.
  bool sortAgain = false;
  do {
    sortAgain = false;
    head = RecursiveSort(head, NULL, sortAgain);
  } while (sortAgain == true);
  return head;
}


// Print the keys of the list separated by commas.
void Print(const List *head) {
  const List *node = head;
  std::cout << "List: ";
  while (node != NULL) {
    std::cout << node->key << ",";
    node = node->next;
  }
  std::cout << "\n";
}



int main(int, char**)
{
  // Create an unsorted array that will
  // be transformed into an unsorted linked
  // list.
  int a[10];
  const int numElements = sizeof(a) / sizeof(int);
  for(int i = 0; i < numElements; ++i)
    a[i] = i * (i % 2 ? -1 : 1);
  randomize();
  std::random_shuffle(&a[0], &a[numElements]);

  // Transfer the unsorted array into a list...
  List *head = NULL;
  List *tail = NULL;
  for(int i = 0; i < numElements; ++i) {
    List *node = new List(a[i]);
    if (head == NULL) {
      head = node;
      tail = node;
    }
    else {
      tail->next = node;
      tail = node;
    }
  }

  std::cout << "Before sort:\n";
  Print(head);

  head = Sort(head);

  std::cout << "\nAfter sort:\n";
  Print(head);

  return 0;
}

Listing I: Recursive Sort
Iterative list sorting

Sort a linked list without using recursion.
Listing J shows my solution for nonrecursively sorting the single-linked list. I cheated a little bit and used the recursive sort solution from listing I as a starting point. It's not really cheating, though, because I'm allowed to use whatever resources are available.

In the process of looking at the swap algorithm a second time, I noticed it could be improved a little. I think the version in listing J is a little clearer because only the work that's needed for the boundary condition (the very first element in the list) is inside of the if statement.

 
// Code and debug time: 15 minutes (using the RecursiveSort.cpp 
// as a starting point)

#include <stdlib.h>   // for rand()
#include <algorithm>
#include <function>
#include <iostream>

struct List {
  List(int val) : key(val), next(NULL)
  {}
  int key;
  List *next;
};


// Sort the single-linked list.
List * Sort(List *head) {
  if (head == NULL || head->next == NULL)
    return head;    // nothing to sort

  List *prev = NULL;
  List *current = NULL;

  bool sortAgain = false;
  do {
    sortAgain = false;
    current = head;
    prev = NULL;
    while (current != NULL && current->next != NULL) {
      if (current->key > current->next->key) {
        sortAgain = true;

        // The unsorted order of the nodes is:
        //    prev, current, node, after
        // The sorted order of the nodes is:
        //    prev, node, current, after
        List *node = current->next;
        List *after = node->next;

        if (prev == NULL) {
          head = current->next;
        }
        else {
          prev->next = node;
        }
        current->next = after;
        node->next = current;
      }
      prev = current;
      current = current->next;
    }
  } while (sortAgain == true);

  return head;
}



// Print the keys of the list separated by commas.
void Print(const List *head) {
  const List *node = head;
  std::cout << "List: ";
  while (node != NULL) {
    std::cout << node->key << ",";
    node = node->next;
  }
  std::cout << "\n";
}



int main(int, char**)
{
  // Create an unsorted array that will
  // be transformed into an unsorted linked
  // list.
  int a[10];
  const int numElements = sizeof(a) / sizeof(int);
  for(int i = 0; i < numElements; ++i)
    a[i] = i * (i % 2 ? -1 : 1);
  randomize();
  std::random_shuffle(&a[0], &a[numElements]);

  // Transfer the unsorted array into a list...
  List *head = NULL;
  List *tail = NULL;
  for(int i = 0; i < numElements; ++i) {
    List *node = new List(a[i]);
    if (head == NULL) {
      head = node;
      tail = node;
    }
    else {
      tail->next = node;
      tail = node;
    }
  }

  std::cout << "Before sort:\n";
  Print(head);

  head = Sort(head);

  std::cout << "\nAfter sort:\n";
  Print(head);

  return 0;
}

Listing J: Iterative List Sorting
Reversing a single linked list

Reverse a single-linked list without using recursion.
My solution for reversing the single-linked list, in Listing K, was based on the code in Listing J. The solution does not overwrite the next pointer for the head node until the entire list has been sorted. I thought this would be easier than checking, on each loop iteration, if the head node was being modified.

As with the sorting solutions, any solutions that involve moving the data values instead of changing the head and next pointers is a failure.

If I were to provide the linked list problems as an interviewer, I would provide everything in the solution except for the sorting or reversing method and everything in the main() function up to the first Print method.

 
// Code and debug time: 20 minutes (using the 
// IterativeSort.cpp as a starting point)

#include <iostream>

struct List {
  List(int val) : key(val), next(NULL)
  {}
  int key;
  List *next;
};



// Print the keys of the list separated by commas.
void Print(const List *head) {
  const List *node = head;
  std::cout << "List: ";
  while (node != NULL) {
    std::cout << node->key << ",";
    node = node->next;
  }
  std::cout << "\n";
}


List * ReverseList(List *head) {
  if (head == NULL || head->next == NULL)
    return head;    // Nothing to reverse;

  // Reverse the list except for the
  // head node.
  List *prev = head;
  List *current = prev->next;
  while (current != NULL) {
      List *after = current->next;
      current->next = prev;    // reverse the list
      prev = current;
      current = after;
  }

  // In the reversed list, the head element becomes
  // the last element, so terminate the list at
  // the head element
  head->next = NULL;
  return prev;
}


int main(int, char**)
{
  const int numElements = 10;

  // Create a list from 0..9:
  List *head = NULL;
  List *tail = NULL;
  for(int i = 0; i < numElements; ++i) {
    List *node = new List(i);
    if (head == NULL) {
      head = node;
    }
    else {
      tail->next = node;
    }
    tail = node;
  }

  std::cout << "Before Reverse:\n";
  Print(head);

  head = ReverseList(head);

  std::cout << "\nAfter Reverse:\n";
  Print(head);

  return 0;
}

Listing K: Reversing a Single Linked List









	
	
Answers for C++ Language Lawyer Questions
by Curtis Krauskopf
Language lawyer questions sometimes seem pointless, but they come into practice when you're modifying a program written by someone else. The previous developer might have misunderstood a part of the language or the language might have changed since the code was written. Being able to know the details of the language and even know how the language has changed over the years shows that you're able to understand the existing programs that the customer or employer has.

Q1) Show an example of a valid C program that fails to compile in C++.

A1) Use any C++ keyword that doesn't exist in C. The class keyword is a good example: int class = 5;

Q2) Show an example of a valid C program that compiles cleanly in C++ but gives a different result.

A2) This one is a little bit trickier. We want some feature in C++ that wasn't backwards compatible with C. Thinking outside of the box, you could come up with:


#ifdef __cplusplus
  printf("I am C++\n");
#else
  printf("I am C\n");
#endif

The interviewer might accept that the __cplusplus compiler directive was not defined in a normal C program.

However, keeping with the spirit of the question, there are a couple reasonable solutions available:

1. C++ comments use both // and /* */ whereas standard C uses only //. If you can construct an expression in a C program that contains /* and */, it will compile cleanly in both compilers but give different runtime results.

2. Literal characters in C (such as 'a'), are of type int. Therefore, in C, sizeof('a') is the same as sizeof(int). Literal characters in C++ are of type char. On all Borland C++ compilers, sizeof(int) != sizeof(char).

David Tribble's web site contains a detailed synopsis of the incompatibilities between C and C++.

Q3) Why won't this compile?


for (int i = 0; i < 10; i++) {
  for (int k = 0; k < 10; k++) {
    if (e == 0) goto next_i;
  }
  next_i;
} 


A3) The next_i label needs a colon (:) after it, like this: next_i:

Q4) Is there a "placement delete"?

A4) No, but you can write your own. Stroustrup discusses this on his C++ FAQ page at att.com.








	
Answers to Unfair C++ Job Interview Questions
by Curtis Krauskopf
Preparing for unfair questions will also prepare you for the toughest 'fair' questions. In both cases, just remain calm, think about your answer and then proceed. Whatever you do, don't argue with the interviewer or complain that the question is unfair.

If it's a legally unfair question (a question that should not be asked during an interview), then proceed using your best judgment. An article on CareerBuilder.com that is no longer available provided several provided several techniques for dodging a question without being antagonistic:

In the United States...

[t]here are several questions that employers may not legally ask applicants. Federal law attempts to ensure that candidates are hired on job qualifications and not by prejudicial criteria. Questions structured to obtain information on race, gender, religion, marital status, age, physical and/or mental status, ethnic background, country of origin, sexual preference, or any other discriminatory factor are generally illegal as grounds for making employment decisions. With few exceptions, these factors contribute nothing to your ability to perform a job, and an employer must substantiate those cases where a direct relationship is thought to exist. Anything that is not a bona fide occupational qualification may not be covered directly, although the interviewer may seek the information indirectly.
Most unfair questions that are not illegal do not have a specific right answer. Many of them depend on your people-skills and being able to read the situation. Consider the situation the same as if you were working a trade-show booth and a potential customer came up to you and asked you a loaded or unfair question. How would you turn that situation around to be a positive for your company and for yourself?

I personally know one person who was given exactly that kind of situation at a trade show. Unbeknownst to my coworker, his company's president was within earshot of the entire exchange. Within two months, my coworker was promoted to a much higher position within the company. Part of the promotion was due to hard work, but part of it was undoubtedly due to the way he handled the customer that had a problem. The other lesson in this example is that you're always interviewing for your next position. Practicing your people-skills will set you apart from the workers who just write code all day long.

Q1) The interviewer looks up from his newspaper, tosses a pencil at you and says, "Sell me this pencil". The interviewer immediately returns to reading his newspaper.

A1) You might be able to relate to this question if you've ever had to sell a programming idea to a negative audience or had to get your boss' attention on an important matter when she seemed distracted. Remember that there is no right answer so whatever you do, other than complain, is an acceptable answer.

Depending on your personality, you might take a passive approach and simply toss the pencil back to the interviewer and say, "Here, you just bought it". A more aggressive responder would yank the newspaper from the interviewer and go into a sales pitch that starts with "You need this pencil because...". If you have the interviewer's phone number in your cell phone, you could call the interviewer and start selling them the pencil when they answer the phone. Do whatever suits your personality best - this way, you will feel the most comfortable while answering the question.

Q2) The interviewer hands you a black pen and says nothing but "This pen is red."

A2) Remember the interviewer I had that thought Java and JavaScript were the same thing? This is almost the same type of question but in my case, the interviewer was seriously ignorant. When I looked at his coworkers to get a read of whether he was trying to trick me or not, they were so embarrassed that they looked like they wanted to crawl under the table.

For the red pen problem, I would write on a piece of paper to see if the ink was black or red even though the outer shell was black. You never know -- he might have installed the ink reservoir from a red pen. If the ink was red, I would agree with him. If it was black, I would show him the proof on the paper.

Q3) Write a program whose output is its own source code.

A3) A program whose output is its own source is called a quine. Some people think those kinds of programs are interesting. The techniques involved in making a quine have applications in compiler, decompiler, and encryption technologies.

Depending on the mood of the interviewer, you could initially try:


cout << "its own source code";

which the interviewer would have to admit does answer the question. A solution that is closer to the spirit of the question is in Listing L.

The interviewer might insist on a self-contained solution that doesn't use external files or resources. I found one on the Internet that is only four lines of code.

 #include<stdio.h>
#include<conio.h>
#include<iostream.h>

int main(int, char**) {
  FILE *fp;
  fp = fopen("myself.cpp","r");
  char buffer[80];
  while (fgets(buffer,sizeof(buffer),fp)) {
    cout << buffer;
  }
  return 0;
}
Listing L: A program whose output is its own source code.
Q4) Tell me the funniest programming joke you've ever heard.

A4) For this unfair question, there's obviously no right answer and the interviewer is just seeing how well you can think "on-your-feet". If you can't think of a joke, you can just make one up on the spot. You can make your own variation of a classic joke ("Three programmers walk into a bar...") or tell about a time when something humorous happened at work. You could resite your favorite xkcd cartoon.

Whatever your response, remember to have fun with the unfair questions. If the question is clearly unfair, and the interviewer just wants to see how you respond to a situation, then go along with the situation. You can decide later if you want to work for the company based on the kinds of interview questions that were asked.
















---------------------------------------------------------------------------------------------------- 

	23.3 
	23.4 
	23.5 
	23.6 
	23.7 
	23.8 
	23.9 


24. Secure coding

	24.1 Cisco, CERT course

		24.1.1  strings

			24.1.1.1 Character strings 
A string consists of a contiguous sequence of characters terminated by and including the first null character (C11 §7.1.1 p1). A pointer to a string points to its initial character. The length of a string is the number of bytes preceding the null character, and the value of a string is the sequence of the values of the contained characters, in order. Here is a string representation of “hello”:
string representation of hello

Strings are implemented as arrays of characters and are susceptible to the same problems as arrays.

As a result, secure coding practices for arrays should also be applied to null-terminated character strings (see the Arrays (ARR) chapter of The CERT C Secure Coding Standard). When dealing with character arrays, it is useful to define some terms: [1]

Bound
    (Definition)
    The number of elements in the array.

Lo
    (Definition)
    The address of the first element of the array.

Hi
    (Definition)
    The address of the last element of the array.

TooFar
    (Definition)
    The address of the one-too-far element of the array, the element just past the Hi element.

Target-size (Tsize)
    (Definition)
    Same as sizeof(array).

The C standard allows for the creation of pointers that point one past the last element of the array object (C11 §6.5.6 p8), although these pointers cannot be dereferenced without invoking undefined behavior. When dealing with strings, some extra terms are also useful:

Null terminated
    (Definition)
    At or before Hi, the null terminator is present. 

Length
    (Definition)
    Number of characters prior to the null terminator.

Example
Array Size

One of the problems with arrays is determining the number of elements. In this example, the function clear() uses the idiom sizeof(array) / sizeof(array[0]) to determine the number of elements in the array. However, array is a pointer type because it is a parameter. As a result, sizeof(array) is equal to sizeof(int *). For example, on an architecture (such as x86-32) where sizeof(int) == 4 and sizeof(int *) == 4, the expression sizeof(array) / sizeof(array[0]) evaluates to 1, regardless of the length of the array passed, leaving the rest of the array unaffected.
01	void clear(int array[]) {
02	  for (size_t i = 0; i < sizeof(array) / sizeof(array[0]); ++i) {
03	     array[i] = 0;
04	   }
05	}
06	  
07	void dowork(void) {
08	  int dis[12];
09	  
10	  clear(dis);
11	  /* ... */
12	}

This is because the sizeof operator yields the size of the adjusted (pointer) type when applied to a parameter declared to have array or function type (C11 §6.5.3.4). The strlen() function can be used to determine the length of a properly null-terminated character string but not the space available in an array. The CERT C Secure Coding Standard includes ARR01-C. Do not apply the sizeof operator to a pointer when taking the size of an array, which warns against this problem.

				24.1.1.1.1 ARR01-C. Do not apply the sizeof operator to a pointer when taking the size of an array
Skip to end of metadata

    Added by Robert C. Seacord, last edited by Carol J. Lallier on Jun 14, 2012  (view change)

Go to start of metadata

The sizeof operator yields the size (in bytes) of its operand, which can be an expression or the parenthesized name of a type. However, using the sizeof operator to determine the size of arrays is error prone.
Noncompliant Code Example

In this noncompliant code example, the function clear() zeros the elements in an array. The function has one parameter declared as int array[] and is passed a static array consisting of 12 int as the argument. The function clear() uses the idiom sizeof(array) / sizeof(array[0]) to determine the number of elements in the array. However, array has a pointer type because it is a parameter. As a result, sizeof(array) is equal to the sizeof(int *). For example, on an architecture (such as IA-32) where the sizeof(int) == 4 and the sizeof(int *) == 4, the expression sizeof(array) / sizeof(array[0]) evaluates to 1, regardless of the length of the array passed, leaving the rest of the array unaffected.
void clear(int array[]) {
  for (size_t i = 0; i < sizeof(array) / sizeof(array[0]); ++i) {
     array[i] = 0;
   }
}
 
void dowork(void) {
  int dis[12];
 
  clear(dis);
  /* ... */
}

Footnote 103 in Section 6.5.3.4 of the C standard [ISO/IEC 9899:2011] explains:

    When applied to a parameter declared to have array or function type, the sizeof operator yields the size of the adjusted (pointer) type.

This applies to all array parameters.
Compliant Solution

In this compliant solution, the size of the array is determined inside the block in which it is declared and passed as an argument to the function.
void clear(int array[], size_t len) {
    for (size_t i = 0; i < len; i++) {
     array[i] = 0;
  }
}
 
void dowork(void) {
  int dis[12];
 
  clear(dis, sizeof(dis) / sizeof(dis[0]));
  /* ... */
}

This sizeof(array) / sizeof(array[0]) idiom will succeed provided the original definition of array is visible.
Noncompliant Code Example

In this noncompliant code example, the sizeof a does not equal 100 * sizeof(int) because the sizeof operator, when applied to a parameter declared to have array or function type, yields the size of the adjusted (pointer) type, even if the parameter declaration specifies a length.
enum {ARR_LEN = 100};
 
void clear(int a[ARR_LEN]) {
  memset(a, 0, sizeof(a)); /* error */
}
 
int main(void) {
  int b[ARR_LEN];
  clear(b);
  assert(b[ARR_LEN / 2]==0); /* may fail */
  return 0;
}
Compliant Solution

In this compliant solution, the size is specified using the expression len * sizeof(int).
enum {ARR_LEN = 100};
 
void clear(int a[], size_t len) {
  memset(a, 0, len * sizeof(int));
}
 
int main(void) {
  int b[ARR_LEN];
  clear(b, ARR_LEN);
  assert(b[ARR_LEN / 2]==0); /* cannot fail */
  return 0;
}
Risk Assessment

Incorrectly using the sizeof operator to determine the size of an array can result in a buffer overflow, allowing the execution of arbitrary code.

Recommendation
	

Severity
	

Likelihood
	

Remediation Cost
	

Priority
	

Level

ARR01-C
	

high
	

probable
	

low
	

P18
	

L1
Automated Detection

Tool
	

Version
	

Checker
	

Description

Splint
	V. 3.1.1	

 
	

 

Compass/ROSE
	

 
	

 
	

Can detect violations of the recommendation but cannot distinguish between incomplete array declarations and pointer declarations.

LDRA tool suite
	V. 8.5.4	

401 S
	

Partially implemented.
Related Vulnerabilities

Search for vulnerabilities resulting from the violation of this rule on the CERT website.
Related Guidelines

CERT C++ Secure Coding Standard: ARR01-CPP. Do not apply the sizeof operator to a pointer when taking the size of an array

ISO/IEC 9899:2011 Section 6.7.6.2, "Array declarators"

MITRE CWE: CWE-467, "Use of sizeof() on a pointer type"
Bibliography

[Drepper 2006] Section 2.1.1, "Respecting memory bounds"


				24.1.1.1.2 did I get this
Array Size

The characters in a string belong to the character set interpreted in the execution environment—the execution character set (C11 §5.2.1). These characters consist of a basic character set, defined by the C standard, and a set of zero or more extended characters, which are not members of the basic character set. The values of the members of the execution character set are implementation defined but may, for example, be the values of the 7-bit US ASCII character set.

C uses the concept of a locale, which can be changed by the setlocale() function, to keep track of various conventions such as language and punctuation supported by the implementation. The current locale determines which characters are available as extended characters.

The basic execution character set includes the 26 uppercase and 26 lowercase letters of the Latin alphabet, the 10 decimal digits, 29 graphic characters, the space character, and control characters representing horizontal tab, vertical tab, form feed, alert, backspace, carriage return, and newline. The representation of each member of the basic character set fits in a single byte. A byte with all bits set to 0, called the null character, must exist in the basic execution character set; it is used to terminate a character string.

The execution character set may contain a large number of characters and therefore require multiple bytes to represent some individual characters in the extended character set. It is called a multibyte character set. In this case, the basic characters must still be present, and each character of the basic character set is encoded as a single byte. The presence, meaning, and representation of any additional characters are locale specific. A string may sometimes be called a multibyte string to emphasize that it might hold multibyte characters. These are not the same as wide strings in which each character has the same length.

A multibyte character set may have a state-dependent encoding, wherein each sequence of multibyte characters begins in an initial shift state and enters other locale-specific shift states when specific multibyte characters are encountered in the sequence. While in the initial shift state, all single-byte characters retain their usual interpretation and do not alter the shift state. The interpretation for subsequent bytes in the sequence is a function of the current shift state.

				24.1.1.1.3 UTF-8

UTF-8
Learning Objectives

    Recognize and identify the different string types in C and C++ language programs.

UTF-8 is a multibyte character set that can represent every character in the Unicode character set but is also backwards-compatible with the 7-bit US ASCII character set. Each UTF-8 character is represented by 1 to 4 bytes. If the character is encoded by just 1 byte, the high-order bit is 0 and the other bits give the code value (in the range 0 to 127). If the character is encoded by a sequence of more than 1 byte, the first byte has as many leading 1 bits as the total number of bytes in the sequence, followed by a 0 bit, and the succeeding bytes are all marked by a leading 10-bit pattern. The remaining bits in the byte sequence are concatenated to form the Unicode code point value (in the range 0x80 to 0x10FFFF). Consequently, a byte with lead bit 0 is a single-byte code, a byte with multiple leading 1 bits is the first of a multibyte sequence, and a byte with a leading 10-bit pattern is a continuation byte of a multibyte sequence. The format of the bytes allows the beginning of each sequence to be detected without decoding from the beginning of the string.
Code point range	Binary code point	UTF-8 bytes	Example
U+0000 to U+007F 	0xxxxxxx 	0xxxxxxx 	character "$"= code point U+0024 = 00100100 → 00100100 → hexadecimal 24
U+0080 to U+07FF 	00000yyy yyxxxxxx 	110yyyyy 10xxxxxx 	character "¢"= code point U+00A2 = 00000000 10100010 → 11000010 10100010 → hexadecimal C2 A2
U+0800 to U+FFFF 	zzzzyyyy yyxxxxxx 	1110zzzz 10yyyyyy 10xxxxxx 	character "€"= code point U+20AC = 00100000 10101100 → 11100010 10000010 10101100 → hexadecimal E2 82AC
U+010000 to U+10FFFF 	000wwwzz zzzzyyyy yyxxxxxx 	11110www 10zzzzzz 10yyyyyy 10xxxxxx 	character "" = code point U+024B62 = 00000010 01001011 01100010 → 11110000 10100100 10101101 10100010 → hexadecimal F0 A4 AD A2

The first 128 characters comprise the basic execution character set; each of these characters fits in a single byte.

UTF-8 decoders are sometimes a security hole. In some circumstances, an attacker can exploit an incautious UTF-8 decoder by sending it an octet sequence that is not permitted by the UTF-8 syntax. The CERT C Secure Coding Standard includes MSC10-C. Character Encoding - UTF-8 Related Issues, which describes this problem and other UTF-8-related issues.

					24.1.1.1.3.1 MSC10-C. Character Encoding - UTF8 Related Issues
Skip to end of metadata

    Added by Xiaoyi Fei, last edited by Carol J. Lallier on Jul 21, 2012  (view change)

Go to start of metadata

UTF-8 is a variable-width encoding for Unicode. UTF-8 uses 1 to 4 bytes per character, depending on the Unicode symbol. UTF-8 has the following properties:

    The classical US-ASCII characters (0 to 0x7f) encode as themselves, so files and strings that are encoded with ASCII values have the same encoding under both ASCII and UTF-8.
    All UCS characters beyond (0x7f) are encoded as a multibyte sequence consisting only of bytes in the range of 0x80 to 0xfd. This means that no ASCII byte (including a null byte) can appear as part of another character. This property supports the use of string-handling functions.
    It is easy to convert between UTF-8 and UCS-2 and UCS-4 fixed-width representations of characters.
    The lexicographic sorting order of UCS-4 strings is preserved.
    All possible 2^31 UCS codes can be encoded using UTF-8.

Generally, programs should validate UTF-8 data before performing other checks. The following table lists all valid UTF-8 sequences.

UCS Code (HEX) Binary UTF-8 Format Valid UTF-8 Values (HEX)

00-7F 0xxxxxxx 00-7F 
80-7FF 110xxxxx 10xxxxxx C2-DF 80-BF
800-FFF 1110xxxx 10xxxxxx 10xxxxxx E0 A0*-BF 80-BF
1000-FFFF 1110xxxx 10xxxxxx 10xxxxxx E1-EF 80-BF 80-BF
10000-3FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx F0 90*-BF 80-BF 80-BF
40000-FFFFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx F1-F3 80-BF 80-BF 80-BF
40000-FFFFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx F1-F3 80-BF 80-BF 80-BF
100000-10FFFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx F4 80-8F* 80-BF 80-BF

Although UTF-8 originated from the Plan 9 developers [Pike 1993], Plan 9's own support covers only the low 16-bit range. In general, many "Unicode" systems support only the low 16-bit range, not the full 31-bit ISO 10646 code space [ISO/IEC 10646:2003(E)].
Security-Related Issues

According to [Yergeau 1998],

    Implementors of UTF-8 need to consider the security aspects of how they handle invalid UTF-8 sequences. It is conceivable that, in some circumstances, an attacker would be able to exploit an incautious UTF-8 parser by sending it an octet sequence that is not permitted by the UTF-8 syntax.

    A particularly subtle form of this attack can be carried out against a parser that performs security-critical validity checks against the UTF-8 encoded form of its input, but interprets certain invalid octet sequences as characters. For example, a parser might prohibit the null character when encoded as the single-octet sequence 00, but allow the invalid two-octet sequence C0 80 and interpret it as a null character. Another example might be a parser which prohibits the octet sequence 2F 2E 2E 2F ("/../"), yet permits the invalid octet sequence 2F C0 AE 2E 2F.

Following are more specific recommendations.
Accept Only the Shortest Form

Only the "shortest" form of UTF-8 should be permitted. Naive decoders might accept encodings that are longer than necessary, allowing for potentially dangerous input to have multiple representations. For example,

    Process A performs security checks but does not check for nonshortest UTF-8 forms.
    Process B accepts the byte sequence from process A and transforms it into UTF-16 while interpreting possible nonshortest forms.
    The UTF-16 text may contain characters that should have been filtered out by process A and can potentially be dangerous. These "nonshortest" UTF-8 attacks have been used to bypass security validations in high-profile products, such as Microsoft's IIS Web server.

Corrigendum #1: UTF-8 Shortest Form to the Unicode Standard [Unicode 2006] describes modifications to version 3.0 of the Unicode Standard necessary to define what is meant by the shortest form.
Handling Invalid Inputs

UTF-8 decoders have no uniformly defined behavior upon encountering an invalid input. Following are several ways a UTF-8 decoder might behave in the event of an invalid byte sequence:

    Insert a replacement character (e.g., ?, the wildcard character).
    Ignore the bytes.
    Interpret the bytes according to a different character encoding (often the ISO-8859-1 character map).
    Fail to notice but decode as if the bytes were some similar bit of UTF-8.
    Stop decoding and report an error.

The following function from John Viega's "Protecting Sensitive Data in Memory" [Viega 2003] detects invalid character sequences in a string but does not reject nonminimal forms. It returns 1 if the string is composed only of legitimate sequences; otherwise, it returns 0.
int spc_utf8_isvalid(const unsigned char *input) {
  int nb;
  const unsigned char *c = input;
 
  for (c = input;  *c;  c += (nb + 1)) {
    if (!(*c & 0x80)) nb = 0;
    else if ((*c & 0xc0) == 0x80) return 0;
    else if ((*c & 0xe0) == 0xc0) nb = 1;
    else if ((*c & 0xf0) == 0xe0) nb = 2;
    else if ((*c & 0xf8) == 0xf0) nb = 3;
    else if ((*c & 0xfc) == 0xf8) nb = 4;
    else if ((*c & 0xfe) == 0xfc) nb = 5;
    while (nb-- > 0)
      if ((*(c + nb) & 0xc0) != 0x80) return 0;
  }
  return 1;
}
Broken Surrogates

Encoding of individual or out-of-order surrogate halves should not be permitted. Broken surrogates are invalid in Unicode and introduce ambiguity when they appear in Unicode data. Broken surrogates are often signs of bad data transmission. They can also indicate internal bugs in an application or intentional efforts to find security vulnerabilities.
Risk Assessment

Failing to properly handle UTF8-encoded data can result in a data integrity violation or denial-of-service attack.

Recommendation Severity Likelihood Remediation Cost Priority Level

MSC10-C medium unlikely high P2 L3
Automated Detection

Tool Version Checker Description

LDRA tool suite V. 8.5.4	176 S 376 S
	

Fully implemented.
Related Vulnerabilities

Search for vulnerabilities resulting from the violation of this rule on the CERT website.
Related Guidelines

CERT C++ Secure Coding Standard: MSC10-CPP. Character Encoding - UTF8 Related Issues

ISO/IEC TR 24772 "AJN Choice of filenames and other external identifiers"

MITRE CWE: CWE-176, "Failure to handle Unicode encoding" and CWE-116, "Improper encoding or escaping of output"

						24.1.1.1.3.1.1 learn by doing
Not counting the null-termination character, how many characters are in the following UTF-8 string?

char str[] = "\xD4\xBC\xF0\x9D\x90\x84\x45\xC6\xAC\x00";

Answer:

- 10.
wrong This is the size in bytes of the array containing the string.

- 9 
wrong, this is strlen()

- 4 
yes.
The first 2 bytes make up the first character. The next 4 bytes make up the second character. The seventh byte makes up the third character. The eighth and ninth bytes make up the 4th character

explain:
D4 -bin: 11010100 - so two bytes char D4 BC
F0 - bin: 11110000 - so 4 bytes char F0 9D 90 84
45 - bin: 01000101 - 1 byte char
C6 - bin: 11000110 - 2 byte char C6 AC
00 - null

						24.1.1.1.3.1.2

				24.1.1.1.4 Wide Strings
Learning Objectives

    Recognize and identify the different string types in C and C++ language programs.

To process the characters of a large character set, a program may represent each character as a wide character, which generally takes more space than an ordinary character. Most implementations choose either 16 or 32 bits to represent a wide character. The problem of sizing wide strings is covered in Sizing Strings.

A wide string is a contiguous sequence of wide characters terminated by and including the first null wide character. A pointer to a wide string points to its initial (lowest addressed) wide character. The length of a wide string is the number of wide characters preceding the null wide character, and the value of a wide string is the sequence of code values of the contained wide characters, in order.

				24.1.1.1.5 String Literals
Learning Objectives

    Recognize and identify the different string types in C and C++ language programs.

A character string literal is a sequence of zero or more characters enclosed in double quotes, as in "xyz". A wide string literal is the same, except prefixed by the letter L, as in L"xyz".

In a character constant or string literal, members of the character set used during execution are represented by corresponding members of the character set in the source code or by escape sequences consisting of the backslash \ followed by one or more characters. A byte with all bits set to 0, called the null character, must exist in the basic execution character set; it is used to terminate a character string.

During compilation, the multibyte character sequences specified by any sequence of adjacent character and identically prefixed string literal tokens are concatenated into a single multibyte character sequence. If any of the tokens have an encoding prefix, the resulting multibyte character sequence is treated as having the same prefix; otherwise, it is treated as a character string literal. Whether differently prefixed wide string literal tokens can be concatenated (and, if so, the treatment of the resulting multibyte character sequence) is implementation defined. For example, each of the following sequences of adjacent string literal tokens

    "a" "b" L"c"
    "a" L"b" "c"
    L"a" "b" L"c"
    L"a" L"b" L"c"

is equivalent to the string literal

    L"abc"

Next, a byte or code of value zero is appended to each character sequence that results from a string literal or literals. (A character string literal need not be a string, because a null character may be embedded in it by a \0 escape sequence.) The character sequence is then used to initialize an array of static storage duration and length just sufficient to contain the sequence. For character string literals, the array elements have type char and are initialized with the individual bytes of the character sequence. For wide string literals, the array elements have type wchar_t and are initialized with the sequence of wide characters corresponding to the character sequence, as defined by the mbstowcs() (multibyte string to wide character string) function with an implementation defined current locale. The value of a string literal containing a character or escape sequence not represented in the execution character set is implementation defined.

The type of a string literal is an array of char in C, but it is an array of const char in C++. Consequently, a string literal is modifiable in C. However, if the program attempts to modify such an array, the behavior is undefined—and therefore such behavior is prohibited by The CERT C Secure Coding Standard STR30-C. Do not attempt to modify string literals. One reason for this rule is that the C standard does not specify that these arrays must be distinct, provided their elements have the appropriate values. For example, compilers sometimes store multiple identical string literals at the same address, so that modifying one such literal might have the effect of changing the others as well. Another reason for this rule is that string literals are frequently stored in read-only memory (ROM).

The C standard allows an array variable to be declared both with a bound index and with an initialization literal. The initialization literal also implies an array size in the number of elements specified. For strings, the size specified by a string literal is the number of characters in the literal plus one for the terminating null character.

Array variables are often initialized by a string literal (C11 §6.7.9 p14) and declared with an explicit bound that matches the number of characters in the string literal. For example, the following declaration initializes an array of characters using a string literal that defines one more character (counting the terminating '\0') than the array can hold.

const char s[3] = "abc";

The size of the array s is 3, although the size of the string literal is 4; consequently, the trailing null byte is omitted. Any subsequent use of the array as a null-terminated byte string can result in a vulnerability, because s is not properly null-terminated.

A better approach is to not specify the bound of a string initialized with a string literal because the compiler will automatically allocate sufficient space for the entire string literal, including the terminating null character.

    const char s[] = "abc";

This approach also simplifies maintenance, because the size of the array can always be derived even if the size of the string literal changes. This issue is further described by The CERT C Secure Coding Standard STR36-C. Do not specify the bound of a character array initialized with a string literal. 
					24.1.1.1.5.1 STR30-C. Do not attempt to modify string literals
Skip to end of metadata

    Added by Confluence Administrator, last edited by Carol J. Lallier on Jun 14, 2012  (view change)

Go to start of metadata

A string literal is a sequence of zero or more multibyte characters enclosed in double quotes (for example, "xyz"). A wide string literal is the same, except prefixed by the letter 'L' (for example, L"xyz").

At compile time, string literals are used to create an array of static storage duration of sufficient length to contain the character sequence and a null-termination character. It is unspecified whether these arrays are distinct. The behavior is undefined if a program attempts to modify string literals but frequently results in an access violation because string literals are typically stored in read-only memory. See also undefined behavior 33  of Annex J of the C standard [ISO/IEC 9899:2011].

Do not attempt to modify a string literal. Use a named array of characters to obtain a modifiable string.
Noncompliant Code Example

In this noncompliant code example, the char pointer p is initialized to the address of a string literal. Attempting to modify the string literal results in undefined behavior.
char *p  = "string literal";
p[0] = 'S';
Compliant Solution

As an array initializer, a string literal specifies the initial values of characters in an array as well as the size of the array. (See STR36-C. Do not specify the bound of a character array initialized with a string literal.) This code creates a copy of the string literal in the space allocated to the character array a. The string stored in a can be safely modified.
char a[] = "string literal";
a[0] = 'S';
Noncompliant Code Example

In this noncompliant code example, a string literal is passed to the (pointer to non-const) parameter of the POSIX function mkstemp(), which then modifies the characters of the string literal.
char *fname;
fname = mkstemp("/tmp/edXXXXXX");
Compliant Solution

Instead of passing a string literal, use a named array:
static char fname[] = "/tmp/edXXXXXX";
mkstemp(fname);
Noncompliant Code Example (Result of strrchr())

In this noncompliant example, the non-const char* result of the strrchr() function is used to modify the object pointed to by pathname. Because the pointer points to a string literal, the effects of the modification are undefined and are likely to cause a signal, such as SIGSEGV, to be generated for the process if the object is stored in read-only memory.
const char* get_dirname(const char* pathname) {
  char* slash;
  slash = strrchr(pathname, '/');
  if (slash)
    *slash = '\0'; /* undefined behavior */
  return pathname;
}
 
int main() {
  puts(get_dirname(__FILE__));
  return 0;
}
Compliant Solution (Result of strrchr())

A compliant solution avoids modifying a const object, even if it is possible to obtain a non-const pointer to such an object by calling a standard C library function, such as strrchr(). To reduce the risk of callers of get_dirname() passing constant objects to the function, the argument is declared to be a non-const pointer. Although converting a string literal to non-const char* is permitted by the language, conforming compilers could issue a diagnostic for such code. See also EXP05-C. Do not cast away a const qualification.
char* get_dirname(char* pathname) {
  char* slash;
  slash = strrchr(pathname, '/');
  if (slash)
    *slash = '\0';
  return pathname;
}
 
int main() {
  char pathname[] = __FILE__;
  /* calling get_dirname(__FILE__) may be diagnosed */
  puts(get_dirname(pathname));
  return 0;
}
Risk Assessment

Modifying string literals can lead to abnormal program termination and possibly denial-of-service attacks.

Rule Severity Likelihood Remediation Cost Priority Level

STR30-C low likely low P9 L2

Automated Detection
Tool Version Checker Description LDRA tool suite
	V. 8.5.4	157 S Partially implemented.
Splint V. 3.1.1	 	
Compass/ROSE
	 	 	

Can detect simple violations of this rule.
Related Vulnerabilities

Search for vulnerabilities resulting from the violation of this rule on the CERT website.
Related Guidelines

CERT C++ Secure Coding Standard: STR30-CPP. Do not attempt to modify string literals

ISO/IEC 9899:2011 Section 6.4.5, "String literals"

ISO/IEC TR 17961 (Draft) Modifying string literals [strmod]
Bibliography

[Summit 1995] comp.lang.c FAQ list, Question 1.32
[Plum 1991] Topic 1.26, "strings—string literals"


					24.1.1.1.5.2 did I get this
const char s[3] = "xyz"; char t[10] ; strcpy (t,s);

why undefined behavior?

b/c s is a char array and not a null terminated string


					24.1.1.1.5.3

				24.1.1.1.6 Standard strings


Multibyte strings and wide strings are both common data types in C++ programs, but many attempts have been made to also create string classes. Most C++ developers have written at least one string class, and a number of widely accepted forms exist. The standardization of C++ [1] promotes the standard class template std::basic_string. The basic_string template represents a sequence of characters. It supports sequence operations as well as string operations such as search and concatenation and is parameterized by character type:

    string is a typedef for the template specialization basic_string<char>
    wstring is a typedef for the template specialization basic_string<wchar_t>

Because the C++ standard defines additional string types, C++ also defines additional terms for multibyte strings. A null-terminated byte string, or NTBS, is a character sequence whose highest addressed element with defined content has the value zero (the terminating null character); no other element in the sequence has the value zero (C++ 2011 §17.5.2.1.4.1). A null-terminated multibyte string, or NTMBS, is an NTBS that constitutes a sequence of valid multibyte characters beginning and ending in the initial shift state (C++ 2011 §17.5.2.1.4.2).

The basic_string class template specializations are less prone to errors and security vulnerabilities than are null-terminated byte strings. Unfortunately, there is a mismatch between C++ string objects and null-terminated byte strings. Specifically, most C++ string objects are treated as atomic entities (usually passed by value or reference) whereas existing C library functions accept pointers to null-terminated character sequences. In the standard C++ string class, the internal representation does not have to be null-terminated, [2] although all common implementations are null-terminated. Some other string types, like Win32 LSA_UNICODE_STRING, do not have to be null-terminated either. As a result, there are different ways to access string contents, determine the string length, and determine whether a string is empty.

It is virtually impossible to avoid multiple string types within a C++ program. [3] If you want to use basic_string exclusively, you must ensure that there are no:

    basic_string literals. A string literal such as "abc" is a static null-terminated byte string.
    interactions with the existing libraries that accept null-terminated byte strings (for example, many of the objects manipulated by function signatures declared in <cstring> [C++ 2011 §21.3] are NTBSs).
    interactions with the existing libraries that accept null-terminated wide-character strings (for example, many of the objects manipulated by function signatures declared in <cwchar> [C++ 2011 §21.3] are wide-character sequences).

Typically, C++ programs use null-terminated byte strings and one string class, although it is often necessary to deal with multiple string classes within a legacy code base.
References

    International Organization for Standardization, International Electrotechnical Commission (ISO/IEC). (1998). ISO/IEC 14882-1998. Programming Languages — C++.
    Stroustrup, Bjarne. (1997). The C++ Programming Language. Addison-Wesley.
    Wilson, M.( August, 2003). "Generalized String Manipulation: Access Shims and Type Tunneling." C/C++ Users Journal. Volume 21. Number 8.


				24.1.1.1.7 character types
The three types char, signed char, and unsigned char are collectively called the character types (C11 §6.2.5 p15). Compilers have the latitude to define char to have the same range, representation, and behavior as either signed char or unsigned char. Regardless of the choice made, char is a distinct type.

Although not stated in one place, the C standard follows a consistent philosophy for choosing character types:

signed char and unsigned char

    Suitable for small integer values.

plain char

    The type of each element of a string literal.

    Used for character data (where signedness has little meaning) as opposed to integer data.

The following program fragment shows the standard string-handling function strlen() being called with a plain character string, a signed character string, and an unsigned character string. The strlen() function takes a single argument of type const char *.
1	size_t len;
2	char cstr[] = "char string";
3	signed char scstr[] = "signed char string";
4	unsigned char ucstr[] = "unsigned char string";
5	 
6	len = strlen(cstr);
7	len = strlen(scstr);  /* warns when char is unsigned */
8	len = strlen(ucstr);  /* warns when char is signed */          

Compiling at high warning levels in compliance with MSC00-C. Compile cleanly at high warning levels causes warnings to be issued when:

    Converting from unsigned char[] to const char * when char is signed.
    Converting from signed char[] to const char * when char is defined to be unsigned.

Casts are required to eliminate these warnings, but excessive casts can make code difficult to read and hide legitimate warning messages.

If this code were compiled using a C++ compiler, conversions from unsigned char[] to const char * and from signed char[] to const char * would be flagged as errors requiring casts. STR04-C. Use plain char for characters in the basic character set recommends the use of plain char for compatibility with standard narrow-string-handling functions.

The int type is used for data that could be either EOF (a negative value) or character data interpreted as unsigned char to prevent sign extension and then converted to int. For example, on a platform in which the int type is represented as a 32-bit value, the extended ASCII code 0xFF would be returned as follows:
00	00	00	FF

Note: EOF is a macro which expands to an integer constant expression with type int and an implementation dependent negative value but is very commonly -1. '\0' is a char with value 0 in C++ and an int with the value 0 in C.


    Consequently, fgetc(), getc(), getchar(), fgetwc(), getwc(), and getwchar() return int.
    The character classification functions declared in <ctype.h>, such as isalpha(), accept int because they might be passed the result of fgetc() or the other functions from this list.

In C, a character constant has type int. Its value is that of a plain char converted to int. The perhaps surprising consequence is that sizeof c is equal to the sizeof int for all character constants c. This also means, for example, that the sizeof a is not equal to sizeof x when x is a variable of type char.

In C++, a character literal that contains only one character has type char and thus, unlike in C, its size is 1. In both C and C++, a wide-character literal has type wchar_t, and a multicharacter literal has type int.

The unsigned char type is useful when the object being manipulated might be of any type, and it is necessary to access all bits of that object, as with fwrite(). Unlike other integer types, unsigned char has the unique property that values stored in objects of type unsigned char are guaranteed to be represented using a pure binary notation (C11 §6.2.1). A pure binary notation is defined by the standard as “a positional representation for integers that uses the binary digits 0 and 1, in which the values represented by successive bits are additive, begin with 1, and are multiplied by successive integral powers of 2, except perhaps the bit with the highest position” (C11 §6.2.6.1 n49)

Objects of type unsigned char are guaranteed to have no padding bits and consequently no trap representation. As a result, non–bit field objects of any type may be copied into an array of unsigned char (for example, via memcpy()) and have their representation examined one byte at a time.

wchar_t

    Wide characters are used for natural-language character data.

STR00-C. Represent characters using an appropriate type recommends that the use of character types follows this same philosophy. For characters in the basic character set, it does not matter which data type is used, except for type compatibility.

					24.1.1.1.7.1  Did I get this
Assuming sizeof(char) != sizeof(int), what type should T be in the following code?


01	// reads at most size-1 chars from the user
02	int read_chars(char *outbuf, size_t size) {
03	  // error checks
04	  if (NULL == outbuf || size < 1) {
05	    return ERROR;
06	  }
07	 
08	  // clear the buffer
09	  memset(outbuf, '\0', size);
10	 
11	  // read the characters
12	  size_t i;
13	  for (i=0; i < size-1; i++) {
14	    T c = getchar();
15	    if (EOF == c) {
16	      return SUCCESS;
17	    }
18	    outbuf[i] = c;
19	  }
20	  return SUCCESS;
21	}

Answer: int
Feedback

Correct! The function getchar() returns a value of type int, which is required to distinguish between the character code 0xFF and the EOF constant, which typically has the value -1.
The reason is that getchar() needs to report some abnorml state. For example, read error or end of file (EOF = -1). In this case the returned value is not 0~255. It is not possible to represent such cases with char type.

					24.1.1.1.7.2 Excerpt on 2s complement
http://en.wikipedia.org/wiki/Two%27s_complement
wo's complement is a mathematical operation on binary numbers, as well as a representation of signed binary numbers based on this operation. The two's complement of an N-bit number is defined as the complement with respect to 2N, in other words the result of subtracting the number from 2N. This is also equivalent to taking the ones' complement and then adding one, since the sum of a number and its ones' complement is all 1 bits. The two's complement of a number behaves like the negative of the original number in most arithmetic, and positive and negative numbers can coexist in a natural way.

In two's-complement representation, negative numbers are represented by the two's complement of their absolute value;[1] in general, negation (reversing the sign) is performed by taking the two's complement. This system is the most common method of representing signed integers on computers.[2] An N-bit two's-complement numeral system can represent every integer in the range −(2N−1) to +(2N−1 − 1) while ones' complement can only represent integers in the range −(2N−1 − 1) to +(2N−1 − 1).

The two's-complement system has the advantage that the fundamental arithmetic operations of addition, subtraction, and multiplication are identical to those for unsigned binary numbers (as long as the inputs are represented in the same number of bits and any overflow beyond those bits is discarded from the result). This property makes the system both simpler to implement and capable of easily handling higher precision arithmetic. Also, zero has only a single representation, obviating the subtleties associated with negative zero, which exists in ones'-complement systems.

The method of complements can also be applied in base-10 arithmetic, using ten's complements by analogy with two's complements.
Bits 	Unsigned value 	2's complement value
00000000 	0 	0
00000001 	1 	1
00000010 	2 	2
01111110 	126 	126
01111111 	127 	127
10000000 	128 	−128
10000001 	129 	−127
10000010 	130 	−126
11111110 	254 	−2
11111111 	255 	−1
8-bit two's-complement integers
					24.1.1.1.7.3

				24.1.1.1.8 Sizing Strings


Sizing strings correctly is essential in preventing buffer overflows and other runtime errors. Incorrect string sizes can lead to buffer overflows when used, for example, to allocate an inadequately sized buffer. The CERT C Secure Coding Standard STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator addresses this issue. Several important properties of arrays and strings are critical to allocating space correctly and preventing buffer overflows:

Size
    Number of bytes allocated to the array (same as sizeof(array)).
Count
    Number of elements in the array (same as the Visual Studio 2010 _countof(array)).
Length
    Number of characters before null terminator.

Confusing these concepts frequently leads to critical errors in C and C++ programs. The C standard guarantees that objects of type char consist of a single byte. Consequently, the size of an array of char is equal to the count of an array of char, which is also the bounds. The length is the number of characters before the null terminator. For a properly null-terminated string of type char, the length must be less than or equal to the size minus 1.

Wide character strings may be improperly sized when they are mistaken for narrow strings or for multibyte character strings. The C standard defines wchar_t to be an integer type whose range of values can represent distinct codes for all members of the largest extended character set specified among the supported locales (C11 §7.19 p2). Windows uses UTF-16 character encodings, so the size of wchar_t is typically 2 bytes. Linux and OS X (GCC/g++ and XCode) uses UTF-32 character encodings, so the size of wchar_t is typically 4 bytes. On most platforms, the size of wchar_t is at least 2 bytes, and consequently, the size of an array of wchar_t is no longer equal to the count of the same array. Programs that assume otherwise are likely to contain errors. For example, in the following program fragment, the strlen() function is incorrectly used to determine the size of a wide character string.
Example
1	wchar_t wide_str1[] = L"0123456789";
2	wchar_t *wide_str2 = (wchar_t *)malloc(strlen(wide_str1) + 1);
3	if (wide_str2 == NULL) {
4	  /* Handle Error */
5	}
6	/* ... */
7	free(wide_str2);
8	wide_str2 = NULL;

When this program is compiled, Microsoft Visual Studio 2010 generates an incompatible type warning and terminates translation. GCC 4.6.1 also generates an incompatible type warning but continues compilation.

The strlen() function counts the number of characters in a null-terminated byte string preceding the terminating null byte (the length). However, wide characters contain null bytes, particularly when taken from the ASCII character set, as in this example. As a result, the strlen() function will return the number of bytes preceding the first null byte in the string.

In the following program fragment, the wcslen() function is correctly used to determine the size of a wide character string, but the length is not multiplied by sizeof(wchar_t).
Example
1	wchar_t wide_str1[] = L"0123456789";
2	wchar_t *wide_str3 = (wchar_t *)malloc(wcslen(wide_str1) + 1);
3	if (wide_str3 == NULL) {
4	  /* Handle Error */
5	}
6	/* ... */
7	free(wide_str3);
8	wide_str3 = NULL;

The following program fragment correctly calculates the number of bytes required to contain a copy of the wide string (including the termination character).
Example
01	wchar_t wide_str1[] = L"0123456789";
02	wchar_t *wide_str2 = (wchar_t *)malloc(
03	  (wcslen(wide_str1) + 1) * sizeof(wchar_t)
04	);
05	if (wide_str2 == NULL) {
06	  /* Handle Error */
07	}
08	/* ... */
09	free(wide_str2);
10	wide_str2 = NULL;

The CERT C Secure Coding Standard STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator correctly provides additional information with respect to sizing wide strings.
References

    Plum, Thomas, & Keaton, David M. (2005). Eliminating Buffer Overflows, Using the Compiler or a Standalone Tool. Proceedings of the Workshop on Software Security Assurance Tools, Techniques, and Metrics. Long Beach, CA, November. U.S. National Institute of Standards and Technology (NIST).

					24.1.1.1.8.1 STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator
Skip to end of metadata

    Added by Confluence Administrator, last edited by Carol J. Lallier on Jun 14, 2012  (view change)

Go to start of metadata

Copying data to a buffer that is not large enough to hold that data results in a buffer overflow. While not limited to null-terminated byte strings (NTBS), buffer overflows often occur when manipulating NTBS data. To prevent such errors, either limit copies through truncation or, preferably, ensure that the destination is of sufficient size to hold the character data to be copied and the null-termination character. (See STR03-C. Do not inadvertently truncate a null-terminated byte string.)
Noncompliant Code Example (Off-by-One Error)

This noncompliant code example demonstrates what is commonly called an off-by-one error [Dowd 2006]. The loop copies data from src to dest. However, the null terminator may incorrectly be written one byte past the end of dest because the loop does not account for the null-termination character that must be appended to dest.
char dest[ARRAY_SIZE];
char src[ARRAY_SIZE];
size_t i;
/* ... */
for (i=0; src[i] && (i < sizeof(dest)); i++) {
  dest[i] = src[i];
}
dest[i] = '\0';
/* ... */
Compliant Solution (Off-by-One Error)

To correct this example, the loop termination condition must be modified to account for the null-termination character that is appended to dest.
char dest[ARRAY_SIZE];
char src[ARRAY_SIZE];
size_t i;
/* ... */
for (i=0; src[i] && (i < sizeof(dest)-1); i++) {
  dest[i] = src[i];
}
dest[i] = '\0';
/* ... */
Noncompliant Code Example (argv) (strcpy())

Arguments read from the command line are stored in process memory. The function main(), called at program startup, is typically declared as follows when the program accepts command-line arguments:
int main(int argc, char *argv[]) { /* ... */ }

Command-line arguments are passed to main() as pointers to null-terminated byte strings in the array members argv[0] through argv[argc-1]. If the value of argc is greater than zero, the string pointed to by argv[0] is, by convention, the program name. If the value of argc is greater than one, the strings referenced by argv[1] through argv[argc-1] are the actual program arguments.

Vulnerabilities can occur when inadequate space is allocated to copy a command-line argument or other program input. In this noncompliant code example, the contents of argv[0] can be manipulated by an attacker to cause a buffer overflow:
int main(int argc, char *argv[]) {
  /* ... */
  char prog_name[128];
  strcpy(prog_name, argv[0]);
  /* ... */
}
Compliant Solution (argv) (strcpy())

The strlen() function can be used to determine the length of the strings referenced by argv[0] through argv[argc-1] so that adequate memory can be dynamically allocated. Note that care must be taken to avoid assuming that argv[0] is non-null.
int main(int argc, char *argv[]) {
  /* Be prepared for argv[0] to be null */
  const char* const name = argv[0] ? argv[0] : "";
  char *prog_name = (char *)malloc(strlen(name) + 1);
  if (prog_name != NULL) {
    strcpy(prog_name, name);
  }
  else {
    /* Failed to allocate memory - recover */
  }
  /* ... */
}

Remember to add a byte to accommodate the null-terminated byte string.
Compliant Solution (argv) (strcpy_s())

The strcpy_s() function provides additional safeguards, including accepting the size of the destination buffer as an additional argument. (See STR07-C. Use the bounds-checking interfaces for remediation of existing string manipulation code.) Do not assume that argv[0] is non-null.
int main(int argc, char *argv[]) {
  /* Be prepared for argv[0] to be null */
  const char* const name = argv[0] ? argv[0] : "";
 
  char * prog_name;
  size_t prog_size;
 
  prog_size = strlen(name) + 1;
  prog_name = (char *)malloc(prog_size);
 
  if (prog_name != NULL) {
    if (strcpy_s(prog_name, prog_size, name)) {
      /* Handle strcpy_s() error */
    }
  }
  else {
 
    /* Failed to allocate memory - recover */
  }
  /* ... */
}

The strcpy_s() function can be used to copy data to or from dynamically allocated memory or a statically allocated array. If insufficient space is available, strcpy_s() returns an error.
Compliant Solution (argv) (memcpy())

The C standard memcpy() function provides a similar capability to strcpy_s() but is universally available. Note that care must be taken to avoid assuming that argv[0] is non-null. Note also that memcpy must not be called with a null pointer even when the second (size) argument is zero.
int main(int argc, char *argv[]) {
  /* Be prepared for argv[0] to be null */
  const char* const name = argv[0] ? argv[0] : "";
 
  char *prog_name;
  size_t prog_size;
 
  prog_size = strlen(name) + 1;
  prog_name = (char *)malloc(prog_size);
 
  if (prog_name != NULL) {
    memcpy(prog_name, name, prog_size);
  }
  else {
    /* Failed to allocate memory - recover */
  }
  /* ... */
}

The memcpy() function differs from strcpy_s() in that it never returns an error. The memcpy() function returns a pointer to the destination string (that is, its first argument). However, memcpy() does not validate that the destination pointer has enough space for the memory being copied and cannot be used if the source and destination strings overlap.
Compliant Solution (argv)

If an argument is not going to be modified or concatenated, there is no reason to make a copy of the string. Not copying a string is the best way to prevent a buffer overflow and is also the most efficient solution. Care must be taken to avoid assuming that argv[0] is non-null.
int main(int argc, char *argv[]) {
  /* Be prepared for argv[0] to be null */
  const char *prog_name = argv[0] ? argv[0] : "";
  size_t prog_size;
  /* ... */
}
Noncompliant Code Example (getenv())

The getenv() function searches an environment list, provided by the host environment, for a string that matches the string pointed to by name. The set of environment names and the method for altering the environment list are implementation-defined. Environment variables can be arbitrarily large, and copying them into fixed-length arrays without first determining the size and allocating adequate storage can result in a buffer overflow.
/* ... */
char buff[256];
char *editor = getenv("EDITOR");
if (editor == NULL) {
  /* EDITOR environment variable not set */
} else {
  strcpy(buff, editor);
}
/* ... */
Compliant Solution (getenv())

Environmental variables are loaded into process memory when the program is loaded. As a result, the length of these null-terminated byte strings can be determined by calling the strlen() function, and the resulting length can be used to allocate adequate dynamic memory:
/* ... */
char *buff;
char *editor = getenv("EDITOR");
if (editor == NULL) {
  /* EDITOR environment variable not set */
} else {
  size_t len = strlen(editor)+1;
  buff = (char *)malloc(len);
  if (buff == NULL) {
    /* Handle malloc() error */
  }
  memcpy(buff, editor, len);
}
/* ... */
Noncompliant Code Example (sprintf())

In this example, name refers to an external string; it could have originated from user input, from the file system, or from the network. The program constructs a file name from the string in preparation for opening the file.
char* name; /* initialized externally */
char filename[128];
sprintf(filename, "%s.txt", name);
/* open filename * /

However, because the sprintf() function makes no guarantees regarding the length of the string generated, a sufficiently long string in name could generate a buffer overflow.
Compliant Solution (sprintf())

The buffer overflow can be prevented by providing a precision length to the %s specifier. The value 123 ensures that filename can contain the first 123 characters of name, the .txt extension, and the null terminator.
char* name; /* initialized externally */
char filename[128];
sprintf(filename, "%.123s.txt", name);
/* open filename * /
Compliant Solution (snprintf())

A more general solution is to use the snprintf() function.
char* name; /* initialized externally */
char filename[128];
snprintf(filename, sizeof(filename), "%s.txt", name);
/* open filename * /
   
   */

					24.1.1.1.8.2 My example, sizing_strings.cpp

code:

/*
 * =====================================================================================
 *
 *       Filename:  sizing_strings.cpp
 *
 *    Description:  
 *
 *        Version:  1.0
 *        Created:  10/ 2/2012 12:34:43 PM
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  Yosi Izaq
 *   Organization:  
 *
 * =====================================================================================
 */
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <cwchar>

int main(){

wchar_t wide_str1[] = L"0123456789";
printf ("strlen incorrect size and count of 0123456789 wide string is: %d\n", strlen((const char *)wide_str1)+1);
printf ("wcslen incorrect size, yet correct count, of 0123456789 wide string is: %d\n", wcslen(wide_str1)+1);
printf ("wcslen multiply by sizeof wchar_t correct size of 0123456789 wide string is: %d\n", (wcslen(wide_str1)+1)*sizeof(wchar_t) );
wchar_t *wide_str2 = (wchar_t *)malloc((wcslen(wide_str1)+1)*sizeof(wchar_t) );
if (wide_str2 == NULL) {
  /* Handle Error */
}
/* ... */
free(wide_str2);
wide_str2 = NULL;

}

output:
[yizaq@yizaq-WS:Tue Oct 02:/cygdrive/c/work/code/CPP/secure:]$ g++ sizing_strings.cpp 
[yizaq@yizaq-WS:Tue Oct 02:/cygdrive/c/work/code/CPP/secure:]$ a.exe 
strlen incorrect size and count of 0123456789 wide string is: 2
wcslen incorrect size, yet correct count, of 0123456789 wide string is: 11
wcslen multiply by sizeof wchar_t correct size of 0123456789 wide string is: 22

					24.1.1.1.8.3 test
What does the following program print out as the size, count, and length?
const char s[256] = "1234567";
size_t size = sizeof s;
size_t count = sizeof s/ sizeof s[0];
size_t length = strlen s;

printf("size = %zu\n", size);
printf("count = %zu\n", count);
printf("length = %zu\n", length);

size: 256
count: 256
length: 7

const wchar_t s[1024] = "12345";
size_t size = sizeof s;
size_t count = size/ sizeof (wchar_t);
size_t length = wcslen( s);

printf("size = %zu\n", size);
printf("count = %zu\n", count);
printf("length = %zu\n", length);

size: 4096 (1024 * 4)
count: 1024
length: 5



					24.1.1.1.8.4

				24.1.1.1.9

			24.1.1.2 Common String Manipulation Errors


Manipulating strings in C or C++ is error prone. Four common errors are:

    unbounded string copies
    off-by-one errors
    null-termination errors
    string truncation


				24.1.1.2.1 Improperly Bounded String Copies
Improperly bounded string copies occur when data is copied from a source to a fixed-length character array (for example, when reading from standard input into a fixed-length buffer).
Example
Reading from stdin()

This example program from Annex A of ISO/IEC TR 24731-2 [1] reads characters from standard input using the gets() function into a fixed-length character array until a newline character is read or an end-of-file (EOF) condition is encountered.
01	#include <stdio.h>
02	#include <stdlib.h>
03	 
04	void get_y_or_n(void) {
05	  char response[8];
06	  printf("Continue? [y] n: ");
07	  gets(response);
08	  if (response[0] == 'n')
09	    exit(0);
10	  return;
11	}

This example uses only interfaces present in C99, although the gets() function has been deprecated in C99 and eliminated from C11. The CERT C Secure Coding Standard MSC34-C. Do not use deprecated or obsolescent functions disallows the use of this function.

This program compiles and runs under Microsoft Visual C++ 2010 but warns about using gets() at warning level /W3. When compiled with G++ 4.6.1, the compiler warns about gets() but otherwise compiles cleanly.

This program has undefined behavior if more than eight characters (including the null terminator) are entered at the prompt. The main problem with the gets() function is that it provides no way to specify a limit on the number of characters to read. This limitation is apparent in the following conforming implementation of this function:
01	char *gets(char *dest) {
02	  int c = getchar();
03	  char *p = dest;
04	  while (c != EOF && c != '\n') {
05	    *p++ = c;
06	    c = getchar();
07	  }
08	  *p = '\0';
09	  return dest;
10	}

Reading data from unbounded sources (such as stdin()) creates an interesting problem for a programmer. Because it is not possible to know beforehand how many characters a user will supply, it is not possible to preallocate an array of sufficient length. A common solution is to statically allocate an array that is thought to be much larger than needed. In this example, the programmer is expects the user to enter only one character and consequently assumes that the eight-character array length will not be exceeded. With friendly users, this approach works well. But with malicious users, a fixed-length character array can be easily exceeded, resulting in undefined behavior. This approach is prohibited by The CERT C Secure Coding Standard STR35-C. Do not copy data from an unbounded source to a fixed-length array.
Copying and Concatenating Strings

It is easy to make errors when copying and concatenating strings because many of the standard library calls that perform this function, such as strcpy(), strcat(), and sprintf(), perform unbounded copy operations.

Arguments read from the command line are stored in process memory. The function main(), called when the program starts, is typically declared as follows when the program accepts command-line arguments:
int main(int argc, char *argv[]) {
    /* ...*/
}

Command-line arguments are passed to main() as pointers to null-terminated strings in the array members argv[0] through argv[argc-1]. If the value of argc is greater than zero, the string pointed to by argv[0] is, by convention, the program name. If the value of argc is greater than one, the strings referenced by argv[1] through argv[argc-1] are the actual program arguments. In any case, argv[argc] is always guaranteed to be NULL.

Vulnerabilities can occur when inadequate space is allocated to copy a program input such as a command-line argument. Although argv[0] contains the program name by convention, an attacker can control the contents of argv[0] to cause a vulnerability in the following program by providing a string with more than 128 bytes. Furthermore, an attacker can invoke this program with argv[0] set to NULL.
1	int main(int argc, char *argv[]) {
2	  /* ... */
3	  char prog_name[128];
4	  strcpy(prog_name, argv[0]);
5	  /* ... */
6	}

This program compiles and runs under Microsoft Visual C++ 2010 but warns about using strcpy() at warning level /W3. The program also compiles and runs under G++ 4.6.1. If _FORTIFY_SOURCE is defined, the program aborts at runtime as a result of object size checking if the call to strcpy() results in a buffer overflow.

The strlen() function can be used to determine the length of the strings referenced by argv[0] through argv[argc-1] so that adequate memory can be dynamically allocated. Remember to add a byte to accommodate the null character that terminates the string. Note that care must be taken to avoid assuming that any element of the argv array, including argv[0], is non-null.
01	int main(int argc, char *argv[]) {
02	  /* Do not assume that argv[0] cannot be null */
03	  const char * const name = argv[0] ? argv[0] : "";
04	  char *prog_name = (char *)malloc(strlen(name) + 1);
05	  if (prog_name != NULL) {
06	    strcpy(prog_name, name);
07	  }
08	  else {
09	      /* Failed to allocate memory - recover */
10	  }
11	  /* ... */
12	}

The use of the strcpy() function is perfectly safe because the destination array has been appropriately sized. It may still be desirable to replace the strcpy() function with a call to a “more secure” function to eliminate diagnostic messages generated by compilers or analysis tools.

The POSIX strdup() function can also be used to copy the string. The strdup() function accepts a pointer to a string and returns a pointer to a newly allocated duplicate string. This memory can be reclaimed by passing the returned pointer to free(). The strdup() function is defined in ISO/IEC TR 24731-2 [1] but is not included in the C99 or C11 standards.
sprintf() Function

Another standard library function that is frequently used to copy strings is the sprintf() function (C11 §7.21.6.6). The sprintf() function writes output to an array, under control of a format string. A null character is written at the end of the characters written. Because sprintf() specifies how subsequent arguments are converted according to the format string, it is often difficult to determine the maximum size required for the target array. For example, on common ILP32 and LP64 platforms where INT_MAX = 2,147,483,647, it can take up to 11 characters to represent the value of an argument of type int as a string (commas are not output, and there might be a minus sign). Floating-point values are even more difficult to predict.

The snprintf() function (C11 §7.21.6.5) adds an additional size_t parameter n. If n is zero, nothing is written, and the destination array may be a null pointer. Otherwise, output characters beyond the n-1st are discarded rather than written to the array, and a null character is written at the end of the characters that are actually written into the array. The snprintf() function returns the number of characters that would have been written had n been sufficiently large, not counting the terminating null character, or a negative value if an encoding error occurred. Consequently, the null-terminated output is completely written if and only if the returned value is nonnegative and less than n. The snprintf() function is a relatively secure function, but like other formatted output functions, it is also susceptible to format string vulnerabilities. [2] Values returned from snprintf() need to be checked because the function may fail not only because of insufficient space in the buffer but for other reasons as well, such as out-of-memory conditions during the execution of the function. See The CERT C Secure Coding Standard FIO04-C. Detect and handle input and output errors and FIO33-C. Detect and handle input output errors resulting in undefined behavior for more information.


					24.1.1.2.1.1 Did I get this?
					The string operations in the following program fragment are properly bounded.
char * name; char filename[128]; sprintf(filename, "%s.txt", name);	  -- False
char * name; char filename[128]; sprintf(filename, "%123s.txt", name);	  -- True
char * name; char filename[128]; sprintf(filename, sizeof(filename), "%s.txt", name);	  -- True

					24.1.1.2.1.2 Unbounded Strings in C++
Unbounded string copies are not limited to the C programming language. For example, if a user inputs more than 11 characters into the following C++ program, it will result in an out-of-bounds write.
1	#include <iostream>
2	 
3	int main(void) {
4	  char buf[12];
5	 
6	  std::cin >> buf;
7	  std::cout << "echo: " << buf << '\n';
8	}

This program compiles cleanly under Microsoft Visual C++ 2010 at warning level /W4. This program also compiles cleanly under GCC 4.6.1 with options: -Wall -Wextra -pedantic.

The type of the standard object std::cin is the std::stream class. The istream class, which is really a specialization of the std::basic_istream class template on the character type char, provides member functions to assist in reading and interpreting input from a stream buffer. All formatted input is performed using the extraction operator operator>>. C++ defines both member and nonmember overloads of operator>>, including:

istream& operator>> (istream& is, char* str);

This operator extracts characters and stores them in successive elements of the array pointed to by str. Extraction ends when the next element is either a valid white space or a null character or EOF is reached. The extraction operation can be limited to a certain number of characters (avoiding the possibility of buffer overflow) if the field width (which can be set with ios_base::width or setw()) is set to a value greater than zero. In this case, the extraction ends one character before the count of characters extracted reaches the value of field width, leaving space for the ending null character. After a call to this extraction operation, the value of the field width is automatically reset to zero. A null character is automatically appended after the extracted characters.

The extraction operation can be limited to a specified number of characters (thereby avoiding the possibility of an out-of-bounds write) if the field width inherited member (ios_base::width) is set to a value greater than 0. In this case, the extraction ends one character before the count of characters extracted reaches the value of field width, leaving space for the ending null character. After a call to this extraction operation, the value of the field width is reset to 0.
Example
Field width Member

This example program eliminates the overflow in the previous example by setting the field width member to the size of the character array buf. This example shows that the C++ extraction operator does not suffer from the same inherent flaw as the C function gets().
1	#include <iostream>
2	 
3	int main(void) {
4	  char buf[12];
5	 
6	  std::cin.width(12);
7	  std::cin >> buf;
8	  std::cout << "echo: " << buf << '\n';
9	}
					24.1.1.2.1.3

				24.1.1.2.2 Off-by-one errors 


Off-by-one errors are another common problem with null-terminated strings. Off-by-one errors are similar to unbounded string copies in that they both involve writing outside the bounds of an array. The following program compiles and links cleanly under Microsoft Visual C++ 2010 at /W4 and runs without error on Windows 7 but contains several off-by-one errors. Can you find all the off-by-one errors in this program?
Off-by-One

Many of these mistakes are rookie errors, but experienced programmers sometimes make them as well. It is easy to develop and deploy programs similar to this one that compile and run without error on most systems.


					24.1.1.2.2.1 did I get this
The following program compiles and links cleanly under Microsoft Visual C++ 2010 at /W4 and runs without error on Windows 7 but contains several off-by-one errors.
01	#include <string.h>
02	#include <stdio.h>
03	#include <stdlib.h>
04	 
05	int main(void) {
06	 char s1[] = "012345678";
07	 char s2[] = "0123456789";
08	 char *dest;
09	 int i;
10	 
11	 strcpy_s(s1, sizeof(s2), s2);
12	 dest = (char *)malloc(strlen(s1));
13	 for (i=1; i <= 11; i++) {
14	   dest[i] = s1[i];
15	 }
16	 dest[i] = '\0';
17	 printf("dest = %s", dest);
18	 /* … */;
19	}                   

Which of the following is NOT an off-by-one (or more) error?

 -   The assignment on line 16 also causes an out-of-bounds write.
 Incorrect. The assignment on line 16 is an out-of-bounds write because the variable i has the value 11 when the for loop terminates and the size of the space referenced by dest is only 9 bytes. This is an off-by-more-than-one error.

 -   The ending condition for the loop (line 13) is i <= 11. This means the loop will iterate one more time than the programmer likely intended.
 Incorrect. The size of the space referenced by dest is only 9 bytes and is written to following the loop. This means the correct for loop for this code should be for (i=0; i < 8; i++). Doing so allows the null character to be written to the ninth element in the array (dest[8]).

 -   The malloc() function (line 12) allocates memory on the heap of the length of the source string. However, the value returned by strlen() does not account for the null character.
 Incorrect. The strlen() returns the length of the string, meaning the number of bytes preceding the null character.

 -   The index value i in the for loop (line 13) starts at 1, but the first position in a C array is indexed by 0.
Incorrect. The first position in a C array is indexed by 0.

 -   The source character array (declared on line 7) is 10 bytes long, but strcpy_s() (line 11) copies 11 bytes, including a 1-byte terminating null character.
Incorrect. This is a common error, particularly when s2 is a literal. Engineers are frequently instructed to use the “safer” strcpy_s() function but fail to realize that the size argument is the size of the destination and not the source. This is one of the drawbacks of these functions—they are more complex than their traditional counterparts and are susceptible to these kinds of errors.

 -   The variable i should be declared as size_t and not int because it is used to index a character array.
Correct! While the variable i should be declared as size_t and not an int, it does not result in an off-by-one error in this context. 

					24.1.1.2.2.2

				24.1.1.2.3 Null-Termination Errors
Another common problem with strings is a failure to properly null-terminate them. A string is properly null-terminated if a null-terminator is present at or before the last element in the array. If a string lacks the terminating null character, the program may be tricked into reading or writing data outside the bounds of the array.

Strings must contain a null-termination character at or before the address of the last element of the array before they can be safely passed as arguments to standard string-handling functions, such as strcpy() or strlen(). The null-termination character is necessary because these functions, as well as other string-handling functions defined by C11, depend on its existence to mark the end of a string. Similarly, strings must be null-terminated before the program iterates on a character array where the termination condition of the loop depends on the existence of a null-termination character within the memory allocated for the string:
1	size_t i;
2	char ntbs[16];
3	/* ... */
4	for (i = 0; i < sizeof(ntbs); ++i) {
5	  if (ntbs[i] == '\0') break;
6	  /* ... */
7	}          
Example

The following program compiles under Microsoft Visual C++ 2010 but warns about using strncpy() and strcpy() at warning level /W3. It is also diagnosed (at runtime) by GCC on Linux when the _FORTIFY_SOURCE macro is defined to a nonzero value.
1	int main(void) {
2	  char a[16];
3	  char b[16];
4	  char c[16];
5	  strncpy(a, "0123456789abcdef", sizeof(a));
6	  strncpy(b, "0123456789abcdef", sizeof(b));
7	  strcpy(c, a);
8	  /* … */
9	}

In this program, three character arrays—a[], b[], and c[]—are each declared to be 16 bytes. Although the strncpy() to a is restricted to writing sizeof(a) (16 bytes), the resulting string is not null-terminated as a result of the historic and standard behavior of the strncpy() function.

According to C11, the strncpy() function has the following signature (C11 §7.24.2.4):
char *strncpy(char *restrict s1, const char *restrict s2, size_t n);

It copies not more than n characters (characters that follow a null character are not copied) from the array pointed to by s2 to the array pointed to by s1.

Consequently, if there is no null character in the first n characters of the array pointed to by s2, as in this example, the result is not null-terminated.

The strncpy() to b has a similar result. Depending on how the compiler allocates storage, the storage following a[] may coincidentally contain a null character, but this is unspecified by the compiler and is unlikely in this example, particularly if the storage is closely packed. The result is that the strcpy() to c may write well beyond the bounds of the array because the string stored in a[] is not correctly null-terminated.

The CERT C Secure Coding Standard includes STR32-C. Null-terminate byte strings as required. Note that the rule does not preclude the use of character arrays. For example, there is nothing wrong with the following program fragment even though the string stored in the ntbs character array may not be properly null-terminated after the call to strncpy():
1	char ntbs[NTBS_SIZE];
2	  
3	strncpy(ntbs, source, sizeof(ntbs)-1);
4	ntbs[sizeof(ntbs)-1] = '\0';

Null-termination errors, like the other string errors described in this section, are difficult to detect and can lie dormant in deployed code until a particular set of inputs causes a failure. Code cannot depend on how the compiler allocates memory, which may change from one compiler release to the next.

					24.1.1.2.3.1 did I get this 

Is there null termination error?

char ntbs[NTBS_SIZE]; ntbs[sizeof(ntbs) -1] = '\0'; strncpy(ntbs, source, sizeof(ntbs));

yes. ntbs is null terminated before strncpy. However, strncpy call may overwrite the null 

					24.1.1.2.3.2

				24.1.1.2.4 String Truncation
String truncation can occur when a destination character array is not large enough to hold the contents of a string. String truncation may occur while the program is reading user input or copying a string and is often the result of a programmer trying to prevent a buffer overflow. Although not as bad as a buffer overflow, string truncation results in a loss of data and, in some cases, can lead to software vulnerabilities.

				24.1.1.2.5 String Errors without Functions
Most of the functions defined in the standard string-handling library <string.h> (C11, §7.24), including strcpy(), strcat(), strncpy(), strncat(), and strtok(), are susceptible to errors. Microsoft Visual Studio, for example, has consequently deprecated many of these functions.

However, because null-terminated byte strings are implemented as character arrays, it is possible to perform an insecure string operation even without invoking a function. The following program contains a defect resulting from a string copy operation but does not call any string library functions.
Example
01	int main(int argc, char *argv[]) {
02	  int i = 0;
03	  char buff[128];
04	  char *arg1 = argv[1];
05	  if (arg1 == NULL) {
06	    printf("No arguments");
07	    return EXIT_FAILURE;
08	  }
09	 
10	  while (arg1[i] != '\0') {
11	    buff[i] = arg1[i];
12	    i++;
13	  }
14	  buff[i] = '\0';
15	 
16	  printf("buff = %s\n", buff);
17	  exit(EXIT_SUCCESS);
18	 }

The defective program accepts a string argument, copies it to the buff character array, and prints the contents of the buffer. The variable buff is declared as a fixed array of 128 characters. If the first argument to the program equals or exceeds 128 characters (remember the trailing null character), the program writes outside the bounds of the fixed-size array.

Clearly, eliminating the use of dangerous functions does not guarantee your program is free from security flaws. In the following sections, you will see how these security flaws can lead to exploitable vulnerabilities.

					24.1.1.2.5.1  did I get this?
What common string manipulation error is present in the following program fragment?
1	char dest[ARRAY_SIZE];
2	char src[ARRAY_SIZE];
3	size_t i;
4	/* ... */
5	for (i=0; src[i] && (i < sizeof(dest)); i++) {
6	  dest[i] = src[i];
7	}
8	dest[i] = '\0';
9	/* ... */

    Improperly bounded string copy (only)
    Null-termination error (only)
    Off-by-one error (only)
    All of the above - True

Feedback

Correct! This program fragment contains an off-by-one error. The loop copies data from src to dest. However, the null terminator may incorrectly be written 1 byte past the end of dest because the loop does not account for the null-termination character that must be appended to dest. This means that the string copy (in the for loop) is improperly bounded and that the resulting array may not be properly null-terminated because the null terminator is not guaranteed to be present at or before the last element in the array. This does presume that the src string is also not null-terminated.
					24.1.1.2.5.2


				24.1.1.2.6
			24.1.1.3 String Vulnerabilities and Exploits


Previous sections described common errors in manipulating strings in C or C++. These errors become dangerous when code operates on untrusted data from external sources such as command-line arguments, environment variables, console input, text files, and network connections. Depending on how a program is used and deployed, external data may be trusted or untrusted. However, it is often difficult to predict all the ways software may be used. Frequently, assumptions made during development are no longer valid when the code is deployed. Changing assumptions is a common source of vulnerabilities. Consequently, it is safer to view all external data as untrusted.

In software security analysis, a value is said to be tainted if it comes from an untrusted source (outside of the program’s control) and has not been sanitized to ensure that it conforms to any constraints on its value that consumers of the value require—for example, that all strings are null-terminated.

				24.1.1.3.1 Tainted Data

Following is a simple example of a program that checks a user password (which should be considered tainted data) and grants or denies access.
Example
The IsPasswordOkay Program
01	bool IsPasswordOkay(void) {
02	 char Password[12];
03	 
04	 gets(Password);
05	 return 0 == strcmp(Password, "goodpass");
06	}
07	 
08	int main(void) {
09	 bool PwStatus;
10	 
11	 puts("Enter password:");
12	 PwStatus = IsPasswordOkay();
13	 if (PwStatus == false) {
14	   puts("Access denied");
15	   exit(-1);
16	 }             

This program shows how strings can be misused and is not an exemplar for password checking. The IsPasswordOkay program starts in the main() function. The first line executed is the puts() call that prints out a string literal. The puts() function, defined in C11 (C11 §7.21.7.9) as a character output function, is declared in <stdio.h> and writes a string to the output stream pointed to by stdout followed by a newline character ('\n'). The IsPasswordOkay() function is called to retrieve a password from the user. The function returns a Boolean value: true if the password is valid, false if it is not. The value of PwStatus is tested and access is allowed or denied.

The IsPasswordOkay() function uses the gets() function to read characters from the input stream (referenced by stdin) into the array pointed to by Password until end-of-file is encountered or a newline character is read. Any newline character is discarded, and a null character is written immediately after the last character read into the array. The strcmp() function defined in <string.h> compares the string pointed to by Password to the string literal "goodpass" and returns an integer value of zero if the strings are equal and a nonzero integer value if they are not. The IsPasswordOkay() function returns true if the password is "goodpass", and the main() function consequently grants access.

In the first run of the program, the user enters the correct password and is granted access:

In the second run, an incorrect password is provided and access is denied.

Unfortunately, this program contains a security flaw that allows an attacker to bypass the password protection logic and gain access to the program. Can you identify this flaw?



The security flaw in the IsPasswordOkay program that allows an attacker to gain unauthorized access is caused by the call to gets(). The gets() function, as already noted, copies characters from standard input into Password until end-of-file is encountered or a newline character is read. The Password array, however, contains only enough space for an 11-character password and a trailing null character. This condition results in writing beyond the bounds of the Password array if the input is greater than 11 characters in length. The following figure shows what happens if a program attempts to copy 16 bytes of data into a 12-byte array:

The condition that allows an out-of-bounds write to occur is referred to in software security as a buffer overflow. A buffer overflow occurs at runtime; however, the condition that allows a buffer overflow to occur (in this case) is an unbounded string read, and it can be recognized when the program is compiled. Before looking at how this buffer overflow poses a security risk, we first need to understand buffer overflows and process memory organization in general.

The IsPasswordOkay program has another problem: it does not check the return status of gets(). This is a violation of FIO04-C. Detect and handle input and output errors. When gets() fails, the contents of the Password buffer are indeterminate, and the subsequent strcmp() call has undefined behavior. In a real program, the buffer might even contain the good password previously entered by another user.

				24.1.1.3.2 Buffer Overflows

Buffer overflows occur when data is written outside of the boundaries of the memory allocated to a particular data structure. C and C++ are susceptible to buffer overflows because these languages

    define strings as null-terminated arrays of characters,
    do not perform implicit bounds checking, and
    provide standard library calls for strings that do not enforce bounds checking.

Depending on the location of the memory and the size of the overflow, a buffer overflow may go undetected but can corrupt data, cause erratic behavior, or terminate the program abnormally.

Buffer overflows are troublesome in that they are not always discovered during the development and testing of software applications. Not all C and C++ implementations identify software flaws that can lead to buffer overflows during compilation or report out-of-bound writes at runtime. Static analysis tools can aid in discovering buffer overflows early in the development process. Dynamic analysis tools can be used to discover buffer overflows as long as the test data precipitates a detectable overflow.

Not all buffer overflows lead to software vulnerabilities. However, a buffer overflow can lead to a vulnerability if an attacker can manipulate user-controlled inputs to exploit the security flaw. There are, for example, well-known techniques for overwriting frames in the stack to execute arbitrary code. Buffer overflows can also be exploited in heap or static memory areas by overwriting data structures in adjacent memory.

Before examining how these exploits behave, it is useful to understand how process memory is organized and managed. If you are already familiar with process memory organization, execution stack, and heap management, skip to the section on Stack Smashing.

				24.1.1.3.3 Process Memory Organization

Process
    (Definition)
    A program instance that is loaded into memory and managed by the operating system.

Process memory is generally organized into code, data, heap, and stack segments, as shown in column (a) of the following figure:

The code or text segment includes instructions and read-only data. It can be marked read only so that modifying memory in the code section results in faults. (Memory can be marked read only by using memory management hardware in the computer hardware platform that supports that feature or by arranging memory so that writable data is not stored in the same page as read-only data.) The data segment contains initialized data, uninitialized data, static variables, and global variables. The heap is used for dynamically allocating process memory. The stack is a last-in, first-out (LIFO) data structure used to support process execution.

The exact organization of process memory depends on the operating system, compiler, linker, and loader—in other words, on the implementation of the programming language. Columns (b) and (c) show possible process memory organization under UNIX and Win32.

				24.1.1.3.4 Stack Management

The stack supports program execution by maintaining automatic process-state data. If the main routine of a program, for example, invokes function a(), which in turn invokes function b(), function b() will eventually return control to function a(), which in turn will return control to the main() function.

To return control to the proper location, the sequence of return addresses must be stored. A stack is well suited for maintaining this information because it is a dynamic data structure that can support any level of nesting within memory constraints. When a subroutine is called, the address of the next instruction to execute in the calling routine is pushed onto the stack. When the subroutine returns, this return address is popped from the stack, and program execution jumps to the specified location. The information maintained in the stack reflects the execution state of the process at any given instant.

In addition to the return address, the stack is used to store the arguments to the subroutine as well as local (or automatic) variables. Information pushed onto the stack as a result of a function call is called a frame. The address of the current frame is stored in the frame or base pointer register. On x86-32, the extended base pointer (ebp) register is used for this purpose. The frame pointer is used as a fixed point of reference within the stack. When a subroutine is called, the frame pointer for the calling routine is also pushed onto the stack so that it can be restored when the subroutine exits.

There are two notations for Intel instructions. Microsoft uses the Intel notation:

mov eax, 4 # Intel Notation

GCC uses the AT&T syntax:

mov $4, %eax # AT&T Notation

Both of these instructions move the immediate value 4 into the eax register.
Example

The following shows the x86-32 disassembly of a call to foo(MyInt, MyStrPtr) using the Intel notation.
01	void foo(int, char *); // function prototype
02	                 
03	int main(void) {
04	  int MyInt=1; // stack variable located at ebp-8
05	  char *MyStrPtr="MyString"; // stack var at ebp-4
06	  /* … */
07	  foo(MyInt, MyStrPtr); // call foo function
08	    mov  eax, [ebp-4]
09	    push eax            # Push 2nd argument on stack
10	    mov  ecx, [ebp-8]
11	    push ecx            # Push 1st argument on stack
12	    call foo            # Push the return address on stack and
13	                        # jump to that address
14	    add  esp, 8
15	  /* … */
16	}

The invocation consists of three steps.

    The second argument is moved into the eax register and pushed onto the stack (lines 8 and 9). Notice how these mov instructions use the ebp register to reference arguments and local variables on the stack.
    The first argument is moved into the ecx register and pushed onto the stack (lines 10 and 11).
    The call instruction pushes a return address (the address of the instruction following the call instruction) onto the stack and transfers control to the foo() function (line 12).

The instruction pointer (eip) points to the next instruction to be executed. When executing sequential instructions, it is automatically incremented by the size of each instruction, so that the CPU will then execute the next instruction in the sequence. Normally, the eip cannot be modified directly; instead, it must be modified indirectly by instructions such as jump, call, and return.

When control is returned to the return address, the stack pointer is incremented by 8 bytes (line 14). (On x86-32, the stack pointer is named esp. The e prefix stands for “extended” and is used to differentiate the 32-bit stack pointer from the 16-bit stack pointer.) The stack pointer points to the top of the stack. The direction the stack grows depends on the implementation of the pop and push instructions for that architecture (that is, they either increment or decrement the stack pointer). For many popular architectures, including x86, SPARC, and MIPS processors, the stack grows toward lower memory. On these architectures, incrementing the stack pointer is equivalent to popping the stack.
foo() Function Prologue

A function prologue contains instructions that are executed by a function upon its invocation. The following is the function prologue for the foo() function:
1	void foo(int i, char *name) {
2	  char LocalChar[24];
3	  int LocalInt;
4	    push ebp       # Save the frame pointer.
5	    mov ebp, esp   # Frame pointer for subroutine is set to the
6	                   # current stack pointer.
7	    sub esp, 28    # Allocates space for local variables.
8	  /* … */  

The push instruction pushes the ebp register containing the pointer to the caller’s stack frame onto the stack. The mov instruction sets the frame pointer for the function (the ebp register) to the current stack pointer. Finally, the function allocates 28 bytes of space on the stack for local variables (24 bytes for LocalChar and 4 bytes for LocalInt).

The stack frame for foo() following execution of the function prologue is shown here. On x86, the stack grows toward low memory, which is shown at the top of this illustration.
Address	Value	Description	Len
0x0012FF4C 	? 	Last Local Variable - Integer - LocalInt 	4
0x0012FF50 	? 	First Local Variable - String - LocalChar 	24
0x0012FF68 	0x12FF80 	Calling Frame of Calling Function: main() 	4
0x0012FF6C 	0x401040 	Return Address of Calling Function: main() 	4
0x0012FF70 	1 	1st argument: MyInt (int) 	4
0x0012FF74 	0x40703C 	2nd argument: Pointer toMyString (char *) 	4
foo() Function Epilogue

A function epilogue contains instructions that are executed by a function to return to the caller. The following is the function epilogue to return from the foo() function:
1	/* … */
2	 return;
3	   mov  esp, ebp   # Restore the stack pointer.
4	   pop  ebp        # Restores the frame pointer  
5	   ret             # Pops the return address off the stack
6	                   # and transfers control to that location.
7	}              

This return sequence is the mirror image of the function prologue shown earlier. The mov instruction restores the caller’s stack pointer (esp) from the frame pointer (ebp). The pop instruction restores the caller’s frame pointer from the stack. The ret instruction pops the return address in the calling function off the stack and transfers control to that location.

					24.1.1.3.4.1 Did I get this
- The following instruction modifies the extended stack pointer (ESP).
 mov  ecx, [ebp-8]   
True. instruction copies the second operand (source operand) to the first operand

- The following instruction modifies the extended stack pointer (ESP).
push ecx
True. instruction decrements the stack pointer and then stores the source operand on the top of the stack

- The following instruction modifies the extended stack pointer (ESP).
call foo
True. call instruction saves procedure linking information on the stack and branches to the called procedure specified using the target operand.

- The following instruction modifies the enhanced instruction pointer (EIP).
ret eip
True. ret instruction transfers program control to a return address located on the top of the stack

- The following instruction modifies the enhanced instruction pointer (EIP).
call foo
True. call instruction saves procedure linking information on the stack and branches to the called procedure specified using the target operand.

				24.1.1.3.5 Stack smashing 


Stack smashing occurs when a buffer overflow overwrites data in the memory allocated to the execution stack. It can have serious consequences for the reliability and security of a program. Buffer overflows in the stack segment may allow an attacker to modify the values of automatic variables or execute arbitrary code.

Overwriting automatic variables can result in a loss of data integrity or, in some cases, a security breach (for example, if a variable containing a user ID or password is overwritten). More often, a buffer overflow in the stack segment can lead to an attacker executing arbitrary code by overwriting a pointer to an address to which control is (eventually) transferred. A common example is overwriting the return address, which is located on the stack. Additionally, it is possible to overwrite a frame- or stack-based exception handler pointer, function pointer, or other addresses to which control may be transferred.

The example IsPasswordOkay program is vulnerable to a stack-smashing attack. To understand why this program is vulnerable, it is necessary to understand exactly how the stack is being used.

The following figure illustrates the contents of the stack before the program calls the IsPasswordOkay() function.

The operating system (OS) or a standard startup sequence puts the return address from main() on the stack. On entry, main() saves the old incoming frame pointer, which again comes from the operating system or a standard startup sequence. Before the call to the IsPasswordOkay() function, the stack contains the local Boolean variable PwStatus that stores the status returned by the function IsPasswordOkay() along with the caller’s frame pointer and return address.

While the program is executing the function IsPasswordOkay(), the stack contains the information shown by the following figure.

Notice that the password is located on the stack with the return address of the caller main(), which is located after the memory that is used to store the password. It is also important to understand that the stack will change during function calls made by IsPasswordOkay().

After the program returns from the IsPasswordOkay() function, the stack is restored to its initial state:

Execution of the main() function resumes; which branch is executed depends on the value returned from the IsPasswordOkay() function.
Security Flaw: IsPasswordOkay

As discussed earlier, the IsPasswordOkay program has a security flaw because the Password array is improperly bounded and can hold only an 11-character password plus a trailing null byte. This flaw can easily be demonstrated by entering a 20-character password of “12345678901234567890” that causes the program to crash, as shown in the following figure:

To determine the cause of the crash, it is necessary to understand the effect of storing a 20-character password in a 12-byte stack variable. Recall that when 20 bytes are input by the user, the amount of memory required to store the string is actually 21 bytes because the string is terminated by a null-terminator character. Because the space available to store the password is only 12 bytes, 9 bytes of the stack (21 – 12 = 9) that have already been allocated to store other information will be overwritten with password data. The following figure shows the corrupted program stack that results when the call to gets() reads a 20-byte password and overflows the allocated buffer. Notice that the caller’s frame pointer, return address, and part of the storage space used for the PwStatus variable have all been corrupted.

When a program fault occurs, the typical user generally does not assume that a potential vulnerability exists. The typical user only wants to restart the program. However, an attacker will investigate to see if the programming flaw can be exploited.

The program crashes because the return address is altered as a result of the buffer overflow, and either the new address is invalid or memory at that address (a) does not contain a valid CPU instruction; (b) does contain a valid instruction, but the CPU registers are not set up for proper execution of the instruction; or (c) is not executable.

A carefully crafted input string can make the program produce unexpected results, as shown in the following screenshot:

The following figure shows how the contents of the stack have changed when the contents of a carefully crafted input string overflow the storage allocated for Password.

The input string consists of a number of funny-looking characters: j�*!. These are all characters that can be input using the keyboard or character map. Each of these characters has a corresponding hexadecimal value: j = 0x6A, � = 0x10, * = 0x2A, and ! = 0x21. In memory, this sequence of four characters corresponds to a 4-byte address that overwrites the return address on the stack, so instead of returning to the instruction immediately following the call in main(), the IsPasswordOkay() function returns control to the “Access granted” branch, bypassing the password validation logic and allowing unauthorized access to the system. This attack is a simple arc injection attack. Arc injection attacks are covered in more detail in Arc Injection.

				24.1.1.3.6 Code Injection

When the return address is overwritten because of a software flaw, it seldom points to valid instructions. Consequently, transferring control to this address typically causes a trap and results in a corrupted stack. But is possible for an attacker to create a specially crafted string that contains a pointer to some malicious code, which the attacker also provides. When the function invocation whose return address has been overwritten returns, control is transferred to this code. The malicious code runs with the permissions that the vulnerable program has when the subroutine returns, which is why programs running with root or other elevated privileges are normally targeted. The malicious code can perform any function that can otherwise be programmed but often simply opens a remote shell on the compromised machine. For this reason, the injected malicious code is referred to as shellcode.

The pièce de résistance of any good exploit is the malicious argument. A malicious argument must have several characteristics.
Characteristics of a Malicious Argument

    It must be accepted by the vulnerable program as legitimate input.
    The argument, along with other controllable inputs, must result in execution of the vulnerable code path.
    The argument must not cause the program to terminate abnormally before control is passed to the shellcode.

The IsPasswordOkay program can also be exploited to execute arbitrary code because of the buffer overflow caused by the call to gets(). The gets() function also has an interesting property in that it reads characters from the input stream pointed to by stdin until end-of-file is encountered or a newline character is read. Any newline character is discarded, and a null character is written immediately after the last character read into the array (C99 §7.19.7.7). As a result, there might be null characters embedded in the string returned by gets() if, for example, input is redirected from a file. It is important to note that the gets() function was deprecated in C99 and eliminated from the C11 standard (most implementations are likely to continue to make gets() available for compatibility reasons). However, data read by the fgets() function may also contain null characters. This issue is further documented in The CERT C Secure Coding Standard FIO37-C. Do not assume that fgets() returns a nonempty string when successful.

The program IsPasswordOkay was compiled for Linux using GCC. The malicious argument can be stored in a binary file and supplied to the vulnerable program using redirection, as follows:

%./BufferOverflow < exploit.bin

When the exploit code is injected into the IsPasswordOkay program, the program stack is overwritten as follows:
01	/* buf[12] */
02	00 00 00 00
03	00 00 00 00
04	00 00 00 00
05	 
06	/* %ebp */
07	00 00 00 00
08	  
09	/* return address */
10	78 fd ff bf
11	  
12	/* "/usr/bin/cal" */
13	2f 75 73 72
14	2f 62 69 6e
15	2f 63 61 6c
16	00 00 00 00
17	 
18	/* null pointer */
19	74 fd ff bf
20	  
21	/* NULL */
22	00 00 00 00
23	 
24	/* exploit code */
25	b0 0b       /* mov  $0xb, %eax */
26	8d 1c 24    /* lea  (%esp), %ebx */
27	8d 4c 24 f0 /* lea  -0x10(%esp), %ecx */
28	8b 54 24 ec /* mov  -0x14(%esp), %edx */
29	cd 50       /* int  $0x50 */

The lea instruction used in this example stands for “load effective address.” The lea instruction computes the effective address of the second operand (the source operand) and stores it in the first operand (destination operand). The source operand is a memory address (offset part) specified with one of the processor’s addressing modes; the destination operand is a general-purpose register. The exploit code works as follows:

    The first mov instruction is used to assign 0xB to the %eax register. 0xB is the number of the execve() system call in Linux.
    The three arguments for the execve() function call are set up in the subsequent three instructions (the two lea instructions and the mov instruction). The data for these arguments is located on the stack, just before the exploit code.
    The int $0x50 instruction is used to invoke execve(), which results in the execution of the Linux calendar program, as shown in the following figure.

The call to the get_s() function is not susceptible to a buffer overflow, but the call to strcpy() is, as shown in the modified IsPasswordOkay program that follows:
01	char buffer[128];
02	 
03	_Bool IsPasswordOkay(void) {
04	  char Password[12];
05	 
06	  fgets(buffer, sizeof buffer, stdin);
07	  if (buffer[ strlen(buffer) - 1] == '\n')
08	    buffer[ strlen(buffer) - 1] = 0;
09	  strcpy(Password, buffer);
10	  return 0 == strcmp(Password, "goodpass");
11	}
12	 
13	int main(void) {
14	  _Bool PwStatus;
15	 
16	  puts("Enter password:");
17	  PwStatus = IsPasswordOkay();
18	  if (!PwStatus) {
19	    puts("Access denied");
20	    exit(-1);
21	  }
22	  else
23	    puts("Access granted");
24	  return 0;
25	}

Because the strcpy() function copies only the source string (stored in buffer), the Password array cannot contain internal null characters. Consequently, the exploit is more difficult because the attacker has to manufacture any required null bytes.

The malicious argument in this case is in the binary file exploit.bin:
000:  31 32 33 34 35 36 37 38 39 30 31 32 33 34 35 36  1234567890123456
010:  37 38 39 30 31 32 33 34 04 fc ff bf 78 78 78 78  78901234....xxxx
020:  31 c0 a3 23 fc ff bf b0 0b bb 27 fc ff bf b9 1f  1..#......'.....
030:  fc ff bf 8b 15 23 fc ff bf cd 80 27 fc ff bf 31  .....#.....'...1
040:  31 31 31 2f 75 73 72 2f 62 69 6e 2f 63 61 6c 0a  111/usr/bin/cal.

This malicious argument can be supplied to the vulnerable program using redirection, as follows:

%./BufferOverflow < exploit.bin

After the strcpy() function returns, the stack is overwritten as follows:
Row	Address	Content
1 	0xbffff9c0 –0xbffff9cf 	"123456789012456" storage for Password (16 bytes) program allocates 12 bytes but compiler defaults to multiples of 16 bytes
2 	0xbffff9d0 –0xbffff9db 	"789012345678" extra space allocated (12 bytes) compiler generated to force 16-byte stack alignments
3 	0xbffff9dc 	(0xbffff9e0) # new return address
4 	0xbffff9e0 	xor %eax,%eax # set eax to zero
5 	0xbffff9e2 	mov %eax,0xbffff9ff # set to NULL word
6 	0xbffff9e7 	mov $0xb,%al # set code for execve
7 	0xbffff9e9 	mov $0xbffffa03,%ebx # ptr to arg 1
8 	0xbffff9ee 	mov $0xbffff9fb,%ecx # ptr to arg 2
9 	0xbffff9f3 	mov 0xbffff9ff,%edx # ptr to arg 3
10 	0xbffff9f9 	int $80 # make system call to execve
11 	0xbffff9fb 	arg 2 array pointer array char *[]={0xbffff9ff, points to a NULL str
12 	0xbffff9ff 	"1111"}; # changed to 0x00000000 terminates ptr array and also used for arg3
13 	0xbffffa03 –0xbffffa0f 	"/usr/bin/cal\0"

The exploit works as follows.

    The first 16 bytes of binary data (row 1) fill the allocated storage space for the password. Even though the program allocated only 12 bytes for the password, the version of the GCC compiler that was used to compile the program allocates stack data in multiples of 16 bytes.
    The next 12 bytes of binary data (row 2) fill the extra storage space that was created by the compiler to keep the stack aligned on a 16-byte boundary. Only 12 bytes are allocated by the compiler because the stack already contained a 4-byte return address when the function was called.
    The return address is overwritten (row 3) to resume program execution (row 4) when the program executes the return statement in the function IsPasswordOkay(), resulting in the execution of code contained on the stack (rows 4–10).
    A zero value is created and used to null-terminate the argument list (rows 4 and 5) because an argument to a system call made by this exploit must contain a list of character pointers terminated by a null pointer. Because the exploit cannot contain null characters until the last byte, the null pointer must be set by the exploit code.
    The system call is set to 0xB, which equates to the execve() system call in Linux (row 6).
    The three arguments for the execve() function call are set up (rows 7–9).
    The data for these arguments is located in rows 12 and 13.
    The execve() system call is executed, which results in the execution of the Linux calendar program (row 10).

Reverse engineering of the code can be used to determine the exact offset from the buffer to the return address in the stack frame, which leads to the location of the injected shellcode. However, it is possible to relax these requirements. [1] For example, the location of the return address can be approximated by repeating the return address several times in the approximate region of the return address. Assuming a 32-bit architecture, the return address is normally 4-byte aligned. Even if the return address is offset, there are only four possibilities to test. The location of the shellcode can also be approximated by prefixing a series of nop instructions before the shellcode (often called a nop sled). The exploit need only jump somewhere in the field of nop instructions to execute the shellcode.

Most real-world stack-smashing attacks behave in this fashion: they overwrite the return address to transfer control to injected code. Exploits that simply change the return address to jump to a new location in the code are less common, partly because these vulnerabilities are harder to find (it depends on finding program logic that can be bypassed) and less useful to an attacker (allowing access to only one program as opposed to running arbitrary code).

					24.1.1.3.6.1 learn by coding


				24.1.1.3.7 Arc Injection

The first exploit for the IsPasswordOkay program, described in the Stack Smashing section, modified the return address to change the control flow of the program (in this case, to circumvent the password protection logic). The arc injection technique (sometimes called return-into-libc) involves transferring control to code that already exists in process memory. These exploits are called arc injection because they insert a new arc (control-flow transfer) into the program’s control-flow graph as opposed to injecting new code. More sophisticated attacks are possible using this technique, including installing the address of an existing function (such as system() or exec(), which can be used to execute commands and other programs already on the local system) on the stack along with the appropriate arguments. When the return address is popped off the stack (by the ret or iret instruction in x86), control is transferred by the return instruction to an attacker-specified function. By invoking functions like system() or exec(), an attacker can easily create a shell on the compromised machine with the permissions of the compromised program.

Worse yet, an attacker can use arc injection to invoke multiple functions in sequence with arguments that are also supplied by the attacker. An attacker can now install and run the equivalent of a small program that includes chained functions, increasing the severity of these attacks.

The following program is vulnerable to a buffer overflow.
01	#include <string.h>
02	 
03	int get_buff(char *user_input, size_t size){
04	  char buff[40];
05	  memcpy(buff, user_input, size);
06	  return 0;
07	}
08	 
09	int main(void) {
10	  /* … */
11	  get_buff(tainted_char_array, tainted_size);
12	  /* … */
13	}

Tainted data in user_input is copied to the buff character array using memcpy(). A buffer overflow can result if user_input is larger than the buff buffer.
An attacker may prefer arc injection over code injection for several reasons. Because arc injection uses code already in memory on the target system, the attacker merely needs to provide the addresses of the functions and arguments for a successful attack. The footprint for this type of attack can be significantly smaller and may be used to exploit vulnerabilities that cannot be exploited by the code injection technique. Because the exploit consists entirely of existing code, it cannot be prevented by memory-based protection schemes such as making memory segments (such as the stack) nonexecutable. It may also be possible to restore the original frame to prevent detection.

Chaining function calls together allows for more powerful attacks. A security-conscious programmer, for example, might follow the principle of least privilege and drop privileges when not required. [1] By chaining multiple function calls together, an exploit could regain privileges, for example, by calling setuid() before calling system().

				24.1.1.3.8 Return-Oriented Programming

The return-oriented programming exploit technique is similar to arc injection, but instead of returning to functions, the exploit code returns to sequences of instructions followed by a return instruction. Any such useful sequence of instructions is called a gadget. A Turing-complete set of gadgets has been identified for the x86 architecture, [2] allowing arbitrary programs to be written in the return-oriented language. A Turing-complete library of code gadgets using snippets of the Solaris libc, a general-purpose programming language, and a compiler for constructing return-oriented exploits have also been developed. [1] Consequently, there is an assumed risk that return-oriented programming exploits could be effective on other architectures as well.

The return-oriented programming language consists of a set of gadgets. Each gadget specifies certain values to be placed on the stack that make use of one or more sequences of instructions in the code segment. Gadgets perform well-defined operations, such as a load, an add, or a jump.

Return-oriented programming consists of putting gadgets together that will perform the desired operations. Gadgets are executed by a return instruction with the stack pointer referring to the address of the gadget.

For example, the sequence of instructions:
pop %ebx;
ret

forms a gadget that can be used to load a constant value into the ebx register, as shown in the following illustration:

The left side of this illustration shows the x86-32 assembly language instruction necessary to copy the constant value $0xdeadbeef into the ebx register, and the right side shows the equivalent gadget. With the stack pointer referring to the gadget, the return instruction is executed by the CPU. The resulting gadget pops the constant from the stack and returns execution to the next gadget on the stack.

Return-oriented programming also supports both conditional and unconditional branching. In return-oriented programming, the stack pointer takes the place of the instruction pointer in controlling the flow of execution. An unconditional jump requires simply changing the value of the stack pointer to point to a new gadget. This is easily accomplished using the instruction sequence:
pop %esp;
ret

The x86-32 assembly language programming and return-oriented programming idioms for unconditional branching are contrasted in the following figure:

An unconditional branch can be used to branch to an earlier gadget on the stack, resulting in an infinite loop. Conditional iteration can be implemented by a conditional branch out of the loop.

Shacham’s paper contains a more complete tutorial on return-oriented programming. [2] While return-oriented programming might seem very complex, this complexity can be abstracted behind a programming language and compiler, making it a viable technique for writing exploits.

				24.1.1.3.9

			24.1.1.4 Mitigation Strategies
Learning Objectives

    Identify applicable mitigation strategies, evaluate candidate mitigation strategies, and select the most appropriate mitigation strategy (or strategies) for a given context.
    Apply mitigation strategies to reduce the introduction of errors into new code or repair security flaws in existing code.

Because errors in string manipulation have long been recognized as a leading source of buffer overflows in C and C++, a number of mitigation strategies have been devised. These include mitigation strategies designed to prevent buffer overflows from occurring and strategies designed to detect buffer overflows and securely recover without allowing the failure to be exploited.

Rather than completely relying on a given mitigation strategy, it is often advantageous to follow a defense-in-depth tactic that combines multiple strategies. A common approach is to consistently apply a secure technique to string handling (a prevention strategy) and back it up with one or more runtime detection and recovery schemes.

				24.1.1.4.1 String Handling

The CERT C Secure Coding Standard STR01-C. Adopt and implement a consistent plan for managing strings recommends selecting a single approach to handling character strings and applying it consistently across a project. Otherwise, the decision is left to individual programmers who are likely to make different, inconsistent choices. String-handling functions can be categorized according to how they manage memory. There are three basic models:

    Caller allocates, caller frees (C99, OpenBSD, C11 Annex K)
    Callee allocates, caller frees (ISO/IEC TR 24731-2)
    Callee allocates, callee frees (C++ std::basic_string)

It could be argued whether the first model is more secure than the second model, or vice versa. The first model makes it clearer when memory needs to be freed, and it is more likely to prevent leaks, but the second model makes sure sufficient memory is available (except when a call to malloc() fails).

The third memory management mode, in which the callee both allocates and frees storage, is the most secure of the three solutions but is available only in C++.

				24.1.1.4.2 C11 Annex K, Bounds-Checking Interfaces

The first memory management model (caller allocates, caller frees) is implemented by the C string-handling functions defined in <string.h>, the OpenBSD functions strlcpy() and strlcat(), and by the C11 Annex K bounds-checking interfaces. Memory can be statically or dynamically allocated before invoking these functions, making this model optimally efficient. Annex K provides alternative library functions that promote safer, more secure programming. The alternative functions verify that output buffers are large enough for the intended result and return a failure indicator if they are not. Data is never written past the end of an array. All string results are null terminated.

C11 Annex K bounds-checking interfaces are primarily designed to be safer replacements for existing functions. For example, C11 Annex K defines the strcpy_s(), strcat_s(), strncpy_s(), and strncat_s() functions as replacements for strcpy(), strcat(), strncpy(), and strncat(), respectively, suitable in situations when the length of the source string is not known or guaranteed to be less than the known size of the destination buffer.

The C11 Annex K functions were created by Microsoft to help retrofit its existing legacy code base in response to numerous well-publicized security incidents over the past decade. These functions were subsequently proposed to the ISO/IEC JTC1/SC22/WG14 international standardization working group for the programming language C for standardization. These functions were published as ISO/IEC TR 24731-1 [1] and later incorporated in C11 in the form of a set of optional extensions specified in a normative annex. Because the C11 Annex K functions can often be used as simple replacements for the original library functions in legacy code, The CERT C Secure Coding Standard STR07-C. Use TR 24731 for remediation of existing string manipulation code recommends using them for this purpose on implementations that implement the Annex. (Such implementations are expected to define the __STDC_LIB_EXT1__ macro.)

Annex K also addresses another problem that complicates writing robust code: functions that are not reentrant because they return pointers to static objects owned by the function. Such functions can be troublesome because a previously returned result can change if the function is called again, perhaps by another thread.

C11 Annex K is a normative but optional annex—you should make sure it is available on all your target platforms. Even though these functions were originally developed by Microsoft, the implementation of the bounds-checking library that ships with Microsoft Visual C++ 2010 and earlier releases does not conform completely with Annex K because of changes to these functions during the standardization process that have not been retrofitted to Microsoft Visual C++.
Example
Reading from stdin using gets_s()

The example from Section 2, “Improperly Bounded String Copies,” can be reimplemented using the C11 Annex K functions as follows:
01	#define __STDC_WANT_LIB_EXT1__ 1
02	#include <stdio.h>
03	#include <stdlib.h>
04	 
05	void get_y_or_n(void) {
06	  char response[8];
07	  size_t len = sizeof(response);
08	  printf("Continue? [y] n: ");
09	  gets_s(response, len);
10	  if (response[0] == ’n’)
11	    exit(0);
12	}

This program is similar to the original example except that the array bounds are checked. There is implementation-defined behavior (typically program aborts) if eight or more characters are input.

Most bounds-checking functions, upon detecting an error such as invalid arguments or not enough bytes available in an output buffer, call a special runtime-constraint-handler function. This function might print an error message and/or abort the program. The programmer can control which handler function is called via the set_constraint_handler_s() function and can make the handler simply return if desired. If the handler simply returns, the function that invoked the handler indicates a failure to its caller using its return value. Programs that install a handler that returns must check the return value of each call to any of the bounds-checking functions and handle errors appropriately. The CERT C Secure Coding Standard ERR03-C. Use runtime-constraint handlers when calling functions defined by TR24731-1 recommends installing a runtime-constraint handler to eliminate implementation-defined behavior.
Example
Reading from stdin using gets_s() (improved)

The “Improperly Bounded String Copies” example of reading from stdin using the C11 Annex K bounds-checking functions can be improved to remove the implementation-defined behavior at the cost of some additional complexity:
01	#define __STDC_WANT_LIB_EXT1__ 1
02	#include <stdio.h>
03	#include <stdlib.h>
04	 
05	void get_y_or_n(void) {
06	  char response[8];
07	  size_t len = sizeof(response);
08	 
09	  printf("Continue? [y] n: ");
10	  if ((gets_s(response, len) == NULL) || (response[0] == ’n’)) {
11	     exit(0);
12	  }
13	}
14	 
15	int main(void) {
16	  constraint_handler_t oconstraint =
17	    set_constraint_handler_s(ignore_handler_s);
18	  get_y_or_n();
19	}

This example adds a call to set_constraint_handler_s() to install the ignore_handler_s() function as the runtime-constraint handler. If the runtime-constraint handler is set to the ignore_handler_s() function, any library function in which a runtime-constraint violation occurs will return to its caller. The caller can determine whether a runtime-constraint violation occurred on the basis of the library function’s specification. Most bounds-checking functions return a nonzero errno_t. Instead, the get_s() function returns a null pointer so that it can serve as a close drop-in replacement for gets().

In conformance with The CERT C Secure Coding Standard ERR00-C. Adopt and implement a consistent and comprehensive error-handling policy, the constraint handler is set in main() to allow for a consistent error-handling policy throughout the application. Custom library functions may wish to avoid setting a specific constraint-handler policy because it might conflict with the overall policy enforced by the application. In this case, library functions should assume that calls to bounds-checked functions will return and check the return status accordingly. In cases in which the library function does set a constraint handler, the function must restore the original constraint handler (returned by the set_constraint_handler_s() function) before returning or exiting (in case there are atexit() registered functions).
learn by doing
Runtime-Constraint Handling

Both the C string-handling and C11 Annex K bounds-checking functions require that storage be preallocated. It is impossible to add new data once the destination memory is filled. Consequently, these functions must either discard excess data or fail. It is important that the programmer ensures the destination is of sufficient size to hold the character data to be copied and the null-termination character, as described by The CERT C Secure Coding Standard STR31-C. Guarantee that storage for strings has sufficient space for character data and the null terminator.

The bounds-checking functions defined in C11 Annex K are not foolproof. If an invalid size is passed to one of the functions, it could still suffer from buffer overflow problems while appearing to have addressed such issues. Because the functions typically take more arguments than their traditional counterparts, using them requires a solid understanding of the purpose of each argument. Introducing the bounds-checking functions into a legacy code base as replacements for their traditional counterparts also requires great care to avoid inadvertently injecting new defects in the process. It is also worth noting that it is not always appropriate to replace every C string-handling function with its corresponding bounds-checking function.

				24.1.1.4.3 Dynamic Allocation Functions

The second memory management model (callee allocates, caller frees) is implemented by the dynamic allocation functions defined by ISO/IEC TR 24731-2. [2] ISO/IEC TR 24731-2 defines replacements for many of the standard C string-handling functions that use dynamically allocated memory to ensure that buffer overflow does not occur. Because the use of such functions requires introducing additional calls to free the buffers later, these functions are better suited to new development than to retrofitting existing code.

In general, the functions described in ISO/IEC TR 24731-2 provide greater assurance that buffer overflow problems will not occur, because buffers are always automatically sized to hold the data required. Applications that use dynamic memory allocation might, however, suffer from denial-of-service attacks in which data is presented until memory is exhausted. They are also more prone to dynamic memory management errors, which can also result in vulnerabilities. [4]
Example
Reading from stdin using getline()

The “Improperly Bounded String Copies” example can be implemented using the dynamic allocation functions as follows:
01	#define __STDC_WANT_LIB_EXT2__ 1
02	#include <stdio.h>
03	#include <stdlib.h>
04	 
05	void get_y_or_n(void) {
06	  char *response = NULL;
07	  size_t len;
08	 
09	  printf("Continue? [y] n: ");
10	  if ((getline(&response, &len, stdin) < 0) ||
11	      (len && response[0] == ’n’)) {
12	    free(response);
13	    exit(0);
14	  }
15	  free(response);
16	}

This program has defined behavior for any input, including the assumption that an extremely long line that exhausts all available memory to hold it should be treated as if it were a “no” response. Because the getline() function dynamically allocates the response buffer, the program must call free() to release any allocated memory.

ISO/IEC TR 24731-2 [2] allows you to define streams that do not correspond to open files. One such type of stream takes input from or writes output to a memory buffer. These streams are used by the GNU C library, for example, to implement the sprintf() and sscanf() functions.

A stream associated with a memory buffer has the same operations for text files that a stream associated with an external file would have. In addition, the stream orientation is determined in exactly the same fashion.

You can create a string stream explicitly using the fmemopen(), open_memstream(), or open_wmemstream() function. These functions allow you to perform I/O to a string or memory buffer. The fmemopen() and open_memstream() functions are declared in <stdio.h> as follows:
FILE *fmemopen(
  void * restrict buf, size_t size, const char * restrict mode
);
FILE *open_memstream(char ** restrict bufp, size_t * restrict sizep);
            

The open_wmemstream() function is defined in <wchar.h> and has the following signature:
1	FILE *open_wmemstream(wchar_t **bufp, size_t *sizep);

The fmemopen() function opens a stream that allows you to read from or write to a specified buffer. The open_memstream() function opens a byte-oriented stream for writing to a buffer, and the open_wmemstream() function creates a wide-oriented stream. When the stream is closed with fclose() or flushed with fflush(), the locations bufp and sizep are updated to contain the pointer to the buffer and its size. These values remain valid only as long as no further output on the stream takes place. If you perform additional output, you must flush the stream again to store new values before you use them again. A null character is written at the end of the buffer but is not included in the size value stored at sizep.

Input and output operations on a stream associated with a memory buffer by a call to fmemopen(), open_memstream(), or open_wmemstream() are constrained by the implementation to take place within the bounds of the memory buffer. In the case of a stream opened by open_memstream() or open_wmemstream(), the memory area grows dynamically to accommodate write operations as necessary. For output, data are moved from the buffer provided by setvbuf() to the memory stream during a flush or close operation. If there is insufficient memory to grow the memory area, or the operation requires access outside of the associated memory area, the associated operation fails.

The following program opens a stream to write to memory on line 6.
01	#include <stdio.h>
02	 
03	    int main(void) {
04	      char *buf;
05	      size_t size;
06	      FILE *stream;
07	 
08	      stream = open_memstream(&buf, &size);
09	      if (stream == NULL) /* handle error */ ;
10	      fprintf(stream, "hello");
11	      fflush(stream);
12	      printf("buf = '%s', size = %zu\n", buf, size);
13	      fprintf(stream, ", world");
14	      fclose(stream);
15	      printf("buf = '%s', size = %zu\n", buf, size);
16	      free(buf);
17	      return 0;
18	    }

The string "hello" is written to the stream on line 10, and the stream is flushed on line 11. The call to fflush() updates buf and size so that the printf() function on line 12 outputs:
1	buf ='hello', size =5

After the string ", world" is written to the stream on line 13, the stream is closed on line 14. Closing the stream also updates buf and size so that the printf() function on line 15 outputs:
1	buf ='hello, world', size =12

The size is the cumulative (total) size of the buffer. The fmemopen() function provides a safer mechanism for writing to memory because it uses a dynamic approach that allocates memory as required. However, it does require the caller to free the allocated memory, as shown on line 16 of the example.

Dynamic allocation is often disallowed in safety-critical systems. For example, the MISRA standard requires that “dynamic heap memory allocation shall not be used.” [3] Some safety-critical systems can take advantage of dynamic memory allocation during initialization but not during operations. For example, avionics software may dynamically allocate memory while initializing the aircraft but not during flight.

The dynamic allocation functions are drawn from existing implementations that have widespread usage; many of these functions are included in POSIX. [1] 

				24.1.1.4.4 C++ std::basic_string

An earlier section of the course described a common programming flaw using the C++ extraction operator operator>> to read input from the standard std::cin iostream object into a character array. Although setting the field width eliminates the buffer overflow vulnerability, it does not address the issue of truncation. Also, unexpected program behavior could result when the maximum field width is reached and the remaining characters in the input stream are consumed by the next call to the extraction operator.

C++ programmers have the option of using the standard std::string class defined in ISO/IEC 14882. [1] The std::string class is a specialization of the std::basic_string template on type char. The std::wstring class is a specialization of the std::basic_string template on type wchar_t.

The basic_string class represents a sequence of characters. It supports sequence operations as well as string operations such as search and concatenation and is parameterized by character type.

The basic_string class uses a dynamic approach to strings in that memory is allocated as required—meaning that in all cases, size() <= capacity(). The basic_string class is convenient because the language supports the class directly. Also, many existing libraries already use this class, which simplifies integration.

The basic_string class implements the “callee allocates, callee frees” memory management strategy. This is the most secure approach, but it is only supported in C++. Because basic_string manages memory, the caller does not need to worry about the details of memory management. For example, string concatenation is handled simply as follows:
1	string str1 = "hello, ";
2	string str2 = "world";
3	string str3 = str1 + str2;

Internally, the basic_string methods allocate memory dynamically; buffers are always automatically sized to hold the data required, typically by invoking realloc(). These methods scale better than their C counterparts and do not discard excess data.

The following program shows a solution to extracting characters from std::cin into a std::string, using a std::string object instead of a character array.
01	#include <iostream>
02	#include <string>
03	using namespace std;
04	 
05	int main(void) {
06	  string str;
07	 
08	  cin >> str;
09	  cout << "str 1: " << str << '\n';
10	}

This program is simple and elegant, handles buffer overflows and string truncation, and behaves in a predictable fashion. What more could you possibly want?

The basic_string class is less prone to security vulnerabilities than null-terminated byte strings, although coding errors leading to security vulnerabilities are still possible. One area of concern when using the basic_string class is iterators. Iterators can be used to iterate over the contents of a string:
view source
print?
1	string::iterator i;
2	for (i = str.begin(); i != str.end(); ++i) {
3	  cout << *i;
4	}

				24.1.1.4.5 Invalidating String Object References

References, pointers, and iterators referencing string objects are invalidated by operations that modify the string, which can lead to errors. Using an invalid iterator is undefined behavior and can result in a security vulnerability.

For example, the following program fragment attempts to sanitize an email address stored in the input character array before passing it to a command shell by copying the null-terminated byte string to a string object (email), replacing each semicolon with a space character:
Example
01	char input[];
02	string email;
03	string::iterator loc = email.begin();
04	// copy into string converting ";" to " "
05	for (size_t i=0; i < strlen(input); i++) {
06	  if (input[i] != ';') {
07	    email.insert(loc++, input[i]); // invalid iterator
08	  }
09	  else email.insert(loc++, ' '); // invalid iterator
10	}

The problem with this code is that the iterator loc is invalidated after the first call to insert(), and every subsequent call to insert() results in undefined behavior. This problem can be easily repaired if the programmer is aware of the issue:
01	char input[];
02	string email;
03	string::iterator loc = email.begin();
04	// copy into string converting ";" to " "
05	for (size_t i=0; i < strlen(input); ++i) {
06	  if (input[i] != ';') {
07	    loc = email.insert(loc, input[i]);
08	  }
09	  else loc = email.insert(loc, ' ');
10	  ++loc;
11	}

In this version of the program, the value of the iterator loc is properly updated as a result of each insertion, eliminating the undefined behavior. Most checked standard template library (STL) implementations detect common errors automatically. Use a checked STL implementation. At a minimum, run on a single platform during prerelease testing using your full complement of tests.

The basic_string class generally protects against buffer overflow, but there are still situations in which programming errors can lead to buffer overflows. While C++ generally throws an exception of type std::out_of_range when an operation references memory outside the bounds of the string, for maximum efficiency, the subscript member std::string::operator[] (which does not perform bounds checking) does not. For example, the following program fragment can result in a write outside the bounds of the storage allocated to the bs string object if f() >= bs.size().
1	string bs("01234567");
2	size_t i = f();
3	bs[i] = '\0';

The at() method behaves in a similar fashion to the index operator[] but throws an out_of_range exception if pos >= size().

string bs("01234567");
1	string bs("01234567");
2	try {
3	  size_t i = f();
4	  bs.at(i) = '\0';
5	}
6	catch (out_of_range& oor) {
7	  cerr << "Out of Range error: " << oor.what() << '\n';
8	}

Although the basic_string class is generally more secure, the use of null-terminated byte strings in a C++ program is generally unavoidable except in rare circumstances in which there are no string literals and no interaction with existing libraries that accept null-terminated byte strings. The c_str() method can be used to generate a null-terminated sequence of characters with the same content as the string object and returns it as a pointer to an array of characters.
1	string str = x;
2	cout << strlen(str.c_str());

The c_str() method returns a const value, which means that calling free() or delete on the returned string is an error. Modifying the returned string can also lead to an error, so if you need to modify the string, make a copy first and then modify the copy.

Other Common Mistakes in basic_string Usage

Other common mistakes using the basic_string class include:

    Using an invalidated or uninitialized iterator.
    Passing an out-of-bounds index.
    Using an iterator range that really is not a range.
    Passing an invalid iterator position.

These issues are discussed in more detail in C++ Coding Standards: 101 Rules, Guidelines, and Best Practices by Herb Sutter and Andrei Alexandrescu. [1]

Finally, many existing C++ programs and libraries use their own string classes. To use these libraries, you may have to use these string types or constantly convert back and forth. Such libraries are of varying quality when it comes to security. It is generally best to use the standard library (when possible) or to understand completely the semantics of the selected library. Generally speaking, libraries should be evaluated on the basis of how easy or complex they are to use, the type of errors that can be made, how easy those errors are to make, and what the potential consequences may be.

					24.1.1.4.5.1 String Copy Question 1
Select one answer.

Compare and contrast the following two program fragments. Each counts the number of spaces in a string.

Solution A
1	string::iterator i;
2	size_t count = 0;
3	for (i=str.begin(); i != str.end(); ++i) {
4	  if (str[i] == ' ') count++;
5	}

Solution B
1	string::iterator i;
2	size_t count = 0;
3	for (i=str.begin(); i != str.end(); ++i) {
4	  if (str.at(i) == ' ') count++;
5	}
6	                

    Both solutions are equally secure, but solution A is faster.  - Correct
    Solution B is both more secure and faster.
    Solution B is more secure, but solution A is faster.
    Both solutions are equally secure and are equally fast.

Feedback

Correct! Because there is no possibility of an out-of-bounds read or write, both solutions are equally secure, but the unchecked operator[] is faster.

					24.1.1.4.5.2
			24.1.1.5 gets( )

If there were ever a hard and fast rule for secure programming in C and C++, it would be this: never invoke the gets() function. The gets() function has been used extensively in the examples of vulnerable programs in this course. The gets() function reads a line from standard input into a buffer until a terminating newline or end-of-file (EOF) is found. No check for buffer overflow is performed. The following quote is from the manual page for the function:

    Never use gets(). Because it is impossible to tell without knowing the data in advance how many characters gets() will read, and because gets() will continue to store characters past the end of the buffer, it is extremely dangerous to use. It has been used to break computer security.

As already mentioned, the gets() function has been deprecated in ISO/IEC 9899:TC3 and removed from C11.

Because the gets() function cannot be securely used, it is necessary to use an alternative replacement function, of which several good options are available. Which function you select primarily depends on the overall approach taken.
C11

Two options for a strictly C11-conforming application are to replace gets() with either fgets() or getchar().

The C11 fgets() function (C11 §7.21.7.2) has similar behavior to gets(). The fgets() function accepts two additional arguments: the number of characters to read and an input stream. When stdin is specified as the stream, fgets() can be used to simulate the behavior of gets().
Example
Reading from stdin using fgets()

The following program fragment reads a line of text from stdin using the fgets() function:
01	char buf[LINE_MAX];
02	int ch;
03	char *p;
04	  
05	if (fgets(buf, sizeof(buf), stdin)) {
06	  /* fgets succeeds, scan for newline character */
07	  p = strchr(buf, '\n');
08	  if (p) {
09	    *p = '\0';
10	  }
11	  else {
12	    /* newline not found, flush stdin to end of line */
13	    while (((ch = getchar()) != '\n')
14	          && !feof(stdin)
15	          && !ferror(stdin)
16	    );
17	  }
18	}
19	else {
20	  /* fgets failed, handle error */
21	}

Unlike gets(), the fgets() function retains the newline character, meaning that the function cannot be used as a direct replacement for gets().

When using fgets(), it is possible to read a partial line. Truncation of user input can be detected because the input buffer will not contain a newline character.

The fgets() function reads, at most, one less than the number of characters specified from the stream into an array. No additional characters are read after a newline character or EOF. A null character is written immediately after the last character read into the array.

It is possible to use fgets() to securely process input lines too long to store in the destination array, but this is not recommended for performance reasons. The fgets() function can result in a buffer overflow if the specified number of characters to input exceeds the length of the destination buffer.

A second alternative for replacing the gets() function in a strictly C11-conforming application is to use the getchar() function (C11 §7.21.7.6). The getchar() function returns the next character from the input stream pointed to by stdin. If the stream is at EOF, the EOF indicator for the stream is set and getchar() returns EOF. If a read error occurs, the error indicator for the stream is set and getchar() returns EOF.
Example
Reading from stdin using getchar()

The following program fragment reads a line of text from stdin using the getchar() function:
01	unsigned char buf[BUFSIZ];
02	int ch;
03	int index = 0;
04	int chars_read = 0;
05	 
06	while ( ( (ch = getchar()) != '\n')
07	        && !feof(stdin)
08	        && !ferror(stdin) )
09	{
10	  if (index < BUFSIZ-1) {
11	    buf[index++] = (unsigned char)ch;
12	  }
13	  chars_read++;
14	} /* end while */
15	buf[index] = '\0';  /* null-terminate */
16	if (feof(stdin)) {
17	  /* handle EOF */
18	}
19	if (ferror(stdin)) {
20	  /* handle error */
21	}
22	if (chars_read > index) {
23	  /* handle truncation */
24	}

If at the end of the loop feof(stdin) !=0, the loop has read through to the end of the file without encountering a newline character. If at the end of the loop ferror(stdin) !=0, a read error occurred before the loop encountered a newline character. If at the end of the loop chars_read > index, the input string has been truncated. The CERT C Secure Coding Standard FIO34-C. Use int to capture the return value of character IO functions is also applied in this solution.

Using the getchar() function to read in a line can still result in a buffer overflow if writes to the buffer are not properly bounded.

Reading one character at a time provides more flexibility in controlling behavior without additional performance overhead.

The following test for the while loop is normally sufficient.

while (( (ch =getchar()) !='\n') &&ch !=EOF )

See The CERT C Secure Coding FIO35-C. Use feof() and ferror() to detect end-of-file and file errors when sizeof(int) == sizeof(char) for the case where feof() and ferror() must be used instead.

				24.1.1.5.1 did I get this
String Handling
What, if anything, is wrong with the following program fragment?
1	char buf[BUFSIZ], *p;
2	int ch;
3	p = buf;
4	while ( ( (ch = getchar()) != '\n') && ch != EOF ) {
5	  *p++ = ch;
6	}
7	*p++ = 0;

    There are no guarantees that this code will not result in a buffer overflow. - Correct
    The getchar() function returns a value of type char, not a value of type int.
    The program must use the array index operator [], not pointer arithmetic.
    The program fragment fails to use the gets_s() function.

Feedback

Correct! There is no guarantee that an array of size BUFSIZ will be large enough to contain all the characters preceding the newline character in the input stream.

				24.1.1.5.2

			24.1.1.6 C11 Annex K, Bounds-Checking Interfaces: gets()

The C11 gets_s() function (C11 §K.3.5.4.1) is a compatible but more secure version of gets(). The gets_s() function is a closer replacement for the gets() function than fgets() in that it only reads from the stream pointed to by stdin and does not retain the newline character. The gets_s() function accepts an additional argument, rsize_t, that specifies the maximum number of characters to input. An error condition occurs if this argument is equal to zero or greater than RSIZE_MAX or if the pointer to the destination character array is NULL. If an error condition occurs, no input is performed and the character array is not modified. Otherwise, the gets_s() function reads, at most, one less than the number of characters specified, and a null character is written immediately after the last character read into the array.
Example
Reading from stdin using gets_s()

The following program fragment reads a line of text from stdin using the gets_s() function:
1	char buf[BUFSIZ];
2	  
3	if (gets_s(buf, sizeof(buf)) == NULL) {
4	  /* handle error */
5	}

The gets_s() function returns a pointer to the character array if successful. A null pointer is returned if the function arguments are invalid, an end-of-file is encountered, and no characters have been read into the array or if a read error occurs during the operation.

The gets_s() function succeeds only if it reads a complete line (that is, it reads a newline character). If a complete line cannot be read, the function returns NULL, sets the buffer to the null string, and clears the input stream to the next newline character.

The gets_s() function can still result in a buffer overflow if the specified number of characters to input exceeds the length of the destination buffer.

As noted earlier, the fgets() function allows properly written programs to safely process input lines too long to store in the result array. In general, this requires that callers of fgets() pay attention to the presence or absence of a newline character in the result array. Using gets_s() with input lines that might be too long requires overriding its runtime-constraint handler (and resetting it to its default value when done). Consider using fgets() (along with any needed processing based on newline characters) instead of gets_s().

			24.1.1.7 Dynamic Allocation Functions

ISO/IEC TR 24731-2 [1] describes the getline() function derived from POSIX. The behavior of the getline() function is similar to that of fgets() but offers several extra features. First, if the input line is too long, rather than truncating input, the function resizes the buffer using realloc(). Second, if successful, it returns the number of characters read, which is useful in determining whether the input has any null characters before the newline. The getline() function works only with buffers allocated with malloc(). If passed a null pointer, getline() allocates a buffer of sufficient size to hold the input. As such, the user must explicitly free() the buffer later. The getline() function is equivalent to the getdelim() function (also defined in ISO/IEC TR 24731-2) with the delimiter character equal to the newline character.
Example
Reading from stdin using getline()

The following program fragment reads a line of text from stdin using the getline() function:
01	int ch;
02	char *p;
03	size_t buffer_size = 10;
04	char *buffer = malloc(buffer_size);
05	ssize_t size;
06	  
07	if ((size = getline(&buffer, &buffer_size, stdin)) == -1) {
08	  /* handle error */
09	} else {
10	  p = strchr(buffer, '\n');
11	  if (p) {
12	    *p = '\0';
13	  } else {
14	    /* newline not found, flush stdin to end of line */
15	    while (((ch = getchar()) != '\n')
16	       && !feof(stdin)
17	       && !ferror(stdin)
18	       );
19	  }
20	}
21	  
22	/* ... work with buffer ... */
23	  
24	free(buffer);

The getline() function returns the number of characters written into the buffer, including the newline character if one was encountered before end-of-file. If a read error occurs, the error indicator for the stream is set, and getline() returns −1. Consequently, the design of this function violates The CERT C Secure Coding Standard ERR02-C. Avoid in-band error indicators, as evidenced by the use of the ssize_t type that was created for the purpose of providing in-band error indicators.

Note that this code also does not check to see if malloc() succeeds. If malloc() fails, however, it returns NULL, which gets passed to getline(), which promptly allocates a buffer of its own.

The following table summarizes some of the alternative functions for gets() described in this section. All of these functions can be used securely (with the exception of gets()).
	Standard/TR	Retains Newline Character	Dynamically Allocates Memory
gets() 	C11 	no 	no
fgets() 	C11 	yes 	no
getline() 	TR 24731-2 	yes 	yes
gets_s() 	C11 	no 	no

				24.1.1.7.1 did I get this
gets() Alternatives
Question 1
Select one answer.
Correct
Show Hint
Which of the following techniques cannot be used by an attacker to exploit a stack-based buffer overflow on a program protected by stack canaries to execute arbitrary code?

    gets()
    getline() - Correct
    gets_s()
    fgets()

Feedback

Correct! The getline() function has the following signature: ssize_t getline(char ** lineptr, size_t * n, FILE * stream);. The value of *lineptr must be a valid argument that could be passed to the free() function. Consequently, passing getline() a pointer to statically allocated memory results in undefined behavior and may corrupt the heap.
				24.1.1.7.2
			24.1.1.8 strcpy( ) and strcat( )

The strcpy() (C99 §7.21.2.3, C11 §7.24.2.3) and strcat() (C99 §7.21.3.1, C11 §7.24.3.1) functions are frequent sources of buffer overflows because they do not allow the caller to specify the size of the destination array, and many prevention strategies recommend more secure variants of these functions.

Not all uses of strcpy() are flawed. For example, it is often possible to dynamically allocate the required space:
Example
Dynamically Allocating Required Space
1	dest = (char *)malloc(strlen(source) + 1);
2	if (dest) {
3	  strcpy(dest, source);
4	} else {
5	  /* handle error */
6	  ...
7	}

For this code to be secure, the source string must be fully validated, for example, to ensure that the string is not overly long. In some cases, it is clear that no potential exists for writing beyond the array bounds. As a result, it may not be cost effective to replace or otherwise secure every call to strcpy(). In other cases, it may still be desirable to replace the strcpy() function with a call to a safer alternative function to eliminate diagnostic messages generated by compilers or analysis tools.

The C11 strncpy() function is frequently recommended as an alternative to the strcpy() function. Unfortunately, strncpy() is prone to null-termination errors and other problems and consequently is not considered to be a secure alternative to strcpy().
OpenBSD

The strlcpy() and strlcat() functions first appeared in OpenBSD 2.4. [1] These functions copy and concatenate strings in a less error-prone manner than the corresponding C11 functions. These functions’ prototypes are as follows:
size_t strlcpy(char *dst, const char *src, size_t size);
size_t strlcat(char *dst, const char *src, size_t size);
                    

The strlcpy() function copies the null-terminated string from src to dst (up to size characters). The strlcat() function appends the null-terminated string src to the end of dst (but no more than size characters will be in the destination).

To help prevent writing outside the bounds of the array, the strlcpy() and strlcat() functions accept the full size of the destination string as a size parameter.

Both functions guarantee that the destination string is null-terminated for all nonzero-length buffers.

The strlcpy() and strlcat() functions return the total length of the string they tried to create. For strlcpy(), that is simply the length of the source; for strlcat(), it is the length of the destination (before concatenation) plus the length of the source. To check for truncation, the programmer must verify that the return value is less than the size parameter. If the resulting string is truncated, the programmer now has the number of bytes needed to store the entire string and may reallocate and recopy.

Neither strlcpy() nor strlcat() zero-fill their destination strings (other than the compulsory null byte to terminate the string). The result is performance close to that of strcpy() and much better than that of strncpy(). [1]


The strcpy_s() and strcat_s() functions are defined in C11 Annex K as close replacement functions for strcpy() and strcat(). The strcpy_s() function has an additional parameter giving the size of the destination array to prevent buffer overflow:
1	errno_t strcpy_s(
2	  char * restrict s1, rsize_t s1max, const char * restrict s2
3	);

The strcpy_s() function is similar to strcpy() when there are no constraint violations. The strcpy_s() function copies characters from a source string to a destination character array up to and including the terminating null character.

The strcpy_s() function succeeds only when the source string can be fully copied to the destination without overflowing the destination buffer. The function returns zero on success, implying that all of the requested characters from the string pointed to by s2 fit within the array pointed to by s1 and that the result in s1 is null-terminated. Otherwise, a nonzero value is returned.

The strcpy_s() function enforces a variety of runtime constraints. A runtime-constraint error occurs if either s1 or s2 is a null pointer; if the maximum length of the destination buffer is equal to zero, greater than RSIZE_MAX, or less than or equal to the length of the source string; or if copying takes place between overlapping objects. The destination string is set to the null string, and the function returns a nonzero value to increase the visibility of the problem.
Example
Open Watcom Implementation of the strcpy_s() function

The following is the Open Watcom implementation of the strcpy_s() function. The runtime-constraint error checks are followed by comments.
01	errno_t strcpy_s(
02	  char * restrict s1,     
03	  rsize_t s1max,
04	  const char * restrict s2
05	) {
06	  errno_t   rc = -1;
07	  const char  *msg;
08	  rsize_t   s2len = strnlen_s(s2, s1max);
09	  // Verify runtime-constraints
10	  if (nullptr_msg(msg, s1) && // s1 not NULL
11	    nullptr_msg(msg, s2) && // s2 not NULL
12	    maxsize_msg(msg, s1max) && // s1max <= RSIZE_MAX
13	    zero_msg(msg, s1max) && // s1max != 0
14	    a_gt_b_msg(msg, s2len, s1max - 1) &&
15	                        // s1max > strnlen_s(s2, s1max)
16	    overlap_msg(msg,s1,s1max,s2,s2len) // s1 s2 no overlap
17	  ) {
18	    while (*s1++ = *s2++);
19	    rc = 0;
20	  } else {
21	    // Runtime-constraints violated, make dest string empty
22	    if ((s1 != NULL) && (s1max > 0) && lte_rsizmax(s1max)) {
23	    s1[0] = NULLCHAR;
24	    }
25	  // Now call the handler
26	    __rtct_fail(__func__, msg, NULL);
27	  }
28	  return(rc);
29	}

The strcat_s() function appends the characters of the source string, up to and including the null character, to the end of the destination string. The initial character from the source string overwrites the null character at the end of the destination string.

The strcat_s() function returns zero on success. However, the destination string is set to the null string and a nonzero value is returned if either the source or destination pointer is NULL or if the maximum length of the destination buffer is equal to zero or greater than RSIZE_MAX. The strcat_s() function will also fail if the destination string is already full or if there is not enough room to fully append the source string.

The strcpy_s() and strcat_s() functions can still result in a buffer overflow if the maximum length of the destination buffer is incorrectly specified.

			24.1.1.9 Dynamic Allocation Functions

ISO/IEC TR 24731-2 [ISO/IEC TR 24731-2:2010] describes the POSIX strdup() function, which can also be used to copy a string. ISO/IEC TR 24731-2 does not define any alternative functions to strcat(). The strdup() function accepts a pointer to a string and returns a pointer to a newly allocated duplicate string. This memory must be reclaimed by passing the returned pointer to free(). 

				24.1.1.9.1  learn by doing
The code example from ENV00-C. Do not store the pointer to the string returned by getenv() can have unexpected results because the string referenced by tmpvar may be overwritten as a result of the second call to the getenv() function. Consequently, it is possible that both tmpvar and tempvar will compare equal even if the two environment variables have different values. Rewrite the following example using only the dynamic allocation functions defined in ISO/IEC TR 24731-2.

01	char *tmpvar;
02	char *tempvar;
03	  
04	tmpvar = getenv("TMP");
05	if (!tmpvar) return -1;
06	tempvar = getenv("TEMP");
07	if (!tempvar) return -1;
08	  
09	if (strcmp(tmpvar, tempvar) == 0) {
10	  if (puts("TMP and TEMP are the same.\n") == EOF) {
11	    /* Handle error */
12	  }
13	}
14	else {
15	  if (puts("TMP and TEMP are NOT the same.\n") == EOF) {
16	    /* Handle error */
17	  }
18	}

char *tmpvar;
char *tempvar;
  
tmpvar = strdup(getenv("TMP"));
if (!tmpvar) return -1;
tempvar = strdup(getenv("TEMP"));
if (!tempvar) return -1;
  
if (strcmp(tmpvar, tempvar) == 0) {
  if (puts("TMP and TEMP are the same.\n") == EOF) {
    /* Handle error */
  }
}
else {
  if (puts("TMP and TEMP are NOT the same.\n") == EOF) {
    /* Handle error */
  }
}
free(tmpvar);
free(tempvar);

				24.1.1.9.2
			24.1.1.10 Summary Alternatives

The following table summarizes some of the alternative functions for strcpy() described in this section.
	Standard/TR	Buffer Overflow Protection	Guarantees Proper Null-Termination	May Truncate String	Allocates Dynamic Memory
strcpy() 	C11 	no 	no 	no 	no
strncpy() 	C11 	yes 	no 	yes 	no
strlcpy() 	OpenBSD 	yes 	yes 	yes 	no
strdup() 	TR 24731-2 	yes 	yes 	no 	yes
strcpy_s() 	C11 	yes 	yes 	no 	no

The following table summarizes some of the alternative functions for strcat() described in this section. TR 24731-2 does not define an alternative function to strcat().
	Standard/TR	Buffer Overflow Protection	Guarantees Null-Termination	May Truncate String	Allocates Dynamic Memory
strcat() 	C11 	no 	no 	no 	no
strncat() 	C11 	yes 	no 	yes 	no
strlcat() 	OpenBSD 	yes 	yes 	yes 	no
strcat_s() 	C11 	yes 	yes 	no 	no
strncpy() and strncat()

The strncpy() (C11 ?7.24.2.4) and strncat() (C11 ?7.24.3.2) functions are similar to the strcpy() and strcat() functions, but each has an additional size_t parameter n that limits the number of characters to be copied. These functions can be thought of as truncating copy and concatenation functions.

The strncpy() library function performs a similar function to strcpy() but allows a maximum size n to be specified:
1	char *strncpy(
2	  char * restrict s1, const char * restrict s2, size_t n
3	);

The strncpy() function can be used as shown in the following example:
strncpy(dest, source, dest_size - 1);

Because the strncpy() function is not guaranteed to null-terminate the destination string, the programmer must be careful to ensure that the destination string is properly null-terminated without overwriting the last character.

The C11 strncpy() function is frequently recommended as a ?more secure? alternative to strcpy(). However, strncpy() is prone to string termination errors, as detailed in Section C11 Annex K, (normative) Bounds-Checking Interfaces: strncpy_s() and strncat_s of this module.

The strncat() function has the following signature:
1	char *strncat(
2	  char * restrict s1, const char * restrict s2, size_t n
3	);

The strncat() function appends not more than n characters (a null character and characters that follow it are not appended) from the array pointed to by s2 to the end of the string pointed to by s1. The initial character of s2 overwrites the null character at the end of s1. A terminating null character is always appended to the result. Consequently, the maximum number of characters that can end up in the array pointed to by s1 is strlen(s1)+n+1.

strncpy() and strncat() must be used with care, or should not be used at all, particularly as less error-prone alternatives are available. The following is an actual code example resulting from a simplistic transformation of existing code from strcpy() and strcat() to strncpy() and strncat():
1	strncpy(record, user, MAX_STRING_LEN - 1);
2	strncat(record, cpw, MAX_STRING_LEN - 1);

The problem is that the last argument to strncat() should not be the total buffer length; it should be the space remaining after the call to strncpy(). Both functions require that you specify the remaining space and not the total size of the buffer. Because the remaining space changes every time data is added or removed, programmers must track or constantly recompute the remaining space. These processes are error-prone and can lead to vulnerabilities. The following call correctly calculates the remaining space when concatenating a string using strncat():

strncat(dest, source, dest_size-strlen(dest)-1)

Another problem with using strncpy() and strncat() as alternatives to strcpy() and strcat() functions is that neither of the former functions provides a status code or reports when the resulting string is truncated. Both functions return a pointer to the destination buffer, requiring significant effort by the programmer to determine whether the resulting string was truncated.

There is also a performance problem with strncpy() in that it fills the entire destination buffer with null bytes after the source data is exhausted. Although there is no good reason for this behavior, many programs now depend on it, and as a result, it is difficult to change.

				24.1.1.10.1  Did I get this?
What is the problem with the following program fragment?
1	char ntbs[NTBS_SIZE];
2	  
3	const char *source = getenv("SOURCE");
4	if (source == 0) {                 
5	  exit(1);                         
6	}
7	ntbs[sizeof(ntbs)-1] = '\0';
8	strncpy(ntbs, source, sizeof(ntbs));
9	                

    If there is no null character in the first NTBS_SIZE characters of the source array, the result will not be null-terminated, and any remaining characters are truncated. - Correct
    Undefined behavior occurs if source is a null pointer.
    A buffer overflow will occur if the number of characters in the array designated by source is greater than the size of the ntbs array.
    There are no problems with this program fragment.

Feedback

Correct! The ntbs character array is null-terminated before the call to strncpy(). However, the subsequent execution of strncpy() can overwrite the null-termination character.

				24.1.1.10.2

			24.1.1.11 strncpy( ) and strncat( )

The strncpy() and strncat() functions serve a role outside of their use as alternative functions to strcpy() and strcat(). The original purpose of these functions was to allow copying and concatenation of a substring. However, these functions are prone to buffer overflow and null-termination errors.

C11 Annex K, Bounds-Checking Interfaces

C11 Annex K specifies the strncpy_s() and strncat_s() functions as close replacements for strncpy() and strncat().

The strncpy_s() function copies not more than a specified number of successive characters (characters that follow a null character are not copied) from a source string to a destination character array. The strncpy_s() function has the following signature:
1	errno_t strncpy_s(
2	  char * restrict s1,
3	  rsize_t s1max,
4	  const char * restrict s2,
5	  rsize_t n
6	);

The strncpy_s() function has an additional parameter giving the size of the destination array to prevent buffer overflow. If a runtime-constraint violation occurs, the destination array is set to the empty string to increase the visibility of the problem.

The strncpy_s() function stops copying the source string to the destination array when one of the following two conditions occurs:

    The null character terminating the source string is copied to the destination.
    The number of characters specified by the n argument has been copied.

The result in the destination is provided with a null character terminator if one was not copied from the source. The result, including the null terminator, must fit within the destination, or a runtime-constraint violation occurs. Storage outside of the destination array is never modified.

The strncpy_s() function returns zero to indicate success. If the input arguments are invalid, it returns a nonzero value and sets the destination string to the null string. Input validation fails if either the source or destination pointers are NULL or if the maximum size of the destination string is zero or greater than RSIZE_MAX. The input is also considered invalid when the specified number of characters to be copied exceeds RSIZE_MAX.

A strncpy_s() operation can actually succeed when the number of characters specified to be copied exceeds the maximum length of the destination string as long as the source string is shorter than the maximum length of the destination string. If the number of characters to copy is greater than or equal to the maximum size of the destination string and the source string is longer than the destination buffer, the operation will fail.

Because the number of characters in the source is limited by the n parameter and the destination has a separate parameter giving the maximum number of elements in the destination, the strncpy_s() function can safely copy a substring, not just an entire string or its tail.

Because unexpected string truncation is a possible security vulnerability, strncpy_s() does not truncate the source (as delimited by the null terminator and the n parameter) to fit the destination. Truncation is a runtime-constraint violation. However, there is an idiom that allows a program to force truncation using the strncpy_s() function. If the n argument is the size of the destination minus 1, strncpy_s() will copy the entire source to the destination or truncate it to fit (as always, the result will be null-terminated). For example, the following call will copy src to the dest array, resulting in a properly null-terminated string in dest. The copy will stop when dest is full (including the null terminator) or when all of src has been copied:

strncpy_s(dest, sizeof dest, src, (sizeof dest)-1)

Although OpenBSD function strlcpy() is similar to strncpy(), it is more similar to strcpy_s() than to strncpy_s(). Unlike strlcpy(), strncpy_s() supports checking runtime constraints such as the size of the destination array, and it will not truncate the string.

Use of the strncpy_s() function is less likely to introduce a security flaw because the size of the destination buffer and the maximum number of characters to append must be specified. Consider the following definitions:
1	char src1[100] = "hello";
2	char src2[7] = {'g','o','o','d','b','y','e'};
3	char dst1[6], dst2[5], dst3[5];
4	errno_t r1, r2, r3;

Because there is sufficient storage in the destination character array, the following call to strncpy_s() assigns the value zero to r1 and the sequence hello\0 to dst1.

r1 = strncpy_s(dst1, sizeof(dst1), src1, sizeof(src1));

The following call assigns the value zero to r2 and the sequence good\0 to dst2.

r2 = strncpy_s(dst2, sizeof(dst2), src2, 4);

However, there is inadequate space to copy the src1 string to dst3. Consequently, if the following call to strncpy_s() returns, r3 is assigned a nonzero value and dst3[0] is assigned '\0'.

r3 = strncpy_s(dst3, sizeof(dst3), src1, sizeof(src1));

If strncpy() had been used instead of strncpy_s(), the destination array dst3 would not have been properly null-terminated.

The strncat_s() function appends not more than a specified number of successive characters (characters that follow a null character are not copied) from a source string to a destination character array. The initial character from the source string overwrites the null character at the end of the destination array. If no null character was copied from the source string, then a null character is written at the end of the appended string. The strncat_s() function has the following signature:
1	errno_t strncat_s(
2	  char * restrict s1,
3	  rsize_t s1max,
4	  const char * restrict s2,
5	  rsize_t n
6	);

A runtime-constraint violation occurs and the strncat_s() function returns a nonzero value if either the source or destination pointers are NULL or if the maximum length of the destination buffer is equal to zero or greater than RSIZE_MAX. The function fails when the destination string is already full or if there is not enough room to fully append the source string. The strncat_s() function also ensures null-termination of the destination string.

The strncat_s() function has an additional parameter giving the size of the destination array to prevent buffer overflow. The original string in the destination plus the new characters appended from the source must fit and be null-terminated to avoid a runtime-constraint violation. If a runtime-constraint violation occurs, the destination array is set to a null string to increase the visibility of the problem.

The strncat_s() function stops appending the source string to the destination array when the first of the following two conditions occurs:

    The null-terminating source string is copied to the destination.
    The number of characters specified by the n parameter has been copied.

The result in the destination is provided with a null character terminator if one was not copied from the source. The result, including the null terminator, must fit within the destination, or a runtime-constraint violation occurs. Storage outside of the destination array is never modified.

Because the number of characters in the source is limited by the n parameter and the destination has a separate parameter giving the maximum number of elements in the destination, the strncat_s() function can safely append a substring, not just an entire string or its tail.

Because unexpected string truncation is a possible security vulnerability, strncat_s() does not truncate the source (as specified by the null terminator and the n parameter) to fit the destination. Truncation is a runtime-constraint violation. However, there is an idiom that allows a program to force truncation using the strncat_s() function. If the n argument is the number of elements minus 1 remaining in the destination, strncat_s() will append the entire source to the destination or truncate it to fit (as always, the result will be null-terminated). For example, the following call will append src to the dest array, resulting in a properly null-terminated string in dest. The concatenation will stop when dest is full (including the null terminator) or when all of src has been appended:
1	strncat_s(
2	  dest,
3	  sizeof dest,
4	  src,
5	  (sizeof dest) - strnlen_s(dest, sizeof dest) - 1
6	);

Although OpenBSD function strlcat() is similar to strncat(), it is more similar to strcat_s() than to strncat_s(). Unlike strlcat(), strncat_s() supports checking runtime constraints such as the size of the destination array, and it will not truncate the string.

The strncpy_s() and strncat_s() functions can still overflow a buffer if the maximum length of the destination buffer and number of characters to copy are incorrectly specified.

			24.1.1.12 Dynamic Allocation Functions

ISO/IEC TR 24731-2 [ISO/IEC TR 24731-2:2010] describes the strndup() function, which can also be used as an alternative function to strncpy(). ISO/IEC TR 24731-2 does not define any alternative functions to strncat(). The strndup() function is equivalent to the strdup() function, duplicating the provided string in a new block of memory allocated as if by using malloc(), with the exception being that strndup() copies, at most, n plus 1 byte into the newly allocated memory, terminating the new string with a null byte. If the length of the string is larger than n, only n bytes are duplicated. If n is larger than the length of the string, all bytes in the string are copied into the new memory buffer, including the terminating null byte. The newly created string will always be properly terminated. The allocated string must be reclaimed by passing the returned pointer to free(). 

			24.1.1.13 Summary of Alternatives

The following table summarizes some of the alternative functions for strncpy() described in this section.
	Standard/TR	Buffer Overflow Protection	Properly Null-Terminates	May Truncate String	Allocates Dynamic Memory	Checks Runtime Constraints
strncpy() 	C11 	yes 	no 	yes 	no 	no
strlcpy() 	OpenBSD 	yes 	yes 	yes 	no 	no
strndup() 	TR 24731-2 	yes 	yes 	yes 	yes 	no
strncpy_s() 	C11 	yes 	yes 	no 	no 	yes

The following table summarizes some of the alternative functions for strncat() described in this section. TR 24731-2 does not define an alternative function to strcat().
	Standard/TR	Buffer Overflow Protection	Properly Null-Terminates	May Truncate String	Allocates Dynamic Memory	Checks Runtime Constraints
strncat() 	C11 	yes 	no 	yes 	no 	no
strlcat() 	OpenBSD 	yes 	yes 	yes 	no 	no
strncat_s() 	C11 	yes 	yes 	no 	no 	yes

			24.1.1.14 memcpy( ) and memmove( )

The C11 memcpy() (C11 §7.24.2.1) and memmove() (C11 §7.24.2.2) functions are prone to error because they do not allow the caller to specify the size of the destination array.


C11 Annex K, Bounds-Checking Interfaces

The memcpy_s() and memmove_s() functions defined in C11 Annex K are similar to the corresponding, less-secure memcpy() and memmove() functions but provide some additional safeguards. To prevent buffer overflow, the memcpy_s() and memmove_s() functions have additional parameters that specify the size of the destination array. If a runtime-constraint violation occurs, the destination array is zeroed to increase the visibility of the problem. Additionally, to reduce the number of cases of undefined behavior, the memcpy_s() function must report a constraint violation if an attempt is being made to copy overlapping objects.

The memcpy_s() and memmove_s() functions return zero if successful. A nonzero value is returned if either the source or destination pointer is NULL, if the specified number of characters to copy/move is greater than the maximum size of the destination buffer, or if the number of characters to copy/move or the maximum size of the destination buffer is greater than RSIZE_MAX.

			24.1.1.15 strlen( )

The strlen() function is not particularly flawed, but its operations can be subverted because of the weaknesses of the underlying string representation. The strlen() function accepts a pointer to a character array and returns the number of characters that precede the terminating null character. If the character array is not properly null-terminated, the strlen() function may return an erroneously large number that could result in a vulnerability when used. Furthermore, if passed a non-null-terminated string, strlen() may read past the bounds of a dynamically allocated array and cause the program to be halted.
C99

C99 defines no alternative functions to strlen(). Consequently, it is necessary to ensure that strings are properly null-terminated before passing them to strlen() or that the result of the function is in the expected range when developing strictly conforming C99 programs.
C11 Annex K, Bounds-Checking Interfaces

C11 provides an alternative to the strlen() functionthe bounds-checking strnlen_s() function. In addition to a character pointer, the strnlen_s() function accepts a maximum size. If the string is longer than the maximum size specified, the maximum size rather than the actual size of the string is returned. The strnlen_s() function has no runtime constraints. This lack of runtime constraints, along with the values returned for a null pointer or an unterminated string argument, makes strnlen_s() useful in algorithms that gracefully handle such exceptional data.

There is a misconception that the bounds-checking functions are always inherently safer than their traditional counterparts and that the traditional functions should never be used. Dogmatically replacing calls to C99 functions with calls to bounds-checking functions can lead to convoluted code that is no safer than if it used the traditional functions and is inefficient and hard to read. An example is obtaining the length of a string literal, which leads to silly code like this:
1	#define S "foo"
2	size_t n = strnlen_s(S, sizeof S);

The strnlen_s() function is useful when dealing with strings that might lack their terminating null character. That the function returns the number of elements in the array when no terminating null character is found causes many calculations to be more straightforward.

Because the bounds-checking functions defined in C11 Annex K do not produce unterminated strings, in most cases it is unnecessary to replace calls to the strlen() function with calls to strnlen_s().

The strnlen_s() function is identical to the POSIX function strnlen().


			24.1.1.16 
Detection and Recovery
Learning Objectives

    Identify applicable mitigation strategies, evaluate candidate mitigation strategies, and select the most appropriate mitigation strategy (or strategies) for a given context.
    Apply mitigation strategies to reduce the introduction of errors into new code or repair security flaws in existing code.

Detection and recovery mitigation strategies generally make changes to the runtime environment to detect buffer overflows when they occur so that the application or operating system can recover from the error (or at least fail safely). Because attackers have numerous options for controlling execution after a buffer overflow occurs, detection and recovery is not as effective as prevention and should not be relied on as the only mitigation strategy. However, detection and recovery mitigations generally form a second line of defense in case the outer perimeter is compromised. There is a danger that programmers can believe they have solved the problem by using an incomplete detection and recovery strategy, giving them false confidence in vulnerable software. Such strategies should be employed and then forgotten to avoid such biases.

Buffer overflow mitigation strategies can be classified according to which component of the entire system provides the mitigation mechanism:

    The developer via input validation
    The compiler and its associated runtime system
    The operating system

Input Validation

The best way to mitigate buffer overflows is to prevent them. Doing so requires developers to prevent string or memory copies from overflowing their destination buffers. Buffer overflows can be prevented by ensuring that input data does not exceed the size of the smallest buffer in which it is stored. The following is an example of a simple function that performs input validation.
Example
Input Validation
1	void f(const char *arg) {
2	 char buff[100];
3	 if (strlen(arg) >= sizeof(buff)) {
4	   abort();
5	 }
6	 strcpy(buff, arg);
7	 /*  */
8	}

Any data that arrives at a program interface across a trust boundary requires validation. Examples of such data include the argv and argc arguments to function main() and environment variables, as well as data read from sockets, pipes, files, signals, shared memory, and devices.

Although this example is concerned only with string length, many other types of validation are possible. For example, input that is meant to be sent to a SQL database will require validation to detect and prevent SQL injection attacks. If the input may eventually go to a web page, it should also be validated to guard against cross-site scripting (XSS) attacks.

Fortunately, input validation works for all classes of string exploits, but it requires that developers correctly identify and validate all of the external inputs that might result in buffer overflows or other vulnerabilities. Because this process is error prone, it is usually prudent to combine this mitigation strategy with others (for example, replacing suspect functions with more secure ones).

exercise
01	enum limits { USERNAME_LEN=20, PASSWORD_LEN=100 };
02	 
03	typedef struct ut {
04	  char username[USERNAME_LEN];
05	  char password[PASSWORD_LEN];
06	  struct ut * next;
07	} user_type;
08	 
09	user_type *User_List = NULL;
10	 
11	/* Adds username/password to mailinglist.
12	   Returns nonzero if successful */
13	int add(const char * username, const char * password) {
14	  user_type * new_node = malloc(sizeof(user_type));
15	  if (new_node == NULL)
16	    return 0;
17	  strcpy(new_node->username, username);
18	  strcpy(new_node->password, password);
19	  new_node->next = User_List;
20	  User_List = new_node;
21	  return 1;
22	}

Solution
enum limits { USERNAME_LEN=20, PASSWORD_LEN=100 };
 
typedef struct ut {
  char username[USERNAME_LEN];
  char password[PASSWORD_LEN];
  struct ut * next;
} user_type;
 
user_type *User_List = NULL;
 
/* Adds username/password to mailinglist.
   Returns nonzero if successful */
int add(const char * username, const char * password) {
  user_type * new_node = malloc(sizeof(user_type));
  if (new_node == NULL)
    return 0;
  if ( ( username >= USERNAME_LEN)|| (password >= PASSWORD_LEN ) )
  {
	  abort();
  }
  strcpy(new_node->username, username);
  strcpy(new_node->password, password);
  new_node->next = User_List;
  User_List = new_node;
  return 1;
}

			24.1.1.17 Object Size Checking

The GNU C Compiler (GCC) provides limited functionality to access the size of an object given a pointer into that object. Starting with version 4.1, GCC introduced the __builtin_object_size() function to provide this capability. Its signature is size_t __builtin_object_size(void *ptr, int type). The first argument is a pointer into any object. This pointer may, but is not required to, point to the start of the object. For example, if the object is a string or character array, the pointer may point to the first character or to any character in the arrays range. The second argument provides details about the referenced object and may have any value from 0 to 3. The function returns the number of bytes from the referenced byte to the final byte of the referenced object.

This function is limited to objects whose ranges can be determined at compile time. If GCC cannot determine which object is referenced, or if it cannot determine the size of this object, then this function returns either 0 or -1, both invalid sizes. For the compiler to be able to determine the size of the object, the program must be compiled with optimization level -O1 or greater.

The second argument indicates details about the referenced object. If this argument is 0 or 2, then the referenced object is the largest object containing the pointed-to byte; otherwise, the object in question is the smallest object containing the pointed-to byte. To illustrate this distinction, consider the following code:
1	struct V { char buf1[10]; int b; char buf2[10]; } var;
2	void *ptr = &var.b;

If ptr is passed to __builtin_object_size() with type set to 0, then the value returned is the number of bytes from var.b to the end of var, inclusive. (This value will be at least the sum of sizeof(int) and 10 for the buf2 array.) However, if type is 1, then the value returned is the number of bytes from var.b to the end of var.b, inclusive (that is, sizeof(int)).

If __builtin_object_size() cannot determine the size of the pointed-to object, it returns (size_t) -1 if the second argument is 0 or 1. If the second argument is 2 or 3, it returns (size_t) 0. The following table summarizes how the type argument affects the behavior of __builtin_object_size().
Value of Type Argument	Operates On	If Unknown, Returns
0 	maximum object 	(size_t) -1
1 	minimum object 	(size_t) -1
2 	maximum object 	(size_t) 0
3 	minimum object 	(size_t) 0
Use of Object Size Checking

The __builtin_object_size() function is used to add lightweight buffer overflow protection to the following standard functions when _FORTIFY_SOURCE is defined:
memcpy() 	strcpy() 	strcat() 	sprintf() 	vsprintf()
memmove() 	strncpy() 	strncat() 	snprintf() 	vsnprintf()
memset() 	fprintf() 	vfprintf() 	printf() 	vprintf()

Many operating systems that support GCC turn on object size checking by default. Others provide a macro (such as _FORTIFY_SOURCE) to enable the feature as an option. On Red Hat Linux, for example, no protection is performed by default. When _FORTIFY_SOURCE is set at optimization level 1 (_FORTIFY_SOURCE=1)or higher, security measures that should not change behavior of conforming programs are taken. _FORTIFY_SOURCE=2 adds some more checking, but some conforming programs might fail.

For example, the memcpy() function may be implemented as follows when _FORTIFY_SOURCE is defined:
1	__attribute__ ((__nothrow__)) memcpy(
2	  void * __restrict __dest,
3	  __const void * __restrict __src,
4	  size_t __len
5	) {
6	  return ___memcpy_chk(
7	           __dest, __src, __len, __builtin_object_size(__dest, 0)
8	         );
9	}

When using the memcpy() and strcpy() functions, the following behaviors are possible:

| 1. The following case is known to be correct:
| 1	char buf[5];
| 2	memcpy(buf, foo, 5);
| 3	strcpy(buf, "abcd");
| 
| No runtime checking is needed, and consequently the memcpy() and strcpy() functions are called.
| 
| 2. The following case is not known to be correct but is checkable at runtime:
| 1	memcpy(buf, foo, n);
| 2	strcpy(buf, bar);
| 
| The compiler knows the number of bytes remaining in the object but does not know the length of the actual copy that will happen. Alternative functions __memcpy_chk() or __strcpy_chk() are used in this case; these functions check whether buffer overflow happened. If buffer overflow is detected, __chk_fail() is called and typically aborts the application after writing a diagnostic message to stderr.
| 
| 3. The following case is known to be incorrect:
| 1	memcpy(buf, foo, 6);
| 2	strcpy(buf, "abcde");
| 
| The compiler can detect buffer overflows at compile time. It issues warnings and calls the checking alternatives at runtime.
| 
| 4. The last case is when the code is not known to be correct and is not checkable at runtime.
| 1	memcpy(p, q, n);
| 2	strcpy(p, q);

The compiler does not know the buffer size, and no checking is done. Overflows go undetected in these cases.


exercise:
Assume no padding between objects in a struct and that the size of all pointers is 4 bytes. What value is returned by the size() function?
01	     
02	enum limits { USERNAME_LEN=20, PASSWORD_LEN=100 };
03	             
04	typedef struct ut {
05	  char username[USERNAME_LEN];
06	  char password[PASSWORD_LEN];
07	  struct ut * next;
08	} user_type;
09	             
10	size_t size() {
11	  user_type mt;
12	  return __builtin_object_size(mt.password, 1);
13	}

size?
    20
    124
    100
    104

Feedback

Correct! 100 is the size of the password array.

Learn More: Using _builtin_object_size()

This function can be used in conjunction with copying operations. For example, a string may be safely copied into a fixed array by checking for the size of the array:
01	char dest[BUFFER_SIZE];
02	char *src = /* valid pointer */;
03	size_t src_end = __builtin_object_size(src, 0);
04	if (src_end == (size_t) -1 && /* don’t know if src is too big */
05	    strlen(src) < BUFFER_SIZE) {
06	strcpy(dest, src);
07	} else if (src_end <= BUFFER_SIZE) {
08	strcpy(dest, src);
09	} else {
10	/* src would overflow dest */
11	}

The advantage of using __builtin_object_size() is that if it returns a valid size (instead of 0 or −1), then the call to strlen() at runtime is unnecessary and can be bypassed, improving runtime performance.

GCC implements strcpy() as an inline function that calls __builtin___strcpy_chk() when _FORTIFY_SOURCE is defined. Otherwise, strcpy() is an ordinary glibc function. The __builtin___strcpy_chk() function has the following signature:
char *__builtin___strcpy_chk(char *dest, const char *src,
                             size_t dest_end)

This function behaves like strcpy(), but it first checks that the dest buffer is big enough to prevent buffer overflow. This is provided via the dest_end parameter, which is typically the result of a call to __builtin_object_size(). This check can often be performed at compile time. If the compiler can determine that buffer overflow never occurs, it can optimize away the runtime check. Similarly, if the compiler determines that buffer overflow always occurs, it issues a warning, and the call aborts at runtime. If the compiler knows the space in the destination string but not the length of the source string, it adds a runtime check. Finally, if the compiler cannot guarantee that adequate space exists in the destination string, then the call devolves to standard strcpy() with no check added.
Visual Studio Compiler-Generated Runtime Checks

The MS Visual Studio C++ compiler provides several options to enable certain checks at runtime. These options can be enabled using a specific compiler flag. In particular, the /RTCs compiler flag turns on checks for the following errors:

    Overflows of local variables such as arrays (except when used in a structure with internal padding)
    Use of uninitialized variables
    Stack pointer corruption, which can be caused by a calling convention mismatch

These flags can be tweaked on or off for various regions in the code. For example, the following pragma:
#pragma runtime_checks("s", off)

turns off the /RTCs flag checks for any subsequent functions in the code. The check may be restored with the following pragma:
#pragma runtime_checks("s", restore)

Runtime Bounds Checkers

Although not publicly available, some existing C language compiler and runtime systems do perform array bounds-checking.
Libsafe and Libverify

Libsafe, available from Avaya Labs Research, is a dynamic library for limiting the impact of buffer overflows on the stack. The library intercepts and checks the bounds of arguments to C library functions that are susceptible to buffer overflow. [1] The library makes sure that frame pointers and return addresses cannot be overwritten by an intercepted function. The Libverify library, also described by Baratloo and colleagues, implements a return address verification scheme similar to Libsafe’s but does not require recompilation of source code, which allows it to be used with existing binaries.
CRED

Jones and Kelley proposed an approach for bounds checking using referent objects. [2] This approach is based on the principle that an address computed from an in-bounds pointer must share the same referent object as the original pointer. Unfortunately, a surprisingly large number of programs generate and store out-of-bounds addresses and later retrieve these values in their computation without causing buffer overflows, making these programs incompatible with this bounds-checking approach. [3] This approach to runtime bounds checking also has significant performance costs, particularly in pointer-intensive programs in which performance may slow down by up to 30 times.

Ruwase and Lam improved the Jones and Kelley approach in their C Range Error Detector (CRED). [4] According to the authors, CRED enforces a relaxed standard of correctness by allowing program manipulations of out-of-bounds addresses that do not result in buffer overflows. This relaxed standard of correctness provides higher compatibility with existing software.

CRED can be configured to check all bounds of all data or of string data only. Full bounds checking, like the Jones and Kelley approach, imposes significant performance overhead. Limiting the bounds checking to strings improves the performance for most programs. Overhead ranges from 1% to 130% depending on the use of strings in the application.

Bounds checking is effective in preventing most overflow conditions but is not perfect. The CRED solution, for example, cannot detect conditions under which an out-of-bounds pointer is cast to an integer, used in an arithmetic operation, and cast back to a pointer. The approach does prevent overflows in the stack, heap, and data segments. CRED, even when when optimized to check only for overflows in strings, was effective in detecting 20 different buffer overflow attacks developed by Wilander and Kamkar for evaluating dynamic buffer overflow detectors. [5]

CRED has been merged into the latest Jones and Kelly checker for GCC 3.3.1, which is currently maintained by Herman ten Brugge.

Dhurjati and Adve proposed a collection of improvements, including pool allocation, which allows the compiler to generate code that knows where to search for an object in an object table at runtime. [6] Performance was improved significantly, but overhead was still as high as 69%.

----------------------------------------------------------------------------------------------------
-Stack Canaries

Stack canaries are another mechanism used to detect and prevent stack-smashing attacks. Instead of performing generalized bounds checking, canaries are used to protect the return address on the stack from sequential writes through memory (for example, resulting from a call to strcpy()). Canaries consist of a value that is difficult to insert or spoof and are written to an address before the section of the stack being protected. A sequential write would consequently need to overwrite this value on the way to the protected region. The canary is initialized immediately after the return address is saved and checked immediately before the return address is accessed. A canary could consist, for example, of four different termination characters (CR, LF, NULL, and –1). The termination characters would guard against a buffer overflow caused by an unbounded strcpy() call, for example, because an attacker would need to include a null byte in his or her buffer. The canary guards against buffer overflows caused by string operations but not memory copy operations. A hard-to-spoof or random canary is a 32-bit secret random number that changes each time the program is executed. This approach works well as long as the canary remains a secret.

Canaries are implemented in StackGuard [3] as well as in GCC’s Stack Smashing Protector, also known as ProPolice, and Microsoft’s Visual C++ .NET as part of the stack buffer overrun detection capability.

The stack buffer overrun detection capability was introduced to the C/C++ compiler in Visual Studio .NET 2002 and has been updated in subsequent versions. [4] The /GS compiler switch instructs the compiler to add startup code and function epilog and prolog code to generate and check a random number that is placed in a function’s stack. If this value is corrupted, a handler function is called to terminate the application, reducing the chance that the shellcode attempting to exploit a buffer overrun will execute correctly.

Note that Visual C++ 2005 (and later) also reorders data on the stack to make it harder to predictably corrupt that data. Examples include:

    Moving buffers to higher memory than nonbuffers. This step can help protect function pointers that reside on the stack.
    Moving pointer and buffer arguments to lower memory at runtime to mitigate various buffer overrun attacks.

Visual C++ 2010 includes enhancements to /GS that expand the heuristics used to determine when /GS should be enabled for a function and when it can safely be optimized away.

To take advantage of enhanced /GS heuristics when using Visual C++ 2005 SP1 or later, add the following instruction in a commonly used header file to increase the number of functions protected by /GS:

#pragma strict_gs_check(on)

The rules for determining which functions require /GS protections are more aggressive in Visual C++ 2010 than they are in the compiler’s earlier versions; however, the strict_gs_check rules are even more aggressive than Visual C++ 2010’s rules. Even though Visual C++ 2010 strikes a good balance, strict_gs_check should be used for Internet-facing products.

To use stack buffer overrun detection for Microsoft Visual Studio, you should:

    Compile your code with the most recent version of the compiler. At the time of writing, this version is VC++ 2010 (cl.exe version 16.00).
    Add #pragma string_gs_check(on) to a common header file when using versions of VC++ older than VC++ 2010.
    Add #pragma string_gs_check(on) to Internet-facing products when using VC++ 2010 and later.
    Compile with the /GS flag.
    Link with libraries that use /GS.

As currently implemented, canaries are useful only against exploits that attempt to overwrite the stack return address by overflowing a buffer on the stack. Canaries do not protect the program from exploits that modify variables, data pointers, or function pointers. Canaries cannot prevent buffer overflows from occurring in any location, including the stack segment. They detect some of these buffer overflows only after the fact. Exploits that overwrite bytes directly to the location of the return address on the stack can defeat terminator and random canaries. [1] To solve these direct access exploits, StackGuard added Random XOR canaries that XOR the return address with the canary. [2] Again, this works well for protecting the return address provided the canary remains a secret. In general, canaries offer weak runtime protection.

---------------------------------------------------------------------------------------------------
Stack Smashing Protector (ProPolice)

In version 4.1, GCC introduced the Stack Smashing Protector (SSP) feature, which implements canaries derived from StackGuard. [1] Also known as ProPolice, SSP is a GCC extension for protecting applications written in C from the most common forms of stack buffer overflow exploits and is implemented as an intermediate language translator of GCC. SSP provides buffer overflow detection and variable reordering to avoid the corruption of pointers. Specifically, SSP reorders local variables to place buffers after pointers and copies pointers in function arguments to an area preceding local variable buffers to avoid the corruption of pointers that could be used to further corrupt arbitrary memory locations.

The SSP feature is enabled using GCC command-line arguments. The -fstack-protector and -fno-stack-protector options enable and disable stack-smashing protection for functions with vulnerable objects (such as arrays). The -fstack-protector-all and -fno-stack-protector-all options enable and disable the protection of every function, not just the functions with character arrays. Finally, the -Wstack-protector option emits warnings about functions that receive no stack protection when -fstack-protector is used.

SSP works by introducing a canary to detect changes to the arguments, return address, and previous frame pointer in the stack. SSP inserts code fragments into appropriate locations as follows: a random number is generated for the guard value during application initialization, preventing discovery by an unprivileged user. Unfortunately, this activity can easily exhaust a system’s entropy.

SSP also provides a safer stack structure:

This structure establishes the following constraints:

    Location (A) has no array or pointer variables.
    Location (B) has arrays or structures that contain arrays.
    Location (C) has no arrays.

Placing the guard after the section containing the arrays (B) prevents a buffer overflow from overwriting the arguments, return address, previous frame pointer, or local variables (but not other arrays). For example, the compiler cannot rearrange struct members so that a stack object of a type such as:
1	struct S {
2	    char buffer[40];
3	    void (*f)(struct S*);
4	};

would remain unprotected.

---------------------------------------------------------------------------------------------------
Operating System Strategies

The prevention strategies described in this section are provided as part of the platform’s runtime support environment, including the operating system and the hardware. They are enabled and controlled by the operating system. Programs running under such an environment may not need to be aware of these added security measures; consequently, these strategies are useful for executing programs for which source code is unavailable.

Unfortunately, this advantage can also be a disadvantage because extra security checks that occur during runtime can accidentally alter or halt the execution of nonmalicious programs, often as a result of previously unknown bugs in the programs. Consequently, such runtime strategies may not be applied to all programs that can be run on the platform. Certain programs must be allowed to run with such strategies disabled, which requires maintaining a whitelist of programs exempt from the strategy; unless carefully maintained, such a whitelist enables attackers to target whitelisted programs, bypassing the runtime security entirely.


---------------------------------------------------------------------------------------------------
Detection and Recovery

Address space layout randomization (ASLR) is a security feature of many operating systems; its purpose is to prevent arbitrary code execution. The feature randomizes the address of memory pages used by the program. ASLR cannot prevent the return address on the stack from being overwritten by a stack-based overflow. However, by randomizing the address of stack pages, it may prevent attackers from correctly predicting the address of the shellcode, system function, or return-oriented programming gadget that they want to invoke. Some ASLR implementations randomize memory addresses every time a program runs; as a result, leaked memory addresses become useless if the program is restarted (perhaps because of a crash).

ASLR reduces the probability but does not eliminate the possibility of a successful attack. It is theoretically possible that attackers could correctly predict or guess the address of their shellcode and overwrite the return pointer on the stack with this value.

Furthermore, even on implementations that randomize addresses on each invocation, ASLR can be bypassed by an attacker on a long-running process. Attackers can execute their shellcode if they can discover the address of the shellcode without terminating the process. They can do so, for example, by exploiting a format-string vulnerability or other information leak to reveal memory contents.
Linux

ASLR was first introduced to Linux in the PaX project in 2000. While the PaX patch has not been submitted to the mainstream Linux kernel, many of its features are incorporated into mainstream Linux distributions. For example, ASLR has been part of Ubuntu since 2008 and Debian since 2007. Both platforms allow for fine-grained tuning of ASLR via the following command:

sysctl -w kernel.randomize_va_space=2

Most platforms execute this command during the boot process. The randomize_va_space parameter may take the following values:
0 	Turns off ASLR completely. This is the default only for platforms that do not support this feature.
1 	Turns on ASLR for stacks, libraries, and position-independent binary programs.
2 	Turns on ASLR for the heap as well as for memory randomized by option 1.
Windows

ASLR has been available on Windows since Vista. On Windows, ASLR moves executable images into random locations when a system boots, making it harder for exploit code to operate predictably. [1] For a component to support ASLR, all components that it loads must also support ASLR. For example, if A.exe depends on B.dll and C.dll, all three must support ASLR. By default, Windows Vista and subsequent versions of the Windows operating system randomize system dynamic link libraries (DLLs) and executables (EXEs). However, developers of custom DLLs and EXEs must opt in to support ASLR using the /DYNAMICBASE linker option.

Windows ASLR also randomizes heap and stack memory. The heap manager creates the heap at a random location to help reduce the chance that an attempt to exploit a heap-based buffer overrun succeeds. Heap randomization is enabled by default for all applications running on Windows Vista and later. When a thread starts in a process linked with /DYNAMICBASE, Windows Vista and later versions of Windows move the thread’s stack to a random location to help reduce the chance that a stack-based buffer overrun exploit will succeed.

To enable ASLR under Microsoft Windows, you should

    Link with Microsoft Linker version 8.00.50727.161 (the first version to support ASLR) or later.
    Link with the /DYNAMICBASE linker switch unless using Microsoft Linker version 10.0 or later, which enables /DYNAMICBASE by default.
    Test your application on Windows Vista and later versions, and note and fix failures resulting from the use of ASLR.



---------------------------------------------------------------------------------------------------
Nonexecutable Stacks

A nonexecutable stack is a runtime solution to buffer overflows that is designed to prevent executable code from running in the stack segment. Many operating systems can be configured to use nonexecutable stacks.

Nonexecutable stacks are often represented as a panacea in securing against buffer overflow vulnerabilities. However, nonexecutable stacks prevent malicious code from executing only if it is in stack memory. They do not prevent buffer overflows from occurring in the heap or data segments. They do not prevent an attacker from using a buffer overflow to modify a return address, variable, data pointer, or function pointer. And they do not prevent arc injection or injection of the execution code in the heap or data segments. Not allowing an attacker to run executable code on the stack can prevent the exploitation of some vulnerabilities, but it is often only a minor inconvenience to an attacker.

Depending on how they are implemented, nonexecutable stacks can affect performance. Nonexecutable stacks can also break programs that execute code in the stack segment, including Linux signal delivery and GCC trampolines.


---------------------------------------------------------------------------------------------------
W ^ X

Several operating systems, including OpenBSD, Windows, Linux, and OS/X, enforce reduced privileges in the kernel so that no part of the process address space is both writable and executable. This policy is called W xor X, or more concisely, W^X, and is supported by the use of a No eXecute (NX) bit on several CPUs.

The NX bit enables a memory page to be marked as data, disabling the execution of code on these pages. This bit is named NX on AMD CPUs, XD (for eXecute Disable) on Intel CPUs, and XN (for eXecute Never) on ARM v6 and later CPUs. Most modern Intel CPUs and all current AMD CPUs now support this capability.

W^X requires that no code is intended to be executed that is not part of the program itself. This prevents the execution of shellcode on the stack, heap, or data segment. W^X also prevents the intentional execution of code in a data page. For example, a just-in-time (JIT) compiler often constructs assembly code from external data (such as bytecode) and then executes it. To work in this environment, the JIT compiler must conform to these restrictions, for example, by ensuring that pages containing executable instructions are appropriately marked.
Data Execution Prevention

Data execution prevention (DEP) is an implementation of the W^X policy for Microsoft Visual Studio. DEP uses NX technology to prevent the execution of instructions stored in data segments. This feature has been available on Windows since XP SP2. DEP assumes that no code is intended to be executed that is not part of the program itself. Consequently, it does not properly handle code that is intended to be executed in a “forbidden” page. For example, a JIT compiler often constructs assembly code from external data (such as bytecode) and then executes it, only to be foiled by DEP. Furthermore, DEP can often expose hidden bugs in software.

If your application targets Windows XP SP3, then you should call SetProcessDEPPolicy() to enforce DEP/NX. [1] If it is unknown whether or not the application will run on a down-level platform that includes support for SetProcessDEPPolicy(), then call the following code early in the startup code:
01	BOOL __cdecl EnableNX(void) {
02	   HMODULE hK = GetModuleHandleW(L"KERNEL32.DLL");
03	   BOOL (WINAPI *pfnSetDEP)(DWORD);
04	 
05	   *(FARPROC *) &pfnSetDEP; = GetProcAddress(hK, "SetProcessDEPPolicy");
06	 
07	   if (pfnSetDEP)
08	      return (*pfnSetDEP)(PROCESS_DEP_ENABLE);
09	   return(FALSE);
10	}

If your application has self-modifying code or performs JIT compilation, DEP may cause the application to fail. To alleviate this issue, you should still opt in to DEP (see the following linker switch) and mark any data that will be used for JIT compilation as follows:
01	PVOID pBuff = VirtualAlloc(NULL,4096,MEM_COMMIT,PAGE_READWRITE );
02	if (pBuff) {
03	    // Copy executable ASM code to buffer
04	    memcpy_s(pBuff, 4096);
05	     
06	    // Buffer is ready to go so mark as executable and protect from writes
07	    DWORD dwOldProtect = 0;
08	    if (!VirtualProtect(pBuff, 4096, PAGE_EXECUTE_READ, &dwOldProtect)) {
09	        // error
10	    } else {
11	        // Call into pBuff
12	    }
13	    VirtualFree(pBuff,0,MEM_RELEASE);
14	}

DEP/NX has no performance impact on Windows. To enable DEP, you should link your code with /NXCOMPAT or call SetProcessDEPPolicy() and test your applications on a DEP-capable CPU, then note and fix any failures resulting from the use of DEP. The use of /NXCOMPAT is very similar to calling SetProcessDEPPolicy() on Vista or later Windows versions. However, Windows XP’s loader does not recognize the /NXCOMPAT link option. Consequently, the use of SetProcessDEPPolicy() is generally preferred.

ASLR and DEP each provide different protections on Windows platforms. Consequently, you should enable both mechanisms (/DYNAMICBASE and /NXCOMPAT) for all binaries.

 DEP does not prevent arc injection attacks or return-oriented exploits in which an attacker modifies the control flow to execute code already in the code segment under the attacker’s control.
---------------------------------------------------------------------------------------------------
PaX

In Linux, the concept of the nonexecutable stack was pioneered by the PaX kernel patch. PaX specifically labeled program memory as nonwritable and data memory as nonexecutable. PaX also provided address space layout randomization (ASLR; discussed under “Detection and Recovery”). It terminates any program that tries to transfer control to nonexecutable memory. PaX can use NX technology, if available, or can emulate it otherwise (at the cost of slower performance). Interrupting attempts to transfer control to nonexecutable memory reduces any remote-code-execution or information-disclosure vulnerability to a mere denial of service (DoS), which makes PaX ideal for systems in which DoS is an acceptable consequence of protecting information or preventing arc injection attacks. Systems that cannot tolerate DoS should not use PaX. PaX is now part of the grsecurity project, which provides several additional security enhancements to the Linux kernel.
StackGap

Many stack-based buffer overflow exploits rely on the buffer being at a known location in memory. If the attacker can overwrite the function return address, which is at a fixed location in the overflow buffer, execution of the attacker-supplied code starts. Introducing a randomly sized gap of space upon allocation of stack memory makes it more difficult for an attacker to locate a return value on the stack and costs no more than one page of real memory. This offsets the beginning of the stack by a random amount so the attacker will not know the absolute address of any item on the stack from one run of the program to the next. This mitigation can be relatively easy to add to an operating system. The following shows the change to the Linux kernel required to implement StackGap.
01	PVOID pBuff = VirtualAlloc(NULL,4096,MEM_COMMIT,PAGE_READWRITE );
02	if (pBuff) {
03	    // Copy executable ASM code to buffer
04	    memcpy_s(pBuff, 4096);
05	     
06	    // Buffer is ready to go so mark as executable and protect from writes
07	    DWORD dwOldProtect = 0;
08	    if (!VirtualProtect(pBuff, 4096, PAGE_EXECUTE_READ, &dwOldProtect)) {
09	        // error
10	    } else {
11	        // Call into pBuff
12	    }
13	    VirtualFree(pBuff,0,MEM_RELEASE);
14	}

Although StackGap may make it more difficult for an attacker to exploit a vulnerability, it does not prevent exploits if the attacker can use relative, rather than absolute, values.
Other Platforms

ASLR has been partially available on Mac OS X since 2007 (10.5) and is fully functional since 2011 (10.7). It has also been functional on IOS (used for iPhones and iPads) since version 4.3.

---------------------------------------------------------------------------------------------------
Future Directions

Future buffer overflow prevention mechanisms will surpass existing capabilities in HP aCC, Intel ICC, and GCC compilers to provide complete coverage by combining more thorough compile-time checking with runtime checks where necessary to minimize the required overhead. One such mechanism is Safe-Secure C/C++ (SSCC). [1]

SSCC infers the requirements and guarantees of functions and uses them to discover whether all requirements are met. For example, in the following function, n is required to be a suitable size for the array pointed to by s. Also, the returned string is guaranteed to be null-terminated.
1	char *substring_before(char *s, size_t n, char c) {
2	  for (int i = 0; i < n; ++i)
3	    if (s[i] == c) {
4	      s[i] = ‘\0’;
5	      return s;
6	    }
7	  s[0] = ‘\0’;
8	  return s;
9	}

To discover and track requirements and guarantees between functions and source files, SSCC uses a bounds data file. The following figure shows one possible implementation of the SSCC mechanism.

If SSCC is given the entire source code to the application, including all libraries, it can guarantee that there are no buffer overflows.
---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------------------

			24.1.1.18 Test

				24.1.1.18.1  1st attempt

 	
SCORE REPORT

You may return to this on-line report at any time using the URL sent to the e-mail address connected to the CCO login used to launch this assessment. To report any disputes about missed questions, click the "Feedback" link above. (NOTE: COLT allows review of missed questions for several months after the assessment was scored. If you scored less than 100% and no "missed questions" appear below, your period for review has expired.)
Sorry, you did not pass the assessment. You may wish to review the section below which lists the questions you missed and where they are found in the course.

SUMMARY
Learner: Yosi Izaq
Master Assessment Name: Assessment for Secure Coding for C/C++ - Strings
Attempt Number: 1
Total Questions Generated: 12
Language: English
Passing Threshold: 85
Score Achieved: 75 %
Grade: Fail

QUESTIONS MISSED
If the "Score Achieved" listed above is less than 100, the following questions were answered partially or incorrectly:

UNIT NAME Strings

OBJECTIVE Strings
7. Which of the following calls is guaranteed not to produce undefined behavior, given that c is declared as char? (answered incorrectly)
The incorrect option(s) you chose have the associated feedback:
Option D: The correct answer is "isdigit((unsigned char)c);" as using an unsigned char is guaranteed to produce consistent behavior.

10. Which behavior is exhibited by the following invocation of strtoul()? (answered incorrectly)
The incorrect option(s) you chose have the associated feedback:
Option C: You are incorrect. The error return check "number == ULONG_MAX" will ALWAYS detect errors resulting from the call. You are correct that the check "errno == ERANGE" will SOMETIMES identify errors that did not occur as "errno" was not reset to zero. It might erroneously contain the value ERANGE from a previous library call hence identify an error that did not occur on this call.

11. What is the problem with the following code? (answered incorrectly)
The incorrect option(s) you chose have the associated feedback:
Option A: This code will cause a buffer overflow writing to b. 

				24.1.1.18.2 2nd attempt

SCORE REPORT

You may return to this on-line report at any time using the URL sent to the e-mail address connected to the CCO login used to launch this assessment. To report any disputes about missed questions, click the "Feedback" link above. (NOTE: COLT allows review of missed questions for several months after the assessment was scored. If you scored less than 100% and no "missed questions" appear below, your period for review has expired.)
Congratulations. You have passed the "Assessment for Secure Coding for C/C++ - Strings"

SUMMARY
Learner: Yosi Izaq
Master Assessment Name: Assessment for Secure Coding for C/C++ - Strings
Attempt Number: 2
Total Questions Generated: 12
Language: English
Passing Threshold: 85
Score Achieved: 100 %
Grade: Pass

QUESTIONS MISSED
If the "Score Achieved" listed above is less than 100, the following questions were answered partially or incorrectly:
				24.1.1.18.3

			24.1.1.19
		24.1.2 Integers


		24.1.3

	24.2

25. references

	25.1 C++ QUICK REFERENCE

		25.1.1 PREPROCESSOR
// Comment to end of line
/* Multi-line comment */
#include <stdio.h> // Insert standard header file
#include "myfile.h" // Insert file in current directory
#define X some text // Replace X with some text
#define F(a,b) a+b // Replace F(1,2) with 1+2
#define X \
some text // Line continuation
#undef X // Remove definition
#if defined(X) // Condional compilation (#ifdef X)
#else // Optional (#ifndef X or #if !defined(X))
#endif // Required after #if, #ifdef

		25.1.2 LITERALS
255, 0377, 0xff // Integers (decimal, octal, hex)
2147483647L, 0x7fffffffl // Long (32-bit) integers
| 123.0, 1.23e2 // double (real) numbers
'a', '\141', '\x61' // Character (literal, octal, hex)
'\n', '\\', '\'', '\"' // Newline, backslash, single quote, double
quote
"string\n" // Array of characters ending with newline and
\0
"hello" "world" // Concatenated strings
true, false // bool constants 1 and 0

		25.1.3 DECLARATIONS

int x; // Declare x to be an integer (value undefined)
int x=255; // Declare and initialize x to 255
short s; long l; // Usually 16 or 32 bit integer (int may be
either)
char c='a'; // Usually 8 bit character
unsigned char u=255; signed char s=-1; // char might be either
unsigned long x=0xffffffffL; // short, int, long are signed
float f; double d; // Single or double precision real (never
unsigned)
bool b=true; // true or false, may also use int (1 or 0)
int a, b, c; // Multiple declarations
int a[10]; // Array of 10 ints (a[0] through a[9])
int a[]={0,1,2}; // Initialized array (or a[3]={0,1,2}; )
int a[2][3]={{1,2,3},{4,5,6}}; // Array of array of ints
char s[]="hello"; // String (6 elements including '\0')
int* p; // p is a pointer to (address of) int
char* s="hello"; // s points to unnamed array containing "hello"
void* p=NULL; // Address of untyped memory (NULL is 0)
int& r=x; // r is a reference to (alias of) int x
enum weekend {SAT,SUN}; // weekend is a type with values SAT and SUN
enum weekend day; // day is a variable of type weekend
enum weekend {SAT=0,SUN=1}; // Explicit representation as int
enum {SAT,SUN} day; // Anonymous enum
typedef String char*; // String s; means char* s;
const int c=3; // Constants must be initialized, cannot assign
to
const int* p=a; // Contents of p (elements of a) are constant
int* const p=a; // p (but not contents) are constant
const int* const p=a; // Both p and its contents are constant
const int& cr=x; // cr cannot be assigned to change x

		25.1.4 STORAGE CLASSES

int x; // Auto (memory exists only while in scope)
static int x; // Global lifetime even if local scope
extern int x; // Information only, declared elsewhere

		25.1.5 STATEMENTS

x=y; // Every expression is a statement
int x; // Declarations are statements
; // Empty statement
{ // A block is a single statement
int x; // Scope of x is from declaration to end of
block
a; // In C, declarations must precede statements
}
if (x) a; // If x is true (not 0), evaluate a
else if (y) b; // If not x and y (optional, may be repeated)
else c; // If not x and not y (optional)
while (x) a; // Repeat 0 or more times while x is true
for (x; y; z) a; // Equivalent to: x; while(y) {a; z;}
do a; while (x); // Equivalent to: a; while(x) a;
switch (x) { // x must be int
case X1: a; // If x == X1 (must be a const), jump here
case X2: b; // Else if x == X2, jump here
default: c; // Else jump here (optional)
}
break; // Jump out of while, do, or for loop, or switch
continue; // Jump to bottom of while, do, or for loop
return x; // Return x from function to caller
try { a; }
catch (T t) { b; } // If a throws a T, then jump here
catch (...) { c; } // If a throws something else, jump here

		25.1.6 FUNCTIONS

int f(int x, int); // f is a function taking 2 ints and returning
int
void f(); // f is a procedure taking no arguments
void f(int a=0); // f() is equivalent to f(0)
f(); // Default return type is int
inline f(); // Optimize for speed
f() { statements; } // Function definition (must be global)
T operator+(T x, T y); // a+b (if type T) calls operator+(a, b)
T operator-(T x); // -a calls function operator-(a)
T operator++(int); // postfix ++ or -- (parameter ignored)
extern "C" {void f();} // f() was compiled in C

Function parameters and return values may be of any type. A function must either be declared or defined before
it is used. It may be declared first and defined later. Every program consists of a set of a set of global variable
declarations and a set of function definitions (possibly in separate files), one of which must be:
int main() { statements... } or
int main(int argc, char* argv[]) { statements... }
argv is an array of argc strings from the command line. By convention, main returns status 0 if successful, 1 or
higher for errors.
Functions with different parameters may have the same name (overloading). Operators except :: . .* ?: may be
overloaded. Precedence order is not affected. New operators may not be created.

		25.1.7 EXPRESSIONS

Operators are grouped by precedence, highest first. Unary operators and assignment evaluate right to left. All
others are left to right. Precedence does not affect order of evaluation, which is undefined. There are no run time
checks for arrays out of bounds, invalid pointers, etc.
T::X // Name X defined in class T
N::X // Name X defined in namespace N
::X // Global name X
t.x // Member x of struct or class t
p->x // Member x of struct or class pointed to by p
a[i] // i'th element of array a
f(x,y) // Call to function f with arguments x and y
T(x,y) // Object of class T initialized with x and y
x++ // Add 1 to x, evaluates to original x (postfix)
x-- // Subtract 1 from x, evaluates to original x
typeid(x) // Type of x
typeid(T) // Equals typeid(x) if x is a T
dynamic_cast<T>(x) // Converts x to a T, checked at run time
static_cast<T>(x) // Converts x to a T, not checked
reinterpret_cast<T>(x) // Interpret bits of x as a T
const_cast<T>(x) // Converts x to same type T but not const
sizeof x // Number of bytes used to represent object x
sizeof(T) // Number of bytes to represent type T
++x // Add 1 to x, evaluates to new value (prefix)
--x // Subtract 1 from x, evaluates to new value
~x // Bitwise complement of x
!x // true if x is 0, else false (1 or 0 in C)
-x // Unary minus
+x // Unary plus (default)
&x // Address of x
*p // Contents of address p (*&x equals x)
new T // Address of newly allocated T object
new T(x, y) // Address of a T initialized with x, y
new T[x] // Address of allocated n-element array of T
delete p // Destroy and free object at address p
delete[] p // Destroy and free array of objects at p
(T) x // Convert x to T (obsolete, use .._cast<T>(x))
x * y // Multiply
x / y // Divide (integers round toward 0)
x % y // Modulo (result has sign of x)
x + y // Add, or &x[y]
x - y // Subtract, or number of elements from *x to *y
x << y // x shifted y bits to left (x * pow(2, y))
x >> y // x shifted y bits to right (x / pow(2, y))
x < y // Less than
x <= y // Less than or equal to
x > y // Greater than
x >= y // Greater than or equal to
x == y // Equals
x != y // Not equals
x & y // Bitwise and (3 & 6 is 2)
x ^ y // Bitwise exclusive or (3 ^ 6 is 5)
x | y // Bitwise or (3 | 6 is 7)
x && y // x and then y (evaluates y only if x (not 0))
x || y // x or else y (evaluates y only if x is false
(0))
x = y // Assign y to x, returns new value of x
x += y // x = x + y, also -= *= /= <<= >>= &= |= ^=
x ? y : z // y if x is true (nonzero), else z
throw x // Throw exception, aborts if not caught
x , y // evaluates x and y, returns y (seldom used)

		25.1.8 CLASSES

class T { // A new type
private: // Section accessible only to T's member
functions
protected: // Also accessable to classes derived from T
public: // Accessable to all
int x; // Member data
void f(); // Member function
void g() {return;} // Inline member function
void h() const; // Does not modify any data members
int operator+(int y); // t+y means t.operator+(y)
int operator-(); // -t means t.operator-()
T(): x(1) {} // Constructor with initialization list
T(const T& t): x(t.x) {} // Copy constructor
T& operator=(const T& t) {x=t.x; return *this; } // Assignment operator
~T(); // Destructor (automatic cleanup routine)
explicit T(int a); // Allow t=T(3) but not t=3
operator int() const {return x;} // Allows int(t)
friend void i(); // Global function i() has private access
friend class U; // Members of class U have private access
static int y; // Data shared by all T objects
static void l(); // Shared code. May access y but not x
class Z {}; // Nested class T::Z
typedef int V; // T::V means int
};
void T::f() { // Code for member function f of class T
this->x = x;} // this is address of self (means x=x;)
int T::y = 2; // Initialization of static member (required)
T::l(); // Call to static member

struct T { // Equivalent to: class T { public:
virtual void f(); // May be overridden at run time by derived
class
virtual void g()=0; }; // Must be overridden (pure virtual)
class U: public T {}; // Derived class U inherits all members of base
T
class V: private T {}; // Inherited members of T become private
class W: public T, public U {}; // Multiple inheritance
class X: public virtual T {}; // Classes derived from X have base T
directly
All classes have a default copy constructor, assignment operator, and destructor, which perform the
corresponding operations on each data member and each base class as shown above. There is also a default noargument
constructor (required to create arrays) if the class has no constructors. Constructors, assignment, and
destructors do not inherit.

		25.1.9 TEMPLATES

template <class T> T f(T t); // Overload f for all types
template <class T> class X { // Class with type parameter T
X(T t); }; // A constructor
template <class T> X<T>::X(T t) {} // Definition of constructor
X<int> x(3); // An object of type "X of int"
template <class T, class U=T, int n=0> // Template with default
parameters

		25.1.10 NAMESPACES

namespace N {class T {};} // Hide name T
N::T t; // Use name T in namespace N
using namespace N; // Make T visible without N::

		25.1.11 C/C++ STANDARD LIBRARY

Only the most commonly used functions are listed. Header files without .h are in namespace std. File names are
actually lower case.

		25.1.12 STDIO.H, CSTDIO (Input/output)

FILE* f=fopen("filename", "r"); // Open for reading, NULL (0) if error
// Mode may also be "w" (write) "a" append, "a+" update, "rb" binary
fclose(f); // Close file f
fprintf(f, "x=%d", 3); // Print "x=3" Other conversions:
"%5d %u %-8ld" // int width 5, unsigned int, long left just.
"%o %x %X %lx" // octal, hex, HEX, long hex
"%f %5.1f" // float or double: 123.000000, 123.0
"%e %g" // 1.23e2, use either f or g
"%c %s" // char, char*
"%%" // %
sprintf(s, "x=%d", 3); // Print to array of char s
printf("x=%d”, 3); // Print to stdout (screen unless redirected)
fprintf(stderr, ... // Print to standard error (not redirected)
getc(f); // Read one char (as an int) or EOF from f
ungetc(c, f); // Put back one c to f
getchar(); // getc(stdin);
putc(c, f) // fprintf(f, "%c", c);
putchar(c); // putc(c, stdout);
fgets(s, n, f); // Read line into char s[n] from f. NULL if EOF
gets(s) // fgets(s, INT_MAX, f); no bounds check
fread(s, n, 1, f); // Read n bytes from f to s, return number read
fwrite(s, n, 1, f); // Write n bytes of s to f, return number
written
fflush(f); // Force buffered writes to f
fseek(f, n, SEEK_SET); // Position binary file f at n
ftell(f); // Position in f, -1L if error
rewind(f); // fseek(f, 0L, SEEK_SET); clearerr(f);
feof(f); // Is f at end of file?
ferror(f); // Error in f?
perror(s); // Print char* s and error message
clearerr(f); // Clear error code for f
remove("filename"); // Delete file, return 0 if OK
rename("old", "new"); // Rename file, return 0 if OK
f = tmpfile(); // Create temporary file in mode "wb+"
tmpnam(s); // Put a unique file name in char s[L_tmpnam]

		25.1.13 STDLIB.H, CSTDLIB (Misc. functions)

atof(s); atol(s); atoi(s);// Convert char* s to float, long, int
rand(), srand(seed); // Random int 0 to RAND_MAX, reset rand()
void* p = malloc(n); // Allocate n bytes. Obsolete: use new
free(p); // Free memory. Obsolete: use delete
exit(n); // Kill program, return status n
system(s); // Execute OS command s (system dependent)
getenv("PATH"); // Environment variable or 0 (system dependent)
abs(n); labs(ln); // Absolute value as int, long

		25.1.14 STRING.H, CSTRING (Character array handling functions)

Strings are type char[] with a '\0' in the last element used.
strcpy(dst, src); // Copy string. Not bounds checked
strcat(dst, src); // Concatenate to dst. Not bounds checked
strcmp(s1, s2); // Compare, <0 if s1<s2, 0 if s1==s2, >0 if
s1>s2
strncpy(dst, src, n); // Copy up to n chars, also strncat(), strncmp()
strlen(s); // Length of s not counting \0
strchr(s,c); strrchr(s,c);// Address of first/last char c in s or 0
strstr(s, sub); // Address of first substring in s or 0
// mem... functions are for any pointer types (void*), length n bytes
memmove(dst, src, n); // Copy n bytes from src to dst
memcmp(s1, s2, n); // Compare n bytes as in strcmp
memchr(s, c, n); // Find first byte c in s, return address or 0
memset(s, c, n); // Set n bytes of s to c

		25.1.15 CTYPE.H, CCTYPE (Character types)

isalnum(c); // Is c a letter or digit?
isalpha(c); isdigit(c); // Is c a letter? Digit?
islower(c); isupper(c); // Is c lower case? Upper case?
tolower(c); toupper(c); // Convert c to lower/upper case

		25.1.16 MATH.H, CMATH (Floating point math)

sin(x); cos(x); tan(x); // Trig functions, x (double) is in radians

asin(x); acos(x); atan(x);// Inverses
atan2(y, x); // atan(y/x)
sinh(x); cosh(x); tanh(x);// Hyperbolic
exp(x); log(x); log10(x); // e to the x, log base e, log base 10
pow(x, y); sqrt(x); // x to the y, square root
ceil(x); floor(x); // Round up or down (as a double)
fabs(x); fmod(x, y); // Absolute value, x mod y

		25.1.17 TIME.H, CTIME (Clock)

clock()/CLOCKS_PER_SEC; // Time in seconds since program started
time_t t=time(0); // Absolute time in seconds or -1 if unknown
tm* p=gmtime(&t); // 0 if UCT unavailable, else p->tm_X where X
is:
sec, min, hour, mday, mon (0-11), year (-1900), wday, yday, isdst
asctime(p); // "Day Mon dd hh:mm:ss yyyy\n"
asctime(localtime(&t)); // Same format, local time

		25.1.18 ASSERT.H, CASSERT (Debugging aid)

assert(e); // If e is false, print message and abort
#define NDEBUG // (before #include <assert.h>), turn off assert

		25.1.19 NEW.H, NEW (Out of memory handler)

set_new_handler(handler); // Change behavior when out of memory
void handler(void) {throw bad_alloc();} // Default

		25.1.20 IOSTREAM.H, IOSTREAM (Replaces stdio.h)

cin >> x >> y; // Read words x and y (any type) from stdin
cout << "x=" << 3 << endl; // Write line to stdout
cerr << x << y << flush; // Write to stderr and flush
c = cin.get(); // c = getchar();
cin.get(c); // Read char
cin.getline(s, n, '\n'); // Read line into char s[n] to '\n' (default)
if (cin) // Good state (not EOF)?
// To read/write any type T:
istream& operator>>(istream& i, T& x) {i >> ...; x=...; return i;}
ostream& operator<<(ostream& o, const T& x) {return o << ...;}

		25.1.21 FSTREAM.H, FSTREAM (File I/O works like cin, cout as above)

ifstream f1("filename"); // Open text file for reading
if (f1) // Test if open and input available
f1 >> x; // Read object from file
f1.get(s); // Read char or line
f1.getline(s, n); // Read line into string s[n]
ofstream f2("filename"); // Open file for writing
if (f2) f2 << x; // Write to file

		25.1.22 IOMANIP.H, IOMANIP (Output formatting)

cout << setw(6) << setprecision(2) << setfill('0') << 3.1; // print
"003.10"

		25.1.23 STRING (Variable sized character array)

string s1, s2="hello"; // Create strings
s1.size(), s2.size(); // Number of characters: 0, 5
s1 += s2 + ' ' + "world"; // Concatenation
s1 == "hello world" // Comparison, also <, >, !=, etc.
s1[0]; // 'h'
s1.substr(m, n); // Substring of size n starting at s1[m]
s1.c_str(); // Convert to const char*
getline(cin, s); // Read line ending in '\n'

		25.1.24 VECTOR (Variable sized array/stack with built in memory allocation)

vector<int> a(10); // a[0]..a[9] are int (default size is 0)
a.size(); // Number of elements (10)
a.push_back(3); // Increase size to 11, a[10]=3
a.back()=4; // a[10]=4;
a.pop_back(); // Decrease size by 1
a.front(); // a[0];
a[20]=1; // Crash: not bounds checked
a.at(20)=1; // Like a[20] but throws out_of_range()
for (vector<int>::iterator p=a.begin(); p!=a.end(); ++p)
*p=0; // Set all elements of a to 0
vector<int> b(a.begin(), a.end()); // b is copy of a
vector<T> c(n, x); // c[0]..c[n-1] init to x
T d[10]; vector<T> e(d, d+10); // e is initialized from d

		25.1.25 DEQUE (array/stack/queue)

deque<T> is like vector<T>, but also supports:
a.push_front(x); // Puts x at a[0], shifts elements toward back
a.pop_front(); // Removes a[0], shifts toward front

		25.1.26 UTILITY (Pair)

pair<string, int> a("hello", 3); // A 2-element struct
a.first; // "hello"
a.second; // 3

Example
// make_pair example
#include <utility>      // std::pair
#include <iostream>     // std::cout

int main () {
  std::pair <int,int> foo;
  std::pair <int,int> bar;

  foo = std::make_pair (10,20);
  bar = std::make_pair (10.5,'A'); // ok: implicit conversion from pair<double,char>

  std::cout << "foo: " << foo.first << ", " << foo.second << '\n';
  std::cout << "bar: " << bar.first << ", " << bar.second << '\n';

  return 0;
}

Another:

		25.1.27 MAP (associative array)

map<string, int> a; // Map from string to int
a["hello"]=3; // Add or replace element a["hello"]
for (map<string, int>::iterator p=a.begin(); p!=a.end(); ++p)
cout << (*p).first << (*p).second; // Prints hello, 3
a.size(); // 1

		25.1.28 ALGORITHM (A collection of 60 algorithms on sequences with iterators)

min(x, y); max(x, y); // Smaller/larger of x, y (any type defining <)
swap(x, y); // Exchange values of variables x and y
sort(a, a+n); // Sort array a[0]..a[n-1] by <
sort(a.begin(), a.end()); // Sort vector or deque

	25.2

26. Make

	26.1  Tutorials

	26.2 Troubleshooting

		26.2.1 gcc makefile error: “No rule to make target …”

			26.2.1.1  Problem
I'm trying to use GCC (linux) with a makefile to compile my project.

I get the following error which is can't seem to decipher in this context:
"No rule to make target vertex.cpp', needed by vertex.o'. Stop."

This is the makefile:

a.out: vertex.o edge.o elist.o main.o vlist.o enode.o vnode.o
    g++ vertex.o edge.o elist.o main.o vlist.o enode.o vnode.o

main.o: main.cpp main.h
    g++ -c main.cpp

vertex.o: vertex.cpp vertex.h
    g++ -c vertex.cpp

edge.o: edge.cpp edge.h
    g++ -c num.cpp

vlist.o: vlist.cpp vlist.h
    g++ -c vlist.cpp

elist.o: elist.cpp elist.h
    g++ -c elist.cpp

vnode.o: vnode.cpp vnode.h
    g++ -c vnode.cpp

enode.o: enode.cpp enode.h
    g++ -c node.cpp
			26.2.1.2 Solutions
That's usually because you don't have a file called vertex.cpp available to make. Check that:

that file exists.
you're in the right directory when you make.
Other than that, I've not much else to suggest. Perhaps you could give us a directory listing of that directory.

-------------------------------------------------------
The more common reason for this message to be printed is because you forgot to include the directory in which the source file resides. As a result, gcc "thinks" this file does not exist.

You can add the directory using the -I argument to gcc.
-------------------------------------------------------
-------------------------------------------------------
			26.2.1.3
		26.2.2


	26.3 Sergey's example
c:\work\code\CPP\make\example\Makefile 

		26.3.1 c:\work\code\CPP\make\example\Makefile 
SUBDIRS = main static dynamic

.PHONY: all clean depend $(SUBDIRS)

all : CMD=all
all : $(SUBDIRS)

clean : CMD=clean 
clean : $(SUBDIRS)

depend : CMD=depend
depend : $(SUBDIRS)

$(SUBDIRS):
	$(MAKE) -C $@ $(CMD)
    
main: static dynamic

		26.3.2 c:\work\code\CPP\make\example\make-settings.gmk 
CC = g++
LINK = g++
CFLAGS += -g -fPIC
LFLAGS = -g 

		26.3.3 dynamic/Makefile
include ../make-settings.gmk

TARGET = libdynamic.so
FILES = dynamic.cpp
OFILES = $(FILES:.cpp=.o)
DFILES = $(FILES:.cpp=.d)

LIBS = 

.PHONY: all clean depend

all: $(TARGET)

clean:
	rm -f $(TARGET) $(OFILES) $(DFILES)

depend: $(DFILES)

$(DFILES): %.d: %.cpp
	@echo Building dependency file
	@set -e; rm -f $@; \
	$(CC) -MM $(CFLAGS) $< > $@; \
	sed -i 's,\($*\)\.o[ :]*,\1.o $@ : ,g' $@;

-include $(DFILES)

$(OFILES): %.o: %.cpp
	$(CC) -o $@ -c $(CFLAGS) $<

$(TARGET): $(OFILES)
	$(LINK) -o $@ -shared $(LFLAGS) $^ $(LIBS)

----------------------------

		26.3.4 main/Makefile
include ../make-settings.gmk

TARGET = main
FILES = main.cpp
OFILES = $(FILES:.cpp=.o)
DFILES = $(FILES:.cpp=.d)

CFLAGS += -I../static -I../dynamic
LIBS = -L../static -lstatic -L../dynamic -ldynamic

.PHONY: all clean depend

all: $(TARGET)

clean:
	rm -f $(TARGET) $(OFILES) $(DFILES)

depend: $(DFILES)

$(DFILES): %.d: %.cpp
	@echo Building dependency file
	@set -e; rm -f $@; \
	$(CC) -MM $(CFLAGS) $< > $@; \
	sed -i 's,\($*\)\.o[ :]*,\1.o $@ : ,g' $@;

-include $(DFILES)

$(OFILES): %.o: %.cpp
	$(CC) -o $@ -c $(CFLAGS) $< 

$(TARGET): $(OFILES)
	$(LINK) -o $@ $(LFLAGS) $^ $(LIBS) 

----------------------------

		26.3.5 static/Makefile
include ../make-settings.gmk

TARGET = libstatic.a
FILES = static.cpp
OFILES = $(FILES:.cpp=.o)
DFILES = $(FILES:.cpp=.d)

.PHONY: all clean depend

all: $(TARGET)

clean:
	rm -f $(TARGET) $(OFILES) $(DFILES)

depend: $(DFILES)

$(DFILES): %.d: %.cpp
	@echo Building dependency file
	@set -e; rm -f $@; \
	$(CC) -MM $(CFLAGS) $< > $@; \
	sed -i 's,\($*\)\.o[ :]*,\1.o $@ : ,g' $@;

-include $(DFILES)

$(OFILES): %.o: %.cpp
	$(CC) -o $@ -c $(CFLAGS) $<

$(TARGET): $(OFILES)
	ar rcs $@ $^ 

----------------------------

		26.3.6
	26.4
27. Concurrency

	27.1 Theory

		27.1.1 Mutex

			27.1.1.1 How does a mutex work? What does it cost?

Concurrent programming requires synchronisation. We can’t have more than one thread accessing data at the same time otherwise we end up with a data race. The most common solution is to wrap the critical data access in a mutex. Mutexes are, of course, not free. How the mutex is used has a significant impact in the cost of the code we are writing. When used correctly we’ll barely notice the overhead. When used incorrectly it can cause a program to run worse in threaded mode than it would have single threaded!

Also view CPU Memory – Why do I need a mutex?

What is a mutex?

A mutex, in its most fundamental form, is just an integer in memory. This memory can have a few different values depending on the that state of the mutex. Though usually when we speak of mutexes we also talk of the locks which use the mutex. The integer in memory is not very interesting, but the operations around it are.

There are two fundamental operations which a mutex must provide to be useful:

lock
unlock
unlock is a simple case since it’s usually just one function. Unlocking a mutex makes it available for another process to lock. lock on the other hand usually has several variants. In most cases we’d like to wait until we can lock the mutex, so the most common lock operation does exactly this. Other users may wish to only wait for a given period of time, and yet some other users may not want to wait at all. Thus lock has a few variants, all of which have the goal to lock the mutex.

There can be only one lock on a mutex at any given time. If another thread wishes to lock the same mutex it must wait for the first to unlock it. This is the primary goal of the mutex. Attempting to lock an already locked mutex is called contention. In a well planned program contention should be quite low; you should be designing your code so that most attempts to lock the mutex will not block.

There are two reasons why you want to avoid contention. The first is simply that any thread waiting on a mutex is obviously not doing anything else — possibly resulting in unused CPU cycles. The second reason is more interesting for high performance code. Locking a currently unlocked mutex is extremely cheap compared to the contention case. We have to look at how the mutex works to understand why.

How does it work?

As mentioned before, the data of a mutex is simply an integer in memory. It’s value starts as 0, meaning that it is unlocked. If you wish to lock the mutex you can simply check if it is zero and then assign one. The mutex is now locked and you are the owner of it.

The trick is that the test and set operation has to be atomic. If two threads happen to read 0 at the exact same time, then both would write 1 and think they own the mutex. Without CPU support there is no way to implement a mutex in user space: this operation must be atomic with respect to the other threads. Fortunately CPUs has a function called “compare-and-set” or “test-and-set” which does exactly this. This function takes the address of the integer, and two integer values: a compare and set value. If the compare value matches the current value of the integer then it is replaced with the new value. In C style code this might like look this:

1
2
3
4
5
int compare_set( int * to_compare, int compare, int set );
 
int mutex_value;
int result = compare_set( &mutex_value, 0, 1 );
if( !result ) { /* we got the lock */ }
The caller determines what happens by the return value. It is the value at the pointer provided prior to the swap. If this value is equal to the test value the caller knows the set was successful. If the value is different then the caller knows the value has not changed. When the piece of code is done with the mutex it can simply set the value back to 0. This makes up the very basic part of our mutex.

Atomic increment/decrement functions could also be used and is the recommended way if using the Linux futex.
What about waiting?

Now comes the tricky part. Well, only in a way is it tricky, in another way it is simple. The above test-and-set mechanism provides no support for a thread to wait on the value (aside from a CPU intensive spin-lock). The CPU doesn’t really understand high-level threads and processes, so it isn’t in a position to implement waiting. The OS must provide the waiting functionality.

In order for the CPU to wait correctly a caller is going to need to go through a system call. It is the only thing that can synchronise the various threads and provide the waiting functionality. So if we have to wait on a mutex, or release a waiting mutex, we have no choice but to call the OS. Most OSs have built in mutex primitives. In some cases they provide full fledged mutexes. So if a system call does provide a full mutex why would we bother with any sort of test-and-set in user space? The answer is that system calls have quite a bit of overhead and should be avoided when possible.

Various operating systems diverge greatly at this point, and will likely change as time goes on. Under linux there is a system call futex which provides mutex like semantics. It is specifically designed so that non-contention cases can be completely resolved in user space. Contention cases are then delegated to the operating system to handle in a safe, albeit far costlier manner. The waiting is then handled as part of the OS process scheduler.

futex is actually quite flexible and various locking mechanisms could be build in addition to a mutex, such as a semaphore, a barrier, a read-write mutex, or any kind of signalling.
The Costs

There are a few points of interest when it comes to the cost of a mutex. The first, and very vital point, is waiting time. Your threads should spend only a fraction of their time waiting on mutexes. If they are waiting too often then you are losing concurrency. In a worst case scenario many threads always trying to lock the same mutex may result in performance worse than a single thread serving all requests. This really isn’t a cost of the mutex itself, but a serious concern with concurrent programming.

The overhead costs of a mutex relate to the test-and-set operation and the system call that implements a mutex. The test-and-set is likely very low cost; being essential to concurrent processing the CPUs have good reason to make it efficient. We’ve kind of omitted another important instruction however: the fence. This is used in all high-level mutexes and may have a higher cost than the test-and-set operation. More costlier than even that however is the system call. Not only do you suffer the context switch overhead of the system call, the kernel now spends some time in its scheduling code.

			27.1.1.2
		27.1.2

	27.2

28. Cisco related

	28.1 COSI

		28.1.1 Overview of the Software Development Process 

			28.1.1.1 Types of Programming Languages

Source code is a term that refers to a sequence of statements and declarations written in a human-readable computer programming language. There are many different programming languages, all differing to some extent in their syntax, keywords, operations, and organization. Many different programming languages are used at Cisco, including C, C++, Java, Perl, Tcl, and others.
Example Source Code written in C:
#include <stdio.h>

int main(int argc, const char* argv[]) {
   int a=10;
   while (a >= 1) {
      printf("a is %2d\n",a);
      a--;
   }
}

The details of building software products differ depending on the technologies that are being used, but in general software development falls into one of three categories based on the type of programming language being used:

Compiled Languages

Programming languages where source code must be transformed into binary executable instructions are called "compiled languages." Examples include C and C++. Programs are passed to an application called a compiler that turns the human-readable source code into either object code or an executable image that can be run directly on the computer hardware. For compilers that generate object code, an additional step called linking must be performed to yield an executable. Compiled languages require that a build process be performed before the program can be executed.

Interpreted Languages

Most scripting languages, like Perl, Tcl, and Korn Shell, are called "interpreted languages" because programs written in these languages are executed by an interpreter directly from the human-readable source code. Interpreted languages do not need to be passed through a compiler before they can be executed, and no executable image is created. Although any programming language could theoretically be interpreted or compiled, some languages have only been designed to be interpreted. Interpreted languages tend to be more dynamic in the sense that many possess the ability to execute arbitrary strings containing source code while the program itself is running. Interpreted languages do not require a build process.

Programs written in interpreted languages tend to be orders of magnitude slower than compiled programs because the interpreter must parse each token of the source code before performing the operations it describes. For this reason, interpreted languages are typically only used for programs where performance is not as important as flexibility and ease of development.

Bytecode Languages

Bytecode languages, like Java, sit midway between compiled and interpreted languages. Source code is transformed by a compiler into a universal machine code, or bytecode, which is not directly executable on any computer hardware. Instead, the bytecode is then interpreted by a virtual machine which has been designed to understand it. The virtual machine can execute programs in bytecode form much faster than a normal source-code interpreter can. Bytecode languages require that a build process be performed before the program can be executed.

Generally, for programming languages that are compiled, only the binary executables are distributed and the source code remains proprietary and unavailable to the end user. The same is true for bytecode languages. In contrast, with interpreted programming languages, the source code must be released to the end user since an interpreter will execute the program by interpreting the source code directly.



			28.1.1.2 Compiling


Both compiled languages, like C and C++, and bytecode languages, like Java, require that the program's source code be passed through a compiler in order to be transformed into an executable program. In simple terms, a compiler takes human-readable source code as input, analyzes it into a series of tokens stored in a symbol table ("lexical analysis"), parses the tokens to make sure the syntax is correct ("syntactic analysis") and to create a parse tree, transforms the parse tree into an intermediate code format ("semantic analysis"), optimizes the intermediate code, and then outputs object code. Depending on the programming language, this object code will either be bytecode, which can be interpreted directly by a virtual machine, or it will be a non-executable binary code, which must be passed through a linker to resolve calls to library functions, finally leading to the creation of an executable file.
Steps taken by a compiler:
                             Source

                            +-------------+
                            | Lexical     <-----------------------+
                            |  Analysis   |                       |
                            +-----+-------+                       |
                                  |Lex. Items                     |-----------------+
                            +-----v-------+                       | Symbol Table    |
                            |Syntactic    +----------------------->                 |
                            |Analysis     +                       |                 |
                            +-----+-------+                       +-----------------+
                                  |Parse tree                     | Other tables    |
                            +-----v-------+                       |                 |
                            |Semantic     +----------------------->                 |
                            |Anal.        +                       +----------^------+
                            +-----+-------+                                  |
                                  |Inter. code                               |
                            +-----v-------+                                  |
                            |Optimization |                                  |
                            |             +----------------------------------+
                            +-----+-------+
                                  |Optimized Inter. code
                            +-----v-------+
                            |Code Gener.  |
                            |             |
                            +-----+-------+
                                  |Object code
                            +-----v----------------+
                            |Link & Load           +------->  Executable
                            +----------------------+

At Cisco, most C and C++ programs are compiled using the GNU Compiler Collection, GCC. On UNIX systems, the compiler will create object files with a ".o" extension. These object files must be linked against library files in order to create an executable program.

Java may also be compiled using GCC, but at Cisco other compilers are also used to turn Java source code into bytecode. Compiling Java source code results in a bytecode file having a ".class" extension.

			28.1.1.3 Linking

For compiled programming languages, an additional step above and beyond compiling is required to turn the object code generated by the compiler into an executable binary file. This additional step is called linking. Linking consists of combining multiple files containing object code, including the compiled code for any functions called by the program, and creating an executable file.

The linking phase of compilation allows a computer program to make use of libraries containing multiple functions without requiring the entire library to be included in the final executable. The linker will resolve any symbols referred to in the program by looking at the library files that are passed to it. A linked program only needs to be recompiled into object code form if the source has been modified.

Most build tools handle both the compiling and linking phases. The make utility is often used to automate both steps, allowing dependencies between source files and libraries to be specified explicitly.

			28.1.1.4 Distributing

Computer applications are distributed to the end user in a variety of ways depending on the target platform, the language used to create the program, and the procedure that will be used to install the program.

Compiled applications may be distributed as separate executable files or bundled together into a tarball or a ZIP file. A tarball is an archive file, usually in a compressed format, that contains multiple files. For some UNIX-based systems, an installation package might be distributed, such as a Red Hat Package Manager ("RPM") package for Red Hat Linux and several other flavors of Linux and UNIX. Windows-based applications are typically distributed as Windows Installer ("MSI") packages.

Applications compiled to Java bytecode format are typically distributed as one or more Java Archive files. A Java Archive file is referred to as a "JAR" and will have a ".jar" extension. JAR files contain one or more Java bytecode files with a ".class" extension along with metadata describing the contents of the JAR. Java applications may also be distributed as Web Application Archive ("WAR") files, or as Enterprise Archive ("EAR") files.

Java applications in the form of Applets may also be distributed directly to a web browser through the Internet. An Applet consists of a .class file which may be contained inside a JAR file. The architecture of Java technology is discussed in detail below.

Interpreted programs written in Perl or Tcl are usually distributed as source code. Perl programs typically have a ".pl" extension or a ".pm" extension for a Perl module, while Tcl programs may have a ".tcl" or ".exp" extension. Tcl programs may also be distributed in the form of a starpack or a starkit that combines all the Tcl source files into a single binary executable.

		28.1.2 Including Files in Source Code

			28.1.2.1 Sourcing Files

Best practices in computer science suggest that computer programs should be written to be as modular as possible, with functionality separated into individual files. This allows multiple developers to work on or enhance different aspects of an application without interfering with one another, reduces redundancy, and allows code to be reused more easily. Splitting programs into multiple files also promotes a higher degree of organization and allows for more fine-grained delegation of tasks and defect tracking.

Most programming languages provide at least one way of merging the contents of one source file into another source file. The commands used to accomplish this vary, but the result is always the same: the file that sources in another file acts as if the other file was typed directly into it.

			28.1.2.2 Language Constructs for Sourcing

The commands and syntax required to include one source code file into another vary by language. Below we summarize the techniques used to accomplish this in the programming languages used most often at Cisco.

In a C program, source files can be merged into the program using a #include compiler directive. This directive tells the compiler to read the contents of the named file and merge it into the source code prior to compiling.
Sourcing in C:

#include <stdio.h>
#include "utils/otherfile.c"

The #include directive is most commonly used in C to include header files (usually having a ".h" extension), but additional C source code may also be sourced in this way. The use of angle braces surrounding the filename indicates that the compiler should look for the referenced file in its standard INCLUDE directories. Using double quotes around the name tells the compiler to look for the file in a location relative to the current directory.

The command for sourcing files in C++ is the same as for C, namely the use of the #include compiler directive. The only difference is that in C++, standard headers do not have to be files and are therefore usually specified without a ".h" extension.
Sourcing in C++:

#include <iostream>
#include "utils/otherfile.cpp"


By design, the Java programming language does not have direct support for sourcing additional files into a program. However, the import statement may be used to instruct the Java compiler to load in class definitions so that they may be used within the given program. This is very different from sourcing a file, since the files that are imported can either be in source form or may be compiled .class files.
Importing in Java:

import java.awt.*;
import com.cisco.provisioning.cpe.*;

Even though the source code to classes that are imported is not actually merged into the current file, from a licensing perspective, the import statement may be considered to be similar to a source statement in another language.

There are many ways to include a source file into another file in Perl. These include use of the following commands: do, eval, require, or use.

One form of the do command allows a filename to be specified. The referenced file will be loaded and executed at runtime as if it had been typed into the program at the location of the do command.
Using "do" to source a file in Perl:

do 'otherfile.pl';

The eval command executes a string which contains Perl code. Like the do command above, this causes the contents of the string to be executed at runtime as if the string was typed into the program at that point. There are several ways to have eval execute the contents of a file, two of which are shown below.
Using "eval" to source a file in Perl:

eval `cat otherfile.pl`;

# or even:

open(IN,"otherfile.pl");
@lines=<IN>;
close(IN);
eval join '',@lines;

The require command causes Perl to load and execute the specified file just like the do command did above. However, unlike do, using require guarantees that the same file will not be included more than once. Note that any file that is to be required must return true, which is most commonly accomplished by placing a "1;" statement at the end of the file.

If the argument to require is a bare word, the command assumes that the argument is the name of a Perl module and appends a ".pm" extension to it and replaces any "::" characters with "/".
Using "require" to source a file in Perl:

require 'otherfile.pl';
require Parse::RecDescent;

Another way to include a file is via the use command. When followed by a package name, the use command is exactly idential to using a require statement inside a BEGIN block, meaning that the file will be found and loaded prior to the current file being executed.
Using "use" to source a file in Perl:

use Parse::RecDescent;
use LWP::Simple;




In Tcl, the contents of a file may be included into another file using the source command. This has the same effect as if the contents of the referenced file had been typed at that point in the program.

Tcl also allows files to be included using the package require command. This command causes the Tcl interpreter to search for a package matching the argument and execute the pkgIndex.tcl file, which itself usually contains multiple source commands.
Sourcing in Tcl:

package require Csccon
source $env(ATS_EASY)/etc/device.exp


			28.1.2.3
		28.1.3 Static and Dynamic Linking
Overview of Linking

Applications that are written in a compiled programming language must be transformed from source code into an executable file before they can be run. The first phase of this transformation, i.e., compiling, involves parsing the source code and converting it into object code. Object code is an intermediate binary format that is not directly executable but also is not source code. In order to become executable, a linker utility must process the object code and resolve any symbolic references to library functions that are called from within the program.

Essentially, linking is the process of combining all the functionality necessary for a program to become executable on a machine. For C and C++ programs at Cisco, GCC is used for both compiling and linking.


			28.1.3.1 Static Linking

Static linking is the process of combining a program with the parts of various library routines that it uses, resulting in an executable that contains all the code necessary for the program to run. The linker takes one or more object files and parses them for any unresolved symbolic references to function calls, and for each one finds the appropriate library containing the object code that implements that function, extracts the code from the library and adds it to the executable. This process continues until all symbolic references have been resolved.

In UNIX and Linux, object files are binary files that have a ".o" extension. Libraries that are designed for static linking will also have a .o extension, or .a extension if the file is an archive.

Static linking results in an executable file that contains all the machine-executable code necessary to run the program. This means that any library functions that are called by the program are included in the executable itself. Although there may be a small increase in performance over dynamic linking because everything is in the same executable, static linking suffers from some serious problems. For example, subsequent versions of the operating system which update, fix, or enhance a library function will not be used by an application that has been statically linked unless the application is re-linked. Furthermore, statically linked programs cannot make use of many internationalization, localization, and networking features that vary from device to device. Also, RAM can be wasted due to multiple copies of the same library function being loaded for each application in which it is used. For these and other reasons, dynamic linking is preferred to static linking in most instances. However, static linking may be required for security-related applications, where the application must be certain that the library functions it uses are what it expects.

For C and C++ programs, the GCC compiler is used both for compiling source code to object code and for linking.

				28.1.3.1.1 Dynamic Linking

In dynamic linking, the linker does not copy library code for functions called by the program into the program's executable. Instead, the linker resolves all symbolic references to library routines and adds startup code to load the required libraries at runtime, with each library call being made through a jump table. The first time an application calls a library function, the jump table is initialized to point to the library routine; additional calls then incur only a very small overhead.

Dynamic linking makes use of shared object libraries. On UNIX and Linux systems, these libraries will have a ".so" extension often followed by a version number, for example: /usr/lib/libc.so.1


		28.1.4 Java Architecture and Technologies

			28.1.4.1 Object-Oriented Terminology
A class is a language construct of object-oriented languages. A class is the blueprint from which individual objects are created. Classes have "attributes" which typically store data, and "methods" (or "functions") which perform actions on the object. In object-oriented terms, a once a class is instantiated in the run time environment, it is called an object. As an example, we may define a class to model a car. Let's call it the "Car" class. It has attributes such as the numbers of doors and the car's color. If we want to model a specific car, it is necessary to create an object from the class definition. Once the object is created, the number of doors and the color could be set or modified using a method.

Inheritance is the object-oriented concept of creating a new class that is based on an existing class for the purpose of extending its functionality. The original class is called the "base" class, and the new class being defined is called the "child" class.

A runtime instantiation of a class, also known as an object. Suppose a "Car" class was defined to model a car, and supposed a program creates a specific object to model Joe's car. It is necessary to create an object or instance of the Car class to model the specific car. Creating an second instance of the Car class to model your friend Bill's car is possible as well. In this case, both Joe's car and Bill's car are instances of the Car class.

An interface is a special type of class that consists only of methods or functions that have no implementation. It can be thought of as a template or abstract class. Child classes that implement an interface must define the body of each method or function.

An abstract concept used in computer science to denote a grouping of unique names or identifiers in a software program. The same name can be used in different name spaces, thus allowing names to be reused.

An object is a run time instance of a class. For a more complete definition, see the definition of Instance above.


			28.1.4.2 Java Language 
Java is a very popular object-oriented programming language. Java programs are written as a set of classes that define methods (i.e., "functions") and class variables. Typically a method will call one or more other methods that exist either in one of the standard Java libraries or in a third party library.

Java programs are written in plain text files ending with a ".java" extension. Source files are then compiled into bytecode files having a ".class" extension. Java bytecode is an abstract, universal machine code that cannot be run directly on a computer; instead, it is designed to be interpreted by a Java Virtual Machine ("JVM"). The java launch tool may be used to execute a compiled application written in Java by launching an instance of the Java Virtual Machine. These applications may consist of .class files or Java Archive files (.jar files). Most JVMs, including Sun's HotSpot, use a just-in-time ("JIT") compiler to improve execution speed by compiling the bytecode into register-based machine code on-the-fly.

Because JVMs are available for a wide variety of operating systems and platforms, the same .class files can be executed on all of them without modification. This is what leads to Java's platform independence.

Language Features

The Java language is completely object-oriented and, unlike C++, deals only with classes. Java provides implementation hiding and well-structured semantics for separating interfaces from implementation. It is also polymorphic, so the implementations can be changed at runtime. The following are some salient features:



Only variables and methods labeled as “public” are visible to other top-level classes. Classes with no modifiers or with the “protected” modifier are visible to other classes in the same package . Classes with the “protected” modifier are also visible to subclasses.

Documentation and usage details of a class are usually contained in javadoc.

A class can “implement” an interface or “extend” another class. Unlike C++, Java only allows a class to inherit functionality from a single parent class using the extends keyword. Classes may, however, implement as many class interfaces as required using the implements keyword

Classes are usually distributed in packages called JAR files, which have a manifest as well as the compiled .class bytecode files.

A classpath can contain names of directories as well as the names of JAR files. The compiler and JVM search for JAR files in the directories specified by the CLASSPATH environment variable as well as within JAR files located in the CLASSPATH variable. However, using the command line options –classpath and –bootclasspath, one can change the path the JVM searches. The JVM also looks for classes in the ../lib/ext directory.

There are well-known design patterns like factory pattern and inversion of control where the actual class implementations are selected declaratively at runtime. See, for example, http://www.martinfowler.com/articles/injection.html. In these cases, it is possible to compile the Java programs against an interface and test it with any implementation. The customers can then download the actual instances. For example, the Java Runtime Environment ("JRE") has a ../lib/ext directory which it searches by default for third-party JAR files.

Java applets are applications that are designed to be loaded and run from within a web browser containing a JVM. Applets can be loaded either by an HTML page within a browser, or can be loaded by an applet viewer application. If necessary, Java plugin can be loaded along with the applet to provide a JRE (Java Runtime Environment) different than the native environment that comes with the browser.

The Applet class loader guarantees that a unique namespace exists for classes that come from the local file system, and that a unique namespace exists for each network source. An applet that is downloaded off the network from a particular host is placed in that host's private namespace for security purpose. This applet has limited access to the local machine 'sresources (e.g., it is not able to make a network connection except to the machine from which it had been downloaded). Exceptions to this rule can be made in a policy file.


			28.1.4.3 Java Build Process

Java source files are transformed into Java bytecode by a Java compiler. The standard compiler is called javac, however numerous other compilers exist, including GCC. The compiler takes one or more .java files and transforms them into .class files, which contain Java bytecode. Each .class file contains exactly one public Java class definition. Multiple classes may be stored together, along with a metadata file describing them, in a JAR file.

There are numerous Integrated Development Environments ("IDE") available for Java, including IBM WebSphere, Eclipse, and Sun's Java Studio. In addition to using an IDE, some Java developers within Cisco also make use of Apache Ant, which is a tool for automating software build processes. Ant is similar to make but is written in Java and is most often used for Java projects.


			28.1.4.4 Class Loaders and Address Space Models

The JVM handles name conflict problems through its class loader architecture. Every class in an application is loaded by an associated class loader object. The JVM solves the name collision problem by treating classes loaded by different class loaders as entirely different types, even if their packages and names are exactly the same. The class loaders are like environment blocks. Classes in a JVM are constrained to the scope of their class loader environment. A class loader can spawn multiple child class loaders, and thus create sub-environments. The classes in these child class loader environments can "see" up the hierarchy toward the system class loader, but usually cannot see classes that are lower in the hierarchy.

Whenever a class loader loads a class, it must consult its parent first. A standard Java application begins with a delegation of three class loaders: the system class loader, the extension class loader, and the bootstrap class loader. The system class loader loads classes from the class path, and delegates to the extension class loader, which loads Java extensions. The parent of the extension class loader is the bootstrap class loader, also known as the null class loader. The bootstrap class loader loads the core API.

The delegation model has three important benefits. First, it protects the core API. Application-defined class loaders are not able to load new versions of the core API classes because they must eventually delegate to the bootstrap loader. This prevents the accidental or malicious loading of system classes that might corrupt or compromise the security of the JVM. Second, the delegation model makes it easy to place common classes in a shared location. For example, in a servlet engine, the servlet API classes could be placed in the class path where they can be shared. But the actual servlet implementations might be loaded by a separate URLClassLoader so that they can be reloaded later. Third, the delegation model makes it possible for objects loaded by different class loaders to refer to each other through superclasses or superinterfaces that are loaded by a shared class loader higher in the delegation.

For Java applets, a browser's native class loader is the system class loader that loads core Java classes during browser (and JVM) initialization. The web browser fires off a Java application that installs a class loader object (applet class loader), which knows how to request class files from an HTTP server. The Java application started by the web browser usually creates a different applet class loader object/instance for each location on the network from which it retrieves class files. As a result, class files from different sources are loaded by different class loader objects. This places them into different namespaces inside the host Java application. Because the class files for applets from different sources are placed in separate namespaces, the code of a malicious applet is restricted from interfering directly with class files downloaded from any other source. The applet security is enforced according to namespace (as a barrier) and the security manager (as the policy enforcer).

		28.1.5 	Linux Kernel and KLMs

			28.1.5.1 	Linking Models for Extending the Kernel

Adding code to a Linux kernel can be accomplished in two ways. One way to do this is to add source files to the Linux kernel's source tree and then recompile the kernel. But a better way to add functionality to the Linux kernel is by using a kernel loadable module ("KLM" -- sometimes also referred to as "LKM"). A KLM is a chunk of code that may be linked to the kernel while it is running.

KLMs are typically used for one of three things: 1) to implement network or device drivers, 2) to implement filesystem drivers, or 3) to implement system calls. KLMs communicate directly with the base kernel and are correctly said to be "part of" the kernel.

The Linux kernel may be extended in functionality in any of several ways. These include:

• Modifications to existing statically linked kernel code
• Addition of statically linked kernel code
• Modification of kernel code that is loaded in dynamically
• Addition of kernel code that is loaded in dynamically

The linking models are static and dynamic. A static link model resolves all symbols for the kernel and the kernel extension code together when the kernel image is created (i.e. before it is booted). The advantage of static linking is that the functionality provided by the linked in code is available to the kernel before a file system is located. This early availability of functionality is useful for drivers and other code that is required to locate the file system.

Code that is dynamically linked is not referenced anywhere in the statically linked kernel. This code resides in a partially linked module (file) in the file system. Administrative (root privileged user level) programs locate any such modules as required, relocate them to kernel addresses, resolve symbols and place them in the kernel address space. An initialization routine in the module is then called by the kernel. When the module is unloaded, the kernel calls an "exit" routine in the module.

KLMs are useful because they extend the functionality of the kernel (generally by providing drivers) if and when such functionality is needed. If the functionality is not needed, the code is not loaded in and kernel physical memory is saved. These modules may also be unloaded and reloaded as needed. The ability to reload modules makes it possible to update them in a running system without the inconvenience of a system reboot. 

			28.1.5.2 Kernel Address Space and KLMs
The Linux kernel is a fully linked program that is relocated to run at an (often) fixed physical memory address. The kernel runs with supervisor privileges and includes system services such as scheduling, memory management, interrupt and timer management as well as basic device drivers. Generally, the kernel has access to all processor registers and physical memory, although it may need to map some physical memory to access it.

Much as with any other modern program, kernel memory may be divided into several types. Although there are additional memory types, the following ones are of particular interest:

• Text: Object code for the kernel/program
• Data: Initialized data loaded in with the kernel/program
• Block Starting with Symbol ("BSS"): Uninitialized data allocated by the boot loader
• Heap: Memory (generally for data) specifically managed by API calls
• Stack: Memory (generally for data and context) automatically managed by the scheduler and memory subsystem.
• Page: Pages of memory to be allocated to user processes.

The statically linked kernel is loaded by the boot loader, and the boot image includes Text, Data and BSS memory. All other system memory is placed in free lists by the kernel and allocated as need.

A dynamically linked kernel module (KLM) is loaded in a cooperative effort between the running kernel and administrative programs. The physical memory for a KLM is allocated from the Heap. The Text, Data and BSS memory regions specified in the KLM object file are placed in the Heap allocated memory region. The kernel sets the access permissions as required for these pages (Data and BSS are read/write, Text is read/execute) and then executes an initialization routine in the Text area. 

		28.1.6 
	28.2 Using GPL V.2/LGPL V.2.1 Open Source Licenses

		28.2.1 GPLv2 Overview

In this section, when we discuss "GPL," we are referring strictly to version 2 of the GNU General Public License, which has been in use since 1991. Cisco's current policy strictly prohibits any use of GPL v3 codes. This prohibition applies to both internal use as well as using it to develop or embed into any Cisco product or service.

The GPL is probably the most commonly used open source software license. The vast majority (approximately 70%) of all open source projects are licensed under the GPL. It is used to distribute a number of important open source software projects, including the Linux kernel. As a result, a strong community of developers has built up around this version of the GPL.

Within the spectrum of open source licenses, the GPL falls under the "strong copyleft" category. Like other copyleft licenses, if you modify GPL code and distribute the modified code, the GPL requires you to release the source code of your modifications. In addition, under the terms of the GPL, you may also have to release of the source code of your proprietary code that links or interacts with the GPL code in certain ways, thus making the GPL a strong copyleft license.

In other words, in some circumstances Cisco might be required by the GPL license to release Cisco's own source code when Cisco's source is configured to interact in certain ways with the GPL code. Sometimes this is referred to as "contamination" of Cisco's source code.

Great care is needed to avoid inadvertently contaminating Cisco's proprietary source code. A key goal of this section is to help you ensure that this does not happen.

Click here to view definitions of key terms related to this subject.
Linking û static and dynamic:

    Static linking: a set of routines, external functions and variables which are resolved in a caller at compile-time and copied into a target application by a compiler, linker, or binder, producing an object file and a stand-alone executable. This executable and the process of compiling it are both known static linking of a program.
    Dynamic linking: Dynamic linking means that the subroutines of a library are loaded into an application program at runtime, rather than being linked in at compile time, and remain as separate files on disk.

Intimate knowledge: code contains intimate knowledge of an open source program if it utilizes internal data structures that are private to the open source program or knows about symbols that are not part of a public API.

Shared memory: shared memory is a memory sharing mechanism that may be simultaneously accessed by multiple programs with an intent to provide communication among them.

User space and kernel space:

    User space: user space is a separate process running space from kernel. Each user space process normally runs in its own virtual memory space, and, unless explicitly requested, cannot access the memory of other processes.
    Kernel space: kernel space is where the kernel runs. Kernel is the central component of most computer operating systems (OS). Its responsibilities include process scheduling, memory management, hardware access and user space communications.

Address space: an address space defines a range of discrete addresses, each of which may correspond to a range of physical or virtual memory.

Header Files: In modern programming languages such as C and C++, definitions of commonly used data structure and values are placed in a file called header file. A data structure is used to exchange a structured information to other part of the program or another executable running remotely. Pre-defined and commonly used values, e.g., Cisco 1800 number, are also defined in a header file. The program file, that is, the file where all the functional operations are implemented, shared those header files so that they can exchange the same structured data and values.


		28.2.2 LGPLv2.1 Overview

In this section, when we discuss "LGPL," we are referring strictly to version 2.1 of the GNU Lesser General Public License. Currently, Cisco policy strictly prohibits any use of LGPL v3 codes. This prohibition applies to both internal use as well as using it to develop or embed into any Cisco product or service.

The GNU Lesser General Public License was originally named the Library General Public License. The Lesser GPL replaced the Library GPL in 1999. Other than the name change, the Lesser GPL is substantially the same as the Library GPL. The Lesser GPL (LGPL) is used primarily for software libraries.

The LGPL is an open source license published by the Free Software Foundation. It was designed to encourage wider commercial adoption or use of a certain software libraries, e.g., GNU C Library, by imposing weaker copyleft terms than those in GPL.

Like other copyleft licenses, the LGPL requires you to distribute the source code of any modifications you make to the LGPL code. However, unlike the GPL or other strong copyleft licenses, linking your proprietary code with the LGPL code will not always trigger the copyleft terms, i.e., you might not be required to distribute the source code of proprietary code linked to LGPL code. To understand the impact of linking to LGPL code, it is necessary to distinguish between dynamic and static linking.

The LGPL does not require you to distribute the source code of your proprietary software that is linked dynamically with the LGPL code. However, if you statically link any proprietary code with the LGPL code, this does trigger a certain copyleft requirement. Under the LGPL, if you statically link your proprietary code with the LGPL code, you must permit modification of the proprietary code for "the customer's own use and reverse engineering for debugging such modifications."

In other words, if you statically link any proprietary code with the LGPL code, you must either

    release the object code of your proprietary code along with the source of the original LGPL library, or
    use a "suitable shared library mechanism" that does not copy the library into the executable and operates properly with an interface compatible modified version of the library. (Note: unlike executable code, object code is an intermediary version of software that requires further compilation before it can be executed by a computer and used by an end user).

Although few customers may want to take advantage of this provision since the use is limited, you should be aware of this potential obligation

		28.2.3 Understanding Cisco's GPL and LGPL Policies

Whether a particular type of linking triggers certain copyleft terms is one of the most debated and important issues surrounding the GPL and LGPL. Over the years, there has been much discussion and debate in the open source community about when the copyright provisions of the GPL/LGPL licenses requires the release of proprietary code that links or interacts with the GPL or LGPL code. A consensus in the open source community has gradually evolved over the last few years, helping to explain what activity will trigger the copyleft terms under the GPL/LGPL and what does not. At times, this community consensus goes beyond what one may actually be legally required under the terms of the GPL/LGPL.

For purposes of this section, we are using the concept of a Red Flag to help identify uses of GPL and LGPL code where further legal and executive approval is required. In this section, you will learn to identify situations where there is an elevated risk for using GPL code (we call these "Red Flags") and you will have a better understanding of when Cisco's policies require that you obtain further approvals.

It is important to understand that the Red Flag is not a legal concept or a concept commonly used in the open source community. Instead, it is a teaching tool for this training section to help you navigate Cisco's policies. A Red Flag does not mean that Cisco code is contaminated. Instead, it means that there is a possibility that it may be either contaminated or considered contaminated by the GPL/LGPL community. Cisco's objective is to avoid this potential contamination risk of unexpectedly having to disclose the source code of Cisco's proprietary code. Hence, if your current or planned use of the GPL/LGPL code triggers the Red Flag and has not already been reviewed by legal or an open source specialist, then please ensure that proper legal and business approval is obtained.

		28.2.4 Cisco's Policies on GPL and LGPL: Avoid the "Red Flag"

Cisco's policies take into account the legal framework of the GPL and LGPL, and also the community understanding of those licenses. The policies are designed to help identify those situations where there is an elevated legal risk or an elevated risk of harming Cisco's reputation in the open source community:

When your use of GPL or LGPL code triggers a "Red Flag," it means that your use might subject Cisco's code to the copyleft terms and thus you must either obtain appropriate approvals in light of the potential requirement to release Cisco proprietary code or you must alter the use of the GPL/LGPL code. You should never use GPL or LGPL code this way without appropriate legal and business approvals.

Complying with Cisco's GPL and LGPL policies (avoiding the Red Flag) will help protect Cisco's code against inadvertently subjecting the code under the copyleft terms and potentially requiring Cisco's proprietary source code to be released under either the GPL or the LGPL.

		28.2.5 GPL Red Flags

The following five pages describe scenarios in which use of GPL code may lead to a Red Flag. These scenarios include the following:

			28.2.5.1 Making Modifications to GPL Source Code
If you modify the source code of a GPL program, and Cisco distributes the modified version, this triggers a Red Flag. Cisco will be required to release the source code of the modifications under the GPL. 

			28.2.5.2 Embedding GPL Code into Cisco Code or Vice Versa
If you embed or incorporate GPL code directly into your program (or the other way around) and Cisco distributes the program, this triggers a Red Flag. Cisco will be required to release the source code of the program under the GPL

(Like copy paste code snippets)

			28.2.5.3 Static & Dynamic Linking
There are two common methods for linking source code:

    Static Linking - Source code is combined at compile time, creating a single executable.
    Dynamic Linking - Source code is linked at runtime, where there is not a single executable, but rather where different bits are loaded into memory on an as-needed basis.

Any linking (whether static or dynamic) triggers a Red Flag. You should not link any GPL code with Cisco code without seeking proper legal and business approval. 
			28.2.5.4 Intimate Knowledge

Intimate Knowledge

As a general rule, the more the GPL code and the Cisco proprietary code look like independent programs in how they function and interact, the lower the risk that the GPL's copyleft provisions will be triggered, requiring the release of Cisco's proprietary source code:

If the interaction above requires a detailed or "intimate knowledge" of the inner workings of the GPL code, this also increases the risk that the copyleft provisions of the GPL will be triggered, requiring Cisco to release proprietary source code.

If Cisco code contains intimate knowledge of a GPL program, this triggers a Red Flag.

For purposes of Cisco Policies, Cisco code contains intimate knowledge of a GPL program (thus creating a Red Flag) if the Cisco Program utilizes internal data structures that are private to the GPL program or knows about symbols that are not part of a public API. Cisco policy considers a header file or an API to be private to a GPL program if it is intended to be used only for building that GPL program or other programs that are part of a closely related suite of programs.

You should not create any Cisco code which contains such intimate knowledge of GPL code unless you have first obtained appropriate legal and business approval. 
			28.2.5.5 Additional Examples
All Use of Open Source Requires Approval

Please keep in mind that all use of open source code requires that you obtain approval via the Open Source Approval tool, which is located at http://wwwin-tools.cisco.com/legal/osldb/jsp/osldb_home.jsp. Depending on your use (for example, if the proposed use has no Red Flags), your request may obtain quicker approval. This process allows us to keep a central database of all use of open source code within Cisco. 
		28.2.6 LGPL Red Flags

The following two pages describe scenarios in which use of LGPL code may lead to a Red Flag. These scenarios include the following:

			28.2.6.1. Making Modifications to LGPL Source Code
			Making Modifications to LGPL Source Code

If you modify the source code of a LGPL program, and Cisco distributes the modified version, this triggers a Red Flag. Cisco will be required to release the source code of the modifications under the LGPL.
Embedding LGPL Code into Cisco Code or Embedding Cisco Code into LGPL Code

    			28.2.6.2. Embedding LGPL Code into Cisco Code or Vice Versa
If you embed or incorporate LGPL code directly into your program (or the other way around) and Cisco distributes the program, this triggers a Red Flag. Cisco will be required to release the source code of the program under the LGPL.

    			28.2.6.3. Static Linking
Statically linking the LGPL code with the Cisco proprietary code triggers a Red Flag.

 		28.2.7.  Special Cases
libgcc and libstdc++

These two files, licensed under GPLv2, contain special license exemptions that permit linking to the unmodified binary versions of these files without triggering the copyleft provisions that would ordinarily apply.

These are special cases, where neither static nor dynamic linking to these files risk triggering the copyleft provisions of the GPL. However, any modification of libgcc or libstdc++ code remains a Red Flag, since Cisco will be required to share the modified source code of those files.
	28.3

29. g++

	29.1  manual
g++(1) - Linux man page

Name

gcc - GNU project C and C++ compiler

Synopsis


 
gcc [-c|-S|-E] [-std=standard] [-g] [-pg] [-Olevel] [-Wwarn...] [-pedantic] [-Idir...] [-Ldir...] [-Dmacro[=defn]...] [-Umacro] [-foption...] [-mmachine-option...] [-o outfile] [@file] infile...

Only the most useful options are listed here; see below for the remainder. g++ accepts mostly the same options as gcc.

Description

When you invoke GCC , it normally does preprocessing, compilation, assembly and linking. The "overall options" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler.

Other options are passed on to one stage of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them.

Most of the command line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C ++ ), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages.

The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v.

You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant.

Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo would be -fno-foo. This manual documents only one of these two forms, whichever one is not the default.

Options

Option Summary

Here is a summary of all the options, grouped by type. Explanations are in the following sections.
Overall Options
-c -S -E -o file -combine -pipe -pass-exit-codes -x language -v -### --help[=class[,...]] --target-help --version -wrapper@file
C Language Options
-ansi -std=standard -fgnu89-inline -aux-info filename -fno-asm -fno-builtin -fno-builtin-function -fhosted -ffreestanding -fopenmp -fms-extensions -trigraphs -no-integrated-cpp -traditional -traditional-cpp -fallow-single-precision -fcond-mismatch -flax-vector-conversions -fsigned-bitfields -fsigned-char -funsigned-bitfields -funsigned-char
C ++ Language Options
-fabi-version=n -fno-access-control -fcheck-new -fconserve-space -ffriend-injection -fno-elide-constructors -fno-enforce-eh-specs -ffor-scope -fno-for-scope -fno-gnu-keywords -fno-implicit-templates -fno-implicit-inline-templates -fno-implement-inlines -fms-extensions -fno-nonansi-builtins -fno-operator-names -fno-optional-diags -fpermissive -frepo -fno-rtti -fstats -ftemplate-depth-n -fno-threadsafe-statics -fuse-cxa-atexit -fno-weak -nostdinc++ -fno-default-inline -fvisibility-inlines-hidden -fvisibility-ms-compat -Wabi -Wctor-dtor-privacy -Wnon-virtual-dtor -Wreorder -Weffc++ -Wstrict-null-sentinel -Wno-non-template-friend -Wold-style-cast -Woverloaded-virtual -Wno-pmf-conversions -Wsign-promo
Objective-C and Objective-C ++ Language Options
-fconstant-string-class=class-name -fgnu-runtime -fnext-runtime -fno-nil-receivers -fobjc-call-cxx-cdtors -fobjc-direct-dispatch -fobjc-exceptions -fobjc-gc -freplace-objc-classes -fzero-link -gen-decls -Wassign-intercept -Wno-protocol -Wselector -Wstrict-selector-match -Wundeclared-selector
Language Independent Options
-fmessage-length=n -fdiagnostics-show-location=[once|every-line] -fdiagnostics-show-option
Warning Options
-fsyntax-only -pedantic -pedantic-errors -w -Wextra -Wall -Waddress -Waggregate-return -Warray-bounds -Wno-attributes -Wno-builtin-macro-redefined -Wc++-compat -Wc++0x-compat -Wcast-align -Wcast-qual -Wchar-subscripts -Wclobbered -Wcomment -Wconversion -Wcoverage-mismatch -Wno-deprecated -Wno-deprecated-declarations -Wdisabled-optimization -Wno-div-by-zero -Wempty-body -Wenum-compare -Wno-endif-labels -Werror -Werror=* -Wfatal-errors -Wfloat-equal -Wformat -Wformat=2 -Wno-format-contains-nul -Wno-format-extra-args -Wformat-nonliteral -Wformat-security -Wformat-y2k -Wframe-larger-than=len -Wignored-qualifiers -Wimplicit -Wimplicit-function-declaration -Wimplicit-int -Winit-self -Winline -Wno-int-to-pointer-cast -Wno-invalid-offsetof -Winvalid-pch -Wlarger-than=len -Wunsafe-loop-optimizations -Wlogical-op -Wlong-long -Wmain -Wmissing-braces -Wmissing-field-initializers -Wmissing-format-attribute -Wmissing-include-dirs -Wmissing-noreturn -Wno-mudflap -Wno-multichar -Wnonnull -Wno-overflow -Woverlength-strings -Wpacked -Wpacked-bitfield-compat -Wpadded -Wparentheses -Wpedantic-ms-format -Wno-pedantic-ms-format -Wpointer-arith -Wno-pointer-to-int-cast -Wredundant-decls -Wreturn-type -Wsequence-point -Wshadow -Wsign-compare -Wsign-conversion -Wstack-protector -Wstrict-aliasing -Wstrict-aliasing=n -Wstrict-overflow -Wstrict-overflow=n -Wswitch -Wswitch-default -Wswitch-enum -Wsync-nand -Wsystem-headers -Wtrigraphs -Wtype-limits -Wundef -Wuninitialized -Wunknown-pragmas -Wno-pragmas -Wunreachable-code -Wunused -Wunused-function -Wunused-label -Wunused-parameter -Wunused-value -Wunused-variable -Wunused-but-set-parameter -Wunused-but-set-variable -Wvariadic-macros -Wvla -Wvolatile-register-var -Wwrite-strings
C and Objective-C-only Warning Options
-Wbad-function-cast -Wmissing-declarations -Wmissing-parameter-type -Wmissing-prototypes -Wnested-externs -Wold-style-declaration -Wold-style-definition -Wstrict-prototypes -Wtraditional -Wtraditional-conversion -Wdeclaration-after-statement -Wpointer-sign
Debugging Options
-dletters -dumpspecs -dumpmachine -dumpversion -fdbg-cnt-list -fdbg-cnt=counter-value-list -fdump-noaddr -fdump-unnumbered -fdump-unnumbered-links -fdump-translation-unit[-n] -fdump-class-hierarchy[-n] -fdump-ipa-all -fdump-ipa-cgraph -fdump-ipa-inline -fdump-statistics -fdump-tree-all -fdump-tree-original[-n] -fdump-tree-optimized[-n] -fdump-tree-cfg -fdump-tree-vcg -fdump-tree-alias -fdump-tree-ch -fdump-tree-ssa[-n] -fdump-tree-pre[-n] -fdump-tree-ccp[-n] -fdump-tree-dce[-n] -fdump-tree-gimple[-raw] -fdump-tree-mudflap[-n] -fdump-tree-dom[-n] -fdump-tree-dse[-n] -fdump-tree-phiopt[-n] -fdump-tree-forwprop[-n] -fdump-tree-copyrename[-n] -fdump-tree-nrv -fdump-tree-vect -fdump-tree-sink -fdump-tree-sra[-n] -fdump-tree-fre[-n] -fdump-tree-vrp[-n] -ftree-vectorizer-verbose=n -fdump-tree-storeccp[-n] -fdump-final-insns=file -fcompare-debug[=opts] -fcompare-debug-second -feliminate-dwarf2-dups -feliminate-unused-debug-types -feliminate-unused-debug-symbols -femit-class-debug-always -fmem-report -fpre-ipa-mem-report -fpost-ipa-mem-report -fprofile-arcs -frandom-seed=string -fsched-verbose=n -fsel-sched-verbose -fsel-sched-dump-cfg -fsel-sched-pipelining-verbose -ftest-coverage -ftime-report -fvar-tracking -fvar-tracking-assignments -fvar-tracking-assignments-toggle -g -glevel -gtoggle -gcoff -gdwarf-version -ggdb -gstabs -gstabs+ -gstrict-dwarf -gno-strict-dwarf -gvms -gxcoff -gxcoff+ -fno-merge-debug-strings -fno-dwarf2-cfi-asm -fdebug-prefix-map=old=new -femit-struct-debug-baseonly -femit-struct-debug-reduced -femit-struct-debug-detailed[=spec-list] -p -pg -print-file-name=library -print-libgcc-file-name -print-multi-directory -print-multi-lib -print-multi-os-directory -print-prog-name=program -print-search-dirs -Q -print-sysroot -print-sysroot-headers-suffix -save-temps -time[=file]
Optimization Options
-falign-functions[=n] -falign-jumps[=n] -falign-labels[=n] -falign-loops[=n] -fassociative-math -fauto-inc-dec -fbranch-probabilities -fbranch-target-load-optimize -fbranch-target-load-optimize2 -fbtr-bb-exclusive -fcaller-saves -fcheck-data-deps -fconserve-stack -fcprop-registers -fcrossjumping -fcse-follow-jumps -fcse-skip-blocks -fcx-fortran-rules -fcx-limited-range -fdata-sections -fdce -fdce -fdelayed-branch -fdelete-null-pointer-checks -fdse -fdse -fearly-inlining -fexpensive-optimizations -ffast-math -ffinite-math-only -ffloat-store -fforward-propagate -ffunction-sections -fgcse -fgcse-after-reload -fgcse-las -fgcse-lm -fgcse-sm -fif-conversion -fif-conversion2 -findirect-inlining -finline-functions -finline-functions-called-once -finline-limit=n -finline-small-functions -fipa-cp -fipa-cp-clone -fipa-matrix-reorg -fipa-pta -fipa-pure-const -fipa-reference -fipa-struct-reorg -fipa-type-escape -fira-algorithm=algorithm -fira-region=region -fira-coalesce -fno-ira-share-save-slots -fno-ira-share-spill-slots -fira-verbose=n -fivopts -fkeep-inline-functions -fkeep-static-consts -floop-block -floop-interchange -floop-strip-mine -fmerge-all-constants -fmerge-constants -fmodulo-sched -fmodulo-sched-allow-regmoves -fmove-loop-invariants -fmudflap -fmudflapir -fmudflapth -fno-branch-count-reg -fno-default-inline -fno-defer-pop -fno-function-cse -fno-guess-branch-probability -fno-inline -fno-math-errno -fno-peephole -fno-peephole2 -fno-sched-interblock -fno-sched-spec -fno-signed-zeros -fno-toplevel-reorder -fno-trapping-math -fno-zero-initialized-in-bss -fomit-frame-pointer -foptimize-register-move -foptimize-sibling-calls -fpeel-loops -fpredictive-commoning -fprefetch-loop-arrays -fprofile-correction -fprofile-dir=path -fprofile-generate -fprofile-generate=path -fprofile-use -fprofile-use=path -fprofile-values -freciprocal-math -fregmove -frename-registers -freorder-blocks -freorder-blocks-and-partition -freorder-functions -frerun-cse-after-loop -freschedule-modulo-scheduled-loops -frounding-math -frtl-abstract-sequences -fsched2-use-superblocks -fsched2-use-traces -fsched-spec-load -fsched-spec-load-dangerous -fsched-stalled-insns-dep[=n] -fsched-stalled-insns[=n] -fschedule-insns -fschedule-insns2 -fsection-anchors -fsee -fselective-scheduling -fselective-scheduling2 -fsel-sched-pipelining -fsel-sched-pipelining-outer-loops -fsignaling-nans -fsingle-precision-constant -fsplit-ivs-in-unroller -fsplit-wide-types -fstack-protector -fstack-protector-all -fstrict-aliasing -fstrict-overflow -fthread-jumps -ftracer -ftree-builtin-call-dce -ftree-ccp -ftree-ch -ftree-coalesce-inline-vars -ftree-coalesce-vars -ftree-copy-prop -ftree-copyrename -ftree-dce -ftree-dominator-opts -ftree-dse -ftree-fre -ftree-loop-im -ftree-loop-distribution -ftree-loop-ivcanon -ftree-loop-linear -ftree-loop-optimize -ftree-parallelize-loops=n -ftree-pre -ftree-reassoc -ftree-sink -ftree-sra -ftree-switch-conversion -ftree-ter -ftree-vect-loop-version -ftree-vectorize -ftree-vrp -funit-at-a-time -funroll-all-loops -funroll-loops -funsafe-loop-optimizations -funsafe-math-optimizations -funswitch-loops -fvariable-expansion-in-unroller -fvect-cost-model -fvpt -fweb -fwhole-program --param name=value -O -O0 -O1 -O2 -O3 -Os
Preprocessor Options
-Aquestion=answer -A-question[=answer] -C -dD -dI -dM -dN -Dmacro[=defn] -E -H -idirafter dir -include file -imacros file -iprefix file -iwithprefix dir -iwithprefixbefore dir -isystem dir -imultilib dir -isysroot dir -M -MM -MF -MG -MP -MQ -MT -nostdinc -P -fworking-directory -remap -trigraphs -undef -Umacro -Wp,option -Xpreprocessor option
Assembler Option
-Wa,option -Xassembler option
Linker Options
object-file-name -llibrary -nostartfiles -nodefaultlibs -nostdlib -pie -rdynamic -s -static -static-libgcc -shared -shared-libgcc -symbolic -T script -Wl,option -Xlinker option -u symbol
Directory Options
-Bprefix -Idir -iquotedir -Ldir -specs=file -I- --sysroot=dir
Target Options
-V version -b machine
Machine Dependent Options
ARC Options -EB -EL -mmangle-cpu -mcpu=cpu -mtext=text-section -mdata=data-section -mrodata=readonly-data-section
ARM Options -mapcs-frame -mno-apcs-frame -mabi=name -mapcs-stack-check -mno-apcs-stack-check -mapcs-float -mno-apcs-float -mapcs-reentrant -mno-apcs-reentrant -msched-prolog -mno-sched-prolog -mlittle-endian -mbig-endian -mwords-little-endian -mfloat-abi=name -msoft-float -mhard-float -mfpe -mthumb-interwork -mno-thumb-interwork -mcpu=name -march=name -mfpu=name -mstructure-size-boundary=n -mabort-on-noreturn -mlong-calls -mno-long-calls -msingle-pic-base -mno-single-pic-base -mpic-register=reg -mnop-fun-dllimport -mcirrus-fix-invalid-insns -mno-cirrus-fix-invalid-insns -mpoke-function-name -mthumb -marm -mtpcs-frame -mtpcs-leaf-frame -mcaller-super-interworking -mcallee-super-interworking -mtp=name -mword-relocations -mfix-cortex-m3-ldrd

AVR Options -mmcu=mcu -msize -mno-interrupts -mcall-prologues -mno-tablejump -mtiny-stack -mint8

Blackfin Options -mcpu=cpu[-sirevision] -msim -momit-leaf-frame-pointer -mno-omit-leaf-frame-pointer -mspecld-anomaly -mno-specld-anomaly -mcsync-anomaly -mno-csync-anomaly -mlow-64k -mno-low64k -mstack-check-l1 -mid-shared-library -mno-id-shared-library -mshared-library-id=n -mleaf-id-shared-library -mno-leaf-id-shared-library -msep-data -mno-sep-data -mlong-calls -mno-long-calls -mfast-fp -minline-plt -mmulticore -mcorea -mcoreb -msdram -micplb

CRIS Options -mcpu=cpu -march=cpu -mtune=cpu -mmax-stack-frame=n -melinux-stacksize=n -metrax4 -metrax100 -mpdebug -mcc-init -mno-side-effects -mstack-align -mdata-align -mconst-align -m32-bit -m16-bit -m8-bit -mno-prologue-epilogue -mno-gotplt -melf -maout -melinux -mlinux -sim -sim2 -mmul-bug-workaround -mno-mul-bug-workaround

CRX Options -mmac -mpush-args

Darwin Options -all_load -allowable_client -arch -arch_errors_fatal -arch_only -bind_at_load -bundle -bundle_loader -client_name -compatibility_version -current_version -dead_strip -dependency-file -dylib_file -dylinker_install_name -dynamic -dynamiclib -exported_symbols_list -filelist -flat_namespace -force_cpusubtype_ALL -force_flat_namespace -headerpad_max_install_names -iframework -image_base -init -install_name -keep_private_externs -multi_module -multiply_defined -multiply_defined_unused -noall_load -no_dead_strip_inits_and_terms -nofixprebinding -nomultidefs -noprebind -noseglinkedit -pagezero_size -prebind -prebind_all_twolevel_modules -private_bundle -read_only_relocs -sectalign -sectobjectsymbols -whyload -seg1addr -sectcreate -sectobjectsymbols -sectorder -segaddr -segs_read_only_addr -segs_read_write_addr -seg_addr_table -seg_addr_table_filename -seglinkedit -segprot -segs_read_only_addr -segs_read_write_addr -single_module -static -sub_library -sub_umbrella -twolevel_namespace -umbrella -undefined -unexported_symbols_list -weak_reference_mismatches -whatsloaded -F -gused -gfull -mmacosx-version-min=version -mkernel -mone-byte-bool

DEC Alpha Options -mno-fp-regs -msoft-float -malpha-as -mgas -mieee -mieee-with-inexact -mieee-conformant -mfp-trap-mode=mode -mfp-rounding-mode=mode -mtrap-precision=mode -mbuild-constants -mcpu=cpu-type -mtune=cpu-type -mbwx -mmax -mfix -mcix -mfloat-vax -mfloat-ieee -mexplicit-relocs -msmall-data -mlarge-data -msmall-text -mlarge-text -mmemory-latency=time

DEC Alpha/VMS Options -mvms-return-codes

FR30 Options -msmall-model -mno-lsim

FRV Options -mgpr-32 -mgpr-64 -mfpr-32 -mfpr-64 -mhard-float -msoft-float -malloc-cc -mfixed-cc -mdword -mno-dword -mdouble -mno-double -mmedia -mno-media -mmuladd -mno-muladd -mfdpic -minline-plt -mgprel-ro -multilib-library-pic -mlinked-fp -mlong-calls -malign-labels -mlibrary-pic -macc-4 -macc-8 -mpack -mno-pack -mno-eflags -mcond-move -mno-cond-move -moptimize-membar -mno-optimize-membar -mscc -mno-scc -mcond-exec -mno-cond-exec -mvliw-branch -mno-vliw-branch -mmulti-cond-exec -mno-multi-cond-exec -mnested-cond-exec -mno-nested-cond-exec -mtomcat-stats -mTLS -mtls -mcpu=cpu

GNU/Linux Options -muclibc

H8/300 Options -mrelax -mh -ms -mn -mint32 -malign-300

HPPA Options -march=architecture-type -mbig-switch -mdisable-fpregs -mdisable-indexing -mfast-indirect-calls -mgas -mgnu-ld -mhp-ld -mfixed-range=register-range -mjump-in-delay -mlinker-opt -mlong-calls -mlong-load-store -mno-big-switch -mno-disable-fpregs -mno-disable-indexing -mno-fast-indirect-calls -mno-gas -mno-jump-in-delay -mno-long-load-store -mno-portable-runtime -mno-soft-float -mno-space-regs -msoft-float -mpa-risc-1-0 -mpa-risc-1-1 -mpa-risc-2-0 -mportable-runtime -mschedule=cpu-type -mspace-regs -msio -mwsio -munix=unix-std -nolibdld -static -threads

i386 and x86-64 Options -mtune=cpu-type -march=cpu-type -mfpmath=unit -masm=dialect -mno-fancy-math-387 -mno-fp-ret-in-387 -msoft-float -mno-wide-multiply -mrtd -malign-double -mpreferred-stack-boundary=num -mincoming-stack-boundary=num -mcld -mcx16 -msahf -mmovbe -mcrc32 -mrecip -mmmx -msse -msse2 -msse3 -mssse3 -msse4.1 -msse4.2 -msse4 -mavx -maes -mpclmul -mfsgsbase -mrdrnd -mf16c -mfused-madd -msse4a -m3dnow -mpopcnt -mabm -mbmi -mtbm -mfma4 -mxop -mlwp -mthreads -mno-align-stringops -minline-all-stringops -minline-stringops-dynamically -mstringop-strategy=alg -mpush-args -maccumulate-outgoing-args -m128bit-long-double -m96bit-long-double -mregparm=num -msseregparm -mveclibabi=type -mpc32 -mpc64 -mpc80 -mstackrealign -momit-leaf-frame-pointer -mno-red-zone -mno-tls-direct-seg-refs -mcmodel=code-model -m32 -m64 -mlarge-data-threshold=num -msse2avx

i386 and x86-64 Windows Options -mconsole -mcygwin -mno-cygwin -mdll -mnop-fun-dllimport -mthread -mwin32 -mwindows

IA-64 Options -mbig-endian -mlittle-endian -mgnu-as -mgnu-ld -mno-pic -mvolatile-asm-stop -mregister-names -mno-sdata -mconstant-gp -mauto-pic -minline-float-divide-min-latency -minline-float-divide-max-throughput -minline-int-divide-min-latency -minline-int-divide-max-throughput -minline-sqrt-min-latency -minline-sqrt-max-throughput -mno-dwarf2-asm -mearly-stop-bits -mfixed-range=register-range -mtls-size=tls-size -mtune=cpu-type -mt -pthread -milp32 -mlp64 -mno-sched-br-data-spec -msched-ar-data-spec -mno-sched-control-spec -msched-br-in-data-spec -msched-ar-in-data-spec -msched-in-control-spec -msched-ldc -mno-sched-control-ldc -mno-sched-spec-verbose -mno-sched-prefer-non-data-spec-insns -mno-sched-prefer-non-control-spec-insns -mno-sched-count-spec-in-critical-path

M32R/D Options -m32r2 -m32rx -m32r -mdebug -malign-loops -mno-align-loops -missue-rate=number -mbranch-cost=number -mmodel=code-size-model-type -msdata=sdata-type -mno-flush-func -mflush-func=name -mno-flush-trap -mflush-trap=number -G num

M32C Options -mcpu=cpu -msim -memregs=number

M680x0 Options -march=arch -mcpu=cpu -mtune=tune -m68000 -m68020 -m68020-40 -m68020-60 -m68030 -m68040 -m68060 -mcpu32 -m5200 -m5206e -m528x -m5307 -m5407 -mcfv4e -mbitfield -mno-bitfield -mc68000 -mc68020 -mnobitfield -mrtd -mno-rtd -mdiv -mno-div -mshort -mno-short -mhard-float -m68881 -msoft-float -mpcrel -malign-int -mstrict-align -msep-data -mno-sep-data -mshared-library-id=n -mid-shared-library -mno-id-shared-library -mxgot -mno-xgot

M68hc1x Options -m6811 -m6812 -m68hc11 -m68hc12 -m68hcs12 -mauto-incdec -minmax -mlong-calls -mshort -msoft-reg-count=count

MCore Options -mhardlit -mno-hardlit -mdiv -mno-div -mrelax-immediates -mno-relax-immediates -mwide-bitfields -mno-wide-bitfields -m4byte-functions -mno-4byte-functions -mcallgraph-data -mno-callgraph-data -mslow-bytes -mno-slow-bytes -mno-lsim -mlittle-endian -mbig-endian -m210 -m340 -mstack-increment

MIPS Options -EL -EB -march=arch -mtune=arch -mips1 -mips2 -mips3 -mips4 -mips32 -mips32r2 -mips64 -mips64r2 -mips16 -mno-mips16 -mflip-mips16 -minterlink-mips16 -mno-interlink-mips16 -mabi=abi -mabicalls -mno-abicalls -mshared -mno-shared -mplt -mno-plt -mxgot -mno-xgot -mgp32 -mgp64 -mfp32 -mfp64 -mhard-float -msoft-float -msingle-float -mdouble-float -mdsp -mno-dsp -mdspr2 -mno-dspr2 -mfpu=fpu-type -msmartmips -mno-smartmips -mpaired-single -mno-paired-single -mdmx -mno-mdmx -mips3d -mno-mips3d -mmt -mno-mt -mllsc -mno-llsc -mlong64 -mlong32 -msym32 -mno-sym32 -Gnum -mlocal-sdata -mno-local-sdata -mextern-sdata -mno-extern-sdata -mgpopt -mno-gopt -membedded-data -mno-embedded-data -muninit-const-in-rodata -mno-uninit-const-in-rodata -mcode-readable=setting -msplit-addresses -mno-split-addresses -mexplicit-relocs -mno-explicit-relocs -mcheck-zero-division -mno-check-zero-division -mdivide-traps -mdivide-breaks -mmemcpy -mno-memcpy -mlong-calls -mno-long-calls -mmad -mno-mad -mfused-madd -mno-fused-madd -nocpp -mfix-r4000 -mno-fix-r4000 -mfix-r4400 -mno-fix-r4400 -mfix-r10000 -mno-fix-r10000 -mfix-vr4120 -mno-fix-vr4120 -mfix-vr4130 -mno-fix-vr4130 -mfix-sb1 -mno-fix-sb1 -mflush-func=func -mno-flush-func -mbranch-cost=num -mbranch-likely -mno-branch-likely -mfp-exceptions -mno-fp-exceptions -mvr4130-align -mno-vr4130-align

MMIX Options -mlibfuncs -mno-libfuncs -mepsilon -mno-epsilon -mabi=gnu -mabi=mmixware -mzero-extend -mknuthdiv -mtoplevel-symbols -melf -mbranch-predict -mno-branch-predict -mbase-addresses -mno-base-addresses -msingle-exit -mno-single-exit

MN10300 Options -mmult-bug -mno-mult-bug -mam33 -mno-am33 -mam33-2 -mno-am33-2 -mreturn-pointer-on-d0 -mno-crt0 -mrelax

PDP-11 Options -mfpu -msoft-float -mac0 -mno-ac0 -m40 -m45 -m10 -mbcopy -mbcopy-builtin -mint32 -mno-int16 -mint16 -mno-int32 -mfloat32 -mno-float64 -mfloat64 -mno-float32 -mabshi -mno-abshi -mbranch-expensive -mbranch-cheap -msplit -mno-split -munix-asm -mdec-asm

picoChip Options -mae=ae_type -mvliw-lookahead=N -msymbol-as-address -mno-inefficient-warnings

PowerPC Options See RS/6000 and PowerPC Options.

RS/6000 and PowerPC Options -mcpu=cpu-type -mtune=cpu-type -mcmodel=code-model -mpower -mno-power -mpower2 -mno-power2 -mpowerpc -mpowerpc64 -mno-powerpc -maltivec -mno-altivec -mpowerpc-gpopt -mno-powerpc-gpopt -mpowerpc-gfxopt -mno-powerpc-gfxopt -mmfcrf -mno-mfcrf -mpopcntb -mno-popcntb -mpopcntd -mno-popcntd -mfprnd -mno-fprnd -mcmpb -mno-cmpb -mmfpgpr -mno-mfpgpr -mhard-dfp -mno-hard-dfp -mnew-mnemonics -mold-mnemonics -mfull-toc -mminimal-toc -mno-fp-in-toc -mno-sum-in-toc -m64 -m32 -mxl-compat -mno-xl-compat -mpe -malign-power -malign-natural -msoft-float -mhard-float -mmultiple -mno-multiple -msingle-float -mdouble-float -msimple-fpu -mstring -mno-string -mupdate -mno-update -mavoid-indexed-addresses -mno-avoid-indexed-addresses -mfused-madd -mno-fused-madd -mbit-align -mno-bit-align -mstrict-align -mno-strict-align -mrelocatable -mno-relocatable -mrelocatable-lib -mno-relocatable-lib -mtoc -mno-toc -mlittle -mlittle-endian -mbig -mbig-endian -mdynamic-no-pic -maltivec -mswdiv -mprioritize-restricted-insns=priority -msched-costly-dep=dependence_type -minsert-sched-nops=scheme -mcall-sysv -mcall-netbsd -maix-struct-return -msvr4-struct-return -mabi=abi-type -msecure-plt -mbss-plt -misel -mno-isel -misel=yes -misel=no -mspe -mno-spe -mspe=yes -mspe=no -mpaired -mgen-cell-microcode -mwarn-cell-microcode -mvrsave -mno-vrsave -mmulhw -mno-mulhw -mdlmzb -mno-dlmzb -mfloat-gprs=yes -mfloat-gprs=no -mfloat-gprs=single -mfloat-gprs=double -mprototype -mno-prototype -msim -mmvme -mads -myellowknife -memb -msdata -msdata=opt -mvxworks -G num -pthread

S/390 and zSeries Options -mtune=cpu-type -march=cpu-type -mhard-float -msoft-float -mhard-dfp -mno-hard-dfp -mlong-double-64 -mlong-double-128 -mbackchain -mno-backchain -mpacked-stack -mno-packed-stack -msmall-exec -mno-small-exec -mmvcle -mno-mvcle -m64 -m31 -mdebug -mno-debug -mesa -mzarch -mtpf-trace -mno-tpf-trace -mfused-madd -mno-fused-madd -mwarn-framesize -mwarn-dynamicstack -mstack-size -mstack-guard

Score Options -meb -mel -mnhwloop -muls -mmac -mscore5 -mscore5u -mscore7 -mscore7d

SH Options -m1 -m2 -m2e -m3 -m3e -m4-nofpu -m4-single-only -m4-single -m4 -m4a-nofpu -m4a-single-only -m4a-single -m4a -m4al -m5-64media -m5-64media-nofpu -m5-32media -m5-32media-nofpu -m5-compact -m5-compact-nofpu -mb -ml -mdalign -mrelax -mbigtable -mfmovd -mhitachi -mrenesas -mno-renesas -mnomacsave -mieee -mbitops -misize -minline-ic_invalidate -mpadstruct -mspace -mprefergot -musermode -multcost=number -mdiv=strategy -mdivsi3_libfunc=name -mfixed-range=register-range -madjust-unroll -mindexed-addressing -mgettrcost=number -mpt-fixed -minvalid-symbols

SPARC Options -mcpu=cpu-type -mtune=cpu-type -mcmodel=code-model -m32 -m64 -mapp-regs -mno-app-regs -mfaster-structs -mno-faster-structs -mfpu -mno-fpu -mhard-float -msoft-float -mhard-quad-float -msoft-quad-float -mimpure-text -mno-impure-text -mlittle-endian -mstack-bias -mno-stack-bias -munaligned-doubles -mno-unaligned-doubles -mv8plus -mno-v8plus -mvis -mno-vis -threads -pthreads -pthread

SPU Options -mwarn-reloc -merror-reloc -msafe-dma -munsafe-dma -mbranch-hints -msmall-mem -mlarge-mem -mstdmain -mfixed-range=register-range

System V Options -Qy -Qn -YP,paths -Ym,dir

V850 Options -mlong-calls -mno-long-calls -mep -mno-ep -mprolog-function -mno-prolog-function -mspace -mtda=n -msda=n -mzda=n -mapp-regs -mno-app-regs -mdisable-callt -mno-disable-callt -mv850e1 -mv850e -mv850 -mbig-switch

VAX Options -mg -mgnu -munix

VxWorks Options -mrtp -non-static -Bstatic -Bdynamic -Xbind-lazy -Xbind-now

x86-64 Options See i386 and x86-64 Options.

Xstormy16 Options -msim

Xtensa Options -mconst16 -mno-const16 -mfused-madd -mno-fused-madd -mserialize-volatile -mno-serialize-volatile -mtext-section-literals -mno-text-section-literals -mtarget-align -mno-target-align -mlongcalls -mno-longcalls

zSeries Options See S/390 and zSeries Options.

Code Generation Options
-fcall-saved-reg -fcall-used-reg -ffixed-reg -fexceptions -fnon-call-exceptions -funwind-tables -fasynchronous-unwind-tables -finhibit-size-directive -finstrument-functions -finstrument-functions-exclude-function-list=sym,sym,... -finstrument-functions-exclude-file-list=file,file,... -fno-common -fno-ident -fpcc-struct-return -fpic -fPIC -fpie -fPIE -fno-jump-tables -frecord-gcc-switches -freg-struct-return -fshort-enums -fshort-double -fshort-wchar -fverbose-asm -fpack-struct[=n] -fstack-check -fstack-limit-register=reg -fstack-limit-symbol=sym -fno-stack-limit -fargument-alias -fargument-noalias -fargument-noalias-global -fargument-noalias-anything -fleading-underscore -ftls-model=model -ftrapv -fwrapv -fbounds-check -fvisibility
Options Controlling the Kind of Output

Compilation can involve up to four stages: preprocessing, compilation proper, assembly and linking, always in that order. GCC is capable of preprocessing and compiling several files either into several assembler input files, or into one assembler input file; then each assembler input file produces an object file, and linking combines all the object files (those newly compiled, and those specified as input) into an executable file.
For any given input file, the file name suffix determines what kind of compilation is done:

file.c
C source code which must be preprocessed.
file.i
C source code which should not be preprocessed.
file.ii
C ++ source code which should not be preprocessed.
file.m
Objective-C source code. Note that you must link with the libobjc library to make an Objective-C program work.
file.mi
Objective-C source code which should not be preprocessed.
file.mm
file.M
Objective-C ++ source code. Note that you must link with the libobjc library to make an Objective-C ++ program work. Note that .M refers to a literal capital M.
file.mii
Objective-C ++ source code which should not be preprocessed.
file.h
C, C ++ , Objective-C or Objective-C ++ header file to be turned into a precompiled header.
file.cc
file.cp
file.cxx
file.cpp
file.CPP
file.c++
file.C
C ++ source code which must be preprocessed. Note that in .cxx, the last two letters must both be literally x. Likewise, .C refers to a literal capital C.
file.mm
file.M
Objective-C ++ source code which must be preprocessed.
file.mii
Objective-C ++ source code which should not be preprocessed.
file.hh
file.H
file.hp
file.hxx
file.hpp
file.HPP
file.h++
file.tcc
C ++ header file to be turned into a precompiled header.
file.f
file.for
file.ftn
Fixed form Fortran source code which should not be preprocessed.
file.F
file.FOR
file.fpp
file.FPP
file.FTN
Fixed form Fortran source code which must be preprocessed (with the traditional preprocessor).
file.f90
file.f95
file.f03
file.f08
Free form Fortran source code which should not be preprocessed.
file.F90
file.F95
file.F03
file.F08
Free form Fortran source code which must be preprocessed (with the traditional preprocessor).
file.ads
Ada source code file which contains a library unit declaration (a declaration of a package, subprogram, or generic, or a generic instantiation), or a library unit renaming declaration (a package, generic, or subprogram renaming declaration). Such files are also called specs.
file.adb
Ada source code file containing a library unit body (a subprogram or package body). Such files are also called bodies.
file.s
Assembler code.
file.S
file.sx
Assembler code which must be preprocessed.
other
An object file to be fed straight into linking. Any file name with no recognized suffix is treated this way.
You can specify the input language explicitly with the -x option:
-x language
Specify explicitly the language for the following input files (rather than letting the compiler choose a default based on the file name suffix). This option applies to all following input files until the next -x option. Possible values for language are:
c  c-header  c-cpp-output
c++  c++-header  c++-cpp-output
objective-c  objective-c-header  objective-c-cpp-output
objective-c++ objective-c++-header objective-c++-cpp-output
assembler  assembler-with-cpp
ada
f77  f77-cpp-input f95  f95-cpp-input
java
-x none
Turn off any specification of a language, so that subsequent files are handled according to their file name suffixes (as they are if -x has not been used at all).
-pass-exit-codes
Normally the gcc program will exit with the code of 1 if any phase of the compiler returns a non-success return code. If you specify -pass-exit-codes, the gcc program will instead return with numerically highest error produced by any phase that returned an error indication. The C, C ++ , and Fortran frontends return 4, if an internal compiler error is encountered.
If you only want some of the stages of compilation, you can use -x (or filename suffixes) to tell gcc where to start, and one of the options -c, -S, or -E to say where gcc is to stop. Note that some combinations (for example, -x cpp-output -E) instruct gcc to do nothing at all.
-c
Compile or assemble the source files, but do not link. The linking stage simply is not done. The ultimate output is in the form of an object file for each source file.

By default, the object file name for a source file is made by replacing the suffix .c, .i, .s, etc., with .o.
Unrecognized input files, not requiring compilation or assembly, are ignored.

-S
Stop after the stage of compilation proper; do not assemble. The output is in the form of an assembler code file for each non-assembler input file specified.

By default, the assembler file name for a source file is made by replacing the suffix .c, .i, etc., with .s.
Input files that don't require compilation are ignored.

-E
Stop after the preprocessing stage; do not run the compiler proper. The output is in the form of preprocessed source code, which is sent to the standard output.

Input files which don't require preprocessing are ignored.
-o file
Place output in file file. This applies regardless to whatever sort of output is being produced, whether it be an executable file, an object file, an assembler file or preprocessed C code.
If -o is not specified, the default is to put an executable file in a.out, the object file for source.suffix in source.o, its assembler file in source.s, a precompiled header file in source.suffix.gch, and all preprocessed C source on standard output.

-v
Print (on standard error output) the commands executed to run the stages of compilation. Also print the version number of the compiler driver program and of the preprocessor and the compiler proper.

-###
Like -v except the commands are not executed and all command arguments are quoted. This is useful for shell scripts to capture the driver-generated command lines.
-pipe
Use pipes rather than temporary files for communication between the various stages of compilation. This fails to work on some systems where the assembler is unable to read from a pipe; but the GNU assembler has no trouble.
-combine
If you are compiling multiple source files, this option tells the driver to pass all the source files to the compiler at once (for those languages for which the compiler can handle this). This will allow intermodule analysis ( IMA ) to be performed by the compiler. Currently the only language for which this is supported is C. If you pass source files for multiple languages to the driver, using this option, the driver will invoke the compiler(s) that support IMA once each, passing each compiler all the source files appropriate for it. For those languages that do not support IMA this option will be ignored, and the compiler will be invoked once for each source file in that language. If you use this option in conjunction with -save-temps, the compiler will generate multiple pre-processed files (one for each source file), but only one (combined) .o or .s file.
--help
Print (on the standard output) a description of the command line options understood by gcc. If the -v option is also specified then --help will also be passed on to the various processes invoked by gcc, so that they can display the command line options they accept. If the -Wextra option has also been specified (prior to the --help option), then command line options which have no documentation associated with them will also be displayed.
--target-help
Print (on the standard output) a description of target-specific command line options for each tool. For some targets extra target-specific information may also be printed.
--help={class|[^]qualifier}[,...]
Print (on the standard output) a description of the command line options understood by the compiler that fit into all specified classes and qualifiers. These are the supported classes:
optimizers
This will display all of the optimization options supported by the compiler.
warnings
This will display all of the options controlling warning messages produced by the compiler.
target
This will display target-specific options. Unlike the --target-help option however, target-specific options of the linker and assembler will not be displayed. This is because those tools do not currently support the extended --help= syntax.
params
This will display the values recognized by the --param option.
language
This will display the options supported for language, where language is the name of one of the languages supported in this version of GCC .
common
This will display the options that are common to all languages.
These are the supported qualifiers:
undocumented
Display only those options which are undocumented.
joined
Display options which take an argument that appears after an equal sign in the same continuous piece of text, such as: --help=target.
separate
Display options which take an argument that appears as a separate word following the original option, such as: -o output-file.
Thus for example to display all the undocumented target-specific switches supported by the compiler the following can be used:
--help=target,undocumented
The sense of a qualifier can be inverted by prefixing it with the ^ character, so for example to display all binary warning options (i.e., ones that are either on or off and that do not take an argument), which have a description the following can be used:
--help=warnings,^joined,^undocumented
The argument to --help= should not consist solely of inverted qualifiers.
Combining several classes is possible, although this usually restricts the output by so much that there is nothing to display. One case where it does work however is when one of the classes is target. So for example to display all the target-specific optimization options the following can be used:

--help=target,optimizers
The --help= option can be repeated on the command line. Each successive use will display its requested class of options, skipping those that have already been displayed.
If the -Q option appears on the command line before the --help= option, then the descriptive text displayed by --help= is changed. Instead of describing the displayed options, an indication is given as to whether the option is enabled, disabled or set to a specific value (assuming that the compiler knows this at the point where the --help= option is used).

Here is a truncated example from the ARM port of gcc:

% gcc -Q -mabi=2 --help=target -c
The following options are target specific:
-mabi=                                2
-mabort-on-noreturn                   [disabled]
-mapcs                                [disabled]
The output is sensitive to the effects of previous command line options, so for example it is possible to find out which optimizations are enabled at -O2 by using:
-Q -O2 --help=optimizers
Alternatively you can discover which binary optimizations are enabled by -O3 by using:
gcc -c -Q -O3 --help=optimizers > /tmp/O3-opts
gcc -c -Q -O2 --help=optimizers > /tmp/O2-opts
diff /tmp/O2-opts /tmp/O3-opts | grep enabled
--version
Display the version number and copyrights of the invoked GCC .
-wrapper
Invoke all subcommands under a wrapper program. It takes a single comma separated list as an argument, which will be used to invoke the wrapper:
gcc -c t.c -wrapper gdb,--args
This will invoke all subprograms of gcc under "gdb --args", thus cc1 invocation will be "gdb --args cc1 ...".
@file
Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed.
Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively.

Compiling C ++ Programs

C ++ source files conventionally use one of the suffixes .C, .cc, .cpp, .CPP, .c++, .cp, or .cxx; C ++ header files often use .hh, .hpp, .H, or (for shared template code) .tcc; and preprocessed C ++ files use the suffix .ii. GCC recognizes files with these names and compiles them as C ++ programs even if you call the compiler the same way as for compiling C programs (usually with the name gcc).
However, the use of gcc does not add the C ++ library. g++ is a program that calls GCC and treats .c, .h and .i files as C ++ source files instead of C source files unless -x is used, and automatically specifies linking against the C ++ library. This program is also useful when precompiling a C header file with a .h extension for use in C ++ compilations. On many systems, g++ is also installed with the name c++.

When you compile C ++ programs, you may specify many of the same command-line options that you use for compiling programs in any language; or command-line options meaningful for C and related languages; or options that are meaningful only for C ++ programs.

Options Controlling C Dialect

The following options control the dialect of C (or languages derived from C, such as C ++ , Objective-C and Objective-C ++ ) that the compiler accepts:
-ansi
In C mode, this is equivalent to -std=c89. In C ++ mode, it is equivalent to -std=c++98.
This turns off certain features of GCC that are incompatible with ISO C90 (when compiling C code), or of standard C ++ (when compiling C ++ code), such as the "asm" and "typeof" keywords, and predefined macros such as "unix" and "vax" that identify the type of system you are using. It also enables the undesirable and rarely used ISO trigraph feature. For the C compiler, it disables recognition of C ++ style // comments as well as the "inline" keyword.

The alternate keywords "__asm__", "__extension__", "__inline__" and "__typeof__" continue to work despite -ansi. You would not want to use them in an ISO C program, of course, but it is useful to put them in header files that might be included in compilations done with -ansi. Alternate predefined macros such as "__unix__" and "__vax__" are also available, with or without -ansi.

The -ansi option does not cause non-ISO programs to be rejected gratuitously. For that, -pedantic is required in addition to -ansi.

The macro "__STRICT_ANSI__" is predefined when the -ansi option is used. Some header files may notice this macro and refrain from declaring certain functions or defining certain macros that the ISO standard doesn't call for; this is to avoid interfering with any programs that might use these names for other things.

Functions that would normally be built in but do not have semantics defined by ISO C (such as "alloca" and "ffs") are not built-in functions when -ansi is used.

-std=
Determine the language standard. This option is currently only supported when compiling C or C ++ .
The compiler can accept several base standards, such as c89 or c++98, and GNU dialects of those standards, such as gnu89 or gnu++98. By specifying a base standard, the compiler will accept all programs following that standard and those using GNU extensions that do not contradict it. For example, -std=c89 turns off certain features of GCC that are incompatible with ISO C90, such as the "asm" and "typeof" keywords, but not other GNU extensions that do not have a meaning in ISO C90, such as omitting the middle term of a "?:" expression. On the other hand, by specifying a GNU dialect of a standard, all features the compiler support are enabled, even when those features change the meaning of the base standard and some strict-conforming programs may be rejected. The particular standard is used by -pedantic to identify which features are GNU extensions given that version of the standard. For example -std=gnu89 -pedantic would warn about C ++ style // comments, while -std=gnu99 -pedantic would not.

A value for this option must be provided; possible values are

c89
iso9899:1990
Support all ISO C90 programs (certain GNU extensions that conflict with ISO C90 are disabled). Same as -ansi for C code.
iso9899:199409
ISO C90 as modified in amendment 1.
c99
c9x

iso9899:1999
iso9899:199x
ISO C99. Note that this standard is not yet fully supported; see <http://gcc.gnu.org/gcc-4.4/c99status.html> for more information. The names c9x and iso9899:199x are deprecated.
gnu89
GNU dialect of ISO C90 (including some C99 features). This is the default for C code.
gnu99
gnu9x
GNU dialect of ISO C99. When ISO C99 is fully implemented in GCC , this will become the default. The name gnu9x is deprecated.
c++98
The 1998 ISO C ++ standard plus amendments. Same as -ansi for C ++ code.
gnu++98
GNU dialect of -std=c++98. This is the default for C ++ code.
c++0x
The working draft of the upcoming ISO C ++ 0x standard. This option enables experimental features that are likely to be included in C ++ 0x. The working draft is constantly changing, and any feature that is enabled by this flag may be removed from future versions of GCC if it is not part of the C ++ 0x standard.
gnu++0x
GNU dialect of -std=c++0x. This option enables experimental features that may be removed in future versions of GCC .
-fgnu89-inline
The option -fgnu89-inline tells GCC to use the traditional GNU semantics for "inline" functions when in C99 mode. This option is accepted and ignored by GCC versions 4.1.3 up to but not including 4.3. In GCC versions 4.3 and later it changes the behavior of GCC in C99 mode. Using this option is roughly equivalent to adding the "gnu_inline" function attribute to all inline functions.
The option -fno-gnu89-inline explicitly tells GCC to use the C99 semantics for "inline" when in C99 or gnu99 mode (i.e., it specifies the default behavior). This option was first supported in GCC 4.3. This option is not supported in C89 or gnu89 mode.

The preprocessor macros "__GNUC_GNU_INLINE__" and "__GNUC_STDC_INLINE__" may be used to check which semantics are in effect for "inline" functions.

-aux-info filename
Output to the given filename prototyped declarations for all functions declared and/or defined in a translation unit, including those in header files. This option is silently ignored in any language other than C.
Besides declarations, the file indicates, in comments, the origin of each declaration (source file and line), whether the declaration was implicit, prototyped or unprototyped (I, N for new or O for old, respectively, in the first character after the line number and the colon), and whether it came from a declaration or a definition (C or F, respectively, in the following character). In the case of function definitions, a K&R-style list of arguments followed by their declarations is also provided, inside comments, after the declaration.

-fno-asm
Do not recognize "asm", "inline" or "typeof" as a keyword, so that code can use these words as identifiers. You can use the keywords "__asm__", "__inline__" and "__typeof__" instead. -ansi implies -fno-asm.
In C ++ , this switch only affects the "typeof" keyword, since "asm" and "inline" are standard keywords. You may want to use the -fno-gnu-keywords flag instead, which has the same effect. In C99 mode (-std=c99 or -std=gnu99), this switch only affects the "asm" and "typeof" keywords, since "inline" is a standard keyword in ISO C99.

-fno-builtin
-fno-builtin-function
Don't recognize built-in functions that do not begin with __builtin_ as prefix.
GCC normally generates special code to handle certain built-in functions more efficiently; for instance, calls to "alloca" may become single instructions that adjust the stack directly, and calls to "memcpy" may become inline copy loops. The resulting code is often both smaller and faster, but since the function calls no longer appear as such, you cannot set a breakpoint on those calls, nor can you change the behavior of the functions by linking with a different library. In addition, when a function is recognized as a built-in function, GCC may use information about that function to warn about problems with calls to that function, or to generate more efficient code, even if the resulting code still contains calls to that function. For example, warnings are given with -Wformat for bad calls to "printf", when "printf" is built in, and "strlen" is known not to modify global memory.

With the -fno-builtin-function option only the built-in function function is disabled. function must not begin with __builtin_. If a function is named that is not built-in in this version of GCC , this option is ignored. There is no corresponding -fbuiltin-function option; if you wish to enable built-in functions selectively when using -fno-builtin or -ffreestanding, you may define macros such as:

#define abs(n)          __builtin_abs ((n))
#define strcpy(d, s)    __builtin_strcpy ((d), (s))
-fhosted
Assert that compilation takes place in a hosted environment. This implies -fbuiltin. A hosted environment is one in which the entire standard library is available, and in which "main" has a return type of "int". Examples are nearly everything except a kernel. This is equivalent to -fno-freestanding.
-ffreestanding
Assert that compilation takes place in a freestanding environment. This implies -fno-builtin. A freestanding environment is one in which the standard library may not exist, and program startup may not necessarily be at "main". The most obvious example is an OS kernel. This is equivalent to -fno-hosted.
-fopenmp
Enable handling of OpenMP directives "#pragma omp" in C/C ++ and "!$omp" in Fortran. When -fopenmp is specified, the compiler generates parallel code according to the OpenMP Application Program Interface v2.5 <http://www.openmp.org/>. This option implies -pthread, and thus is only supported on targets that have support for -pthread.
-fms-extensions
Accept some non-standard constructs used in Microsoft header files.
Some cases of unnamed fields in structures and unions are only accepted with this option.

-trigraphs
Support ISO C trigraphs. The -ansi option (and -std options for strict ISO C conformance) implies -trigraphs.
-no-integrated-cpp
Performs a compilation in two passes: preprocessing and compiling. This option allows a user supplied "cc1", "cc1plus", or "cc1obj" via the -B option. The user supplied compilation step can then add in an additional preprocessing step after normal preprocessing but before compiling. The default is to use the integrated cpp (internal cpp)
The semantics of this option will change if "cc1", "cc1plus", and "cc1obj" are merged.

-traditional
-traditional-cpp
Formerly, these options caused GCC to attempt to emulate a pre-standard C compiler. They are now only supported with the -E switch. The preprocessor continues to support a pre-standard mode. See the GNU CPP manual for details.
-fcond-mismatch
Allow conditional expressions with mismatched types in the second and third arguments. The value of such an expression is void. This option is not supported for C ++ .
-flax-vector-conversions
Allow implicit conversions between vectors with differing numbers of elements and/or incompatible element types. This option should not be used for new code.
-funsigned-char
Let the type "char" be unsigned, like "unsigned char".
Each kind of machine has a default for what "char" should be. It is either like "unsigned char" by default or like "signed char" by default.

Ideally, a portable program should always use "signed char" or "unsigned char" when it depends on the signedness of an object. But many programs have been written to use plain "char" and expect it to be signed, or expect it to be unsigned, depending on the machines they were written for. This option, and its inverse, let you make such a program work with the opposite default.

The type "char" is always a distinct type from each of "signed char" or "unsigned char", even though its behavior is always just like one of those two.

-fsigned-char
Let the type "char" be signed, like "signed char".
Note that this is equivalent to -fno-unsigned-char, which is the negative form of -funsigned-char. Likewise, the option -fno-signed-char is equivalent to -funsigned-char.

-fsigned-bitfields
-funsigned-bitfields
-fno-signed-bitfields
-fno-unsigned-bitfields
These options control whether a bit-field is signed or unsigned, when the declaration does not use either "signed" or "unsigned". By default, such a bit-field is signed, because this is consistent: the basic integer types such as "int" are signed types.
Options Controlling C ++ Dialect

This section describes the command-line options that are only meaningful for C ++ programs; but you can also use most of the GNU compiler options regardless of what language your program is in. For example, you might compile a file "firstClass.C" like this:
g++ -g -frepo -O -c firstClass.C
In this example, only -frepo is an option meant only for C ++ programs; you can use the other options with any language supported by GCC .
Here is a list of options that are only for compiling C ++ programs:

-fabi-version=n
Use version n of the C ++ ABI . Version 2 is the version of the C ++ ABI that first appeared in G++ 3.4. Version 1 is the version of the C ++ ABI that first appeared in G++ 3.2. Version 0 will always be the version that conforms most closely to the C ++ ABI specification. Therefore, the ABI obtained using version 0 will change as ABI bugs are fixed.
The default is version 2.

-fno-access-control
Turn off all access checking. This switch is mainly useful for working around bugs in the access control code.
-fcheck-new
Check that the pointer returned by "operator new" is non-null before attempting to modify the storage allocated. This check is normally unnecessary because the C ++ standard specifies that "operator new" will only return 0 if it is declared throw(), in which case the compiler will always check the return value even without this option. In all other cases, when "operator new" has a non-empty exception specification, memory exhaustion is signalled by throwing "std::bad_alloc". See also new (nothrow).
-fconserve-space
Put uninitialized or runtime-initialized global variables into the common segment, as C does. This saves space in the executable at the cost of not diagnosing duplicate definitions. If you compile with this flag and your program mysteriously crashes after "main()" has completed, you may have an object that is being destroyed twice because two definitions were merged.
This option is no longer useful on most targets, now that support has been added for putting variables into BSS without making them common.

-fno-deduce-init-list
Disable deduction of a template type parameter as std::initializer_list from a brace-enclosed initializer list, i.e.
template <class T> auto forward(T t) -> decltype (realfn (t))
{
  return realfn (t);
}

void f()
{
  forward({1,2}); // call forward<std::initializer_list<int>>
}
This option is present because this deduction is an extension to the current specification in the C ++ 0x working draft, and there was some concern about potential overload resolution problems.
-ffriend-injection
Inject friend functions into the enclosing namespace, so that they are visible outside the scope of the class in which they are declared. Friend functions were documented to work this way in the old Annotated C ++ Reference Manual, and versions of G++ before 4.1 always worked that way. However, in ISO C ++ a friend function which is not declared in an enclosing scope can only be found using argument dependent lookup. This option causes friends to be injected as they were in earlier releases.
This option is for compatibility, and may be removed in a future release of G++.

-fno-elide-constructors
The C ++ standard allows an implementation to omit creating a temporary which is only used to initialize another object of the same type. Specifying this option disables that optimization, and forces G++ to call the copy constructor in all cases.
-fno-enforce-eh-specs
Don't generate code to check for violation of exception specifications at runtime. This option violates the C ++ standard, but may be useful for reducing code size in production builds, much like defining NDEBUG . This does not give user code permission to throw exceptions in violation of the exception specifications; the compiler will still optimize based on the specifications, so throwing an unexpected exception will result in undefined behavior.
-ffor-scope
-fno-for-scope
If -ffor-scope is specified, the scope of variables declared in a for-init-statement is limited to the for loop itself, as specified by the C ++ standard. If -fno-for-scope is specified, the scope of variables declared in a for-init-statement extends to the end of the enclosing scope, as was the case in old versions of G++, and other (traditional) implementations of C ++ .
The default if neither flag is given to follow the standard, but to allow and give a warning for old-style code that would otherwise be invalid, or have different behavior.

-fno-gnu-keywords
Do not recognize "typeof" as a keyword, so that code can use this word as an identifier. You can use the keyword "__typeof__" instead. -ansi implies -fno-gnu-keywords.
-fno-implicit-templates
Never emit code for non-inline templates which are instantiated implicitly (i.e. by use); only emit code for explicit instantiations.
-fno-implicit-inline-templates
Don't emit code for implicit instantiations of inline templates, either. The default is to handle inlines differently so that compiles with and without optimization will need the same set of explicit instantiations.
-fno-implement-inlines
To save space, do not emit out-of-line copies of inline functions controlled by #pragma implementation. This will cause linker errors if these functions are not inlined everywhere they are called.
-fms-extensions
Disable pedantic warnings about constructs used in MFC , such as implicit int and getting a pointer to member function via non-standard syntax.
-fno-nonansi-builtins
Disable built-in declarations of functions that are not mandated by ANSI/ISO C. These include "ffs", "alloca", "_exit", "index", "bzero", "conjf", and other related functions.
-fno-operator-names
Do not treat the operator name keywords "and", "bitand", "bitor", "compl", "not", "or" and "xor" as synonyms as keywords.
-fno-optional-diags
Disable diagnostics that the standard says a compiler does not need to issue. Currently, the only such diagnostic issued by G++ is the one for a name having multiple meanings within a class.
-fpermissive
Downgrade some diagnostics about nonconformant code from errors to warnings. Thus, using -fpermissive will allow some nonconforming code to compile.
-frepo
Enable automatic template instantiation at link time. This option also implies -fno-implicit-templates.
-fno-rtti
Disable generation of information about every class with virtual functions for use by the C ++ runtime type identification features (dynamic_cast and typeid). If you don't use those parts of the language, you can save some space by using this flag. Note that exception handling uses the same information, but it will generate it as needed. The dynamic_cast operator can still be used for casts that do not require runtime type information, i.e. casts to "void *" or to unambiguous base classes.
-fstats
Emit statistics about front-end processing at the end of the compilation. This information is generally only useful to the G++ development team.
-fstrict-enums
Allow the compiler to optimize using the assumption that a value of enumeration type can only be one of the values of the enumeration (as defined in the C ++ standard; basically, a value which can be represented in the minimum number of bits needed to represent all the enumerators). This assumption may not be valid if the program uses a cast to convert an arbitrary integer value to the enumeration type.
-ftemplate-depth-n
Set the maximum instantiation depth for template classes to n. A limit on the template instantiation depth is needed to detect endless recursions during template class instantiation. ANSI/ISO C ++ conforming programs must not rely on a maximum depth greater than 17.
-fno-threadsafe-statics
Do not emit the extra code to use the routines specified in the C ++ ABI for thread-safe initialization of local statics. You can use this option to reduce code size slightly in code that doesn't need to be thread-safe.
-fuse-cxa-atexit
Register destructors for objects with static storage duration with the "__cxa_atexit" function rather than the "atexit" function. This option is required for fully standards-compliant handling of static destructors, but will only work if your C library supports "__cxa_atexit".
-fno-use-cxa-get-exception-ptr
Don't use the "__cxa_get_exception_ptr" runtime routine. This will cause "std::uncaught_exception" to be incorrect, but is necessary if the runtime routine is not available.
-fvisibility-inlines-hidden
This switch declares that the user does not attempt to compare pointers to inline methods where the addresses of the two functions were taken in different shared objects.
The effect of this is that GCC may, effectively, mark inline methods with "__attribute__ ((visibility ("hidden")))" so that they do not appear in the export table of a DSO and do not require a PLT indirection when used within the DSO . Enabling this option can have a dramatic effect on load and link times of a DSO as it massively reduces the size of the dynamic export table when the library makes heavy use of templates.

The behavior of this switch is not quite the same as marking the methods as hidden directly, because it does not affect static variables local to the function or cause the compiler to deduce that the function is defined in only one shared object.

You may mark a method as having a visibility explicitly to negate the effect of the switch for that method. For example, if you do want to compare pointers to a particular inline method, you might mark it as having default visibility. Marking the enclosing class with explicit visibility will have no effect.

Explicitly instantiated inline methods are unaffected by this option as their linkage might otherwise cross a shared library boundary.

-fvisibility-ms-compat
This flag attempts to use visibility settings to make GCC 's C ++ linkage model compatible with that of Microsoft Visual Studio.
The flag makes these changes to GCC 's linkage model:

1.
It sets the default visibility to "hidden", like -fvisibility=hidden.

2.

Types, but not their members, are not hidden by default.

3.

The One Definition Rule is relaxed for types without explicit visibility specifications which are defined in more than one different shared object: those declarations are permitted if they would have been permitted when this option was not used.

In new code it is better to use -fvisibility=hidden and export those classes which are intended to be externally visible. Unfortunately it is possible for code to rely, perhaps accidentally, on the Visual Studio behavior.
Among the consequences of these changes are that static data members of the same type with the same name but defined in different shared objects will be different, so changing one will not change the other; and that pointers to function members defined in different shared objects may not compare equal. When this flag is given, it is a violation of the ODR to define types with the same name differently.

-fno-weak
Do not use weak symbol support, even if it is provided by the linker. By default, G++ will use weak symbols if they are available. This option exists only for testing, and should not be used by end-users; it will result in inferior code and has no benefits. This option may be removed in a future release of G++.
-nostdinc++
Do not search for header files in the standard directories specific to C ++ , but do still search the other standard directories. (This option is used when building the C ++ library.)
In addition, these optimization, warning, and code generation options have meanings only for C ++ programs:
-fno-default-inline
Do not assume inline for functions defined inside a class scope. Note that these functions will have linkage like inline functions; they just won't be inlined by default.
-Wabi (C, Objective-C, C ++ and Objective-C ++ only)
Warn when G++ generates code that is probably not compatible with the vendor-neutral C ++ ABI . Although an effort has been made to warn about all such cases, there are probably some cases that are not warned about, even though G++ is generating incompatible code. There may also be cases where warnings are emitted even though the code that is generated will be compatible.
You should rewrite your code to avoid these warnings if you are concerned about the fact that code generated by G++ may not be binary compatible with code generated by other compilers.

The known incompatibilities at this point include:

• Incorrect handling of tail-padding for bit-fields. G++ may attempt to pack data into the same byte as a base class. For example:
struct A { virtual void f(); int f1 : 1; };
struct B : public A { int f2 : 1; };
In this case, G++ will place "B::f2" into the same byte as"A::f1"; other compilers will not. You can avoid this problem by explicitly padding "A" so that its size is a multiple of the byte size on your platform; that will cause G++ and other compilers to layout "B" identically.
• Incorrect handling of tail-padding for virtual bases. G++ does not use tail padding when laying out virtual bases. For example:
struct A { virtual void f(); char c1; };
struct B { B(); char c2; };
struct C : public A, public virtual B {};
In this case, G++ will not place "B" into the tail-padding for "A"; other compilers will. You can avoid this problem by explicitly padding "A" so that its size is a multiple of its alignment (ignoring virtual base classes); that will cause G++ and other compilers to layout "C" identically.
• Incorrect handling of bit-fields with declared widths greater than that of their underlying types, when the bit-fields appear in a union. For example:
union U { int i : 4096; };
Assuming that an "int" does not have 4096 bits, G++ will make the union too small by the number of bits in an "int".
• Empty classes can be placed at incorrect offsets. For example:
struct A {};

struct B {
  A a;
  virtual void f ();
};

struct C : public B, public A {};
G++ will place the "A" base class of "C" at a nonzero offset; it should be placed at offset zero. G++ mistakenly believes that the "A" data member of "B" is already at offset zero.
• Names of template functions whose types involve "typename" or template template parameters can be mangled incorrectly.
template <typename Q>
void f(typename Q::X) {}

template <template <typename> class Q>
void f(typename Q<int>::X) {}
Instantiations of these templates may be mangled incorrectly.
It also warns psABI related changes. The known psABI changes at this point include:
• For SYSV/x86-64, when passing union with long double, it is changed to pass in memory as specified in psABI. For example:
union U {
  long double ld;
  int i;
};
"union U" will always be passed in memory.
-Wctor-dtor-privacy (C ++ and Objective-C ++ only)
Warn when a class seems unusable because all the constructors or destructors in that class are private, and it has neither friends nor public static member functions.
-Wnon-virtual-dtor (C ++ and Objective-C ++ only)
Warn when a class has virtual functions and accessible non-virtual destructor, in which case it would be possible but unsafe to delete an instance of a derived class through a pointer to the base class. This warning is also enabled if -Weffc++ is specified.
-Wreorder (C ++ and Objective-C ++ only)
Warn when the order of member initializers given in the code does not match the order in which they must be executed. For instance:
struct A {
  int i;
  int j;
  A(): j (0), i (1) { }
};
The compiler will rearrange the member initializers for i and j to match the declaration order of the members, emitting a warning to that effect. This warning is enabled by -Wall.
The following -W... options are not affected by -Wall.
-Weffc++ (C ++ and Objective-C ++ only)
Warn about violations of the following style guidelines from Scott Meyers' Effective C ++ book:
• Item 11: Define a copy constructor and an assignment operator for classes with dynamically allocated memory.
• Item 12: Prefer initialization to assignment in constructors.

• Item 14: Make destructors virtual in base classes.

• Item 15: Have "operator=" return a reference to *this.

• Item 23: Don't try to return a reference when you must return an object.

Also warn about violations of the following style guidelines from Scott Meyers' More Effective C ++ book:
• Item 6: Distinguish between prefix and postfix forms of increment and decrement operators.
• Item 7: Never overload "&&", "||", or ",".

When selecting this option, be aware that the standard library headers do not obey all of these guidelines; use grep -v to filter out those warnings.
-Wstrict-null-sentinel (C ++ and Objective-C ++ only)
Warn also about the use of an uncasted "NULL" as sentinel. When compiling only with GCC this is a valid sentinel, as "NULL" is defined to "__null". Although it is a null pointer constant not a null pointer, it is guaranteed to be of the same size as a pointer. But this use is not portable across different compilers.
-Wno-non-template-friend (C ++ and Objective-C ++ only)
Disable warnings when non-templatized friend functions are declared within a template. Since the advent of explicit template specification support in G++, if the name of the friend is an unqualified-id (i.e., friend foo(int)), the C ++ language specification demands that the friend declare or define an ordinary, nontemplate function. (Section 14.5.3). Before G++ implemented explicit specification, unqualified-ids could be interpreted as a particular specialization of a templatized function. Because this non-conforming behavior is no longer the default behavior for G++, -Wnon-template-friend allows the compiler to check existing code for potential trouble spots and is on by default. This new compiler behavior can be turned off with -Wno-non-template-friend which keeps the conformant compiler code but disables the helpful warning.
-Wold-style-cast (C ++ and Objective-C ++ only)
Warn if an old-style (C-style) cast to a non-void type is used within a C ++ program. The new-style casts (dynamic_cast, static_cast, reinterpret_cast, and const_cast) are less vulnerable to unintended effects and much easier to search for.
-Woverloaded-virtual (C ++ and Objective-C ++ only)
Warn when a function declaration hides virtual functions from a base class. For example, in:
struct A {
  virtual void f();
};

struct B: public A {
  void f(int);
};
the "A" class version of "f" is hidden in "B", and code like:
B* b;
b->f();
will fail to compile.
-Wno-pmf-conversions (C ++ and Objective-C ++ only)
Disable the diagnostic for converting a bound pointer to member function to a plain pointer.
-Wsign-promo (C ++ and Objective-C ++ only)
Warn when overload resolution chooses a promotion from unsigned or enumerated type to a signed type, over a conversion to an unsigned type of the same size. Previous versions of G++ would try to preserve unsignedness, but the standard mandates the current behavior.
struct A {
  operator int ();
  A& operator = (int);
};

main ()
{
  A a,b;
  a = b;
}
In this example, G++ will synthesize a default A& operator = (const A&);, while cfront will use the user-defined operator =.
Options Controlling Objective-C and Objective-C ++ Dialects

( NOTE: This manual does not describe the Objective-C and Objective-C ++ languages themselves. See
This section describes the command-line options that are only meaningful for Objective-C and Objective-C ++ programs, but you can also use most of the language-independent GNU compiler options. For example, you might compile a file "some_class.m" like this:

gcc -g -fgnu-runtime -O -c some_class.m
In this example, -fgnu-runtime is an option meant only for Objective-C and Objective-C ++ programs; you can use the other options with any language supported by GCC .
Note that since Objective-C is an extension of the C language, Objective-C compilations may also use options specific to the C front-end (e.g., -Wtraditional). Similarly, Objective-C ++ compilations may use C ++ -specific options (e.g., -Wabi).

Here is a list of options that are only for compiling Objective-C and Objective-C ++ programs:

-fconstant-string-class=class-name
Use class-name as the name of the class to instantiate for each literal string specified with the syntax "@"..."". The default class name is "NXConstantString" if the GNU runtime is being used, and "NSConstantString" if the NeXT runtime is being used (see below). The -fconstant-cfstrings option, if also present, will override the -fconstant-string-class setting and cause "@"..."" literals to be laid out as constant CoreFoundation strings.
-fgnu-runtime
Generate object code compatible with the standard GNU Objective-C runtime. This is the default for most types of systems.
-fnext-runtime
Generate output compatible with the NeXT runtime. This is the default for NeXT-based systems, including Darwin and Mac OS X. The macro "__NEXT_RUNTIME__" is predefined if (and only if) this option is used.
-fno-nil-receivers
Assume that all Objective-C message dispatches (e.g., "[receiver message:arg]") in this translation unit ensure that the receiver is not "nil". This allows for more efficient entry points in the runtime to be used. Currently, this option is only available in conjunction with the NeXT runtime on Mac OS X 10.3 and later.
-fobjc-call-cxx-cdtors
For each Objective-C class, check if any of its instance variables is a C ++ object with a non-trivial default constructor. If so, synthesize a special "- (id) .cxx_construct" instance method that will run non-trivial default constructors on any such instance variables, in order, and then return "self". Similarly, check if any instance variable is a C ++ object with a non-trivial destructor, and if so, synthesize a special "- (void) .cxx_destruct" method that will run all such default destructors, in reverse order.
The "- (id) .cxx_construct" and/or "- (void) .cxx_destruct" methods thusly generated will only operate on instance variables declared in the current Objective-C class, and not those inherited from superclasses. It is the responsibility of the Objective-C runtime to invoke all such methods in an object's inheritance hierarchy. The "- (id) .cxx_construct" methods will be invoked by the runtime immediately after a new object instance is allocated; the "- (void) .cxx_destruct" methods will be invoked immediately before the runtime deallocates an object instance.

As of this writing, only the NeXT runtime on Mac OS X 10.4 and later has support for invoking the "- (id) .cxx_construct" and "- (void) .cxx_destruct" methods.

-fobjc-direct-dispatch
Allow fast jumps to the message dispatcher. On Darwin this is accomplished via the comm page.
-fobjc-exceptions
Enable syntactic support for structured exception handling in Objective-C, similar to what is offered by C ++ and Java. This option is unavailable in conjunction with the NeXT runtime on Mac OS X 10.2 and earlier.
@try {
  ...
     @throw expr;
  ...
}
@catch (AnObjCClass *exc) {
  ...
    @throw expr;
  ...
    @throw;
  ...
}
@catch (AnotherClass *exc) {
  ...
}
@catch (id allOthers) {
  ...
}
@finally {
  ...
    @throw expr;
  ...
}
The @throw statement may appear anywhere in an Objective-C or Objective-C ++ program; when used inside of a @catch block, the @throw may appear without an argument (as shown above), in which case the object caught by the @catch will be rethrown.
Note that only (pointers to) Objective-C objects may be thrown and caught using this scheme. When an object is thrown, it will be caught by the nearest @catch clause capable of handling objects of that type, analogously to how "catch" blocks work in C ++ and Java. A "@catch(id ...)" clause (as shown above) may also be provided to catch any and all Objective-C exceptions not caught by previous @catch clauses (if any).

The @finally clause, if present, will be executed upon exit from the immediately preceding "@try ... @catch" section. This will happen regardless of whether any exceptions are thrown, caught or rethrown inside the "@try ... @catch" section, analogously to the behavior of the "finally" clause in Java.

There are several caveats to using the new exception mechanism:

• Although currently designed to be binary compatible with "NS_HANDLER"-style idioms provided by the "NSException" class, the new exceptions can only be used on Mac OS X 10.3 (Panther) and later systems, due to additional functionality needed in the (NeXT) Objective-C runtime.
• As mentioned above, the new exceptions do not support handling types other than Objective-C objects. Furthermore, when used from Objective-C ++ , the Objective-C exception model does not interoperate with C ++ exceptions at this time. This means you cannot @throw an exception from Objective-C and "catch" it in C ++ , or vice versa (i.e., "throw ... @catch").

The -fobjc-exceptions switch also enables the use of synchronization blocks for thread-safe execution:
@synchronized (ObjCClass *guard) {
  ...
}
Upon entering the @synchronized block, a thread of execution shall first check whether a lock has been placed on the corresponding "guard" object by another thread. If it has, the current thread shall wait until the other thread relinquishes its lock. Once "guard" becomes available, the current thread will place its own lock on it, execute the code contained in the @synchronized block, and finally relinquish the lock (thereby making "guard" available to other threads).
Unlike Java, Objective-C does not allow for entire methods to be marked @synchronized. Note that throwing exceptions out of @synchronized blocks is allowed, and will cause the guarding object to be unlocked properly.

-fobjc-gc
Enable garbage collection ( GC ) in Objective-C and Objective-C ++ programs.
-freplace-objc-classes
Emit a special marker instructing ld(1) not to statically link in the resulting object file, and allow dyld(1) to load it in at run time instead. This is used in conjunction with the Fix-and-Continue debugging mode, where the object file in question may be recompiled and dynamically reloaded in the course of program execution, without the need to restart the program itself. Currently, Fix-and-Continue functionality is only available in conjunction with the NeXT runtime on Mac OS X 10.3 and later.
-fzero-link
When compiling for the NeXT runtime, the compiler ordinarily replaces calls to "objc_getClass("...")" (when the name of the class is known at compile time) with static class references that get initialized at load time, which improves run-time performance. Specifying the -fzero-link flag suppresses this behavior and causes calls to "objc_getClass("...")" to be retained. This is useful in Zero-Link debugging mode, since it allows for individual class implementations to be modified during program execution.
-gen-decls
Dump interface declarations for all classes seen in the source file to a file named sourcename.decl.
-Wassign-intercept (Objective-C and Objective-C ++ only)
Warn whenever an Objective-C assignment is being intercepted by the garbage collector.
-Wno-protocol (Objective-C and Objective-C ++ only)
If a class is declared to implement a protocol, a warning is issued for every method in the protocol that is not implemented by the class. The default behavior is to issue a warning for every method not explicitly implemented in the class, even if a method implementation is inherited from the superclass. If you use the -Wno-protocol option, then methods inherited from the superclass are considered to be implemented, and no warning is issued for them.
-Wselector (Objective-C and Objective-C ++ only)
Warn if multiple methods of different types for the same selector are found during compilation. The check is performed on the list of methods in the final stage of compilation. Additionally, a check is performed for each selector appearing in a "@selector(...)" expression, and a corresponding method for that selector has been found during compilation. Because these checks scan the method table only at the end of compilation, these warnings are not produced if the final stage of compilation is not reached, for example because an error is found during compilation, or because the -fsyntax-only option is being used.
-Wstrict-selector-match (Objective-C and Objective-C ++ only)
Warn if multiple methods with differing argument and/or return types are found for a given selector when attempting to send a message using this selector to a receiver of type "id" or "Class". When this flag is off (which is the default behavior), the compiler will omit such warnings if any differences found are confined to types which share the same size and alignment.
-Wundeclared-selector (Objective-C and Objective-C ++ only)
Warn if a "@selector(...)" expression referring to an undeclared selector is found. A selector is considered undeclared if no method with that name has been declared before the "@selector(...)" expression, either explicitly in an @interface or @protocol declaration, or implicitly in an @implementation section. This option always performs its checks as soon as a "@selector(...)" expression is found, while -Wselector only performs its checks in the final stage of compilation. This also enforces the coding style convention that methods and selectors must be declared before being used.
-print-objc-runtime-info
Generate C header describing the largest structure that is passed by value, if any.
Options to Control Diagnostic Messages Formatting

Traditionally, diagnostic messages have been formatted irrespective of the output device's aspect (e.g. its width, ...). The options described below can be used to control the diagnostic messages formatting algorithm, e.g. how many characters per line, how often source location information should be reported. Right now, only the C ++ front end can honor these options. However it is expected, in the near future, that the remaining front ends would be able to digest them correctly.
-fmessage-length=n
Try to format error messages so that they fit on lines of about n characters. The default is 72 characters for g++ and 0 for the rest of the front ends supported by GCC . If n is zero, then no line-wrapping will be done; each error message will appear on a single line.
-fdiagnostics-show-location=once
Only meaningful in line-wrapping mode. Instructs the diagnostic messages reporter to emit once source location information; that is, in case the message is too long to fit on a single physical line and has to be wrapped, the source location won't be emitted (as prefix) again, over and over, in subsequent continuation lines. This is the default behavior.
-fdiagnostics-show-location=every-line
Only meaningful in line-wrapping mode. Instructs the diagnostic messages reporter to emit the same source location information (as prefix) for physical lines that result from the process of breaking a message which is too long to fit on a single line.
-fdiagnostics-show-option
This option instructs the diagnostic machinery to add text to each diagnostic emitted, which indicates which command line option directly controls that diagnostic, when such an option is known to the diagnostic machinery.
-Wcoverage-mismatch
Warn if feedback profiles do not match when using the -fprofile-use option. If a source file was changed between -fprofile-gen and -fprofile-use, the files with the profile feedback can fail to match the source file and GCC can not use the profile feedback information. By default, GCC emits an error message in this case. The option -Wcoverage-mismatch emits a warning instead of an error. GCC does not use appropriate feedback profiles, so using this option can result in poorly optimized code. This option is useful only in the case of very minor changes such as bug fixes to an existing code-base.
Options to Request or Suppress Warnings

Warnings are diagnostic messages that report constructions which are not inherently erroneous but which are risky or suggest there may have been an error.
The following language-independent options do not enable specific warnings but control the kinds of diagnostics produced by GCC .

-fsyntax-only
Check the code for syntax errors, but don't do anything beyond that.
-w
Inhibit all warning messages.

-Werror
Make all warnings into errors.
-Werror=
Make the specified warning into an error. The specifier for a warning is appended, for example -Werror=switch turns the warnings controlled by -Wswitch into errors. This switch takes a negative form, to be used to negate -Werror for specific warnings, for example -Wno-error=switch makes -Wswitch warnings not be errors, even when -Werror is in effect. You can use the -fdiagnostics-show-option option to have each controllable warning amended with the option which controls it, to determine what to use with this option.
Note that specifying -Werror=foo automatically implies -Wfoo. However, -Wno-error=foo does not imply anything.

-Wfatal-errors
This option causes the compiler to abort compilation on the first error occurred rather than trying to keep going and printing further error messages.
You can request many specific warnings with options beginning -W, for example -Wimplicit to request warnings on implicit declarations. Each of these specific warning options also has a negative form beginning -Wno- to turn off warnings; for example, -Wno-implicit. This manual lists only one of the two forms, whichever is not the default. For further, language-specific options also refer to C ++ Dialect Options and Objective-C and Objective-C ++ Dialect Options.
-pedantic
Issue all the warnings demanded by strict ISO C and ISO C ++ ; reject all programs that use forbidden extensions, and some other programs that do not follow ISO C and ISO C ++ . For ISO C, follows the version of the ISO C standard specified by any -std option used.
Valid ISO C and ISO C ++ programs should compile properly with or without this option (though a rare few will require -ansi or a -std option specifying the required version of ISO C). However, without this option, certain GNU extensions and traditional C and C ++ features are supported as well. With this option, they are rejected.

-pedantic does not cause warning messages for use of the alternate keywords whose names begin and end with __. Pedantic warnings are also disabled in the expression that follows "__extension__". However, only system header files should use these escape routes; application programs should avoid them.

Some users try to use -pedantic to check programs for strict ISO C conformance. They soon find that it does not do quite what they want: it finds some non-ISO practices, but not all---only those for which ISO C requires a diagnostic, and some others for which diagnostics have been added.

A feature to report any failure to conform to ISO C might be useful in some instances, but would require considerable additional work and would be quite different from -pedantic. We don't have plans to support such a feature in the near future.

Where the standard specified with -std represents a GNU extended dialect of C, such as gnu89 or gnu99, there is a corresponding base standard, the version of ISO C on which the GNU extended dialect is based. Warnings from -pedantic are given where they are required by the base standard. (It would not make sense for such warnings to be given only for features not in the specified GNU C dialect, since by definition the GNU dialects of C include all features the compiler supports with the given option, and there would be nothing to warn about.)

-pedantic-errors
Like -pedantic, except that errors are produced rather than warnings.
-Wall
This enables all the warnings about constructions that some users consider questionable, and that are easy to avoid (or modify to prevent the warning), even in conjunction with macros. This also enables some language-specific warnings described in C ++ Dialect Options and Objective-C and Objective-C ++ Dialect Options.
-Wall turns on the following warning flags:

-Waddress -Warray-bounds (only with -O2) -Wc++0x-compat -Wchar-subscripts -Wimplicit-int -Wimplicit-function-declaration -Wcomment -Wformat -Wmain (only for C/ObjC and unless -ffreestanding) -Wmissing-braces -Wnonnull -Wparentheses -Wpointer-sign -Wreorder -Wreturn-type -Wsequence-point -Wsign-compare (only in C ++ ) -Wstrict-aliasing -Wstrict-overflow=1 -Wswitch -Wtrigraphs -Wuninitialized -Wunknown-pragmas -Wunused-function -Wunused-label -Wunused-value -Wunused-variable -Wvolatile-register-var

Note that some warning flags are not implied by -Wall. Some of them warn about constructions that users generally do not consider questionable, but which occasionally you might wish to check for; others warn about constructions that are necessary or hard to avoid in some cases, and there is no simple way to modify the code to suppress the warning. Some of them are enabled by -Wextra but many of them must be enabled individually.

-Wextra
This enables some extra warning flags that are not enabled by -Wall. (This option used to be called -W. The older name is still supported, but the newer name is more descriptive.)
-Wclobbered -Wempty-body -Wignored-qualifiers -Wmissing-field-initializers -Wmissing-parameter-type (C only) -Wold-style-declaration (C only) -Woverride-init -Wsign-compare -Wtype-limits -Wuninitialized -Wunused-parameter (only with -Wunused or -Wall)

The option -Wextra also prints warning messages for the following cases:

• A pointer is compared against integer zero with <, <=, >, or >=.
• (C ++ only) An enumerator and a non-enumerator both appear in a conditional expression.

• (C ++ only) Ambiguous virtual bases.

• (C ++ only) Subscripting an array which has been declared register.

• (C ++ only) Taking the address of a variable which has been declared register.

• (C ++ only) A base class is not initialized in a derived class' copy constructor.

-Wchar-subscripts
Warn if an array subscript has type "char". This is a common cause of error, as programmers often forget that this type is signed on some machines. This warning is enabled by -Wall.
-Wcomment
Warn whenever a comment-start sequence /* appears in a /* comment, or whenever a Backslash-Newline appears in a // comment. This warning is enabled by -Wall.
-Wformat
Check calls to "printf" and "scanf", etc., to make sure that the arguments supplied have types appropriate to the format string specified, and that the conversions specified in the format string make sense. This includes standard functions, and others specified by format attributes, in the "printf", "scanf", "strftime" and "strfmon" (an X/Open extension, not in the C standard) families (or other target-specific families). Which functions are checked without format attributes having been specified depends on the standard version selected, and such checks of functions without the attribute specified are disabled by -ffreestanding or -fno-builtin.
The formats are checked against the format features supported by GNU libc version 2.2. These include all ISO C90 and C99 features, as well as features from the Single Unix Specification and some BSD and GNU extensions. Other library implementations may not support all these features; GCC does not support warning about features that go beyond a particular library's limitations. However, if -pedantic is used with -Wformat, warnings will be given about format features not in the selected standard version (but not for "strfmon" formats, since those are not in any version of the C standard).

Since -Wformat also checks for null format arguments for several functions, -Wformat also implies -Wnonnull.

-Wformat is included in -Wall. For more control over some aspects of format checking, the options -Wformat-y2k, -Wno-format-extra-args, -Wno-format-zero-length, -Wformat-nonliteral, -Wformat-security, and -Wformat=2 are available, but are not included in -Wall.

-Wformat-y2k
If -Wformat is specified, also warn about "strftime" formats which may yield only a two-digit year.
-Wno-format-contains-nul
If -Wformat is specified, do not warn about format strings that contain NUL bytes.
-Wno-format-extra-args
If -Wformat is specified, do not warn about excess arguments to a "printf" or "scanf" format function. The C standard specifies that such arguments are ignored.
Where the unused arguments lie between used arguments that are specified with $ operand number specifications, normally warnings are still given, since the implementation could not know what type to pass to "va_arg" to skip the unused arguments. However, in the case of "scanf" formats, this option will suppress the warning if the unused arguments are all pointers, since the Single Unix Specification says that such unused arguments are allowed.

-Wno-format-zero-length (C and Objective-C only)
If -Wformat is specified, do not warn about zero-length formats. The C standard specifies that zero-length formats are allowed.
-Wformat-nonliteral
If -Wformat is specified, also warn if the format string is not a string literal and so cannot be checked, unless the format function takes its format arguments as a "va_list".
-Wformat-security
If -Wformat is specified, also warn about uses of format functions that represent possible security problems. At present, this warns about calls to "printf" and "scanf" functions where the format string is not a string literal and there are no format arguments, as in "printf (foo);". This may be a security hole if the format string came from untrusted input and contains %n. (This is currently a subset of what -Wformat-nonliteral warns about, but in future warnings may be added to -Wformat-security that are not included in -Wformat-nonliteral.)
-Wformat=2
Enable -Wformat plus format checks not included in -Wformat. Currently equivalent to -Wformat -Wformat-nonliteral -Wformat-security -Wformat-y2k.
-Wnonnull (C and Objective-C only)
Warn about passing a null pointer for arguments marked as requiring a non-null value by the "nonnull" function attribute.
-Wnonnull is included in -Wall and -Wformat. It can be disabled with the -Wno-nonnull option.

-Winit-self (C, C ++ , Objective-C and Objective-C ++ only)
Warn about uninitialized variables which are initialized with themselves. Note this option can only be used with the -Wuninitialized option.
For example, GCC will warn about "i" being uninitialized in the following snippet only when -Winit-self has been specified:

int f()
{
  int i = i;
  return i;
}
-Wimplicit-int (C and Objective-C only)
Warn when a declaration does not specify a type. This warning is enabled by -Wall.
-Wimplicit-function-declaration (C and Objective-C only)
Give a warning whenever a function is used before being declared. In C99 mode (-std=c99 or -std=gnu99), this warning is enabled by default and it is made into an error by -pedantic-errors. This warning is also enabled by -Wall.
-Wimplicit
Same as -Wimplicit-int and -Wimplicit-function-declaration. This warning is enabled by -Wall.
-Wignored-qualifiers (C and C ++ only)
Warn if the return type of a function has a type qualifier such as "const". For ISO C such a type qualifier has no effect, since the value returned by a function is not an lvalue. For C ++ , the warning is only emitted for scalar types or "void". ISO C prohibits qualified "void" return types on function definitions, so such return types always receive a warning even without this option.
This warning is also enabled by -Wextra.

-Wmain
Warn if the type of main is suspicious. main should be a function with external linkage, returning int, taking either zero arguments, two, or three arguments of appropriate types. This warning is enabled by default in C ++ and is enabled by either -Wall or -pedantic.
-Wmissing-braces
Warn if an aggregate or union initializer is not fully bracketed. In the following example, the initializer for a is not fully bracketed, but that for b is fully bracketed.
int a[2][2] = { 0, 1, 2, 3 };
int b[2][2] = { { 0, 1 }, { 2, 3 } };
This warning is enabled by -Wall.
-Wmissing-include-dirs (C, C ++ , Objective-C and Objective-C ++ only)
Warn if a user-supplied include directory does not exist.
-Wparentheses
Warn if parentheses are omitted in certain contexts, such as when there is an assignment in a context where a truth value is expected, or when operators are nested whose precedence people often get confused about.
Also warn if a comparison like x<=y<=z appears; this is equivalent to (x<=y ? 1 : 0) <= z, which is a different interpretation from that of ordinary mathematical notation.

Also warn about constructions where there may be confusion to which "if" statement an "else" branch belongs. Here is an example of such a case:

{
  if (a)
    if (b)
      foo ();
  else
    bar ();
}
In C/C ++ , every "else" branch belongs to the innermost possible "if" statement, which in this example is "if (b)". This is often not what the programmer expected, as illustrated in the above example by indentation the programmer chose. When there is the potential for this confusion, GCC will issue a warning when this flag is specified. To eliminate the warning, add explicit braces around the innermost "if" statement so there is no way the "else" could belong to the enclosing "if". The resulting code would look like this:
{
  if (a)
    {
      if (b)
        foo ();
      else
        bar ();
    }
}
This warning is enabled by -Wall.
-Wsequence-point
Warn about code that may have undefined semantics because of violations of sequence point rules in the C and C ++ standards.
The C and C ++ standards defines the order in which expressions in a C/C ++ program are evaluated in terms of sequence points, which represent a partial ordering between the execution of parts of the program: those executed before the sequence point, and those executed after it. These occur after the evaluation of a full expression (one which is not part of a larger expression), after the evaluation of the first operand of a "&&", "||", "? :" or "," (comma) operator, before a function is called (but after the evaluation of its arguments and the expression denoting the called function), and in certain other places. Other than as expressed by the sequence point rules, the order of evaluation of subexpressions of an expression is not specified. All these rules describe only a partial order rather than a total order, since, for example, if two functions are called within one expression with no sequence point between them, the order in which the functions are called is not specified. However, the standards committee have ruled that function calls do not overlap.

It is not specified when between sequence points modifications to the values of objects take effect. Programs whose behavior depends on this have undefined behavior; the C and C ++ standards specify that "Between the previous and next sequence point an object shall have its stored value modified at most once by the evaluation of an expression. Furthermore, the prior value shall be read only to determine the value to be stored.". If a program breaks these rules, the results on any particular implementation are entirely unpredictable.

Examples of code with undefined behavior are "a = a++;", "a[n] = b[n++]" and "a[i++] = i;". Some more complicated cases are not diagnosed by this option, and it may give an occasional false positive result, but in general it has been found fairly effective at detecting this sort of problem in programs.

The standard is worded confusingly, therefore there is some debate over the precise meaning of the sequence point rules in subtle cases. Links to discussions of the problem, including proposed formal definitions, may be found on the GCC readings page, at <http://gcc.gnu.org/readings.html>.

This warning is enabled by -Wall for C and C ++ .

-Wreturn-type
Warn whenever a function is defined with a return-type that defaults to "int". Also warn about any "return" statement with no return-value in a function whose return-type is not "void" (falling off the end of the function body is considered returning without a value), and about a "return" statement with a expression in a function whose return-type is "void".
For C ++ , a function without return type always produces a diagnostic message, even when -Wno-return-type is specified. The only exceptions are main and functions defined in system headers.

This warning is enabled by -Wall.

-Wswitch
Warn whenever a "switch" statement has an index of enumerated type and lacks a "case" for one or more of the named codes of that enumeration. (The presence of a "default" label prevents this warning.) "case" labels outside the enumeration range also provoke warnings when this option is used. This warning is enabled by -Wall.
-Wswitch-default
Warn whenever a "switch" statement does not have a "default" case.
-Wswitch-enum
Warn whenever a "switch" statement has an index of enumerated type and lacks a "case" for one or more of the named codes of that enumeration. "case" labels outside the enumeration range also provoke warnings when this option is used.
-Wsync-nand (C and C ++ only)
Warn when "__sync_fetch_and_nand" and "__sync_nand_and_fetch" built-in functions are used. These functions changed semantics in GCC 4.4.
-Wtrigraphs
Warn if any trigraphs are encountered that might change the meaning of the program (trigraphs within comments are not warned about). This warning is enabled by -Wall.
-Wunused-but-set-parameter
Warn whenever a function parameter is assigned to, but otherwise unused (aside from its declaration).
To suppress this warning use the unused attribute.

-Wunused-but-set-variable
Warn whenever a local variable is assigned to, but otherwise unused (aside from its declaration).
To suppress this warning use the unused attribute.

-Wunused-function
Warn whenever a static function is declared but not defined or a non-inline static function is unused. This warning is enabled by -Wall.
-Wunused-label
Warn whenever a label is declared but not used. This warning is enabled by -Wall.
To suppress this warning use the unused attribute.

-Wunused-parameter
Warn whenever a function parameter is unused aside from its declaration.
To suppress this warning use the unused attribute.

-Wunused-variable
Warn whenever a local variable or non-constant static variable is unused aside from its declaration. This warning is enabled by -Wall.
To suppress this warning use the unused attribute.

-Wunused-value
Warn whenever a statement computes a result that is explicitly not used. To suppress this warning cast the unused expression to void. This includes an expression-statement or the left-hand side of a comma expression that contains no side effects. For example, an expression such as x[i,j] will cause a warning, while x[(void)i,j] will not.
This warning is enabled by -Wall.

-Wunused
All the above -Wunused options combined.
In order to get a warning about an unused function parameter, you must either specify -Wextra -Wunused (note that -Wall implies -Wunused), or separately specify -Wunused-parameter.

-Wuninitialized
Warn if an automatic variable is used without first being initialized or if a variable may be clobbered by a "setjmp" call. In C ++ , warn if a non-static reference or non-static const member appears in a class without constructors.
If you want to warn about code which uses the uninitialized value of the variable in its own initializer, use the -Winit-self option.

These warnings occur for individual uninitialized or clobbered elements of structure, union or array variables as well as for variables which are uninitialized or clobbered as a whole. They do not occur for variables or elements declared "volatile". Because these warnings depend on optimization, the exact variables or elements for which there are warnings will depend on the precise optimization options and version of GCC used.

Note that there may be no warning about a variable that is used only to compute a value that itself is never used, because such computations may be deleted by data flow analysis before the warnings are printed.

These warnings are made optional because GCC is not smart enough to see all the reasons why the code might be correct despite appearing to have an error. Here is one example of how this can happen:

{
  int x;
  switch (y)
    {
    case 1: x = 1;
      break;
    case 2: x = 4;
      break;
    case 3: x = 5;
    }
  foo (x);
}
If the value of "y" is always 1, 2 or 3, then "x" is always initialized, but GCC doesn't know this. Here is another common case:
{
  int save_y;
  if (change_y) save_y = y, y = new_y;
  ...
  if (change_y) y = save_y;
}
This has no bug because "save_y" is used only if it is set.
This option also warns when a non-volatile automatic variable might be changed by a call to "longjmp". These warnings as well are possible only in optimizing compilation.

The compiler sees only the calls to "setjmp". It cannot know where "longjmp" will be called; in fact, a signal handler could call it at any point in the code. As a result, you may get a warning even when there is in fact no problem because "longjmp" cannot in fact be called at the place which would cause a problem.

Some spurious warnings can be avoided if you declare all the functions you use that never return as "noreturn".

This warning is enabled by -Wall or -Wextra.

-Wunknown-pragmas
Warn when a #pragma directive is encountered which is not understood by GCC . If this command line option is used, warnings will even be issued for unknown pragmas in system header files. This is not the case if the warnings were only enabled by the -Wall command line option.
-Wno-pragmas
Do not warn about misuses of pragmas, such as incorrect parameters, invalid syntax, or conflicts between pragmas. See also -Wunknown-pragmas.
-Wstrict-aliasing
This option is only active when -fstrict-aliasing is active. It warns about code which might break the strict aliasing rules that the compiler is using for optimization. The warning does not catch all cases, but does attempt to catch the more common pitfalls. It is included in -Wall. It is equivalent to -Wstrict-aliasing=3
-Wstrict-aliasing=n
This option is only active when -fstrict-aliasing is active. It warns about code which might break the strict aliasing rules that the compiler is using for optimization. Higher levels correspond to higher accuracy (fewer false positives). Higher levels also correspond to more effort, similar to the way -O works. -Wstrict-aliasing is equivalent to -Wstrict-aliasing=n, with n=3.
Level 1: Most aggressive, quick, least accurate. Possibly useful when higher levels do not warn but -fstrict-aliasing still breaks the code, as it has very few false negatives. However, it has many false positives. Warns for all pointer conversions between possibly incompatible types, even if never dereferenced. Runs in the frontend only.

Level 2: Aggressive, quick, not too precise. May still have many false positives (not as many as level 1 though), and few false negatives (but possibly more than level 1). Unlike level 1, it only warns when an address is taken. Warns about incomplete types. Runs in the frontend only.

Level 3 (default for -Wstrict-aliasing): Should have very few false positives and few false negatives. Slightly slower than levels 1 or 2 when optimization is enabled. Takes care of the common punn+dereference pattern in the frontend: "*(int*)&some_float". If optimization is enabled, it also runs in the backend, where it deals with multiple statement cases using flow-sensitive points-to information. Only warns when the converted pointer is dereferenced. Does not warn about incomplete types.

-Wstrict-overflow
-Wstrict-overflow=n
This option is only active when -fstrict-overflow is active. It warns about cases where the compiler optimizes based on the assumption that signed overflow does not occur. Note that it does not warn about all cases where the code might overflow: it only warns about cases where the compiler implements some optimization. Thus this warning depends on the optimization level.
An optimization which assumes that signed overflow does not occur is perfectly safe if the values of the variables involved are such that overflow never does, in fact, occur. Therefore this warning can easily give a false positive: a warning about code which is not actually a problem. To help focus on important issues, several warning levels are defined. No warnings are issued for the use of undefined signed overflow when estimating how many iterations a loop will require, in particular when determining whether a loop will be executed at all.

-Wstrict-overflow=1
Warn about cases which are both questionable and easy to avoid. For example: "x + 1 > x"; with -fstrict-overflow, the compiler will simplify this to 1. This level of -Wstrict-overflow is enabled by -Wall; higher levels are not, and must be explicitly requested.
-Wstrict-overflow=2
Also warn about other cases where a comparison is simplified to a constant. For example: "abs (x) >= 0". This can only be simplified when -fstrict-overflow is in effect, because "abs (INT_MIN)" overflows to "INT_MIN", which is less than zero. -Wstrict-overflow (with no level) is the same as -Wstrict-overflow=2.
-Wstrict-overflow=3
Also warn about other cases where a comparison is simplified. For example: "x + 1 > 1" will be simplified to "x > 0".
-Wstrict-overflow=4
Also warn about other simplifications not covered by the above cases. For example: "(x * 10) / 5" will be simplified to "x * 2".
-Wstrict-overflow=5
Also warn about cases where the compiler reduces the magnitude of a constant involved in a comparison. For example: "x + 2 > y" will be simplified to "x + 1 >= y". This is reported only at the highest warning level because this simplification applies to many comparisons, so this warning level will give a very large number of false positives.
-Warray-bounds
This option is only active when -ftree-vrp is active (default for -O2 and above). It warns about subscripts to arrays that are always out of bounds. This warning is enabled by -Wall.
-Wno-div-by-zero
Do not warn about compile-time integer division by zero. Floating point division by zero is not warned about, as it can be a legitimate way of obtaining infinities and NaNs.
-Wsystem-headers
Print warning messages for constructs found in system header files. Warnings from system headers are normally suppressed, on the assumption that they usually do not indicate real problems and would only make the compiler output harder to read. Using this command line option tells GCC to emit warnings from system headers as if they occurred in user code. However, note that using -Wall in conjunction with this option will not warn about unknown pragmas in system headers---for that, -Wunknown-pragmas must also be used.
-Wfloat-equal
Warn if floating point values are used in equality comparisons.
The idea behind this is that sometimes it is convenient (for the programmer) to consider floating-point values as approximations to infinitely precise real numbers. If you are doing this, then you need to compute (by analyzing the code, or in some other way) the maximum or likely maximum error that the computation introduces, and allow for it when performing comparisons (and when producing output, but that's a different problem). In particular, instead of testing for equality, you would check to see whether the two values have ranges that overlap; and this is done with the relational operators, so equality comparisons are probably mistaken.

-Wtraditional (C and Objective-C only)
Warn about certain constructs that behave differently in traditional and ISO C. Also warn about ISO C constructs that have no traditional C equivalent, and/or problematic constructs which should be avoided.
• Macro parameters that appear within string literals in the macro body. In traditional C macro replacement takes place within string literals, but does not in ISO C.
• In traditional C, some preprocessor directives did not exist. Traditional preprocessors would only consider a line to be a directive if the # appeared in column 1 on the line. Therefore -Wtraditional warns about directives that traditional C understands but would ignore because the # does not appear as the first character on the line. It also suggests you hide directives like #pragma not understood by traditional C by indenting them. Some traditional implementations would not recognize #elif, so it suggests avoiding it altogether.

• A function-like macro that appears without arguments.

• The unary plus operator.

• The U integer constant suffix, or the F or L floating point constant suffixes. (Traditional C does support the L suffix on integer constants.) Note, these suffixes appear in macros defined in the system headers of most modern systems, e.g. the _MIN/_MAX macros in "<limits.h>". Use of these macros in user code might normally lead to spurious warnings, however GCC 's integrated preprocessor has enough context to avoid warning in these cases.

• A function declared external in one block and then used after the end of the block.

• A "switch" statement has an operand of type "long".

• A non-"static" function declaration follows a "static" one. This construct is not accepted by some traditional C compilers.

• The ISO type of an integer constant has a different width or signedness from its traditional type. This warning is only issued if the base of the constant is ten. I.e. hexadecimal or octal values, which typically represent bit patterns, are not warned about.

• Usage of ISO string concatenation is detected.

• Initialization of automatic aggregates.

• Identifier conflicts with labels. Traditional C lacks a separate namespace for labels.

• Initialization of unions. If the initializer is zero, the warning is omitted. This is done under the assumption that the zero initializer in user code appears conditioned on e.g. "__STDC__" to avoid missing initializer warnings and relies on default initialization to zero in the traditional C case.

• Conversions by prototypes between fixed/floating point values and vice versa. The absence of these prototypes when compiling with traditional C would cause serious problems. This is a subset of the possible conversion warnings, for the full set use -Wtraditional-conversion.

• Use of ISO C style function definitions. This warning intentionally is not issued for prototype declarations or variadic functions because these ISO C features will appear in your code when using libiberty's traditional C compatibility macros, "PARAMS" and "VPARAMS". This warning is also bypassed for nested functions because that feature is already a GCC extension and thus not relevant to traditional C compatibility.

-Wtraditional-conversion (C and Objective-C only)
Warn if a prototype causes a type conversion that is different from what would happen to the same argument in the absence of a prototype. This includes conversions of fixed point to floating and vice versa, and conversions changing the width or signedness of a fixed point argument except when the same as the default promotion.
-Wdeclaration-after-statement (C and Objective-C only)
Warn when a declaration is found after a statement in a block. This construct, known from C ++ , was introduced with ISO C99 and is by default allowed in GCC . It is not supported by ISO C90 and was not supported by GCC versions before GCC 3.0.
-Wundef
Warn if an undefined identifier is evaluated in an #if directive.
-Wno-endif-labels
Do not warn whenever an #else or an #endif are followed by text.
-Wshadow
Warn whenever a local variable shadows another local variable, parameter or global variable or whenever a built-in function is shadowed.
-Wlarger-than=len
Warn whenever an object of larger than len bytes is defined.
-Wframe-larger-than=len
Warn if the size of a function frame is larger than len bytes. The computation done to determine the stack frame size is approximate and not conservative. The actual requirements may be somewhat greater than len even if you do not get a warning. In addition, any space allocated via "alloca", variable-length arrays, or related constructs is not included by the compiler when determining whether or not to issue a warning.
-Wunsafe-loop-optimizations
Warn if the loop cannot be optimized because the compiler could not assume anything on the bounds of the loop indices. With -funsafe-loop-optimizations warn if the compiler made such assumptions.
-Wno-pedantic-ms-format (MinGW targets only)
Disables the warnings about non-ISO "printf" / "scanf" format width specifiers "I32", "I64", and "I" used on Windows targets depending on the MS runtime, when you are using the options -Wformat and -pedantic without gnu-extensions.
-Wpointer-arith
Warn about anything that depends on the "size of" a function type or of "void". GNU C assigns these types a size of 1, for convenience in calculations with "void *" pointers and pointers to functions. In C ++ , warn also when an arithmetic operation involves "NULL". This warning is also enabled by -pedantic.
-Wtype-limits
Warn if a comparison is always true or always false due to the limited range of the data type, but do not warn for constant expressions. For example, warn if an unsigned variable is compared against zero with < or >=. This warning is also enabled by -Wextra.
-Wbad-function-cast (C and Objective-C only)
Warn whenever a function call is cast to a non-matching type. For example, warn if "int malloc()" is cast to "anything *".
-Wc++-compat (C and Objective-C only)
Warn about ISO C constructs that are outside of the common subset of ISO C and ISO C ++ , e.g. request for implicit conversion from "void *" to a pointer to non-"void" type.
-Wc++0x-compat (C ++ and Objective-C ++ only)
Warn about C ++ constructs whose meaning differs between ISO C ++ 1998 and ISO C ++ 200x, e.g., identifiers in ISO C ++ 1998 that will become keywords in ISO C ++ 200x. This warning is enabled by -Wall.
-Wcast-qual
Warn whenever a pointer is cast so as to remove a type qualifier from the target type. For example, warn if a "const char *" is cast to an ordinary "char *".
-Wcast-align
Warn whenever a pointer is cast such that the required alignment of the target is increased. For example, warn if a "char *" is cast to an "int *" on machines where integers can only be accessed at two- or four-byte boundaries.
-Wwrite-strings
When compiling C, give string constants the type "const char[ length ]" so that copying the address of one into a non-"const" "char *" pointer will get a warning. These warnings will help you find at compile time code that can try to write into a string constant, but only if you have been very careful about using "const" in declarations and prototypes. Otherwise, it will just be a nuisance. This is why we did not make -Wall request these warnings.
When compiling C ++ , warn about the deprecated conversion from string literals to "char *". This warning is enabled by default for C ++ programs.

-Wclobbered
Warn for variables that might be changed by longjmp or vfork. This warning is also enabled by -Wextra.
-Wconversion
Warn for implicit conversions that may alter a value. This includes conversions between real and integer, like "abs (x)" when "x" is "double"; conversions between signed and unsigned, like "unsigned ui = -1"; and conversions to smaller types, like "sqrtf (M_PI)". Do not warn for explicit casts like "abs ((int) x)" and "ui = (unsigned) -1", or if the value is not changed by the conversion like in "abs (2.0)". Warnings about conversions between signed and unsigned integers can be disabled by using -Wno-sign-conversion.
For C ++ , also warn for conversions between "NULL" and non-pointer types; confusing overload resolution for user-defined conversions; and conversions that will never use a type conversion operator: conversions to "void", the same type, a base class or a reference to them. Warnings about conversions between signed and unsigned integers are disabled by default in C ++ unless -Wsign-conversion is explicitly enabled.

-Wempty-body
Warn if an empty body occurs in an if, else or do while statement. This warning is also enabled by -Wextra.
-Wenum-compare (C ++ and Objective-C ++ only)
Warn about a comparison between values of different enum types. This warning is enabled by default.
-Wsign-compare
Warn when a comparison between signed and unsigned values could produce an incorrect result when the signed value is converted to unsigned. This warning is also enabled by -Wextra; to get the other warnings of -Wextra without this warning, use -Wextra -Wno-sign-compare.
-Wsign-conversion
Warn for implicit conversions that may change the sign of an integer value, like assigning a signed integer expression to an unsigned integer variable. An explicit cast silences the warning. In C, this option is enabled also by -Wconversion.
-Waddress
Warn about suspicious uses of memory addresses. These include using the address of a function in a conditional expression, such as "void func(void); if (func)", and comparisons against the memory address of a string literal, such as "if (x == "abc")". Such uses typically indicate a programmer error: the address of a function always evaluates to true, so their use in a conditional usually indicate that the programmer forgot the parentheses in a function call; and comparisons against string literals result in unspecified behavior and are not portable in C, so they usually indicate that the programmer intended to use "strcmp". This warning is enabled by -Wall.
-Wlogical-op
Warn about suspicious uses of logical operators in expressions. This includes using logical operators in contexts where a bit-wise operator is likely to be expected.
-Waggregate-return
Warn if any functions that return structures or unions are defined or called. (In languages where you can return an array, this also elicits a warning.)
-Wno-attributes
Do not warn if an unexpected "__attribute__" is used, such as unrecognized attributes, function attributes applied to variables, etc. This will not stop errors for incorrect use of supported attributes.
-Wno-builtin-macro-redefined
Do not warn if certain built-in macros are redefined. This suppresses warnings for redefinition of "__TIMESTAMP__", "__TIME__", "__DATE__", "__FILE__", and "__BASE_FILE__".
-Wstrict-prototypes (C and Objective-C only)
Warn if a function is declared or defined without specifying the argument types. (An old-style function definition is permitted without a warning if preceded by a declaration which specifies the argument types.)
-Wold-style-declaration (C and Objective-C only)
Warn for obsolescent usages, according to the C Standard, in a declaration. For example, warn if storage-class specifiers like "static" are not the first things in a declaration. This warning is also enabled by -Wextra.
-Wold-style-definition (C and Objective-C only)
Warn if an old-style function definition is used. A warning is given even if there is a previous prototype.
-Wmissing-parameter-type (C and Objective-C only)
A function parameter is declared without a type specifier in K&R-style functions:
void foo(bar) { }
This warning is also enabled by -Wextra.
-Wmissing-prototypes (C and Objective-C only)
Warn if a global function is defined without a previous prototype declaration. This warning is issued even if the definition itself provides a prototype. The aim is to detect global functions that fail to be declared in header files.
-Wmissing-declarations
Warn if a global function is defined without a previous declaration. Do so even if the definition itself provides a prototype. Use this option to detect global functions that are not declared in header files. In C ++ , no warnings are issued for function templates, or for inline functions, or for functions in anonymous namespaces.
-Wmissing-field-initializers
Warn if a structure's initializer has some fields missing. For example, the following code would cause such a warning, because "x.h" is implicitly zero:
struct s { int f, g, h; };
struct s x = { 3, 4 };
This option does not warn about designated initializers, so the following modification would not trigger a warning:
struct s { int f, g, h; };
struct s x = { .f = 3, .g = 4 };
This warning is included in -Wextra. To get other -Wextra warnings without this one, use -Wextra -Wno-missing-field-initializers.
-Wmissing-noreturn
Warn about functions which might be candidates for attribute "noreturn". Note these are only possible candidates, not absolute ones. Care should be taken to manually verify functions actually do not ever return before adding the "noreturn" attribute, otherwise subtle code generation bugs could be introduced. You will not get a warning for "main" in hosted C environments.
-Wmissing-format-attribute
Warn about function pointers which might be candidates for "format" attributes. Note these are only possible candidates, not absolute ones. GCC will guess that function pointers with "format" attributes that are used in assignment, initialization, parameter passing or return statements should have a corresponding "format" attribute in the resulting type. I.e. the left-hand side of the assignment or initialization, the type of the parameter variable, or the return type of the containing function respectively should also have a "format" attribute to avoid the warning.
GCC will also warn about function definitions which might be candidates for "format" attributes. Again, these are only possible candidates. GCC will guess that "format" attributes might be appropriate for any function that calls a function like "vprintf" or "vscanf", but this might not always be the case, and some functions for which "format" attributes are appropriate may not be detected.

-Wno-multichar
Do not warn if a multicharacter constant (' FOOF ') is used. Usually they indicate a typo in the user's code, as they have implementation-defined values, and should not be used in portable code.
-Wnormalized=<none|id|nfc|nfkc>
In ISO C and ISO C ++ , two identifiers are different if they are different sequences of characters. However, sometimes when characters outside the basic ASCII character set are used, you can have two different character sequences that look the same. To avoid confusion, the ISO 10646 standard sets out some normalization rules which when applied ensure that two sequences that look the same are turned into the same sequence. GCC can warn you if you are using identifiers which have not been normalized; this option controls that warning.
There are four levels of warning that GCC supports. The default is -Wnormalized=nfc, which warns about any identifier which is not in the ISO 10646 "C" normalized form, NFC . NFC is the recommended form for most uses.

Unfortunately, there are some characters which ISO C and ISO C ++ allow in identifiers that when turned into NFC aren't allowable as identifiers. That is, there's no way to use these symbols in portable ISO C or C ++ and have all your identifiers in NFC . -Wnormalized=id suppresses the warning for these characters. It is hoped that future versions of the standards involved will correct this, which is why this option is not the default.

You can switch the warning off for all characters by writing -Wnormalized=none. You would only want to do this if you were using some other normalization scheme (like "D"), because otherwise you can easily create bugs that are literally impossible to see.

Some characters in ISO 10646 have distinct meanings but look identical in some fonts or display methodologies, especially once formatting has been applied. For instance "\u207F", " SUPERSCRIPT LATIN SMALL LETTER N", will display just like a regular "n" which has been placed in a superscript. ISO 10646 defines the NFKC normalization scheme to convert all these into a standard form as well, and GCC will warn if your code is not in NFKC if you use -Wnormalized=nfkc. This warning is comparable to warning about every identifier that contains the letter O because it might be confused with the digit 0, and so is not the default, but may be useful as a local coding convention if the programming environment is unable to be fixed to display these characters distinctly.

-Wno-deprecated
Do not warn about usage of deprecated features.
-Wno-deprecated-declarations
Do not warn about uses of functions, variables, and types marked as deprecated by using the "deprecated" attribute.
-Wno-overflow
Do not warn about compile-time overflow in constant expressions.
-Woverride-init (C and Objective-C only)
Warn if an initialized field without side effects is overridden when using designated initializers.
This warning is included in -Wextra. To get other -Wextra warnings without this one, use -Wextra -Wno-override-init.

-Wpacked
Warn if a structure is given the packed attribute, but the packed attribute has no effect on the layout or size of the structure. Such structures may be mis-aligned for little benefit. For instance, in this code, the variable "f.x" in "struct bar" will be misaligned even though "struct bar" does not itself have the packed attribute:
struct foo {
  int x;
  char a, b, c, d;
} __attribute__((packed));
struct bar {
  char z;
  struct foo f;
};
-Wpacked-bitfield-compat
The 4.1, 4.2 and 4.3 series of GCC ignore the "packed" attribute on bit-fields of type "char". This has been fixed in GCC 4.4 but the change can lead to differences in the structure layout. GCC informs you when the offset of such a field has changed in GCC 4.4. For example there is no longer a 4-bit padding between field "a" and "b" in this structure:
struct foo
{
  char a:4;
  char b:8;
} __attribute__ ((packed));
This warning is enabled by default. Use -Wno-packed-bitfield-compat to disable this warning.
-Wpadded
Warn if padding is included in a structure, either to align an element of the structure or to align the whole structure. Sometimes when this happens it is possible to rearrange the fields of the structure to reduce the padding and so make the structure smaller.
-Wredundant-decls
Warn if anything is declared more than once in the same scope, even in cases where multiple declaration is valid and changes nothing.
-Wnested-externs (C and Objective-C only)
Warn if an "extern" declaration is encountered within a function.
-Wunreachable-code
Warn if the compiler detects that code will never be executed.
This option is intended to warn when the compiler detects that at least a whole line of source code will never be executed, because some condition is never satisfied or because it is after a procedure that never returns.

It is possible for this option to produce a warning even though there are circumstances under which part of the affected line can be executed, so care should be taken when removing apparently-unreachable code.

For instance, when a function is inlined, a warning may mean that the line is unreachable in only one inlined copy of the function.

This option is not made part of -Wall because in a debugging version of a program there is often substantial code which checks correct functioning of the program and is, hopefully, unreachable because the program does work. Another common use of unreachable code is to provide behavior which is selectable at compile-time.

-Winline
Warn if a function can not be inlined and it was declared as inline. Even with this option, the compiler will not warn about failures to inline functions declared in system headers.
The compiler uses a variety of heuristics to determine whether or not to inline a function. For example, the compiler takes into account the size of the function being inlined and the amount of inlining that has already been done in the current function. Therefore, seemingly insignificant changes in the source program can cause the warnings produced by -Winline to appear or disappear.

-Wno-invalid-offsetof (C ++ and Objective-C ++ only)
Suppress warnings from applying the offsetof macro to a non-POD type. According to the 1998 ISO C ++ standard, applying offsetof to a non-POD type is undefined. In existing C ++ implementations, however, offsetof typically gives meaningful results even when applied to certain kinds of non-POD types. (Such as a simple struct that fails to be a POD type only by virtue of having a constructor.) This flag is for users who are aware that they are writing nonportable code and who have deliberately chosen to ignore the warning about it.
The restrictions on offsetof may be relaxed in a future version of the C ++ standard.

-Wno-int-to-pointer-cast (C and Objective-C only)
Suppress warnings from casts to pointer type of an integer of a different size.
-Wno-pointer-to-int-cast (C and Objective-C only)
Suppress warnings from casts from a pointer to an integer type of a different size.
-Winvalid-pch
Warn if a precompiled header is found in the search path but can't be used.
-Wlong-long
Warn if long long type is used. This is default. To inhibit the warning messages, use -Wno-long-long. Flags -Wlong-long and -Wno-long-long are taken into account only when -pedantic flag is used.
-Wvariadic-macros
Warn if variadic macros are used in pedantic ISO C90 mode, or the GNU alternate syntax when in pedantic ISO C99 mode. This is default. To inhibit the warning messages, use -Wno-variadic-macros.
-Wvla
Warn if variable length array is used in the code. -Wno-vla will prevent the -pedantic warning of the variable length array.
-Wvolatile-register-var
Warn if a register variable is declared volatile. The volatile modifier does not inhibit all optimizations that may eliminate reads and/or writes to register variables. This warning is enabled by -Wall.
-Wdisabled-optimization
Warn if a requested optimization pass is disabled. This warning does not generally indicate that there is anything wrong with your code; it merely indicates that GCC 's optimizers were unable to handle the code effectively. Often, the problem is that your code is too big or too complex; GCC will refuse to optimize programs when the optimization itself is likely to take inordinate amounts of time.
-Wpointer-sign (C and Objective-C only)
Warn for pointer argument passing or assignment with different signedness. This option is only supported for C and Objective-C. It is implied by -Wall and by -pedantic, which can be disabled with -Wno-pointer-sign.
-Wstack-protector
This option is only active when -fstack-protector is active. It warns about functions that will not be protected against stack smashing.
-Wno-mudflap
Suppress warnings about constructs that cannot be instrumented by -fmudflap.
-Woverlength-strings
Warn about string constants which are longer than the "minimum maximum" length specified in the C standard. Modern compilers generally allow string constants which are much longer than the standard's minimum limit, but very portable programs should avoid using longer strings.
The limit applies after string constant concatenation, and does not count the trailing NUL . In C89, the limit was 509 characters; in C99, it was raised to 4095. C ++ 98 does not specify a normative minimum maximum, so we do not diagnose overlength strings in C ++ .

This option is implied by -pedantic, and can be disabled with -Wno-overlength-strings.

Options for Debugging Your Program or GCC

GCC has various special options that are used for debugging either your program or GCC:
-g
Produce debugging information in the operating system's native format (stabs, COFF , XCOFF , or DWARF 2). GDB can work with this debugging information.

On most systems that use stabs format, -g enables use of extra debugging information that only GDB can use; this extra information makes debugging work better in GDB but will probably make other debuggers crash or refuse to read the program. If you want to control for certain whether to generate the extra information, use -gstabs+, -gstabs, -gxcoff+, -gxcoff, or -gvms (see below).
GCC allows you to use -g with -O. The shortcuts taken by optimized code may occasionally produce surprising results: some variables you declared may not exist at all; flow of control may briefly move where you did not expect it; some statements may not be executed because they compute constant results or their values were already at hand; some statements may execute in different places because they were moved out of loops.

Nevertheless it proves possible to debug optimized output. This makes it reasonable to use the optimizer for programs that might have bugs.

The following options are useful when GCC is generated with the capability for more than one debugging format.

-ggdb
Produce debugging information for use by GDB . This means to use the most expressive format available ( DWARF 2, stabs, or the native format if neither of those are supported), including GDB extensions if at all possible.
-gstabs
Produce debugging information in stabs format (if that is supported), without GDB extensions. This is the format used by DBX on most BSD systems. On MIPS , Alpha and System V Release 4 systems this option produces stabs debugging output which is not understood by DBX or SDB . On System V Release 4 systems this option requires the GNU assembler.
-feliminate-unused-debug-symbols
Produce debugging information in stabs format (if that is supported), for only symbols that are actually used.
-femit-class-debug-always
Instead of emitting debugging information for a C ++ class in only one object file, emit it in all object files using the class. This option should be used only with debuggers that are unable to handle the way GCC normally emits debugging information for classes because using this option will increase the size of debugging information by as much as a factor of two.
-gstabs+
Produce debugging information in stabs format (if that is supported), using GNU extensions understood only by the GNU debugger ( GDB ). The use of these extensions is likely to make other debuggers crash or refuse to read the program.
-gcoff
Produce debugging information in COFF format (if that is supported). This is the format used by SDB on most System V systems prior to System V Release 4.
-gxcoff
Produce debugging information in XCOFF format (if that is supported). This is the format used by the DBX debugger on IBM RS/6000 systems.
-gxcoff+
Produce debugging information in XCOFF format (if that is supported), using GNU extensions understood only by the GNU debugger ( GDB ). The use of these extensions is likely to make other debuggers crash or refuse to read the program, and may cause assemblers other than the GNU assembler ( GAS ) to fail with an error.
-gdwarf-version
Produce debugging information in DWARF format (if that is supported). This is the format used by DBX on IRIX 6. The value of version may be either 2 or 3; the default version is 3.
Note that with DWARF version 2 some ports require, and will always use, some non-conflicting DWARF 3 extensions in the unwind tables.

-gstrict-dwarf
Disallow using extensions of later DWARF standard version than selected with -gdwarf-version. On most targets using non-conflicting DWARF extensions from later standard versions is allowed.
-gno-strict-dwarf
Allow using extensions of later DWARF standard version than selected with -gdwarf-version.
-gvms
Produce debugging information in VMS debug format (if that is supported). This is the format used by DEBUG on VMS systems.
-glevel
-ggdblevel
-gstabslevel
-gcofflevel
-gxcofflevel
-gvmslevel
Request debugging information and also use level to specify how much information. The default level is 2.
Level 0 produces no debug information at all. Thus, -g0 negates -g.

Level 1 produces minimal information, enough for making backtraces in parts of the program that you don't plan to debug. This includes descriptions of functions and external variables, but no information about local variables and no line numbers.

Level 3 includes extra information, such as all the macro definitions present in the program. Some debuggers support macro expansion when you use -g3.

-gdwarf-2 does not accept a concatenated debug level, because GCC used to support an option -gdwarf that meant to generate debug information in version 1 of the DWARF format (which is very different from version 2), and it would have been too confusing. That debug format is long obsolete, but the option cannot be changed now. Instead use an additional -glevel option to change the debug level for DWARF .

-gtoggle
Turn off generation of debug info, if leaving out this option would have generated it, or turn it on at level 2 otherwise. The position of this argument in the command line does not matter, it takes effect after all other options are processed, and it does so only once, no matter how many times it is given. This is mainly intended to be used with -fcompare-debug.
-fdump-final-insns[=file]
Dump the final internal representation ( RTL ) to file. If the optional argument is omitted (or if file is "."), the name of the dump file will be determined by appending ".gkd" to the compilation output file name.
-fcompare-debug[=opts]
If no error occurs during compilation, run the compiler a second time, adding opts and -fcompare-debug-second to the arguments passed to the second compilation. Dump the final internal representation in both compilations, and print an error if they differ.
If the equal sign is omitted, the default -gtoggle is used.

The environment variable GCC_COMPARE_DEBUG , if defined, non-empty and nonzero, implicitly enables -fcompare-debug. If GCC_COMPARE_DEBUG is defined to a string starting with a dash, then it is used for opts, otherwise the default -gtoggle is used.

-fcompare-debug=, with the equal sign but without opts, is equivalent to -fno-compare-debug, which disables the dumping of the final representation and the second compilation, preventing even GCC_COMPARE_DEBUG from taking effect.

To verify full coverage during -fcompare-debug testing, set GCC_COMPARE_DEBUG to say -fcompare-debug-not-overridden, which GCC will reject as an invalid option in any actual compilation (rather than preprocessing, assembly or linking). To get just a warning, setting GCC_COMPARE_DEBUG to -w%n-fcompare-debug not overridden will do.

-fcompare-debug-second
This option is implicitly passed to the compiler for the second compilation requested by -fcompare-debug, along with options to silence warnings, and omitting other options that would cause side-effect compiler outputs to files or to the standard output. Dump files and preserved temporary files are renamed so as to contain the ".gk" additional extension during the second compilation, to avoid overwriting those generated by the first.
When this option is passed to the compiler driver, it causes the first compilation to be skipped, which makes it useful for little other than debugging the compiler proper.

-feliminate-dwarf2-dups
Compress DWARF2 debugging information by eliminating duplicated information about each symbol. This option only makes sense when generating DWARF2 debugging information with -gdwarf-2.
-femit-struct-debug-baseonly
Emit debug information for struct-like types only when the base name of the compilation source file matches the base name of file in which the struct was defined.
This option substantially reduces the size of debugging information, but at significant potential loss in type information to the debugger. See -femit-struct-debug-reduced for a less aggressive option. See -femit-struct-debug-detailed for more detailed control.

This option works only with DWARF 2.

-femit-struct-debug-reduced
Emit debug information for struct-like types only when the base name of the compilation source file matches the base name of file in which the type was defined, unless the struct is a template or defined in a system header.
This option significantly reduces the size of debugging information, with some potential loss in type information to the debugger. See -femit-struct-debug-baseonly for a more aggressive option. See -femit-struct-debug-detailed for more detailed control.

This option works only with DWARF 2.

-femit-struct-debug-detailed[=spec-list]
Specify the struct-like types for which the compiler will generate debug information. The intent is to reduce duplicate struct debug information between different object files within the same program.
This option is a detailed version of -femit-struct-debug-reduced and -femit-struct-debug-baseonly, which will serve for most needs.

A specification has the syntax [dir:|ind:][ord:|gen:](any|sys|base|none)

The optional first word limits the specification to structs that are used directly (dir:) or used indirectly (ind:). A struct type is used directly when it is the type of a variable, member. Indirect uses arise through pointers to structs. That is, when use of an incomplete struct would be legal, the use is indirect. An example is struct one direct; struct two * indirect;.

The optional second word limits the specification to ordinary structs (ord:) or generic structs (gen:). Generic structs are a bit complicated to explain. For C ++ , these are non-explicit specializations of template classes, or non-template classes within the above. Other programming languages have generics, but -femit-struct-debug-detailed does not yet implement them.

The third word specifies the source files for those structs for which the compiler will emit debug information. The values none and any have the normal meaning. The value base means that the base of name of the file in which the type declaration appears must match the base of the name of the main compilation file. In practice, this means that types declared in foo.c and foo.h will have debug information, but types declared in other header will not. The value sys means those types satisfying base or declared in system or compiler headers.

You may need to experiment to determine the best settings for your application.

The default is -femit-struct-debug-detailed=all.

This option works only with DWARF 2.

-fno-merge-debug-strings
Direct the linker to not merge together strings in the debugging information which are identical in different object files. Merging is not supported by all assemblers or linkers. Merging decreases the size of the debug information in the output file at the cost of increasing link processing time. Merging is enabled by default.
-fdebug-prefix-map=old=new
When compiling files in directory old, record debugging information describing them as in new instead.
-fno-dwarf2-cfi-asm
Emit DWARF 2 unwind info as compiler generated ".eh_frame" section instead of using GAS ".cfi_*" directives.
-p
Generate extra code to write profile information suitable for the analysis program prof. You must use this option when compiling the source files you want data about, and you must also use it when linking.

-pg

Generate extra code to write profile information suitable for the analysis program gprof. You must use this option when compiling the source files you want data about, and you must also use it when linking.

-Q

Makes the compiler print out each function name as it is compiled, and print some statistics about each pass when it finishes.

-ftime-report
Makes the compiler print some statistics about the time consumed by each pass when it finishes.
-fmem-report
Makes the compiler print some statistics about permanent memory allocation when it finishes.
-fpre-ipa-mem-report
-fpost-ipa-mem-report
Makes the compiler print some statistics about permanent memory allocation before or after interprocedural optimization.
-fprofile-arcs
Add code so that program flow arcs are instrumented. During execution the program records how many times each branch and call is executed and how many times it is taken or returns. When the compiled program exits it saves this data to a file called auxname.gcda for each source file. The data may be used for profile-directed optimizations (-fbranch-probabilities), or for test coverage analysis (-ftest-coverage). Each object file's auxname is generated from the name of the output file, if explicitly specified and it is not the final executable, otherwise it is the basename of the source file. In both cases any suffix is removed (e.g. foo.gcda for input file dir/foo.c, or dir/foo.gcda for output file specified as -o dir/foo.o).
--coverage
This option is used to compile and link code instrumented for coverage analysis. The option is a synonym for -fprofile-arcs -ftest-coverage (when compiling) and -lgcov (when linking). See the documentation for those options for more details.
• Compile the source files with -fprofile-arcs plus optimization and code generation options. For test coverage analysis, use the additional -ftest-coverage option. You do not need to profile every source file in a program.
• Link your object files with -lgcov or -fprofile-arcs (the latter implies the former).

• Run the program on a representative workload to generate the arc profile information. This may be repeated any number of times. You can run concurrent instances of your program, and provided that the file system supports locking, the data files will be correctly updated. Also "fork" calls are detected and correctly handled (double counting will not happen).

• For profile-directed optimizations, compile the source files again with the same optimization and code generation options plus -fbranch-probabilities.

• For test coverage analysis, use gcov to produce human readable information from the .gcno and .gcda files. Refer to the gcov documentation for further information.

With -fprofile-arcs, for each function of your program GCC creates a program flow graph, then finds a spanning tree for the graph. Only arcs that are not on the spanning tree have to be instrumented: the compiler adds code to count the number of times that these arcs are executed. When an arc is the only exit or only entrance to a block, the instrumentation code can be added to the block; otherwise, a new basic block must be created to hold the instrumentation code.
-ftest-coverage
Produce a notes file that the gcov code-coverage utility can use to show program coverage. Each source file's note file is called auxname.gcno. Refer to the -fprofile-arcs option above for a description of auxname and instructions on how to generate test coverage data. Coverage data will match the source files more closely, if you do not optimize.
-fdbg-cnt-list
Print the name and the counter upperbound for all debug counters.
-fdbg-cnt=counter-value-list
Set the internal debug counter upperbound. counter-value-list is a comma-separated list of name:value pairs which sets the upperbound of each debug counter name to value. All debug counters have the initial upperbound of UINT_MAX , thus dbg_cnt() returns true always unless the upperbound is set by this option. e.g. With -fdbg-cnt=dce:10,tail_call:0 dbg_cnt(dce) will return true only for first 10 invocations and dbg_cnt(tail_call) will return false always.
-dletters
-fdump-rtl-pass
Says to make debugging dumps during compilation at times specified by letters. This is used for debugging the RTL-based passes of the compiler. The file names for most of the dumps are made by appending a pass number and a word to the dumpname. dumpname is generated from the name of the output file, if explicitly specified and it is not an executable, otherwise it is the basename of the source file. These switches may have different effects when -E is used for preprocessing.
Debug dumps can be enabled with a -fdump-rtl switch or some -d option letters. Here are the possible letters for use in pass and letters, and their meanings:

-fdump-rtl-alignments
Dump after branch alignments have been computed.
-fdump-rtl-asmcons
Dump after fixing rtl statements that have unsatisfied in/out constraints.
-fdump-rtl-auto_inc_dec
Dump after auto-inc-dec discovery. This pass is only run on architectures that have auto inc or auto dec instructions.
-fdump-rtl-barriers
Dump after cleaning up the barrier instructions.
-fdump-rtl-bbpart
Dump after partitioning hot and cold basic blocks.
-fdump-rtl-bbro
Dump after block reordering.
-fdump-rtl-btl1
-fdump-rtl-btl2
-fdump-rtl-btl1 and -fdump-rtl-btl2 enable dumping after the two branch target load optimization passes.
-fdump-rtl-bypass
Dump after jump bypassing and control flow optimizations.
-fdump-rtl-combine
Dump after the RTL instruction combination pass.
-fdump-rtl-compgotos
Dump after duplicating the computed gotos.
-fdump-rtl-ce1
-fdump-rtl-ce2
-fdump-rtl-ce3
-fdump-rtl-ce1, -fdump-rtl-ce2, and -fdump-rtl-ce3 enable dumping after the three if conversion passes.
-fdump-rtl-cprop_hardreg
Dump after hard register copy propagation.
-fdump-rtl-csa
Dump after combining stack adjustments.
-fdump-rtl-cse1
-fdump-rtl-cse2
-fdump-rtl-cse1 and -fdump-rtl-cse2 enable dumping after the two common sub-expression elimination passes.
-fdump-rtl-dce
Dump after the standalone dead code elimination passes.
-fdump-rtl-dbr
Dump after delayed branch scheduling.
-fdump-rtl-dce1
-fdump-rtl-dce2
-fdump-rtl-dce1 and -fdump-rtl-dce2 enable dumping after the two dead store elimination passes.
-fdump-rtl-eh
Dump after finalization of EH handling code.
-fdump-rtl-eh_ranges
Dump after conversion of EH handling range regions.
-fdump-rtl-expand
Dump after RTL generation.
-fdump-rtl-fwprop1
-fdump-rtl-fwprop2
-fdump-rtl-fwprop1 and -fdump-rtl-fwprop2 enable dumping after the two forward propagation passes.
-fdump-rtl-gcse1
-fdump-rtl-gcse2
-fdump-rtl-gcse1 and -fdump-rtl-gcse2 enable dumping after global common subexpression elimination.
-fdump-rtl-init-regs
Dump after the initialization of the registers.
-fdump-rtl-initvals
Dump after the computation of the initial value sets.
-fdump-rtl-into_cfglayout
Dump after converting to cfglayout mode.
-fdump-rtl-ira
Dump after iterated register allocation.
-fdump-rtl-jump
Dump after the second jump optimization.
-fdump-rtl-loop2
-fdump-rtl-loop2 enables dumping after the rtl loop optimization passes.
-fdump-rtl-mach
Dump after performing the machine dependent reorganization pass, if that pass exists.
-fdump-rtl-mode_sw
Dump after removing redundant mode switches.
-fdump-rtl-rnreg
Dump after register renumbering.
-fdump-rtl-outof_cfglayout
Dump after converting from cfglayout mode.
-fdump-rtl-peephole2
Dump after the peephole pass.
-fdump-rtl-postreload
Dump after post-reload optimizations.
-fdump-rtl-pro_and_epilogue
Dump after generating the function pro and epilogues.
-fdump-rtl-regmove
Dump after the register move pass.
-fdump-rtl-sched1
-fdump-rtl-sched2
-fdump-rtl-sched1 and -fdump-rtl-sched2 enable dumping after the basic block scheduling passes.
-fdump-rtl-see
Dump after sign extension elimination.
-fdump-rtl-seqabstr
Dump after common sequence discovery.
-fdump-rtl-shorten
Dump after shortening branches.
-fdump-rtl-sibling
Dump after sibling call optimizations.
-fdump-rtl-split1
-fdump-rtl-split2
-fdump-rtl-split3
-fdump-rtl-split4
-fdump-rtl-split5
-fdump-rtl-split1, -fdump-rtl-split2, -fdump-rtl-split3, -fdump-rtl-split4 and -fdump-rtl-split5 enable dumping after five rounds of instruction splitting.
-fdump-rtl-sms
Dump after modulo scheduling. This pass is only run on some architectures.
-fdump-rtl-stack
Dump after conversion from GCC 's "flat register file" registers to the x87's stack-like registers. This pass is only run on x86 variants.
-fdump-rtl-subreg1
-fdump-rtl-subreg2
-fdump-rtl-subreg1 and -fdump-rtl-subreg2 enable dumping after the two subreg expansion passes.
-fdump-rtl-unshare
Dump after all rtl has been unshared.
-fdump-rtl-vartrack
Dump after variable tracking.
-fdump-rtl-vregs
Dump after converting virtual registers to hard registers.
-fdump-rtl-web
Dump after live range splitting.
-fdump-rtl-regclass
-fdump-rtl-subregs_of_mode_init
-fdump-rtl-subregs_of_mode_finish
-fdump-rtl-dfinit
-fdump-rtl-dfinish
These dumps are defined but always produce empty files.
-fdump-rtl-all
Produce all the dumps listed above.
-dA
Annotate the assembler output with miscellaneous debugging information.

-dD

Dump all macro definitions, at the end of preprocessing, in addition to normal output.

-dH

Produce a core dump whenever an error occurs.

-dm

Print statistics on memory usage, at the end of the run, to standard error.

-dp

Annotate the assembler output with a comment indicating which pattern and alternative was used. The length of each instruction is also printed.

-dP

Dump the RTL in the assembler output as a comment before each instruction. Also turns on -dp annotation.

-dv

For each of the other indicated dump files (-fdump-rtl-pass), dump a representation of the control flow graph suitable for viewing with VCG to file.pass.vcg.

-dx

Just generate RTL for a function instead of compiling it. Usually used with -fdump-rtl-expand.

-dy

Dump debugging information during parsing, to standard error.

-fdump-noaddr
When doing debugging dumps, suppress address output. This makes it more feasible to use diff on debugging dumps for compiler invocations with different compiler binaries and/or different text / bss / data / heap / stack / dso start locations.
-fdump-unnumbered
When doing debugging dumps, suppress instruction numbers and address output. This makes it more feasible to use diff on debugging dumps for compiler invocations with different options, in particular with and without -g.
-fdump-unnumbered-links
When doing debugging dumps (see -d option above), suppress instruction numbers for the links to the previous and next instructions in a sequence.
-fdump-translation-unit (C ++ only)
-fdump-translation-unit-options (C ++ only)
Dump a representation of the tree structure for the entire translation unit to a file. The file name is made by appending .tu to the source file name. If the -options form is used, options controls the details of the dump as described for the -fdump-tree options.
-fdump-class-hierarchy (C ++ only)
-fdump-class-hierarchy-options (C ++ only)
Dump a representation of each class's hierarchy and virtual function table layout to a file. The file name is made by appending .class to the source file name. If the -options form is used, options controls the details of the dump as described for the -fdump-tree options.
-fdump-ipa-switch
Control the dumping at various stages of inter-procedural analysis language tree to a file. The file name is generated by appending a switch specific suffix to the source file name. The following dumps are possible:
all
Enables all inter-procedural analysis dumps.

cgraph
Dumps information about call-graph optimization, unused function removal, and inlining decisions.
inline
Dump after function inlining.
-fdump-statistics-option
Enable and control dumping of pass statistics in a separate file. The file name is generated by appending a suffix ending in .statistics to the source file name. If the -option form is used, -stats will cause counters to be summed over the whole compilation unit while -details will dump every event as the passes generate them. The default with no option is to sum counters for each function compiled.
-fdump-tree-switch
-fdump-tree-switch-options
Control the dumping at various stages of processing the intermediate language tree to a file. The file name is generated by appending a switch specific suffix to the source file name. If the -options form is used, options is a list of - separated options that control the details of the dump. Not all options are applicable to all dumps, those which are not meaningful will be ignored. The following options are available
address
Print the address of each node. Usually this is not meaningful as it changes according to the environment and source file. Its primary use is for tying up a dump file with a debug environment.
slim
Inhibit dumping of members of a scope or body of a function merely because that scope has been reached. Only dump such items when they are directly reachable by some other path. When dumping pretty-printed trees, this option inhibits dumping the bodies of control structures.
raw
Print a raw representation of the tree. By default, trees are pretty-printed into a C-like representation.

details
Enable more detailed dumps (not honored by every dump option).
stats
Enable dumping various statistics about the pass (not honored by every dump option).
blocks
Enable showing basic block boundaries (disabled in raw dumps).
vops
Enable showing virtual operands for every statement.
lineno
Enable showing line numbers for statements.
uid
Enable showing the unique ID ("DECL_UID") for each variable.

verbose
Enable showing the tree dump for each statement.
all
Turn on all options, except raw, slim, verbose and lineno.

The following tree dumps are possible:
original
Dump before any tree based optimization, to file.original.
optimized
Dump after all tree based optimization, to file.optimized.
gimple
Dump each function before and after the gimplification pass to a file. The file name is made by appending .gimple to the source file name.
cfg
Dump the control flow graph of each function to a file. The file name is made by appending .cfg to the source file name.

vcg

Dump the control flow graph of each function to a file in VCG format. The file name is made by appending .vcg to the source file name. Note that if the file contains more than one function, the generated file cannot be used directly by VCG . You will need to cut and paste each function's graph into its own separate file first.

ch

Dump each function after copying loop headers. The file name is made by appending .ch to the source file name.

ssa

Dump SSA related information to a file. The file name is made by appending .ssa to the source file name.

alias
Dump aliasing information for each function. The file name is made by appending .alias to the source file name.
ccp
Dump each function after CCP . The file name is made by appending .ccp to the source file name.

storeccp
Dump each function after STORE-CCP. The file name is made by appending .storeccp to the source file name.
pre
Dump trees after partial redundancy elimination. The file name is made by appending .pre to the source file name.

fre

Dump trees after full redundancy elimination. The file name is made by appending .fre to the source file name.

copyprop
Dump trees after copy propagation. The file name is made by appending .copyprop to the source file name.
store_copyprop
Dump trees after store copy-propagation. The file name is made by appending .store_copyprop to the source file name.
dce
Dump each function after dead code elimination. The file name is made by appending .dce to the source file name.

mudflap
Dump each function after adding mudflap instrumentation. The file name is made by appending .mudflap to the source file name.
sra
Dump each function after performing scalar replacement of aggregates. The file name is made by appending .sra to the source file name.

sink
Dump each function after performing code sinking. The file name is made by appending .sink to the source file name.
dom
Dump each function after applying dominator tree optimizations. The file name is made by appending .dom to the source file name.

dse

Dump each function after applying dead store elimination. The file name is made by appending .dse to the source file name.

phiopt
Dump each function after optimizing PHI nodes into straightline code. The file name is made by appending .phiopt to the source file name.
forwprop
Dump each function after forward propagating single use variables. The file name is made by appending .forwprop to the source file name.
copyrename
Dump each function after applying the copy rename optimization. The file name is made by appending .copyrename to the source file name.
nrv
Dump each function after applying the named return value optimization on generic trees. The file name is made by appending .nrv to the source file name.

vect
Dump each function after applying vectorization of loops. The file name is made by appending .vect to the source file name.
vrp
Dump each function after Value Range Propagation ( VRP ). The file name is made by appending .vrp to the source file name.

all

Enable all the available tree dumps with the flags provided in this option.

-ftree-vectorizer-verbose=n
This option controls the amount of debugging output the vectorizer prints. This information is written to standard error, unless -fdump-tree-all or -fdump-tree-vect is specified, in which case it is output to the usual dump listing file, .vect. For n=0 no diagnostic information is reported. If n=1 the vectorizer reports each loop that got vectorized, and the total number of loops that got vectorized. If n=2 the vectorizer also reports non-vectorized loops that passed the first analysis phase (vect_analyze_loop_form) - i.e. countable, inner-most, single-bb, single-entry/exit loops. This is the same verbosity level that -fdump-tree-vect-stats uses. Higher verbosity levels mean either more information dumped for each reported loop, or same amount of information reported for more loops: If n=3, alignment related information is added to the reports. If n=4, data-references related information (e.g. memory dependences, memory access-patterns) is added to the reports. If n=5, the vectorizer reports also non-vectorized inner-most loops that did not pass the first analysis phase (i.e., may not be countable, or may have complicated control-flow). If n=6, the vectorizer reports also non-vectorized nested loops. For n=7, all the information the vectorizer generates during its analysis and transformation is reported. This is the same verbosity level that -fdump-tree-vect-details uses.
-frandom-seed=string
This option provides a seed that GCC uses when it would otherwise use random numbers. It is used to generate certain symbol names that have to be different in every compiled file. It is also used to place unique stamps in coverage data files and the object files that produce them. You can use the -frandom-seed option to produce reproducibly identical object files.
The string should be different for every file you compile.

-fsched-verbose=n
On targets that use instruction scheduling, this option controls the amount of debugging output the scheduler prints. This information is written to standard error, unless -fdump-rtl-sched1 or -fdump-rtl-sched2 is specified, in which case it is output to the usual dump listing file, .sched or .sched2 respectively. However for n greater than nine, the output is always printed to standard error.
For n greater than zero, -fsched-verbose outputs the same information as -fdump-rtl-sched1 and -fdump-rtl-sched2. For n greater than one, it also output basic block probabilities, detailed ready list information and unit/insn info. For n greater than two, it includes RTL at abort point, control-flow and regions info. And for n over four, -fsched-verbose also includes dependence info.

-save-temps
Store the usual "temporary" intermediate files permanently; place them in the current directory and name them based on the source file. Thus, compiling foo.c with -c -save-temps would produce files foo.i and foo.s, as well as foo.o. This creates a preprocessed foo.i output file even though the compiler now normally uses an integrated preprocessor.
When used in combination with the -x command line option, -save-temps is sensible enough to avoid over writing an input source file with the same extension as an intermediate file. The corresponding intermediate file may be obtained by renaming the source file before using -save-temps.

-time[=file]
Report the CPU time taken by each subprocess in the compilation sequence. For C source files, this is the compiler proper and assembler (plus the linker if linking is done).
Without the specification of an output file, the output looks like this:

# cc1 0.12 0.01
# as 0.00 0.01
The first number on each line is the "user time", that is time spent executing the program itself. The second number is "system time", time spent executing operating system routines on behalf of the program. Both numbers are in seconds.
With the specification of an output file, the output is appended to the named file, and it looks like this:

0.12 0.01 cc1 <options>
0.00 0.01 as <options>
The "user time" and the "system time" are moved before the program name, and the options passed to the program are displayed, so that one can later tell what file was being compiled, and with which options.
-fvar-tracking
Run variable tracking pass. It computes where variables are stored at each position in code. Better debugging information is then generated (if the debugging information format supports this information).
It is enabled by default when compiling with optimization (-Os, -O, -O2, ...), debugging information (-g) and the debug info format supports it.

-fvar-tracking-assignments
Annotate assignments to user variables early in the compilation and attempt to carry the annotations over throughout the compilation all the way to the end, in an attempt to improve debug information while optimizing.
It can be enabled even if var-tracking is disabled, in which case annotations will be created and maintained, but discarded at the end.

-fvar-tracking-assignments-toggle
Toggle -fvar-tracking-assignments, in the same way that -gtoggle toggles -g.
-print-file-name=library
Print the full absolute name of the library file library that would be used when linking---and don't do anything else. With this option, GCC does not compile or link anything; it just prints the file name.
-print-multi-directory
Print the directory name corresponding to the multilib selected by any other switches present in the command line. This directory is supposed to exist in GCC_EXEC_PREFIX .
-print-multi-lib
Print the mapping from multilib directory names to compiler switches that enable them. The directory name is separated from the switches by ;, and each switch starts with an @} instead of the @samp{-, without spaces between multiple switches. This is supposed to ease shell-processing.
-print-multi-os-directory
Print the path to OS libraries for the selected multilib, relative to some lib subdirectory. If OS libraries are present in the lib subdirectory and no multilibs are used, this is usually just ., if OS libraries are present in libsuffix sibling directories this prints e.g. ../lib64, ../lib or ../lib32, or if OS libraries are present in lib/subdir subdirectories it prints e.g. amd64, sparcv9 or ev6.
-print-prog-name=program
Like -print-file-name, but searches for a program such as cpp.
-print-libgcc-file-name
Same as -print-file-name=libgcc.a.
This is useful when you use -nostdlib or -nodefaultlibs but you do want to link with libgcc.a. You can do

gcc -nostdlib <files>... `gcc -print-libgcc-file-name`
-print-search-dirs
Print the name of the configured installation directory and a list of program and library directories gcc will search---and don't do anything else.
This is useful when gcc prints the error message installation problem, cannot exec cpp0: No such file or directory. To resolve this you either need to put cpp0 and the other compiler components where gcc expects to find them, or you can set the environment variable GCC_EXEC_PREFIX to the directory where you installed them. Don't forget the trailing /.

-print-sysroot
Print the target sysroot directory that will be used during compilation. This is the target sysroot specified either at configure time or using the --sysroot option, possibly with an extra suffix that depends on compilation options. If no target sysroot is specified, the option prints nothing.
-print-sysroot-headers-suffix
Print the suffix added to the target sysroot when searching for headers, or give an error if the compiler is not configured with such a suffix---and don't do anything else.
-dumpmachine
Print the compiler's target machine (for example, i686-pc-linux-gnu)---and don't do anything else.
-dumpversion
Print the compiler version (for example, 3.0)---and don't do anything else.
-dumpspecs
Print the compiler's built-in specs---and don't do anything else. (This is used when GCC itself is being built.)
-feliminate-unused-debug-types
Normally, when producing DWARF2 output, GCC will emit debugging information for all types declared in a compilation unit, regardless of whether or not they are actually used in that compilation unit. Sometimes this is useful, such as if, in the debugger, you want to cast a value to a type that is not actually used in your program (but is declared). More often, however, this results in a significant amount of wasted space. With this option, GCC will avoid producing debug symbol output for types that are nowhere used in the source file being compiled.
Options That Control Optimization

These options control various sorts of optimizations.
Without any optimization option, the compiler's goal is to reduce the cost of compilation and to make debugging produce the expected results. Statements are independent: if you stop the program with a breakpoint between statements, you can then assign a new value to any variable or change the program counter to any other statement in the function and get exactly the results you would expect from the source code.

Turning on optimization flags makes the compiler attempt to improve the performance and/or code size at the expense of compilation time and possibly the ability to debug the program.

The compiler performs optimization based on the knowledge it has of the program. Compiling multiple files at once to a single output file mode allows the compiler to use information gained from all of the files when compiling each of them.

Not all optimizations are controlled directly by a flag. Only optimizations that have a flag are listed.

-O
-O1

Optimize. Optimizing compilation takes somewhat more time, and a lot more memory for a large function.

With -O, the compiler tries to reduce code size and execution time, without performing any optimizations that take a great deal of compilation time.
-O turns on the following optimization flags:

-fauto-inc-dec -fcprop-registers -fdce -fdefer-pop -fdelayed-branch -fdse -fguess-branch-probability -fif-conversion2 -fif-conversion -finline-small-functions -fipa-pure-const -fipa-reference -fmerge-constants -fsplit-wide-types -ftree-builtin-call-dce -ftree-ccp -ftree-ch -ftree-copyrename -ftree-dce -ftree-dominator-opts -ftree-dse -ftree-fre -ftree-sra -ftree-ter -funit-at-a-time

-O also turns on -fomit-frame-pointer on machines where doing so does not interfere with debugging.

-O2
Optimize even more. GCC performs nearly all supported optimizations that do not involve a space-speed tradeoff. As compared to -O, this option increases both compilation time and the performance of the generated code.

-O2 turns on all optimization flags specified by -O. It also turns on the following optimization flags: -fthread-jumps -falign-functions -falign-jumps -falign-loops -falign-labels -fcaller-saves -fcrossjumping -fcse-follow-jumps -fcse-skip-blocks -fdelete-null-pointer-checks -fexpensive-optimizations -fgcse -fgcse-lm -findirect-inlining -foptimize-sibling-calls -fpeephole2 -fregmove -freorder-blocks -freorder-functions -frerun-cse-after-loop -fsched-interblock -fsched-spec -fschedule-insns -fschedule-insns2 -fstrict-aliasing -fstrict-overflow -ftree-switch-conversion -ftree-pre -ftree-vrp
Please note the warning under -fgcse about invoking -O2 on programs that use computed gotos.

-O3
Optimize yet more. -O3 turns on all optimizations specified by -O2 and also turns on the -finline-functions, -funswitch-loops, -fpredictive-commoning, -fgcse-after-reload, -ftree-vectorize and -fipa-cp-clone options.

-O0

Reduce compilation time and make debugging produce the expected results. This is the default.

-Os

Optimize for size. -Os enables all -O2 optimizations that do not typically increase code size. It also performs further optimizations designed to reduce code size.

-Os disables the following optimization flags: -falign-functions -falign-jumps -falign-loops -falign-labels -freorder-blocks -freorder-blocks-and-partition -fprefetch-loop-arrays -ftree-vect-loop-version
If you use multiple -O options, with or without level numbers, the last such option is the one that is effective.

Options of the form -fflag specify machine-independent flags. Most flags have both positive and negative forms; the negative form of -ffoo would be -fno-foo. In the table below, only one of the forms is listed---the one you typically will use. You can figure out the other form by either removing no- or adding it.
The following options control specific optimizations. They are either activated by -O options or are related to ones that are. You can use the following flags in the rare cases when "fine-tuning" of optimizations to be performed is desired.

-fno-default-inline
Do not make member functions inline by default merely because they are defined inside the class scope (C ++ only). Otherwise, when you specify -O, member functions defined inside class scope are compiled inline by default; i.e., you don't need to add inline in front of the member function name.
-fno-defer-pop
Always pop the arguments to each function call as soon as that function returns. For machines which must pop arguments after a function call, the compiler normally lets arguments accumulate on the stack for several function calls and pops them all at once.
Disabled at levels -O, -O2, -O3, -Os.

-fforward-propagate
Perform a forward propagation pass on RTL . The pass tries to combine two instructions and checks if the result can be simplified. If loop unrolling is active, two passes are performed and the second is scheduled after loop unrolling.
This option is enabled by default at optimization levels -O2, -O3, -Os.

-fomit-frame-pointer
Don't keep the frame pointer in a register for functions that don't need one. This avoids the instructions to save, set up and restore frame pointers; it also makes an extra register available in many functions. It also makes debugging impossible on some machines.
On some machines, such as the VAX , this flag has no effect, because the standard calling sequence automatically handles the frame pointer and nothing is saved by pretending it doesn't exist. The machine-description macro "FRAME_POINTER_REQUIRED" controls whether a target machine supports this flag.

Enabled at levels -O, -O2, -O3, -Os.

-foptimize-sibling-calls
Optimize sibling and tail recursive calls.
Enabled at levels -O2, -O3, -Os.

-fno-inline
Don't pay attention to the "inline" keyword. Normally this option is used to keep the compiler from expanding any functions inline. Note that if you are not optimizing, no functions can be expanded inline.
-finline-small-functions
Integrate functions into their callers when their body is smaller than expected function call code (so overall size of program gets smaller). The compiler heuristically decides which functions are simple enough to be worth integrating in this way.
Enabled at level -O2.

-findirect-inlining
Inline also indirect calls that are discovered to be known at compile time thanks to previous inlining. This option has any effect only when inlining itself is turned on by the -finline-functions or -finline-small-functions options.
Enabled at level -O2.

-finline-functions
Integrate all simple functions into their callers. The compiler heuristically decides which functions are simple enough to be worth integrating in this way.
If all calls to a given function are integrated, and the function is declared "static", then the function is normally not output as assembler code in its own right.

Enabled at level -O3.

-finline-functions-called-once
Consider all "static" functions called once for inlining into their caller even if they are not marked "inline". If a call to a given function is integrated, then the function is not output as assembler code in its own right.
Enabled at levels -O1, -O2, -O3 and -Os.

-fearly-inlining
Inline functions marked by "always_inline" and functions whose body seems smaller than the function call overhead early before doing -fprofile-generate instrumentation and real inlining pass. Doing so makes profiling significantly cheaper and usually inlining faster on programs having large chains of nested wrapper functions.
Enabled by default.

-finline-limit=n
By default, GCC limits the size of functions that can be inlined. This flag allows coarse control of this limit. n is the size of functions that can be inlined in number of pseudo instructions.
Inlining is actually controlled by a number of parameters, which may be specified individually by using --param name=value. The -finline-limit=n option sets some of these parameters as follows:

max-inline-insns-single
is set to n/2.
max-inline-insns-auto
is set to n/2.
See below for a documentation of the individual parameters controlling inlining and for the defaults of these parameters.
Note: there may be no value to -finline-limit that results in default behavior.

Note: pseudo instruction represents, in this particular context, an abstract measurement of function's size. In no way does it represent a count of assembly instructions and as such its exact meaning might change from one release to an another.

-fkeep-inline-functions
In C, emit "static" functions that are declared "inline" into the object file, even if the function has been inlined into all of its callers. This switch does not affect functions using the "extern inline" extension in GNU C89. In C ++ , emit any and all inline functions into the object file.
-fkeep-static-consts
Emit variables declared "static const" when optimization isn't turned on, even if the variables aren't referenced.
GCC enables this option by default. If you want to force the compiler to check if the variable was referenced, regardless of whether or not optimization is turned on, use the -fno-keep-static-consts option.

-fmerge-constants
Attempt to merge identical constants (string constants and floating point constants) across compilation units.
This option is the default for optimized compilation if the assembler and linker support it. Use -fno-merge-constants to inhibit this behavior.

Enabled at levels -O, -O2, -O3, -Os.

-fmerge-all-constants
Attempt to merge identical constants and identical variables.
This option implies -fmerge-constants. In addition to -fmerge-constants this considers e.g. even constant initialized arrays or initialized constant variables with integral or floating point types. Languages like C or C ++ require each variable, including multiple instances of the same variable in recursive calls, to have distinct locations, so using this option will result in non-conforming behavior.

-fmodulo-sched
Perform swing modulo scheduling immediately before the first scheduling pass. This pass looks at innermost loops and reorders their instructions by overlapping different iterations.
-fmodulo-sched-allow-regmoves
Perform more aggressive SMS based modulo scheduling with register moves allowed. By setting this flag certain anti-dependences edges will be deleted which will trigger the generation of reg-moves based on the life-range analysis. This option is effective only with -fmodulo-sched enabled.
-fno-branch-count-reg
Do not use "decrement and branch" instructions on a count register, but instead generate a sequence of instructions that decrement a register, compare it against zero, then branch based upon the result. This option is only meaningful on architectures that support such instructions, which include x86, PowerPC, IA-64 and S/390.
The default is -fbranch-count-reg.

-fno-function-cse
Do not put function addresses in registers; make each instruction that calls a constant function contain the function's address explicitly.
This option results in less efficient code, but some strange hacks that alter the assembler output may be confused by the optimizations performed when this option is not used.

The default is -ffunction-cse

-fno-zero-initialized-in-bss
If the target supports a BSS section, GCC by default puts variables that are initialized to zero into BSS . This can save space in the resulting code.
This option turns off this behavior because some programs explicitly rely on variables going to the data section. E.g., so that the resulting executable can find the beginning of that section and/or make assumptions based on that.

The default is -fzero-initialized-in-bss.

-fmudflap -fmudflapth -fmudflapir
For front-ends that support it (C and C ++ ), instrument all risky pointer/array dereferencing operations, some standard library string/heap functions, and some other associated constructs with range/validity tests. Modules so instrumented should be immune to buffer overflows, invalid heap use, and some other classes of C/C ++ programming errors. The instrumentation relies on a separate runtime library (libmudflap), which will be linked into a program if -fmudflap is given at link time. Run-time behavior of the instrumented program is controlled by the MUDFLAP_OPTIONS environment variable. See "env MUDFLAP_OPTIONS=-help a.out" for its options.
Use -fmudflapth instead of -fmudflap to compile and to link if your program is multi-threaded. Use -fmudflapir, in addition to -fmudflap or -fmudflapth, if instrumentation should ignore pointer reads. This produces less instrumentation (and therefore faster execution) and still provides some protection against outright memory corrupting writes, but allows erroneously read data to propagate within a program.

-fthread-jumps
Perform optimizations where we check to see if a jump branches to a location where another comparison subsumed by the first is found. If so, the first branch is redirected to either the destination of the second branch or a point immediately following it, depending on whether the condition is known to be true or false.
Enabled at levels -O2, -O3, -Os.

-fsplit-wide-types
When using a type that occupies multiple registers, such as "long long" on a 32-bit system, split the registers apart and allocate them independently. This normally generates better code for those types, but may make debugging more difficult.
Enabled at levels -O, -O2, -O3, -Os.

-fcse-follow-jumps
In common subexpression elimination ( CSE ), scan through jump instructions when the target of the jump is not reached by any other path. For example, when CSE encounters an "if" statement with an "else" clause, CSE will follow the jump when the condition tested is false.
Enabled at levels -O2, -O3, -Os.

-fcse-skip-blocks
This is similar to -fcse-follow-jumps, but causes CSE to follow jumps which conditionally skip over blocks. When CSE encounters a simple "if" statement with no else clause, -fcse-skip-blocks causes CSE to follow the jump around the body of the "if".
Enabled at levels -O2, -O3, -Os.

-frerun-cse-after-loop
Re-run common subexpression elimination after loop optimizations has been performed.
Enabled at levels -O2, -O3, -Os.

-fgcse
Perform a global common subexpression elimination pass. This pass also performs global constant and copy propagation.
Note: When compiling a program using computed gotos, a GCC extension, you may get better runtime performance if you disable the global common subexpression elimination pass by adding -fno-gcse to the command line.

Enabled at levels -O2, -O3, -Os.

-fgcse-lm
When -fgcse-lm is enabled, global common subexpression elimination will attempt to move loads which are only killed by stores into themselves. This allows a loop containing a load/store sequence to be changed to a load outside the loop, and a copy/store within the loop.
Enabled by default when gcse is enabled.

-fgcse-sm
When -fgcse-sm is enabled, a store motion pass is run after global common subexpression elimination. This pass will attempt to move stores out of loops. When used in conjunction with -fgcse-lm, loops containing a load/store sequence can be changed to a load before the loop and a store after the loop.
Not enabled at any optimization level.

-fgcse-las
When -fgcse-las is enabled, the global common subexpression elimination pass eliminates redundant loads that come after stores to the same memory location (both partial and full redundancies).
Not enabled at any optimization level.

-fgcse-after-reload
When -fgcse-after-reload is enabled, a redundant load elimination pass is performed after reload. The purpose of this pass is to cleanup redundant spilling.
-funsafe-loop-optimizations
If given, the loop optimizer will assume that loop indices do not overflow, and that the loops with nontrivial exit condition are not infinite. This enables a wider range of loop optimizations even if the loop optimizer itself cannot prove that these assumptions are valid. Using -Wunsafe-loop-optimizations, the compiler will warn you if it finds this kind of loop.
-fcrossjumping
Perform cross-jumping transformation. This transformation unifies equivalent code and save code size. The resulting code may or may not perform better than without cross-jumping.
Enabled at levels -O2, -O3, -Os.

-fauto-inc-dec
Combine increments or decrements of addresses with memory accesses. This pass is always skipped on architectures that do not have instructions to support this. Enabled by default at -O and higher on architectures that support this.
-fdce
Perform dead code elimination ( DCE ) on RTL . Enabled by default at -O and higher.
-fdse
Perform dead store elimination ( DSE ) on RTL . Enabled by default at -O and higher.
-fif-conversion
Attempt to transform conditional jumps into branch-less equivalents. This include use of conditional moves, min, max, set flags and abs instructions, and some tricks doable by standard arithmetics. The use of conditional execution on chips where it is available is controlled by "if-conversion2".
Enabled at levels -O, -O2, -O3, -Os.

-fif-conversion2
Use conditional execution (where available) to transform conditional jumps into branch-less equivalents.
Enabled at levels -O, -O2, -O3, -Os.

-fdelete-null-pointer-checks
Use global dataflow analysis to identify and eliminate useless checks for null pointers. The compiler assumes that dereferencing a null pointer would have halted the program. If a pointer is checked after it has already been dereferenced, it cannot be null.
In some environments, this assumption is not true, and programs can safely dereference null pointers. Use -fno-delete-null-pointer-checks to disable this optimization for programs which depend on that behavior.

Enabled at levels -O2, -O3, -Os.

-fexpensive-optimizations
Perform a number of minor optimizations that are relatively expensive.
Enabled at levels -O2, -O3, -Os.

-foptimize-register-move
-fregmove
Attempt to reassign register numbers in move instructions and as operands of other simple instructions in order to maximize the amount of register tying. This is especially helpful on machines with two-operand instructions.
Note -fregmove and -foptimize-register-move are the same optimization.

Enabled at levels -O2, -O3, -Os.

-fira-algorithm=algorithm
Use specified coloring algorithm for the integrated register allocator. The algorithm argument should be "priority" or "CB". The first algorithm specifies Chow's priority coloring, the second one specifies Chaitin-Briggs coloring. The second algorithm can be unimplemented for some architectures. If it is implemented, it is the default because Chaitin-Briggs coloring as a rule generates a better code.
-fira-region=region
Use specified regions for the integrated register allocator. The region argument should be one of "all", "mixed", or "one". The first value means using all loops as register allocation regions, the second value which is the default means using all loops except for loops with small register pressure as the regions, and third one means using all function as a single region. The first value can give best result for machines with small size and irregular register set, the third one results in faster and generates decent code and the smallest size code, and the default value usually give the best results in most cases and for most architectures.
-fira-coalesce
Do optimistic register coalescing. This option might be profitable for architectures with big regular register files.
-fno-ira-share-save-slots
Switch off sharing stack slots used for saving call used hard registers living through a call. Each hard register will get a separate stack slot and as a result function stack frame will be bigger.
-fno-ira-share-spill-slots
Switch off sharing stack slots allocated for pseudo-registers. Each pseudo-register which did not get a hard register will get a separate stack slot and as a result function stack frame will be bigger.
-fira-verbose=n
Set up how verbose dump file for the integrated register allocator will be. Default value is 5. If the value is greater or equal to 10, the dump file will be stderr as if the value were n minus 10.
-fdelayed-branch
If supported for the target machine, attempt to reorder instructions to exploit instruction slots available after delayed branch instructions.
Enabled at levels -O, -O2, -O3, -Os.

-fschedule-insns
If supported for the target machine, attempt to reorder instructions to eliminate execution stalls due to required data being unavailable. This helps machines that have slow floating point or memory load instructions by allowing other instructions to be issued until the result of the load or floating point instruction is required.
Enabled at levels -O2, -O3, -Os.

-fschedule-insns2
Similar to -fschedule-insns, but requests an additional pass of instruction scheduling after register allocation has been done. This is especially useful on machines with a relatively small number of registers and where memory load instructions take more than one cycle.
Enabled at levels -O2, -O3, -Os.

-fno-sched-interblock
Don't schedule instructions across basic blocks. This is normally enabled by default when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
-fno-sched-spec
Don't allow speculative motion of non-load instructions. This is normally enabled by default when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
-fsched-spec-load
Allow speculative motion of some load instructions. This only makes sense when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
-fsched-spec-load-dangerous
Allow speculative motion of more load instructions. This only makes sense when scheduling before register allocation, i.e. with -fschedule-insns or at -O2 or higher.
-fsched-stalled-insns
-fsched-stalled-insns=n
Define how many insns (if any) can be moved prematurely from the queue of stalled insns into the ready list, during the second scheduling pass. -fno-sched-stalled-insns means that no insns will be moved prematurely, -fsched-stalled-insns=0 means there is no limit on how many queued insns can be moved prematurely. -fsched-stalled-insns without a value is equivalent to -fsched-stalled-insns=1.
-fsched-stalled-insns-dep
-fsched-stalled-insns-dep=n
Define how many insn groups (cycles) will be examined for a dependency on a stalled insn that is candidate for premature removal from the queue of stalled insns. This has an effect only during the second scheduling pass, and only if -fsched-stalled-insns is used. -fno-sched-stalled-insns-dep is equivalent to -fsched-stalled-insns-dep=0. -fsched-stalled-insns-dep without a value is equivalent to -fsched-stalled-insns-dep=1.
-fsched2-use-superblocks
When scheduling after register allocation, do use superblock scheduling algorithm. Superblock scheduling allows motion across basic block boundaries resulting on faster schedules. This option is experimental, as not all machine descriptions used by GCC model the CPU closely enough to avoid unreliable results from the algorithm.
This only makes sense when scheduling after register allocation, i.e. with -fschedule-insns2 or at -O2 or higher.

-fsched2-use-traces
Use -fsched2-use-superblocks algorithm when scheduling after register allocation and additionally perform code duplication in order to increase the size of superblocks using tracer pass. See -ftracer for details on trace formation.
This mode should produce faster but significantly longer programs. Also without -fbranch-probabilities the traces constructed may not match the reality and hurt the performance. This only makes sense when scheduling after register allocation, i.e. with -fschedule-insns2 or at -O2 or higher.

-fsee
Eliminate redundant sign extension instructions and move the non-redundant ones to optimal placement using lazy code motion ( LCM ).
-freschedule-modulo-scheduled-loops
The modulo scheduling comes before the traditional scheduling, if a loop was modulo scheduled we may want to prevent the later scheduling passes from changing its schedule, we use this option to control that.
-fselective-scheduling
Schedule instructions using selective scheduling algorithm. Selective scheduling runs instead of the first scheduler pass.
-fselective-scheduling2
Schedule instructions using selective scheduling algorithm. Selective scheduling runs instead of the second scheduler pass.
-fsel-sched-pipelining
Enable software pipelining of innermost loops during selective scheduling. This option has no effect until one of -fselective-scheduling or -fselective-scheduling2 is turned on.
-fsel-sched-pipelining-outer-loops
When pipelining loops during selective scheduling, also pipeline outer loops. This option has no effect until -fsel-sched-pipelining is turned on.
-fcaller-saves
Enable values to be allocated in registers that will be clobbered by function calls, by emitting extra instructions to save and restore the registers around such calls. Such allocation is done only when it seems to result in better code than would otherwise be produced.
This option is always enabled by default on certain machines, usually those which have no call-preserved registers to use instead.

Enabled at levels -O2, -O3, -Os.

-fconserve-stack
Attempt to minimize stack usage. The compiler will attempt to use less stack space, even if that makes the program slower. This option implies setting the large-stack-frame parameter to 100 and the large-stack-frame-growth parameter to 400.
-ftree-reassoc
Perform reassociation on trees. This flag is enabled by default at -O and higher.
-ftree-pre
Perform partial redundancy elimination ( PRE ) on trees. This flag is enabled by default at -O2 and -O3.
-ftree-fre
Perform full redundancy elimination ( FRE ) on trees. The difference between FRE and PRE is that FRE only considers expressions that are computed on all paths leading to the redundant computation. This analysis is faster than PRE , though it exposes fewer redundancies. This flag is enabled by default at -O and higher.
-ftree-copy-prop
Perform copy propagation on trees. This pass eliminates unnecessary copy operations. This flag is enabled by default at -O and higher.
-fipa-pure-const
Discover which functions are pure or constant. Enabled by default at -O and higher.
-fipa-reference
Discover which static variables do not escape cannot escape the compilation unit. Enabled by default at -O and higher.
-fipa-struct-reorg
Perform structure reorganization optimization, that change C-like structures layout in order to better utilize spatial locality. This transformation is effective for programs containing arrays of structures. Available in two compilation modes: profile-based (enabled with -fprofile-generate) or static (which uses built-in heuristics). Require -fipa-type-escape to provide the safety of this transformation. It works only in whole program mode, so it requires -fwhole-program and -combine to be enabled. Structures considered cold by this transformation are not affected (see --param struct-reorg-cold-struct-ratio=value).
With this flag, the program debug info reflects a new structure layout.

-fipa-pta
Perform interprocedural pointer analysis. This option is experimental and does not affect generated code.
-fipa-cp
Perform interprocedural constant propagation. This optimization analyzes the program to determine when values passed to functions are constants and then optimizes accordingly. This optimization can substantially increase performance if the application has constants passed to functions. This flag is enabled by default at -O2, -Os and -O3.
-fipa-cp-clone
Perform function cloning to make interprocedural constant propagation stronger. When enabled, interprocedural constant propagation will perform function cloning when externally visible function can be called with constant arguments. Because this optimization can create multiple copies of functions, it may significantly increase code size (see --param ipcp-unit-growth=value). This flag is enabled by default at -O3.
-fipa-matrix-reorg
Perform matrix flattening and transposing. Matrix flattening tries to replace a m-dimensional matrix with its equivalent n-dimensional matrix, where n < m. This reduces the level of indirection needed for accessing the elements of the matrix. The second optimization is matrix transposing that attempts to change the order of the matrix's dimensions in order to improve cache locality. Both optimizations need the -fwhole-program flag. Transposing is enabled only if profiling information is available.
-ftree-sink
Perform forward store motion on trees. This flag is enabled by default at -O and higher.
-ftree-ccp
Perform sparse conditional constant propagation ( CCP ) on trees. This pass only operates on local scalar variables and is enabled by default at -O and higher.
-ftree-switch-conversion
Perform conversion of simple initializations in a switch to initializations from a scalar array. This flag is enabled by default at -O2 and higher.
-ftree-dce
Perform dead code elimination ( DCE ) on trees. This flag is enabled by default at -O and higher.
-ftree-builtin-call-dce
Perform conditional dead code elimination ( DCE ) for calls to builtin functions that may set "errno" but are otherwise side-effect free. This flag is enabled by default at -O2 and higher if -Os is not also specified.
-ftree-dominator-opts
Perform a variety of simple scalar cleanups (constant/copy propagation, redundancy elimination, range propagation and expression simplification) based on a dominator tree traversal. This also performs jump threading (to reduce jumps to jumps). This flag is enabled by default at -O and higher.
-ftree-dse
Perform dead store elimination ( DSE ) on trees. A dead store is a store into a memory location which will later be overwritten by another store without any intervening loads. In this case the earlier store can be deleted. This flag is enabled by default at -O and higher.
-ftree-ch
Perform loop header copying on trees. This is beneficial since it increases effectiveness of code motion optimizations. It also saves one jump. This flag is enabled by default at -O and higher. It is not enabled for -Os, since it usually increases code size.
-ftree-loop-optimize
Perform loop optimizations on trees. This flag is enabled by default at -O and higher.
-ftree-loop-linear
Perform linear loop transformations on tree. This flag can improve cache performance and allow further loop optimizations to take place.
-floop-interchange
Perform loop interchange transformations on loops. Interchanging two nested loops switches the inner and outer loops. For example, given a loop like:
DO J = 1, M
  DO I = 1, N
    A(J, I) = A(J, I) * C
  ENDDO
ENDDO
loop interchange will transform the loop as if the user had written:
DO I = 1, N
  DO J = 1, M
    A(J, I) = A(J, I) * C
  ENDDO
ENDDO
which can be beneficial when "N" is larger than the caches, because in Fortran, the elements of an array are stored in memory contiguously by column, and the original loop iterates over rows, potentially creating at each access a cache miss. This optimization applies to all the languages supported by GCC and is not limited to Fortran. To use this code transformation, GCC has to be configured with --with-ppl and --with-cloog to enable the Graphite loop transformation infrastructure.
-floop-strip-mine
Perform loop strip mining transformations on loops. Strip mining splits a loop into two nested loops. The outer loop has strides equal to the strip size and the inner loop has strides of the original loop within a strip. For example, given a loop like:
DO I = 1, N
  A(I) = A(I) + C
ENDDO
loop strip mining will transform the loop as if the user had written:
DO II = 1, N, 4
  DO I = II, min (II + 3, N)
    A(I) = A(I) + C
  ENDDO
ENDDO
This optimization applies to all the languages supported by GCC and is not limited to Fortran. To use this code transformation, GCC has to be configured with --with-ppl and --with-cloog to enable the Graphite loop transformation infrastructure.
-floop-block
Perform loop blocking transformations on loops. Blocking strip mines each loop in the loop nest such that the memory accesses of the element loops fit inside caches. For example, given a loop like:
DO I = 1, N
  DO J = 1, M
    A(J, I) = B(I) + C(J)
  ENDDO
ENDDO
loop blocking will transform the loop as if the user had written:
DO II = 1, N, 64
  DO JJ = 1, M, 64
    DO I = II, min (II + 63, N)
      DO J = JJ, min (JJ + 63, M)
        A(J, I) = B(I) + C(J)
      ENDDO
    ENDDO
  ENDDO
ENDDO
which can be beneficial when "M" is larger than the caches, because the innermost loop will iterate over a smaller amount of data that can be kept in the caches. This optimization applies to all the languages supported by GCC and is not limited to Fortran. To use this code transformation, GCC has to be configured with --with-ppl and --with-cloog to enable the Graphite loop transformation infrastructure.
-fcheck-data-deps
Compare the results of several data dependence analyzers. This option is used for debugging the data dependence analyzers.
-ftree-loop-distribution
Perform loop distribution. This flag can improve cache performance on big loop bodies and allow further loop optimizations, like parallelization or vectorization, to take place. For example, the loop
DO I = 1, N
  A(I) = B(I) + C
  D(I) = E(I) * F
ENDDO
is transformed to
DO I = 1, N
   A(I) = B(I) + C
ENDDO
DO I = 1, N
   D(I) = E(I) * F
ENDDO
-ftree-loop-im
Perform loop invariant motion on trees. This pass moves only invariants that would be hard to handle at RTL level (function calls, operations that expand to nontrivial sequences of insns). With -funswitch-loops it also moves operands of conditions that are invariant out of the loop, so that we can use just trivial invariantness analysis in loop unswitching. The pass also includes store motion.
-ftree-loop-ivcanon
Create a canonical counter for number of iterations in the loop for that determining number of iterations requires complicated analysis. Later optimizations then may determine the number easily. Useful especially in connection with unrolling.
-fivopts
Perform induction variable optimizations (strength reduction, induction variable merging and induction variable elimination) on trees.
-ftree-parallelize-loops=n
Parallelize loops, i.e., split their iteration space to run in n threads. This is only possible for loops whose iterations are independent and can be arbitrarily reordered. The optimization is only profitable on multiprocessor machines, for loops that are CPU-intensive, rather than constrained e.g. by memory bandwidth. This option implies -pthread, and thus is only supported on targets that have support for -pthread.
-ftree-sra
Perform scalar replacement of aggregates. This pass replaces structure references with scalars to prevent committing structures to memory too early. This flag is enabled by default at -O and higher.
-ftree-copyrename
Perform copy renaming on trees. This pass attempts to rename compiler temporaries to other variables at copy locations, usually resulting in variable names which more closely resemble the original variables. This flag is enabled by default at -O and higher.
-ftree-coalesce-inlined-vars
Permit the copyrename pass to subject inlined variables to coalescing into other variables. This may harm debug information of such inlined variables, but it will keep variables of the main function apart from each other, such that they are more likely to contain the expected values in a debugging session.
-ftree-coalesce-vars
Permit the copyrename pass to subject all variables to SSA coalescing. This may severely limit the ability to debug an optimized program compiled without -fvar-tracking-assignments. In the negated form, this flag prevents SSA coalescing of user variables, including inlined ones.
-ftree-ter
Perform temporary expression replacement during the SSA- >normal phase. Single use/single def temporaries are replaced at their use location with their defining expression. This results in non-GIMPLE code, but gives the expanders much more complex trees to work on resulting in better RTL generation. This is enabled by default at -O and higher.
-ftree-vectorize
Perform loop vectorization on trees. This flag is enabled by default at -O3.
-ftree-vect-loop-version
Perform loop versioning when doing loop vectorization on trees. When a loop appears to be vectorizable except that data alignment or data dependence cannot be determined at compile time then vectorized and non-vectorized versions of the loop are generated along with runtime checks for alignment or dependence to control which version is executed. This option is enabled by default except at level -Os where it is disabled.
-fvect-cost-model
Enable cost model for vectorization.
-ftree-vrp
Perform Value Range Propagation on trees. This is similar to the constant propagation pass, but instead of values, ranges of values are propagated. This allows the optimizers to remove unnecessary range checks like array bound checks and null pointer checks. This is enabled by default at -O2 and higher. Null pointer check elimination is only done if -fdelete-null-pointer-checks is enabled.
-ftracer
Perform tail duplication to enlarge superblock size. This transformation simplifies the control flow of the function allowing other optimizations to do better job.
-funroll-loops
Unroll loops whose number of iterations can be determined at compile time or upon entry to the loop. -funroll-loops implies -frerun-cse-after-loop. This option makes code larger, and may or may not make it run faster.
-funroll-all-loops
Unroll all loops, even if their number of iterations is uncertain when the loop is entered. This usually makes programs run more slowly. -funroll-all-loops implies the same options as -funroll-loops,
-fsplit-ivs-in-unroller
Enables expressing of values of induction variables in later iterations of the unrolled loop using the value in the first iteration. This breaks long dependency chains, thus improving efficiency of the scheduling passes.
Combination of -fweb and CSE is often sufficient to obtain the same effect. However in cases the loop body is more complicated than a single basic block, this is not reliable. It also does not work at all on some of the architectures due to restrictions in the CSE pass.

This optimization is enabled by default.

-fvariable-expansion-in-unroller
With this option, the compiler will create multiple copies of some local variables when unrolling a loop which can result in superior code.
-fpredictive-commoning
Perform predictive commoning optimization, i.e., reusing computations (especially memory loads and stores) performed in previous iterations of loops.
This option is enabled at level -O3.

-fprefetch-loop-arrays
If supported by the target machine, generate instructions to prefetch memory to improve the performance of loops that access large arrays.
This option may generate better or worse code; results are highly dependent on the structure of loops within the source code.

Disabled at level -Os.

-fno-peephole
-fno-peephole2
Disable any machine-specific peephole optimizations. The difference between -fno-peephole and -fno-peephole2 is in how they are implemented in the compiler; some targets use one, some use the other, a few use both.
-fpeephole is enabled by default. -fpeephole2 enabled at levels -O2, -O3, -Os.

-fno-guess-branch-probability
Do not guess branch probabilities using heuristics.
GCC will use heuristics to guess branch probabilities if they are not provided by profiling feedback (-fprofile-arcs). These heuristics are based on the control flow graph. If some branch probabilities are specified by __builtin_expect, then the heuristics will be used to guess branch probabilities for the rest of the control flow graph, taking the __builtin_expect info into account. The interactions between the heuristics and __builtin_expect can be complex, and in some cases, it may be useful to disable the heuristics so that the effects of __builtin_expect are easier to understand.

The default is -fguess-branch-probability at levels -O, -O2, -O3, -Os.

-freorder-blocks
Reorder basic blocks in the compiled function in order to reduce number of taken branches and improve code locality.
Enabled at levels -O2, -O3.

-freorder-blocks-and-partition
In addition to reordering basic blocks in the compiled function, in order to reduce number of taken branches, partitions hot and cold basic blocks into separate sections of the assembly and .o files, to improve paging and cache locality performance.
This optimization is automatically turned off in the presence of exception handling, for linkonce sections, for functions with a user-defined section attribute and on any architecture that does not support named sections.

-freorder-functions
Reorder functions in the object file in order to improve code locality. This is implemented by using special subsections ".text.hot" for most frequently executed functions and ".text.unlikely" for unlikely executed functions. Reordering is done by the linker so object file format must support named sections and linker must place them in a reasonable way.
Also profile feedback must be available in to make this option effective. See -fprofile-arcs for details.

Enabled at levels -O2, -O3, -Os.

-fstrict-aliasing
Allow the compiler to assume the strictest aliasing rules applicable to the language being compiled. For C (and C ++ ), this activates optimizations based on the type of expressions. In particular, an object of one type is assumed never to reside at the same address as an object of a different type, unless the types are almost the same. For example, an "unsigned int" can alias an "int", but not a "void*" or a "double". A character type may alias any other type.
Pay special attention to code like this:

union a_union {
  int i;
  double d;
};

int f() {
  union a_union t;
  t.d = 3.0;
  return t.i;
}
The practice of reading from a different union member than the one most recently written to (called "type-punning") is common. Even with -fstrict-aliasing, type-punning is allowed, provided the memory is accessed through the union type. So, the code above will work as expected. However, this code might not:
int f() {
  union a_union t;
  int* ip;
  t.d = 3.0;
  ip = &t.i;
  return *ip;
}
Similarly, access by taking the address, casting the resulting pointer and dereferencing the result has undefined behavior, even if the cast uses a union type, e.g.:
int f() {
  double d = 3.0;
  return ((union a_union *) &d)->i;
}
The -fstrict-aliasing option is enabled at levels -O2, -O3, -Os.
-fstrict-overflow
Allow the compiler to assume strict signed overflow rules, depending on the language being compiled. For C (and C ++ ) this means that overflow when doing arithmetic with signed numbers is undefined, which means that the compiler may assume that it will not happen. This permits various optimizations. For example, the compiler will assume that an expression like "i + 10 > i" will always be true for signed "i". This assumption is only valid if signed overflow is undefined, as the expression is false if "i + 10" overflows when using twos complement arithmetic. When this option is in effect any attempt to determine whether an operation on signed numbers will overflow must be written carefully to not actually involve overflow.
This option also allows the compiler to assume strict pointer semantics: given a pointer to an object, if adding an offset to that pointer does not produce a pointer to the same object, the addition is undefined. This permits the compiler to conclude that "p + u > p" is always true for a pointer "p" and unsigned integer "u". This assumption is only valid because pointer wraparound is undefined, as the expression is false if "p + u" overflows using twos complement arithmetic.

See also the -fwrapv option. Using -fwrapv means that integer signed overflow is fully defined: it wraps. When -fwrapv is used, there is no difference between -fstrict-overflow and -fno-strict-overflow for integers. With -fwrapv certain types of overflow are permitted. For example, if the compiler gets an overflow when doing arithmetic on constants, the overflowed value can still be used with -fwrapv, but not otherwise.

The -fstrict-overflow option is enabled at levels -O2, -O3, -Os.

-falign-functions
-falign-functions=n
Align the start of functions to the next power-of-two greater than n, skipping up to n bytes. For instance, -falign-functions=32 aligns functions to the next 32-byte boundary, but -falign-functions=24 would align to the next 32-byte boundary only if this can be done by skipping 23 bytes or less.
-fno-align-functions and -falign-functions=1 are equivalent and mean that functions will not be aligned.

Some assemblers only support this flag when n is a power of two; in that case, it is rounded up.

If n is not specified or is zero, use a machine-dependent default.

Enabled at levels -O2, -O3.

-falign-labels
-falign-labels=n
Align all branch targets to a power-of-two boundary, skipping up to n bytes like -falign-functions. This option can easily make code slower, because it must insert dummy operations for when the branch target is reached in the usual flow of the code.
-fno-align-labels and -falign-labels=1 are equivalent and mean that labels will not be aligned.

If -falign-loops or -falign-jumps are applicable and are greater than this value, then their values are used instead.

If n is not specified or is zero, use a machine-dependent default which is very likely to be 1, meaning no alignment.

Enabled at levels -O2, -O3.

-falign-loops
-falign-loops=n
Align loops to a power-of-two boundary, skipping up to n bytes like -falign-functions. The hope is that the loop will be executed many times, which will make up for any execution of the dummy operations.
-fno-align-loops and -falign-loops=1 are equivalent and mean that loops will not be aligned.

If n is not specified or is zero, use a machine-dependent default.

Enabled at levels -O2, -O3.

-falign-jumps
-falign-jumps=n
Align branch targets to a power-of-two boundary, for branch targets where the targets can only be reached by jumping, skipping up to n bytes like -falign-functions. In this case, no dummy operations need be executed.
-fno-align-jumps and -falign-jumps=1 are equivalent and mean that loops will not be aligned.

If n is not specified or is zero, use a machine-dependent default.

Enabled at levels -O2, -O3.

-funit-at-a-time
This option is left for compatibility reasons. -funit-at-a-time has no effect, while -fno-unit-at-a-time implies -fno-toplevel-reorder and -fno-section-anchors.
Enabled by default.

-fno-toplevel-reorder
Do not reorder top-level functions, variables, and "asm" statements. Output them in the same order that they appear in the input file. When this option is used, unreferenced static variables will not be removed. This option is intended to support existing code which relies on a particular ordering. For new code, it is better to use attributes.
Enabled at level -O0. When disabled explicitly, it also imply -fno-section-anchors that is otherwise enabled at -O0 on some targets.

-fweb
Constructs webs as commonly used for register allocation purposes and assign each web individual pseudo register. This allows the register allocation pass to operate on pseudos directly, but also strengthens several other optimization passes, such as CSE , loop optimizer and trivial dead code remover. It can, however, make debugging impossible, since variables will no longer stay in a "home register".
Enabled by default with -funroll-loops.

-fwhole-program
Assume that the current compilation unit represents whole program being compiled. All public functions and variables with the exception of "main" and those merged by attribute "externally_visible" become static functions and in a affect gets more aggressively optimized by interprocedural optimizers. While this option is equivalent to proper use of "static" keyword for programs consisting of single file, in combination with option --combine this flag can be used to compile most of smaller scale C programs since the functions and variables become local for the whole combined compilation unit, not for the single source file itself.
This option is not supported for Fortran programs.

-fcprop-registers
After register allocation and post-register allocation instruction splitting, we perform a copy-propagation pass to try to reduce scheduling dependencies and occasionally eliminate the copy.
Enabled at levels -O, -O2, -O3, -Os.

-fprofile-correction
Profiles collected using an instrumented binary for multi-threaded programs may be inconsistent due to missed counter updates. When this option is specified, GCC will use heuristics to correct or smooth out such inconsistencies. By default, GCC will emit an error message when an inconsistent profile is detected.
-fprofile-dir=path
Set the directory to search the profile data files in to path. This option affects only the profile data generated by -fprofile-generate, -ftest-coverage, -fprofile-arcs and used by -fprofile-use and -fbranch-probabilities and its related options. By default, GCC will use the current directory as path thus the profile data file will appear in the same directory as the object file.
-fprofile-generate
-fprofile-generate=path
Enable options usually used for instrumenting application to produce profile useful for later recompilation with profile feedback based optimization. You must use -fprofile-generate both when compiling and when linking your program.
The following options are enabled: "-fprofile-arcs", "-fprofile-values", "-fvpt".

If path is specified, GCC will look at the path to find the profile feedback data files. See -fprofile-dir.

-fprofile-use
-fprofile-use=path
Enable profile feedback directed optimizations, and optimizations generally profitable only with profile feedback available.
The following options are enabled: "-fbranch-probabilities", "-fvpt", "-funroll-loops", "-fpeel-loops", "-ftracer"

By default, GCC emits an error message if the feedback profiles do not match the source code. This error can be turned into a warning by using -Wcoverage-mismatch. Note this may result in poorly optimized code.

If path is specified, GCC will look at the path to find the profile feedback data files. See -fprofile-dir.

The following options control compiler behavior regarding floating point arithmetic. These options trade off between speed and correctness. All must be specifically enabled.
-ffloat-store
Do not store floating point variables in registers, and inhibit other options that might change whether a floating point value is taken from a register or memory.
This option prevents undesirable excess precision on machines such as the 68000 where the floating registers (of the 68881) keep more precision than a "double" is supposed to have. Similarly for the x86 architecture. For most programs, the excess precision does only good, but a few programs rely on the precise definition of IEEE floating point. Use -ffloat-store for such programs, after modifying them to store all pertinent intermediate computations into variables.

-ffast-math
Sets -fno-math-errno, -funsafe-math-optimizations, -ffinite-math-only, -fno-rounding-math, -fno-signaling-nans and -fcx-limited-range.
This option causes the preprocessor macro "__FAST_MATH__" to be defined.

This option is not turned on by any -O option since it can result in incorrect output for programs which depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications.

-fno-math-errno
Do not set ERRNO after calling math functions that are executed with a single instruction, e.g., sqrt. A program that relies on IEEE exceptions for math error handling may want to use this flag for speed while maintaining IEEE arithmetic compatibility.
This option is not turned on by any -O option since it can result in incorrect output for programs which depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications.

The default is -fmath-errno.

On Darwin systems, the math library never sets "errno". There is therefore no reason for the compiler to consider the possibility that it might, and -fno-math-errno is the default.

-funsafe-math-optimizations
Allow optimizations for floating-point arithmetic that (a) assume that arguments and results are valid and (b) may violate IEEE or ANSI standards. When used at link-time, it may include libraries or startup files that change the default FPU control word or other similar optimizations.
This option is not turned on by any -O option since it can result in incorrect output for programs which depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications. Enables -fno-signed-zeros, -fno-trapping-math, -fassociative-math and -freciprocal-math.

The default is -fno-unsafe-math-optimizations.

-fassociative-math
Allow re-association of operands in series of floating-point operations. This violates the ISO C and C ++ language standard by possibly changing computation result. NOTE: re-ordering may change the sign of zero as well as ignore NaNs and inhibit or create underflow or overflow (and thus cannot be used on a code which relies on rounding behavior like "(x + 2**52) - 2**52)". May also reorder floating-point comparisons and thus may not be used when ordered comparisons are required. This option requires that both -fno-signed-zeros and -fno-trapping-math be in effect. Moreover, it doesn't make much sense with -frounding-math.
The default is -fno-associative-math.

-freciprocal-math
Allow the reciprocal of a value to be used instead of dividing by the value if this enables optimizations. For example "x / y" can be replaced with "x * (1/y)" which is useful if "(1/y)" is subject to common subexpression elimination. Note that this loses precision and increases the number of flops operating on the value.
The default is -fno-reciprocal-math.

-ffinite-math-only
Allow optimizations for floating-point arithmetic that assume that arguments and results are not NaNs or +-Infs.
This option is not turned on by any -O option since it can result in incorrect output for programs which depend on an exact implementation of IEEE or ISO rules/specifications for math functions. It may, however, yield faster code for programs that do not require the guarantees of these specifications.

The default is -fno-finite-math-only.

-fno-signed-zeros
Allow optimizations for floating point arithmetic that ignore the signedness of zero. IEEE arithmetic specifies the behavior of distinct +0.0 and -0.0 values, which then prohibits simplification of expressions such as x+0.0 or 0.0*x (even with -ffinite-math-only). This option implies that the sign of a zero result isn't significant.
The default is -fsigned-zeros.

-fno-trapping-math
Compile code assuming that floating-point operations cannot generate user-visible traps. These traps include division by zero, overflow, underflow, inexact result and invalid operation. This option requires that -fno-signaling-nans be in effect. Setting this option may allow faster code if one relies on "non-stop" IEEE arithmetic, for example.
This option should never be turned on by any -O option since it can result in incorrect output for programs which depend on an exact implementation of IEEE or ISO rules/specifications for math functions.

The default is -ftrapping-math.

-frounding-math
Disable transformations and optimizations that assume default floating point rounding behavior. This is round-to-zero for all floating point to integer conversions, and round-to-nearest for all other arithmetic truncations. This option should be specified for programs that change the FP rounding mode dynamically, or that may be executed with a non-default rounding mode. This option disables constant folding of floating point expressions at compile-time (which may be affected by rounding mode) and arithmetic transformations that are unsafe in the presence of sign-dependent rounding modes.
The default is -fno-rounding-math.

This option is experimental and does not currently guarantee to disable all GCC optimizations that are affected by rounding mode. Future versions of GCC may provide finer control of this setting using C99's "FENV_ACCESS" pragma. This command line option will be used to specify the default state for "FENV_ACCESS".

-frtl-abstract-sequences
It is a size optimization method. This option is to find identical sequences of code, which can be turned into pseudo-procedures and then replace all occurrences with calls to the newly created subroutine. It is kind of an opposite of -finline-functions. This optimization runs at RTL level.
-fsignaling-nans
Compile code assuming that IEEE signaling NaNs may generate user-visible traps during floating-point operations. Setting this option disables optimizations that may change the number of exceptions visible with signaling NaNs. This option implies -ftrapping-math.
This option causes the preprocessor macro "__SUPPORT_SNAN__" to be defined.

The default is -fno-signaling-nans.

This option is experimental and does not currently guarantee to disable all GCC optimizations that affect signaling NaN behavior.

-fsingle-precision-constant
Treat floating point constant as single precision constant instead of implicitly converting it to double precision constant.
-fcx-limited-range
When enabled, this option states that a range reduction step is not needed when performing complex division. Also, there is no checking whether the result of a complex multiplication or division is "NaN + I*NaN", with an attempt to rescue the situation in that case. The default is -fno-cx-limited-range, but is enabled by -ffast-math.
This option controls the default setting of the ISO C99 "CX_LIMITED_RANGE" pragma. Nevertheless, the option applies to all languages.

-fcx-fortran-rules
Complex multiplication and division follow Fortran rules. Range reduction is done as part of complex division, but there is no checking whether the result of a complex multiplication or division is "NaN + I*NaN", with an attempt to rescue the situation in that case.
The default is -fno-cx-fortran-rules.

The following options control optimizations that may improve performance, but are not enabled by any -O options. This section includes experimental options that may produce broken code.
-fbranch-probabilities
After running a program compiled with -fprofile-arcs, you can compile it a second time using -fbranch-probabilities, to improve optimizations based on the number of times each branch was taken. When the program compiled with -fprofile-arcs exits it saves arc execution counts to a file called sourcename.gcda for each source file. The information in this data file is very dependent on the structure of the generated code, so you must use the same source code and the same optimization options for both compilations.
With -fbranch-probabilities, GCC puts a REG_BR_PROB note on each JUMP_INSN and CALL_INSN . These can be used to improve optimization. Currently, they are only used in one place: in reorg.c, instead of guessing which path a branch is mostly to take, the REG_BR_PROB values are used to exactly determine which path is taken more often.

-fprofile-values
If combined with -fprofile-arcs, it adds code so that some data about values of expressions in the program is gathered.
With -fbranch-probabilities, it reads back the data gathered from profiling values of expressions and adds REG_VALUE_PROFILE notes to instructions for their later usage in optimizations.

Enabled with -fprofile-generate and -fprofile-use.

-fvpt
If combined with -fprofile-arcs, it instructs the compiler to add a code to gather information about values of expressions.
With -fbranch-probabilities, it reads back the data gathered and actually performs the optimizations based on them. Currently the optimizations include specialization of division operation using the knowledge about the value of the denominator.

-frename-registers
Attempt to avoid false dependencies in scheduled code by making use of registers left over after register allocation. This optimization will most benefit processors with lots of registers. Depending on the debug information format adopted by the target, however, it can make debugging impossible, since variables will no longer stay in a "home register".
Enabled by default with -funroll-loops.

-ftracer
Perform tail duplication to enlarge superblock size. This transformation simplifies the control flow of the function allowing other optimizations to do better job.
Enabled with -fprofile-use.

-funroll-loops
Unroll loops whose number of iterations can be determined at compile time or upon entry to the loop. -funroll-loops implies -frerun-cse-after-loop, -fweb and -frename-registers. It also turns on complete loop peeling (i.e. complete removal of loops with small constant number of iterations). This option makes code larger, and may or may not make it run faster.
Enabled with -fprofile-use.

-funroll-all-loops
Unroll all loops, even if their number of iterations is uncertain when the loop is entered. This usually makes programs run more slowly. -funroll-all-loops implies the same options as -funroll-loops.
-fpeel-loops
Peels the loops for that there is enough information that they do not roll much (from profile feedback). It also turns on complete loop peeling (i.e. complete removal of loops with small constant number of iterations).
Enabled with -fprofile-use.

-fmove-loop-invariants
Enables the loop invariant motion pass in the RTL loop optimizer. Enabled at level -O1
-funswitch-loops
Move branches with loop invariant conditions out of the loop, with duplicates of the loop on both branches (modified according to result of the condition).
-ffunction-sections
-fdata-sections
Place each function or data item into its own section in the output file if the target supports arbitrary sections. The name of the function or the name of the data item determines the section's name in the output file.
Use these options on systems where the linker can perform optimizations to improve locality of reference in the instruction space. Most systems using the ELF object format and SPARC processors running Solaris 2 have linkers with such optimizations. AIX may have these optimizations in the future.

Only use these options when there are significant benefits from doing so. When you specify these options, the assembler and linker will create larger object and executable files and will also be slower. You will not be able to use "gprof" on all systems if you specify this option and you may have problems with debugging if you specify both this option and -g.

-fbranch-target-load-optimize
Perform branch target register load optimization before prologue / epilogue threading. The use of target registers can typically be exposed only during reload, thus hoisting loads out of loops and doing inter-block scheduling needs a separate optimization pass.
-fbranch-target-load-optimize2
Perform branch target register load optimization after prologue / epilogue threading.
-fbtr-bb-exclusive
When performing branch target register load optimization, don't reuse branch target registers in within any basic block.
-fstack-protector
Emit extra code to check for buffer overflows, such as stack smashing attacks. This is done by adding a guard variable to functions with vulnerable objects. This includes functions that call alloca, and functions with buffers larger than 8 bytes. The guards are initialized when a function is entered and then checked when the function exits. If a guard check fails, an error message is printed and the program exits.
-fstack-protector-all
Like -fstack-protector except that all functions are protected.
-fsection-anchors
Try to reduce the number of symbolic address calculations by using shared "anchor" symbols to address nearby objects. This transformation can help to reduce the number of GOT entries and GOT accesses on some targets.
For example, the implementation of the following function "foo":

static int a, b, c;
int foo (void) { return a + b + c; }
would usually calculate the addresses of all three variables, but if you compile it with -fsection-anchors, it will access the variables from a common anchor point instead. The effect is similar to the following pseudocode (which isn't valid C):
int foo (void)
{
  register int *xr = &x;
  return xr[&a - &x] + xr[&b - &x] + xr[&c - &x];
}
Not all targets support this option.
--param name=value
In some places, GCC uses various constants to control the amount of optimization that is done. For example, GCC will not inline functions that contain more that a certain number of instructions. You can control some of these constants on the command-line using the --param option.
The names of specific parameters, and the meaning of the values, are tied to the internals of the compiler, and are subject to change without notice in future releases.

In each case, the value is an integer. The allowable choices for name are given in the following table:

sra-max-structure-size
The maximum structure size, in bytes, at which the scalar replacement of aggregates ( SRA ) optimization will perform block copies. The default value, 0, implies that GCC will select the most appropriate size itself.
sra-field-structure-ratio
The threshold ratio (as a percentage) between instantiated fields and the complete structure size. We say that if the ratio of the number of bytes in instantiated fields to the number of bytes in the complete structure exceeds this parameter, then block copies are not used. The default is 75.
struct-reorg-cold-struct-ratio
The threshold ratio (as a percentage) between a structure frequency and the frequency of the hottest structure in the program. This parameter is used by struct-reorg optimization enabled by -fipa-struct-reorg. We say that if the ratio of a structure frequency, calculated by profiling, to the hottest structure frequency in the program is less than this parameter, then structure reorganization is not applied to this structure. The default is 10.
predictable-branch-cost-outcome
When branch is predicted to be taken with probability lower than this threshold (in percent), then it is considered well predictable. The default is 10.
max-crossjump-edges
The maximum number of incoming edges to consider for crossjumping. The algorithm used by -fcrossjumping is O(N^2) in the number of edges incoming to each block. Increasing values mean more aggressive optimization, making the compile time increase with probably small improvement in executable size.
min-crossjump-insns
The minimum number of instructions which must be matched at the end of two blocks before crossjumping will be performed on them. This value is ignored in the case where all instructions in the block being crossjumped from are matched. The default value is 5.
max-grow-copy-bb-insns
The maximum code size expansion factor when copying basic blocks instead of jumping. The expansion is relative to a jump instruction. The default value is 8.
max-goto-duplication-insns
The maximum number of instructions to duplicate to a block that jumps to a computed goto. To avoid O(N^2) behavior in a number of passes, GCC factors computed gotos early in the compilation process, and unfactors them as late as possible. Only computed jumps at the end of a basic blocks with no more than max-goto-duplication-insns are unfactored. The default value is 8.
max-delay-slot-insn-search
The maximum number of instructions to consider when looking for an instruction to fill a delay slot. If more than this arbitrary number of instructions is searched, the time savings from filling the delay slot will be minimal so stop searching. Increasing values mean more aggressive optimization, making the compile time increase with probably small improvement in executable run time.
max-delay-slot-live-search
When trying to fill delay slots, the maximum number of instructions to consider when searching for a block with valid live register information. Increasing this arbitrarily chosen value means more aggressive optimization, increasing the compile time. This parameter should be removed when the delay slot code is rewritten to maintain the control-flow graph.
max-gcse-memory
The approximate maximum amount of memory that will be allocated in order to perform the global common subexpression elimination optimization. If more memory than specified is required, the optimization will not be done.
max-gcse-passes
The maximum number of passes of GCSE to run. The default is 1.
max-pending-list-length
The maximum number of pending dependencies scheduling will allow before flushing the current state and starting over. Large functions with few branches or calls can create excessively large lists which needlessly consume memory and resources.
max-inline-insns-single
Several parameters control the tree inliner used in gcc. This number sets the maximum number of instructions (counted in GCC 's internal representation) in a single function that the tree inliner will consider for inlining. This only affects functions declared inline and methods implemented in a class declaration (C ++ ). The default value is 450.
max-inline-insns-auto
When you use -finline-functions (included in -O3), a lot of functions that would otherwise not be considered for inlining by the compiler will be investigated. To those functions, a different (more restrictive) limit compared to functions declared inline can be applied. The default value is 90.
large-function-insns
The limit specifying really large functions. For functions larger than this limit after inlining, inlining is constrained by --param large-function-growth. This parameter is useful primarily to avoid extreme compilation time caused by non-linear algorithms used by the backend. The default value is 2700.
large-function-growth
Specifies maximal growth of large function caused by inlining in percents. The default value is 100 which limits large function growth to 2.0 times the original size.
large-unit-insns
The limit specifying large translation unit. Growth caused by inlining of units larger than this limit is limited by --param inline-unit-growth. For small units this might be too tight (consider unit consisting of function A that is inline and B that just calls A three time. If B is small relative to A, the growth of unit is 300\% and yet such inlining is very sane. For very large units consisting of small inlineable functions however the overall unit growth limit is needed to avoid exponential explosion of code size. Thus for smaller units, the size is increased to --param large-unit-insns before applying --param inline-unit-growth. The default is 10000
inline-unit-growth
Specifies maximal overall growth of the compilation unit caused by inlining. The default value is 30 which limits unit growth to 1.3 times the original size.
ipcp-unit-growth
Specifies maximal overall growth of the compilation unit caused by interprocedural constant propagation. The default value is 10 which limits unit growth to 1.1 times the original size.
large-stack-frame
The limit specifying large stack frames. While inlining the algorithm is trying to not grow past this limit too much. Default value is 256 bytes.
large-stack-frame-growth
Specifies maximal growth of large stack frames caused by inlining in percents. The default value is 1000 which limits large stack frame growth to 11 times the original size.
max-inline-insns-recursive
max-inline-insns-recursive-auto
Specifies maximum number of instructions out-of-line copy of self recursive inline function can grow into by performing recursive inlining.
For functions declared inline --param max-inline-insns-recursive is taken into account. For function not declared inline, recursive inlining happens only when -finline-functions (included in -O3) is enabled and --param max-inline-insns-recursive-auto is used. The default value is 450.

max-inline-recursive-depth
max-inline-recursive-depth-auto
Specifies maximum recursion depth used by the recursive inlining.
For functions declared inline --param max-inline-recursive-depth is taken into account. For function not declared inline, recursive inlining happens only when -finline-functions (included in -O3) is enabled and --param max-inline-recursive-depth-auto is used. The default value is 8.

min-inline-recursive-probability
Recursive inlining is profitable only for function having deep recursion in average and can hurt for function having little recursion depth by increasing the prologue size or complexity of function body to other optimizers.
When profile feedback is available (see -fprofile-generate) the actual recursion depth can be guessed from probability that function will recurse via given call expression. This parameter limits inlining only to call expression whose probability exceeds given threshold (in percents). The default value is 10.

inline-call-cost
Specify cost of call instruction relative to simple arithmetics operations (having cost of 1). Increasing this cost disqualifies inlining of non-leaf functions and at the same time increases size of leaf function that is believed to reduce function size by being inlined. In effect it increases amount of inlining for code having large abstraction penalty (many functions that just pass the arguments to other functions) and decrease inlining for code with low abstraction penalty. The default value is 12.
min-vect-loop-bound
The minimum number of iterations under which a loop will not get vectorized when -ftree-vectorize is used. The number of iterations after vectorization needs to be greater than the value specified by this option to allow vectorization. The default value is 0.
max-unrolled-insns
The maximum number of instructions that a loop should have if that loop is unrolled, and if the loop is unrolled, it determines how many times the loop code is unrolled.
max-average-unrolled-insns
The maximum number of instructions biased by probabilities of their execution that a loop should have if that loop is unrolled, and if the loop is unrolled, it determines how many times the loop code is unrolled.
max-unroll-times
The maximum number of unrollings of a single loop.
max-peeled-insns
The maximum number of instructions that a loop should have if that loop is peeled, and if the loop is peeled, it determines how many times the loop code is peeled.
max-peel-times
The maximum number of peelings of a single loop.
max-completely-peeled-insns
The maximum number of insns of a completely peeled loop.
max-completely-peel-times
The maximum number of iterations of a loop to be suitable for complete peeling.
max-completely-peel-loop-nest-depth
The maximum depth of a loop nest suitable for complete peeling.
max-unswitch-insns
The maximum number of insns of an unswitched loop.
max-unswitch-level
The maximum number of branches unswitched in a single loop.
lim-expensive
The minimum cost of an expensive expression in the loop invariant motion.
iv-consider-all-candidates-bound
Bound on number of candidates for induction variables below that all candidates are considered for each use in induction variable optimizations. Only the most relevant candidates are considered if there are more candidates, to avoid quadratic time complexity.
iv-max-considered-uses
The induction variable optimizations give up on loops that contain more induction variable uses.
iv-always-prune-cand-set-bound
If number of candidates in the set is smaller than this value, we always try to remove unnecessary ivs from the set during its optimization when a new iv is added to the set.
scev-max-expr-size
Bound on size of expressions used in the scalar evolutions analyzer. Large expressions slow the analyzer.
omega-max-vars
The maximum number of variables in an Omega constraint system. The default value is 128.
omega-max-geqs
The maximum number of inequalities in an Omega constraint system. The default value is 256.
omega-max-eqs
The maximum number of equalities in an Omega constraint system. The default value is 128.
omega-max-wild-cards
The maximum number of wildcard variables that the Omega solver will be able to insert. The default value is 18.
omega-hash-table-size
The size of the hash table in the Omega solver. The default value is 550.
omega-max-keys
The maximal number of keys used by the Omega solver. The default value is 500.
omega-eliminate-redundant-constraints
When set to 1, use expensive methods to eliminate all redundant constraints. The default value is 0.
vect-max-version-for-alignment-checks
The maximum number of runtime checks that can be performed when doing loop versioning for alignment in the vectorizer. See option ftree-vect-loop-version for more information.
vect-max-version-for-alias-checks
The maximum number of runtime checks that can be performed when doing loop versioning for alias in the vectorizer. See option ftree-vect-loop-version for more information.
max-iterations-to-track
The maximum number of iterations of a loop the brute force algorithm for analysis of # of iterations of the loop tries to evaluate.
hot-bb-count-fraction
Select fraction of the maximal count of repetitions of basic block in program given basic block needs to have to be considered hot.
hot-bb-frequency-fraction
Select fraction of the maximal frequency of executions of basic block in function given basic block needs to have to be considered hot
max-predicted-iterations
The maximum number of loop iterations we predict statically. This is useful in cases where function contain single loop with known bound and other loop with unknown. We predict the known number of iterations correctly, while the unknown number of iterations average to roughly 10. This means that the loop without bounds would appear artificially cold relative to the other one.
align-threshold
Select fraction of the maximal frequency of executions of basic block in function given basic block will get aligned.
align-loop-iterations
A loop expected to iterate at lest the selected number of iterations will get aligned.
tracer-dynamic-coverage
tracer-dynamic-coverage-feedback
This value is used to limit superblock formation once the given percentage of executed instructions is covered. This limits unnecessary code size expansion.
The tracer-dynamic-coverage-feedback is used only when profile feedback is available. The real profiles (as opposed to statically estimated ones) are much less balanced allowing the threshold to be larger value.

tracer-max-code-growth
Stop tail duplication once code growth has reached given percentage. This is rather hokey argument, as most of the duplicates will be eliminated later in cross jumping, so it may be set to much higher values than is the desired code growth.
tracer-min-branch-ratio
Stop reverse growth when the reverse probability of best edge is less than this threshold (in percent).
tracer-min-branch-ratio
tracer-min-branch-ratio-feedback
Stop forward growth if the best edge do have probability lower than this threshold.
Similarly to tracer-dynamic-coverage two values are present, one for compilation for profile feedback and one for compilation without. The value for compilation with profile feedback needs to be more conservative (higher) in order to make tracer effective.

max-cse-path-length
Maximum number of basic blocks on path that cse considers. The default is 10.
max-cse-insns
The maximum instructions CSE process before flushing. The default is 1000.
max-aliased-vops
Maximum number of virtual operands per function allowed to represent aliases before triggering the alias partitioning heuristic. Alias partitioning reduces compile times and memory consumption needed for aliasing at the expense of precision loss in alias information. The default value for this parameter is 100 for -O1, 500 for -O2 and 1000 for -O3.
Notice that if a function contains more memory statements than the value of this parameter, it is not really possible to achieve this reduction. In this case, the compiler will use the number of memory statements as the value for max-aliased-vops.

avg-aliased-vops
Average number of virtual operands per statement allowed to represent aliases before triggering the alias partitioning heuristic. This works in conjunction with max-aliased-vops. If a function contains more than max-aliased-vops virtual operators, then memory symbols will be grouped into memory partitions until either the total number of virtual operators is below max-aliased-vops or the average number of virtual operators per memory statement is below avg-aliased-vops. The default value for this parameter is 1 for -O1 and -O2, and 3 for -O3.
ggc-min-expand
GCC uses a garbage collector to manage its own memory allocation. This parameter specifies the minimum percentage by which the garbage collector's heap should be allowed to expand between collections. Tuning this may improve compilation speed; it has no effect on code generation.
The default is 30% + 70% * ( RAM/1GB ) with an upper bound of 100% when RAM >= 1GB. If "getrlimit" is available, the notion of " RAM " is the smallest of actual RAM and "RLIMIT_DATA" or "RLIMIT_AS". If GCC is not able to calculate RAM on a particular platform, the lower bound of 30% is used. Setting this parameter and ggc-min-heapsize to zero causes a full collection to occur at every opportunity. This is extremely slow, but can be useful for debugging.

ggc-min-heapsize
Minimum size of the garbage collector's heap before it begins bothering to collect garbage. The first collection occurs after the heap expands by ggc-min-expand% beyond ggc-min-heapsize. Again, tuning this may improve compilation speed, and has no effect on code generation.
The default is the smaller of RAM/8 , RLIMIT_RSS , or a limit which tries to ensure that RLIMIT_DATA or RLIMIT_AS are not exceeded, but with a lower bound of 4096 (four megabytes) and an upper bound of 131072 (128 megabytes). If GCC is not able to calculate RAM on a particular platform, the lower bound is used. Setting this parameter very large effectively disables garbage collection. Setting this parameter and ggc-min-expand to zero causes a full collection to occur at every opportunity.

max-reload-search-insns
The maximum number of instruction reload should look backward for equivalent register. Increasing values mean more aggressive optimization, making the compile time increase with probably slightly better performance. The default value is 100.
max-cselib-memory-locations
The maximum number of memory locations cselib should take into account. Increasing values mean more aggressive optimization, making the compile time increase with probably slightly better performance. The default value is 500.
reorder-blocks-duplicate
reorder-blocks-duplicate-feedback
Used by basic block reordering pass to decide whether to use unconditional branch or duplicate the code on its destination. Code is duplicated when its estimated size is smaller than this value multiplied by the estimated size of unconditional jump in the hot spots of the program.
The reorder-block-duplicate-feedback is used only when profile feedback is available and may be set to higher values than reorder-block-duplicate since information about the hot spots is more accurate.

max-sched-ready-insns
The maximum number of instructions ready to be issued the scheduler should consider at any given time during the first scheduling pass. Increasing values mean more thorough searches, making the compilation time increase with probably little benefit. The default value is 100.
max-sched-region-blocks
The maximum number of blocks in a region to be considered for interblock scheduling. The default value is 10.
max-pipeline-region-blocks
The maximum number of blocks in a region to be considered for pipelining in the selective scheduler. The default value is 15.
max-sched-region-insns
The maximum number of insns in a region to be considered for interblock scheduling. The default value is 100.
max-pipeline-region-insns
The maximum number of insns in a region to be considered for pipelining in the selective scheduler. The default value is 200.
min-spec-prob
The minimum probability (in percents) of reaching a source block for interblock speculative scheduling. The default value is 40.
max-sched-extend-regions-iters
The maximum number of iterations through CFG to extend regions. 0 - disable region extension, N - do at most N iterations. The default value is 0.
max-sched-insn-conflict-delay
The maximum conflict delay for an insn to be considered for speculative motion. The default value is 3.
sched-spec-prob-cutoff
The minimal probability of speculation success (in percents), so that speculative insn will be scheduled. The default value is 40.
sched-mem-true-dep-cost
Minimal distance (in CPU cycles) between store and load targeting same memory locations. The default value is 1.
selsched-max-lookahead
The maximum size of the lookahead window of selective scheduling. It is a depth of search for available instructions. The default value is 50.
selsched-max-sched-times
The maximum number of times that an instruction will be scheduled during selective scheduling. This is the limit on the number of iterations through which the instruction may be pipelined. The default value is 2.
selsched-max-insns-to-rename
The maximum number of best instructions in the ready list that are considered for renaming in the selective scheduler. The default value is 2.
max-last-value-rtl
The maximum size measured as number of RTLs that can be recorded in an expression in combiner for a pseudo register as last known value of that register. The default is 10000.
integer-share-limit
Small integer constants can use a shared data structure, reducing the compiler's memory usage and increasing its speed. This sets the maximum value of a shared integer constant. The default value is 256.
min-virtual-mappings
Specifies the minimum number of virtual mappings in the incremental SSA updater that should be registered to trigger the virtual mappings heuristic defined by virtual-mappings-ratio. The default value is 100.
virtual-mappings-ratio
If the number of virtual mappings is virtual-mappings-ratio bigger than the number of virtual symbols to be updated, then the incremental SSA updater switches to a full update for those symbols. The default ratio is 3.
ssp-buffer-size
The minimum size of buffers (i.e. arrays) that will receive stack smashing protection when -fstack-protection is used.
max-jump-thread-duplication-stmts
Maximum number of statements allowed in a block that needs to be duplicated when threading jumps.
max-fields-for-field-sensitive
Maximum number of fields in a structure we will treat in a field sensitive manner during pointer analysis. The default is zero for -O0, and -O1 and 100 for -Os, -O2, and -O3.
prefetch-latency
Estimate on average number of instructions that are executed before prefetch finishes. The distance we prefetch ahead is proportional to this constant. Increasing this number may also lead to less streams being prefetched (see simultaneous-prefetches).
simultaneous-prefetches
Maximum number of prefetches that can run at the same time.
l1-cache-line-size
The size of cache line in L1 cache, in bytes.
l1-cache-size
The size of L1 cache, in kilobytes.
l2-cache-size
The size of L2 cache, in kilobytes.
use-canonical-types
Whether the compiler should use the "canonical" type system. By default, this should always be 1, which uses a more efficient internal mechanism for comparing types in C ++ and Objective-C ++ . However, if bugs in the canonical type system are causing compilation failures, set this value to 0 to disable canonical types.
switch-conversion-max-branch-ratio
Switch initialization conversion will refuse to create arrays that are bigger than switch-conversion-max-branch-ratio times the number of branches in the switch.
max-partial-antic-length
Maximum length of the partial antic set computed during the tree partial redundancy elimination optimization (-ftree-pre) when optimizing at -O3 and above. For some sorts of source code the enhanced partial redundancy elimination optimization can run away, consuming all of the memory available on the host machine. This parameter sets a limit on the length of the sets that are computed, which prevents the runaway behavior. Setting a value of 0 for this parameter will allow an unlimited set length.
sccvn-max-scc-size
Maximum size of a strongly connected component ( SCC ) during SCCVN processing. If this limit is hit, SCCVN processing for the whole function will not be done and optimizations depending on it will be disabled. The default maximum SCC size is 10000.
ira-max-loops-num
IRA uses a regional register allocation by default. If a function contains loops more than number given by the parameter, only at most given number of the most frequently executed loops will form regions for the regional register allocation. The default value of the parameter is 100.
ira-max-conflict-table-size
Although IRA uses a sophisticated algorithm of compression conflict table, the table can be still big for huge functions. If the conflict table for a function could be more than size in MB given by the parameter, the conflict table is not built and faster, simpler, and lower quality register allocation algorithm will be used. The algorithm do not use pseudo-register conflicts. The default value of the parameter is 2000.
loop-invariant-max-bbs-in-loop
Loop invariant motion can be very expensive, both in compile time and in amount of needed compile time memory, with very large loops. Loops with more basic blocks than this parameter won't have loop invariant motion optimization performed on them. The default value of the parameter is 1000 for -O1 and 10000 for -O2 and above.
max-vartrack-size
Sets a maximum number of hash table slots to use during variable tracking dataflow analysis of any function. If this limit is exceeded with variable tracking at assignments enabled, analysis for that function is retried without it, after removing all debug insns from the function. If the limit is exceeded even without debug insns, var tracking analysis is completely disabled for the function. Setting the parameter to zero makes it unlimited.
min-nondebug-insn-uid
Use uids starting at this parameter for nondebug insns. The range below the parameter is reserved exclusively for debug insns created by -fvar-tracking-assignments, but debug insns may get (non-overlapping) uids above it if the reserved range is exhausted.
Options Controlling the Preprocessor

These options control the C preprocessor, which is run on each C source file before actual compilation.
If you use the -E option, nothing is done except preprocessing. Some of these options make sense only together with -E because they cause the preprocessor output to be unsuitable for actual compilation.

-Wp,option
You can use -Wp,option to bypass the compiler driver and pass option directly through to the preprocessor. If option contains commas, it is split into multiple options at the commas. However, many options are modified, translated or interpreted by the compiler driver before being passed to the preprocessor, and -Wp forcibly bypasses this phase. The preprocessor's direct interface is undocumented and subject to change, so whenever possible you should avoid using -Wp and let the driver handle the options instead.
-Xpreprocessor option
Pass option as an option to the preprocessor. You can use this to supply system-specific preprocessor options which GCC does not know how to recognize.
If you want to pass an option that takes an argument, you must use -Xpreprocessor twice, once for the option and once for the argument.

-D name
Predefine name as a macro, with definition 1.
-D name=definition
The contents of definition are tokenized and processed as if they appeared during translation phase three in a #define directive. In particular, the definition will be truncated by embedded newline characters.
If you are invoking the preprocessor from a shell or shell-like program you may need to use the shell's quoting syntax to protect characters such as spaces that have a meaning in the shell syntax.

If you wish to define a function-like macro on the command line, write its argument list with surrounding parentheses before the equals sign (if any). Parentheses are meaningful to most shells, so you will need to quote the option. With sh and csh, -D'name(args...)=definition' works.

-D and -U options are processed in the order they are given on the command line. All -imacros file and -include file options are processed after all -D and -U options.

-U name
Cancel any previous definition of name, either built in or provided with a -D option.
-undef
Do not predefine any system-specific or GCC-specific macros. The standard predefined macros remain defined.
-I dir
Add the directory dir to the list of directories to be searched for header files. Directories named by -I are searched before the standard system include directories. If the directory dir is a standard system include directory, the option is ignored to ensure that the default search order for system directories and the special treatment of system headers are not defeated . If dir begins with "=", then the "=" will be replaced by the sysroot prefix; see --sysroot and -isysroot.
-o file
Write output to file. This is the same as specifying file as the second non-option argument to cpp. gcc has a different interpretation of a second non-option argument, so you must use -o to specify the output file.
-Wall
Turns on all optional warnings which are desirable for normal code. At present this is -Wcomment, -Wtrigraphs, -Wmultichar and a warning about integer promotion causing a change of sign in "#if" expressions. Note that many of the preprocessor's warnings are on by default and have no options to control them.
-Wcomment
-Wcomments
Warn whenever a comment-start sequence /* appears in a /* comment, or whenever a backslash-newline appears in a // comment. (Both forms have the same effect.)
-Wtrigraphs
Most trigraphs in comments cannot affect the meaning of the program. However, a trigraph that would form an escaped newline (??/ at the end of a line) can, by changing where the comment begins or ends. Therefore, only trigraphs that would form escaped newlines produce warnings inside a comment.
This option is implied by -Wall. If -Wall is not given, this option is still enabled unless trigraphs are enabled. To get trigraph conversion without warnings, but get the other -Wall warnings, use -trigraphs -Wall -Wno-trigraphs.

-Wtraditional
Warn about certain constructs that behave differently in traditional and ISO C. Also warn about ISO C constructs that have no traditional C equivalent, and problematic constructs which should be avoided.
-Wundef
Warn whenever an identifier which is not a macro is encountered in an #if directive, outside of defined. Such identifiers are replaced with zero.
-Wunused-macros
Warn about macros defined in the main file that are unused. A macro is used if it is expanded or tested for existence at least once. The preprocessor will also warn if the macro has not been used at the time it is redefined or undefined.
Built-in macros, macros defined on the command line, and macros defined in include files are not warned about.

Note: If a macro is actually used, but only used in skipped conditional blocks, then CPP will report it as unused. To avoid the warning in such a case, you might improve the scope of the macro's definition by, for example, moving it into the first skipped block. Alternatively, you could provide a dummy use with something like:

#if defined the_macro_causing_the_warning
#endif
-Wendif-labels
Warn whenever an #else or an #endif are followed by text. This usually happens in code of the form
#if FOO
...
#else FOO
...
#endif FOO
The second and third "FOO" should be in comments, but often are not in older programs. This warning is on by default.
-Werror
Make all warnings into hard errors. Source code which triggers warnings will be rejected.
-Wsystem-headers
Issue warnings for code in system headers. These are normally unhelpful in finding bugs in your own code, therefore suppressed. If you are responsible for the system library, you may want to see them.
-w
Suppress all warnings, including those which GNU CPP issues by default.

-pedantic
Issue all the mandatory diagnostics listed in the C standard. Some of them are left out by default, since they trigger frequently on harmless code.
-pedantic-errors
Issue all the mandatory diagnostics, and make all mandatory diagnostics into errors. This includes mandatory diagnostics that GCC issues without -pedantic but treats as warnings.
-M
Instead of outputting the result of preprocessing, output a rule suitable for make describing the dependencies of the main source file. The preprocessor outputs one make rule containing the object file name for that source file, a colon, and the names of all the included files, including those coming from -include or -imacros command line options.

Unless specified explicitly (with -MT or -MQ), the object file name consists of the name of the source file with any suffix replaced with object file suffix and with any leading directory parts removed. If there are many included files then the rule is split into several lines using \-newline. The rule has no commands.
This option does not suppress the preprocessor's debug output, such as -dM. To avoid mixing such debug output with the dependency rules you should explicitly specify the dependency output file with -MF, or use an environment variable like DEPENDENCIES_OUTPUT . Debug output will still be sent to the regular output stream as normal.

Passing -M to the driver implies -E, and suppresses warnings with an implicit -w.

-MM
Like -M but do not mention header files that are found in system header directories, nor header files that are included, directly or indirectly, from such a header.

This implies that the choice of angle brackets or double quotes in an #include directive does not in itself determine whether that header will appear in -MM dependency output. This is a slight change in semantics from GCC versions 3.0 and earlier.
-MF file
When used with -M or -MM, specifies a file to write the dependencies to. If no -MF switch is given the preprocessor sends the rules to the same place it would have sent preprocessed output.
When used with the driver options -MD or -MMD, -MF overrides the default dependency output file.

-MG
In conjunction with an option such as -M requesting dependency generation, -MG assumes missing header files are generated files and adds them to the dependency list without raising an error. The dependency filename is taken directly from the "#include" directive without prepending any path. -MG also suppresses preprocessed output, as a missing header file renders this useless.

This feature is used in automatic updating of makefiles.
-MP
This option instructs CPP to add a phony target for each dependency other than the main file, causing each to depend on nothing. These dummy rules work around errors make gives if you remove header files without updating the Makefile to match.

This is typical output:
test.o: test.c test.h

test.h:
-MT target
Change the target of the rule emitted by dependency generation. By default CPP takes the name of the main input file, deletes any directory components and any file suffix such as .c, and appends the platform's usual object suffix. The result is the target.
An -MT option will set the target to be exactly the string you specify. If you want multiple targets, you can specify them as a single argument to -MT, or use multiple -MT options.

For example, -MT '$(objpfx)foo.o' might give

$(objpfx)foo.o: foo.c
-MQ target
Same as -MT, but it quotes any characters which are special to Make. -MQ '$(objpfx)foo.o' gives
$$(objpfx)foo.o: foo.c
The default target is automatically quoted, as if it were given with -MQ.
-MD
-MD is equivalent to -M -MF file, except that -E is not implied. The driver determines file based on whether an -o option is given. If it is, the driver uses its argument but with a suffix of .d, otherwise it takes the name of the input file, removes any directory components and suffix, and applies a .d suffix.

If -MD is used in conjunction with -E, any -o switch is understood to specify the dependency output file, but if used without -E, each -o is understood to specify a target object file.
Since -E is not implied, -MD can be used to generate a dependency output file as a side-effect of the compilation process.

-MMD
Like -MD except mention only user header files, not system header files.
-fpch-deps
When using precompiled headers, this flag will cause the dependency-output flags to also list the files from the precompiled header's dependencies. If not specified only the precompiled header would be listed and not the files that were used to create it because those files are not consulted when a precompiled header is used.
-fpch-preprocess
This option allows use of a precompiled header together with -E. It inserts a special "#pragma", "#pragma GCC pch_preprocess "<filename>"" in the output to mark the place where the precompiled header was found, and its filename. When -fpreprocessed is in use, GCC recognizes this "#pragma" and loads the PCH .
This option is off by default, because the resulting preprocessed output is only really suitable as input to GCC . It is switched on by -save-temps.

You should not write this "#pragma" in your own code, but it is safe to edit the filename if the PCH file is available in a different location. The filename may be absolute or it may be relative to GCC 's current directory.

-x c
-x c++
-x objective-c
-x assembler-with-cpp
Specify the source language: C, C ++ , Objective-C, or assembly. This has nothing to do with standards conformance or extensions; it merely selects which base syntax to expect. If you give none of these options, cpp will deduce the language from the extension of the source file: .c, .cc, .m, or .S. Some other common extensions for C ++ and assembly are also recognized. If cpp does not recognize the extension, it will treat the file as C; this is the most generic mode.
Note: Previous versions of cpp accepted a -lang option which selected both the language and the standards conformance level. This option has been removed, because it conflicts with the -l option.

-std=standard
-ansi
Specify the standard to which the code should conform. Currently CPP knows about C and C ++ standards; others may be added in the future.
standard may be one of:

"iso9899:1990"
"c89"
The ISO C standard from 1990. c89 is the customary shorthand for this version of the standard.
The -ansi option is equivalent to -std=c89.

"iso9899:199409"
The 1990 C standard, as amended in 1994.
"iso9899:1999"
"c99"
"iso9899:199x"
"c9x"
The revised ISO C standard, published in December 1999. Before publication, this was known as C9X.
"gnu89"
The 1990 C standard plus GNU extensions. This is the default.
"gnu99"
"gnu9x"
The 1999 C standard plus GNU extensions.
"c++98"
The 1998 ISO C ++ standard plus amendments.
"gnu++98"
The same as -std=c++98 plus GNU extensions. This is the default for C ++ code.
-I-
Split the include path. Any directories specified with -I options before -I- are searched only for headers requested with "#include " file ""; they are not searched for "#include < file >". If additional directories are specified with -I options after the -I-, those directories are searched for all #include directives.

In addition, -I- inhibits the use of the directory of the current file directory as the first search directory for "#include " file "". This option has been deprecated.
-nostdinc
Do not search the standard system directories for header files. Only the directories you have specified with -I options (and the directory of the current file, if appropriate) are searched.
-nostdinc++
Do not search for header files in the C ++ -specific standard directories, but do still search the other standard directories. (This option is used when building the C ++ library.)
-include file
Process file as if "#include "file"" appeared as the first line of the primary source file. However, the first directory searched for file is the preprocessor's working directory instead of the directory containing the main source file. If not found there, it is searched for in the remainder of the "#include "..."" search chain as normal.
If multiple -include options are given, the files are included in the order they appear on the command line.

-imacros file
Exactly like -include, except that any output produced by scanning file is thrown away. Macros it defines remain defined. This allows you to acquire all the macros from a header without also processing its declarations.
All files specified by -imacros are processed before all files specified by -include.

-idirafter dir
Search dir for header files, but do it after all directories specified with -I and the standard system directories have been exhausted. dir is treated as a system include directory. If dir begins with "=", then the "=" will be replaced by the sysroot prefix; see --sysroot and -isysroot.
-iprefix prefix
Specify prefix as the prefix for subsequent -iwithprefix options. If the prefix represents a directory, you should include the final /.
-iwithprefix dir
-iwithprefixbefore dir
Append dir to the prefix specified previously with -iprefix, and add the resulting directory to the include search path. -iwithprefixbefore puts it in the same place -I would; -iwithprefix puts it where -idirafter would.
-isysroot dir
This option is like the --sysroot option, but applies only to header files. See the --sysroot option for more information.
-imultilib dir
Use dir as a subdirectory of the directory containing target-specific C ++ headers.
-isystem dir
Search dir for header files, after all directories specified by -I but before the standard system directories. Mark it as a system directory, so that it gets the same special treatment as is applied to the standard system directories. If dir begins with "=", then the "=" will be replaced by the sysroot prefix; see --sysroot and -isysroot.
-iquote dir
Search dir only for header files requested with "#include " file ""; they are not searched for "#include < file >", before all directories specified by -I and before the standard system directories. If dir begins with "=", then the "=" will be replaced by the sysroot prefix; see --sysroot and -isysroot.
-fdirectives-only
When preprocessing, handle directives, but do not expand macros.
The option's behavior depends on the -E and -fpreprocessed options.

With -E, preprocessing is limited to the handling of directives such as "#define", "#ifdef", and "#error". Other preprocessor operations, such as macro expansion and trigraph conversion are not performed. In addition, the -dD option is implicitly enabled.

With -fpreprocessed, predefinition of command line and most builtin macros is disabled. Macros such as "__LINE__", which are contextually dependent, are handled normally. This enables compilation of files previously preprocessed with "-E -fdirectives-only".

With both -E and -fpreprocessed, the rules for -fpreprocessed take precedence. This enables full preprocessing of files previously preprocessed with "-E -fdirectives-only".

-fdollars-in-identifiers
Accept $ in identifiers.
-fextended-identifiers
Accept universal character names in identifiers. This option is experimental; in a future version of GCC , it will be enabled by default for C99 and C ++ .
-fpreprocessed
Indicate to the preprocessor that the input file has already been preprocessed. This suppresses things like macro expansion, trigraph conversion, escaped newline splicing, and processing of most directives. The preprocessor still recognizes and removes comments, so that you can pass a file preprocessed with -C to the compiler without problems. In this mode the integrated preprocessor is little more than a tokenizer for the front ends.
-fpreprocessed is implicit if the input file has one of the extensions .i, .ii or .mi. These are the extensions that GCC uses for preprocessed files created by -save-temps.

-ftabstop=width
Set the distance between tab stops. This helps the preprocessor report correct column numbers in warnings or errors, even if tabs appear on the line. If the value is less than 1 or greater than 100, the option is ignored. The default is 8.
-fexec-charset=charset
Set the execution character set, used for string and character constants. The default is UTF-8 . charset can be any encoding supported by the system's "iconv" library routine.
-fwide-exec-charset=charset
Set the wide execution character set, used for wide string and character constants. The default is UTF-32 or UTF-16 , whichever corresponds to the width of "wchar_t". As with -fexec-charset, charset can be any encoding supported by the system's "iconv" library routine; however, you will have problems with encodings that do not fit exactly in "wchar_t".
-finput-charset=charset
Set the input character set, used for translation from the character set of the input file to the source character set used by GCC . If the locale does not specify, or GCC cannot get this information from the locale, the default is UTF-8 . This can be overridden by either the locale or this command line option. Currently the command line option takes precedence if there's a conflict. charset can be any encoding supported by the system's "iconv" library routine.
-fworking-directory
Enable generation of linemarkers in the preprocessor output that will let the compiler know the current working directory at the time of preprocessing. When this option is enabled, the preprocessor will emit, after the initial linemarker, a second linemarker with the current working directory followed by two slashes. GCC will use this directory, when it's present in the preprocessed input, as the directory emitted as the current working directory in some debugging information formats. This option is implicitly enabled if debugging information is enabled, but this can be inhibited with the negated form -fno-working-directory. If the -P flag is present in the command line, this option has no effect, since no "#line" directives are emitted whatsoever.
-fno-show-column
Do not print column numbers in diagnostics. This may be necessary if diagnostics are being scanned by a program that does not understand the column numbers, such as dejagnu.
-A predicate=answer
Make an assertion with the predicate predicate and answer answer. This form is preferred to the older form -A predicate(answer), which is still supported, because it does not use shell special characters.
-A -predicate=answer
Cancel an assertion with the predicate predicate and answer answer.
-dCHARS
CHARS is a sequence of one or more of the following characters, and must not be preceded by a space. Other characters are interpreted by the compiler proper, or reserved for future versions of GCC , and so are silently ignored. If you specify characters whose behavior conflicts, the result is undefined.
M
Instead of the normal output, generate a list of #define directives for all the macros defined during the execution of the preprocessor, including predefined macros. This gives you a way of finding out what is predefined in your version of the preprocessor. Assuming you have no file foo.h, the command

touch foo.h; cpp -dM foo.h
will show all the predefined macros.
If you use -dM without the -E option, -dM is interpreted as a synonym for -fdump-rtl-mach.

D
Like M except in two respects: it does not include the predefined macros, and it outputs both the #define directives and the result of preprocessing. Both kinds of output go to the standard output file.

N

Like D, but emit only the macro names, not their expansions.

I

Output #include directives in addition to the result of preprocessing.

U

Like D except that only macros that are expanded, or whose definedness is tested in preprocessor directives, are output; the output is delayed until the use or test of the macro; and #undef directives are also output for macros tested but undefined at the time.

-P

Inhibit generation of linemarkers in the output from the

preprocessor. This might be useful when running the preprocessor on something that is not C code, and will be sent to a program which might be confused by the linemarkers.
-C
Do not discard comments. All comments are passed through to the output file, except for comments in processed directives, which are deleted along with the directive.

You should be prepared for side effects when using -C; it causes the preprocessor to treat comments as tokens in their own right. For example, comments appearing at the start of what would be a directive line have the effect of turning that line into an ordinary source line, since the first token on the line is no longer a #.
-CC
Do not discard comments, including during macro expansion. This is like -C, except that comments contained within macros are also passed through to the output file where the macro is expanded.

In addition to the side-effects of the -C option, the -CC option causes all C ++ -style comments inside a macro to be converted to C-style comments. This is to prevent later use of that macro from inadvertently commenting out the remainder of the source line.
The -CC option is generally used to support lint comments.

-traditional-cpp
Try to imitate the behavior of old-fashioned C preprocessors, as opposed to ISO C preprocessors.
-trigraphs
Process trigraph sequences. These are three-character sequences, all starting with ??, that are defined by ISO C to stand for single characters. For example, ??/ stands for \, so '??/n' is a character constant for a newline. By default, GCC ignores trigraphs, but in standard-conforming modes it converts them. See the -std and -ansi options.
The nine trigraphs and their replacements are

Trigraph:       ??(  ??)  ??<  ??>  ??=  ??/  ??'  ??!  ??-
Replacement:      [    ]    {    }    #    \    ^    |    ~
-remap
Enable special code to work around file systems which only permit very short file names, such as MS-DOS.
--help
--target-help
Print text describing all the command line options instead of preprocessing anything.
-v
Verbose mode. Print out GNU CPP 's version number at the beginning of execution, and report the final form of the include path.

-H

Print the name of each header file used, in addition to other normal activities. Each name is indented to show how deep in the #include stack it is. Precompiled header files are also printed, even if they are found to be invalid; an invalid precompiled header file is printed with ...x and a valid one with ...! .

-version
--version
Print out GNU CPP 's version number. With one dash, proceed to preprocess as normal. With two dashes, exit immediately.
Passing Options to the Assembler

You can pass options to the assembler.
-Wa,option
Pass option as an option to the assembler. If option contains commas, it is split into multiple options at the commas.
-Xassembler option
Pass option as an option to the assembler. You can use this to supply system-specific assembler options which GCC does not know how to recognize.
If you want to pass an option that takes an argument, you must use -Xassembler twice, once for the option and once for the argument.

Options for Linking

These options come into play when the compiler links object files into an executable output file. They are meaningless if the compiler is not doing a link step.
object-file-name
A file name that does not end in a special recognized suffix is considered to name an object file or library. (Object files are distinguished from libraries by the linker according to the file contents.) If linking is done, these object files are used as input to the linker.
-c
-S

-E

If any of these options is used, then the linker is not run, and object file names should not be used as arguments.

-llibrary
-l library
Search the library named library when linking. (The second alternative with the library as a separate argument is only for POSIX compliance and is not recommended.)
It makes a difference where in the command you write this option; the linker searches and processes libraries and object files in the order they are specified. Thus, foo.o -lz bar.o searches library z after file foo.o but before bar.o. If bar.o refers to functions in z, those functions may not be loaded.

The linker searches a standard list of directories for the library, which is actually a file named liblibrary.a. The linker then uses this file as if it had been specified precisely by name.

The directories searched include several standard system directories plus any that you specify with -L.

Normally the files found this way are library files---archive files whose members are object files. The linker handles an archive file by scanning through it for members which define symbols that have so far been referenced but not defined. But if the file that is found is an ordinary object file, it is linked in the usual fashion. The only difference between using an -l option and specifying a file name is that -l surrounds library with lib and .a and searches several directories.

-lobjc
You need this special case of the -l option in order to link an Objective-C or Objective-C ++ program.
-nostartfiles
Do not use the standard system startup files when linking. The standard system libraries are used normally, unless -nostdlib or -nodefaultlibs is used.
-nodefaultlibs
Do not use the standard system libraries when linking. Only the libraries you specify will be passed to the linker. The standard startup files are used normally, unless -nostartfiles is used. The compiler may generate calls to "memcmp", "memset", "memcpy" and "memmove". These entries are usually resolved by entries in libc. These entry points should be supplied through some other mechanism when this option is specified.
-nostdlib
Do not use the standard system startup files or libraries when linking. No startup files and only the libraries you specify will be passed to the linker. The compiler may generate calls to "memcmp", "memset", "memcpy" and "memmove". These entries are usually resolved by entries in libc. These entry points should be supplied through some other mechanism when this option is specified.
One of the standard libraries bypassed by -nostdlib and -nodefaultlibs is libgcc.a, a library of internal subroutines that GCC uses to overcome shortcomings of particular machines, or special needs for some languages.

In most cases, you need libgcc.a even when you want to avoid other standard libraries. In other words, when you specify -nostdlib or -nodefaultlibs you should usually specify -lgcc as well. This ensures that you have no unresolved references to internal GCC library subroutines. (For example, __main, used to ensure C ++ constructors will be called.)

-pie
Produce a position independent executable on targets which support it. For predictable results, you must also specify the same set of options that were used to generate code (-fpie, -fPIE, or model suboptions) when you specify this option.
-rdynamic
Pass the flag -export-dynamic to the ELF linker, on targets that support it. This instructs the linker to add all symbols, not only used ones, to the dynamic symbol table. This option is needed for some uses of "dlopen" or to allow obtaining backtraces from within a program.
-s
Remove all symbol table and relocation information from the executable.

-static
On systems that support dynamic linking, this prevents linking with the shared libraries. On other systems, this option has no effect.
-shared
Produce a shared object which can then be linked with other objects to form an executable. Not all systems support this option. For predictable results, you must also specify the same set of options that were used to generate code (-fpic, -fPIC, or model suboptions) when you specify this option.[1]
-shared-libgcc
-static-libgcc
On systems that provide libgcc as a shared library, these options force the use of either the shared or static version respectively. If no shared version of libgcc was built when the compiler was configured, these options have no effect.
There are several situations in which an application should use the shared libgcc instead of the static version. The most common of these is when the application wishes to throw and catch exceptions across different shared libraries. In that case, each of the libraries as well as the application itself should use the shared libgcc.

Therefore, the G++ and GCJ drivers automatically add -shared-libgcc whenever you build a shared library or a main executable, because C ++ and Java programs typically use exceptions, so this is the right thing to do.

If, instead, you use the GCC driver to create shared libraries, you may find that they will not always be linked with the shared libgcc. If GCC finds, at its configuration time, that you have a non-GNU linker or a GNU linker that does not support option --eh-frame-hdr, it will link the shared version of libgcc into shared libraries by default. Otherwise, it will take advantage of the linker and optimize away the linking with the shared version of libgcc, linking with the static version of libgcc by default. This allows exceptions to propagate through such shared libraries, without incurring relocation costs at library load time.

However, if a library or main executable is supposed to throw or catch exceptions, you must link it using the G++ or GCJ driver, as appropriate for the languages used in the program, or using the option -shared-libgcc, such that it is linked with the shared libgcc.

-symbolic
Bind references to global symbols when building a shared object. Warn about any unresolved references (unless overridden by the link editor option -Xlinker -z -Xlinker defs). Only a few systems support this option.
-T script
Use script as the linker script. This option is supported by most systems using the GNU linker. On some targets, such as bare-board targets without an operating system, the -T option may be required when linking to avoid references to undefined symbols.
-Xlinker option
Pass option as an option to the linker. You can use this to supply system-specific linker options which GCC does not know how to recognize.
If you want to pass an option that takes a separate argument, you must use -Xlinker twice, once for the option and once for the argument. For example, to pass -assert definitions, you must write -Xlinker -assert -Xlinker definitions. It does not work to write -Xlinker "-assert definitions", because this passes the entire string as a single argument, which is not what the linker expects.

When using the GNU linker, it is usually more convenient to pass arguments to linker options using the option=value syntax than as separate arguments. For example, you can specify -Xlinker -Map=output.map rather than -Xlinker -Map -Xlinker output.map. Other linkers may not support this syntax for command-line options.

-Wl,option
Pass option as an option to the linker. If option contains commas, it is split into multiple options at the commas. You can use this syntax to pass an argument to the option. For example, -Wl,-Map,output.map passes -Map output.map to the linker. When using the GNU linker, you can also get the same effect with -Wl,-Map=output.map.
-u symbol
Pretend the symbol symbol is undefined, to force linking of library modules to define it. You can use -u multiple times with different symbols to force loading of additional library modules.
Options for Directory Search

These options specify directories to search for header files, for libraries and for parts of the compiler:
-Idir
Add the directory dir to the head of the list of directories to be searched for header files. This can be used to override a system header file, substituting your own version, since these directories are searched before the system header file directories. However, you should not use this option to add directories that contain vendor-supplied system header files (use -isystem for that). If you use more than one -I option, the directories are scanned in left-to-right order; the standard system directories come after.
If a standard system include directory, or a directory specified with -isystem, is also specified with -I, the -I option will be ignored. The directory will still be searched but as a system directory at its normal position in the system include chain. This is to ensure that GCC 's procedure to fix buggy system headers and the ordering for the include_next directive are not inadvertently changed. If you really need to change the search order for system directories, use the -nostdinc and/or -isystem options.

-iquotedir
Add the directory dir to the head of the list of directories to be searched for header files only for the case of #include "file"; they are not searched for #include <file>, otherwise just like -I.
-Ldir
Add directory dir to the list of directories to be searched for -l.
-Bprefix
This option specifies where to find the executables, libraries, include files, and data files of the compiler itself.
The compiler driver program runs one or more of the subprograms cpp, cc1, as and ld. It tries prefix as a prefix for each program it tries to run, both with and without machine/version/.

For each subprogram to be run, the compiler driver first tries the -B prefix, if any. If that name is not found, or if -B was not specified, the driver tries two standard prefixes, which are /usr/lib/gcc/ and /usr/local/lib/gcc/. If neither of those results in a file name that is found, the unmodified program name is searched for using the directories specified in your PATH environment variable.

The compiler will check to see if the path provided by the -B refers to a directory, and if necessary it will add a directory separator character at the end of the path.

-B prefixes that effectively specify directory names also apply to libraries in the linker, because the compiler translates these options into -L options for the linker. They also apply to includes files in the preprocessor, because the compiler translates these options into -isystem options for the preprocessor. In this case, the compiler appends include to the prefix.

The run-time support file libgcc.a can also be searched for using the -B prefix, if needed. If it is not found there, the two standard prefixes above are tried, and that is all. The file is left out of the link if it is not found by those means.

Another way to specify a prefix much like the -B prefix is to use the environment variable GCC_EXEC_PREFIX .

As a special kludge, if the path provided by -B is [dir/]stageN/, where N is a number in the range 0 to 9, then it will be replaced by [dir/]include. This is to help with boot-strapping the compiler.

-specs=file
Process file after the compiler reads in the standard specs file, in order to override the defaults that the gcc driver program uses when determining what switches to pass to cc1, cc1plus, as, ld, etc. More than one -specs=file can be specified on the command line, and they are processed in order, from left to right.
--sysroot=dir
Use dir as the logical root directory for headers and libraries. For example, if the compiler would normally search for headers in /usr/include and libraries in /usr/lib, it will instead search dir/usr/include and dir/usr/lib.
If you use both this option and the -isysroot option, then the --sysroot option will apply to libraries, but the -isysroot option will apply to header files.

The GNU linker (beginning with version 2.16) has the necessary support for this option. If your linker does not support this option, the header file aspect of --sysroot will still work, but the library aspect will not.

-I-
This option has been deprecated. Please use -iquote instead for -I directories before the -I- and remove the -I-. Any directories you specify with -I options before the -I- option are searched only for the case of #include "file"; they are not searched for #include <file>.

If additional directories are specified with -I options after the -I-, these directories are searched for all #include directives. (Ordinarily all -I directories are used this way.)
In addition, the -I- option inhibits the use of the current directory (where the current input file came from) as the first search directory for #include "file". There is no way to override this effect of -I-. With -I. you can specify searching the directory which was current when the compiler was invoked. That is not exactly the same as what the preprocessor does by default, but it is often satisfactory.

-I- does not inhibit the use of the standard system directories for header files. Thus, -I- and -nostdinc are independent.

Specifying Target Machine and Compiler Version

The usual way to run GCC is to run the executable called gcc, or <machine>-gcc when cross-compiling, or <machine>-gcc-<version> to run a version other than the one that was installed last. Sometimes this is inconvenient, so GCC provides options that will switch to another cross-compiler or version.
-b machine
The argument machine specifies the target machine for compilation.
The value to use for machine is the same as was specified as the machine type when configuring GCC as a cross-compiler. For example, if a cross-compiler was configured with configure arm-elf, meaning to compile for an arm processor with elf binaries, then you would specify -b arm-elf to run that cross compiler. Because there are other options beginning with -b, the configuration must contain a hyphen, or -b alone should be one argument followed by the configuration in the next argument.

-V version
The argument version specifies which version of GCC to run. This is useful when multiple versions are installed. For example, version might be 4.0, meaning to run GCC version 4.0.
The -V and -b options work by running the <machine>-gcc-<version> executable, so there's no real reason to use them if you can just run that directly.
Hardware Models and Configurations

Earlier we discussed the standard option -b which chooses among different installed compilers for completely different target machines, such as VAX vs. 68000 vs. 80386.
In addition, each of these target machine types can have its own special options, starting with -m, to choose among various hardware models or configurations---for example, 68010 vs 68020, floating coprocessor or none. A single installed version of the compiler can compile for any model or configuration, according to the options specified.

Some configurations of the compiler also support additional special options, usually for compatibility with other compilers on the same platform.

ARC Options

These options are defined for ARC implementations:
-EL
Compile code for little endian mode. This is the default.

-EB

Compile code for big endian mode.

-mmangle-cpu
Prepend the name of the cpu to all public symbol names. In multiple-processor systems, there are many ARC variants with different instruction and register set characteristics. This flag prevents code compiled for one cpu to be linked with code compiled for another. No facility exists for handling variants that are "almost identical". This is an all or nothing option.
-mcpu=cpu
Compile code for ARC variant cpu. Which variants are supported depend on the configuration. All variants support -mcpu=base, this is the default.
-mtext=text-section
-mdata=data-section
-mrodata=readonly-data-section
Put functions, data, and readonly data in text-section, data-section, and readonly-data-section respectively by default. This can be overridden with the "section" attribute.
-mfix-cortex-m3-ldrd
Some Cortex-M3 cores can cause data corruption when "ldrd" instructions with overlapping destination and base registers are used. This option avoids generating these instructions. This option is enabled by default when -mcpu=cortex-m3 is specified.
ARM Options

These -m options are defined for Advanced RISC Machines ( ARM ) architectures:
-mabi=name
Generate code for the specified ABI . Permissible values are: apcs-gnu, atpcs, aapcs, aapcs-linux and iwmmxt.
-mapcs-frame
Generate a stack frame that is compliant with the ARM Procedure Call Standard for all functions, even if this is not strictly necessary for correct execution of the code. Specifying -fomit-frame-pointer with this option will cause the stack frames not to be generated for leaf functions. The default is -mno-apcs-frame.
-mapcs
This is a synonym for -mapcs-frame.
-mthumb-interwork
Generate code which supports calling between the ARM and Thumb instruction sets. Without this option the two instruction sets cannot be reliably used inside one program. The default is -mno-thumb-interwork, since slightly larger code is generated when -mthumb-interwork is specified.
-mno-sched-prolog
Prevent the reordering of instructions in the function prolog, or the merging of those instruction with the instructions in the function's body. This means that all functions will start with a recognizable set of instructions (or in fact one of a choice from a small set of different function prologues), and this information can be used to locate the start if functions inside an executable piece of code. The default is -msched-prolog.
-mfloat-abi=name
Specifies which floating-point ABI to use. Permissible values are: soft, softfp and hard.
Specifying soft causes GCC to generate output containing library calls for floating-point operations. softfp allows the generation of code using hardware floating-point instructions, but still uses the soft-float calling conventions. hard allows generation of floating-point instructions and uses FPU-specific calling conventions.

Using -mfloat-abi=hard with VFP coprocessors is not supported. Use -mfloat-abi=softfp with the appropriate -mfpu option to allow the compiler to generate code that makes use of the hardware floating-point capabilities for these CPUs.

The default depends on the specific target configuration. Note that the hard-float and soft-float ABIs are not link-compatible; you must compile your entire program with the same ABI , and link with a compatible set of libraries.

-mhard-float
Equivalent to -mfloat-abi=hard.
-msoft-float
Equivalent to -mfloat-abi=soft.
-mlittle-endian
Generate code for a processor running in little-endian mode. This is the default for all standard configurations.
-mbig-endian
Generate code for a processor running in big-endian mode; the default is to compile code for a little-endian processor.
-mwords-little-endian
This option only applies when generating code for big-endian processors. Generate code for a little-endian word order but a big-endian byte order. That is, a byte order of the form 32107654. Note: this option should only be used if you require compatibility with code for big-endian ARM processors generated by versions of the compiler prior to 2.8.
-mcpu=name
This specifies the name of the target ARM processor. GCC uses this name to determine what kind of instructions it can emit when generating assembly code. Permissible names are: arm2, arm250, arm3, arm6, arm60, arm600, arm610, arm620, arm7, arm7m, arm7d, arm7dm, arm7di, arm7dmi, arm70, arm700, arm700i, arm710, arm710c, arm7100, arm720, arm7500, arm7500fe, arm7tdmi, arm7tdmi-s, arm710t, arm720t, arm740t, strongarm, strongarm110, strongarm1100, strongarm1110, arm8, arm810, arm9, arm9e, arm920, arm920t, arm922t, arm946e-s, arm966e-s, arm968e-s, arm926ej-s, arm940t, arm9tdmi, arm10tdmi, arm1020t, arm1026ej-s, arm10e, arm1020e, arm1022e, arm1136j-s, arm1136jf-s, mpcore, mpcorenovfp, arm1156t2-s, arm1176jz-s, arm1176jzf-s, cortex-a8, cortex-a9, cortex-r4, cortex-r4f, cortex-m3, cortex-m1, xscale, iwmmxt, iwmmxt2, ep9312.
-mtune=name
This option is very similar to the -mcpu= option, except that instead of specifying the actual target processor type, and hence restricting which instructions can be used, it specifies that GCC should tune the performance of the code as if the target were of the type specified in this option, but still choosing the instructions that it will generate based on the cpu specified by a -mcpu= option. For some ARM implementations better performance can be obtained by using this option.
-march=name
This specifies the name of the target ARM architecture. GCC uses this name to determine what kind of instructions it can emit when generating assembly code. This option can be used in conjunction with or instead of the -mcpu= option. Permissible names are: armv2, armv2a, armv3, armv3m, armv4, armv4t, armv5, armv5t, armv5e, armv5te, armv6, armv6j, armv6t2, armv6z, armv6zk, armv6-m, armv7, armv7-a, armv7-r, armv7-m, iwmmxt, iwmmxt2, ep9312.
-mfpu=name
-mfpe=number
-mfp=number
This specifies what floating point hardware (or hardware emulation) is available on the target. Permissible names are: fpa, fpe2, fpe3, maverick, vfp, vfpv3, vfpv3-d16 and neon. -mfp and -mfpe are synonyms for -mfpu=fpenumber, for compatibility with older versions of GCC .
If -msoft-float is specified this specifies the format of floating point values.

-mstructure-size-boundary=n
The size of all structures and unions will be rounded up to a multiple of the number of bits set by this option. Permissible values are 8, 32 and 64. The default value varies for different toolchains. For the COFF targeted toolchain the default value is 8. A value of 64 is only allowed if the underlying ABI supports it.
Specifying the larger number can produce faster, more efficient code, but can also increase the size of the program. Different values are potentially incompatible. Code compiled with one value cannot necessarily expect to work with code or libraries compiled with another value, if they exchange information using structures or unions.

-mabort-on-noreturn
Generate a call to the function "abort" at the end of a "noreturn" function. It will be executed if the function tries to return.
-mlong-calls
-mno-long-calls
Tells the compiler to perform function calls by first loading the address of the function into a register and then performing a subroutine call on this register. This switch is needed if the target function will lie outside of the 64 megabyte addressing range of the offset based version of subroutine call instruction.
Even if this switch is enabled, not all function calls will be turned into long calls. The heuristic is that static functions, functions which have the short-call attribute, functions that are inside the scope of a #pragma no_long_calls directive and functions whose definitions have already been compiled within the current compilation unit, will not be turned into long calls. The exception to this rule is that weak function definitions, functions with the long-call attribute or the section attribute, and functions that are within the scope of a #pragma long_calls directive, will always be turned into long calls.

This feature is not enabled by default. Specifying -mno-long-calls will restore the default behavior, as will placing the function calls within the scope of a #pragma long_calls_off directive. Note these switches have no effect on how the compiler generates code to handle function calls via function pointers.

-msingle-pic-base
Treat the register used for PIC addressing as read-only, rather than loading it in the prologue for each function. The run-time system is responsible for initializing this register with an appropriate value before execution begins.
-mpic-register=reg
Specify the register to be used for PIC addressing. The default is R10 unless stack-checking is enabled, when R9 is used.
-mcirrus-fix-invalid-insns
Insert NOPs into the instruction stream to in order to work around problems with invalid Maverick instruction combinations. This option is only valid if the -mcpu=ep9312 option has been used to enable generation of instructions for the Cirrus Maverick floating point co-processor. This option is not enabled by default, since the problem is only present in older Maverick implementations. The default can be re-enabled by use of the -mno-cirrus-fix-invalid-insns switch.
-mpoke-function-name
Write the name of each function into the text section, directly preceding the function prologue. The generated code is similar to this:
t0
    .ascii "arm_poke_function_name", 0
    .align
t1
    .word 0xff000000 + (t1 - t0)
arm_poke_function_name
    mov     ip, sp
    stmfd   sp!, {fp, ip, lr, pc}
    sub     fp, ip, #4
When performing a stack backtrace, code can inspect the value of "pc" stored at "fp + 0". If the trace function then looks at location "pc - 12" and the top 8 bits are set, then we know that there is a function name embedded immediately preceding this location and has length "((pc[-3]) & 0xff000000)".
-mthumb
Generate code for the Thumb instruction set. The default is to use the 32-bit ARM instruction set. This option automatically enables either 16-bit Thumb-1 or mixed 16/32-bit Thumb-2 instructions based on the -mcpu=name and -march=name options.
-mtpcs-frame
Generate a stack frame that is compliant with the Thumb Procedure Call Standard for all non-leaf functions. (A leaf function is one that does not call any other functions.) The default is -mno-tpcs-frame.
-mtpcs-leaf-frame
Generate a stack frame that is compliant with the Thumb Procedure Call Standard for all leaf functions. (A leaf function is one that does not call any other functions.) The default is -mno-apcs-leaf-frame.
-mcallee-super-interworking
Gives all externally visible functions in the file being compiled an ARM instruction set header which switches to Thumb mode before executing the rest of the function. This allows these functions to be called from non-interworking code.
-mcaller-super-interworking
Allows calls via function pointers (including virtual functions) to execute correctly regardless of whether the target code has been compiled for interworking or not. There is a small overhead in the cost of executing a function pointer if this option is enabled.
-mtp=name
Specify the access model for the thread local storage pointer. The valid models are soft, which generates calls to "__aeabi_read_tp", cp15, which fetches the thread pointer from "cp15" directly (supported in the arm6k architecture), and auto, which uses the best available method for the selected processor. The default setting is auto.
-mword-relocations
Only generate absolute relocations on word sized values (i.e. R_ARM_ABS32). This is enabled by default on targets (uClinux, SymbianOS) where the runtime loader imposes this restriction, and when -fpic or -fPIC is specified.
AVR Options

These options are defined for AVR implementations:
-mmcu=mcu
Specify ATMEL AVR instruction set or MCU type.
Instruction set avr1 is for the minimal AVR core, not supported by the C compiler, only for assembler programs ( MCU types: at90s1200, attiny10, attiny11, attiny12, attiny15, attiny28).

Instruction set avr2 (default) is for the classic AVR core with up to 8K program memory space ( MCU types: at90s2313, at90s2323, attiny22, at90s2333, at90s2343, at90s4414, at90s4433, at90s4434, at90s8515, at90c8534, at90s8535).

Instruction set avr3 is for the classic AVR core with up to 128K program memory space ( MCU types: atmega103, atmega603, at43usb320, at76c711).

Instruction set avr4 is for the enhanced AVR core with up to 8K program memory space ( MCU types: atmega8, atmega83, atmega85).

Instruction set avr5 is for the enhanced AVR core with up to 128K program memory space ( MCU types: atmega16, atmega161, atmega163, atmega32, atmega323, atmega64, atmega128, at43usb355, at94k).

-msize
Output instruction sizes to the asm file.
-mno-interrupts
Generated code is not compatible with hardware interrupts. Code size will be smaller.
-mcall-prologues
Functions prologues/epilogues expanded as call to appropriate subroutines. Code size will be smaller.
-mno-tablejump
Do not generate tablejump insns which sometimes increase code size. The option is now deprecated in favor of the equivalent -fno-jump-tables
-mtiny-stack
Change only the low 8 bits of the stack pointer.
-mint8
Assume int to be 8 bit integer. This affects the sizes of all types: A char will be 1 byte, an int will be 1 byte, an long will be 2 bytes and long long will be 4 bytes. Please note that this option does not comply to the C standards, but it will provide you with smaller code size.
Blackfin Options

-mcpu=cpu[-sirevision]
Specifies the name of the target Blackfin processor. Currently, cpu can be one of bf512, bf514, bf516, bf518, bf522, bf523, bf524, bf525, bf526, bf527, bf531, bf532, bf533, bf534, bf536, bf537, bf538, bf539, bf542, bf544, bf547, bf548, bf549, bf561. The optional sirevision specifies the silicon revision of the target Blackfin processor. Any workarounds available for the targeted silicon revision will be enabled. If sirevision is none, no workarounds are enabled. If sirevision is any, all workarounds for the targeted processor will be enabled. The "__SILICON_REVISION__" macro is defined to two hexadecimal digits representing the major and minor numbers in the silicon revision. If sirevision is none, the "__SILICON_REVISION__" is not defined. If sirevision is any, the "__SILICON_REVISION__" is defined to be 0xffff. If this optional sirevision is not used, GCC assumes the latest known silicon revision of the targeted Blackfin processor.
Support for bf561 is incomplete. For bf561, Only the processor macro is defined. Without this option, bf532 is used as the processor by default. The corresponding predefined processor macros for cpu is to be defined. And for bfin-elf toolchain, this causes the hardware BSP provided by libgloss to be linked in if -msim is not given.

-msim
Specifies that the program will be run on the simulator. This causes the simulator BSP provided by libgloss to be linked in. This option has effect only for bfin-elf toolchain. Certain other options, such as -mid-shared-library and -mfdpic, imply -msim.
-momit-leaf-frame-pointer
Don't keep the frame pointer in a register for leaf functions. This avoids the instructions to save, set up and restore frame pointers and makes an extra register available in leaf functions. The option -fomit-frame-pointer removes the frame pointer for all functions which might make debugging harder.
-mspecld-anomaly
When enabled, the compiler will ensure that the generated code does not contain speculative loads after jump instructions. If this option is used, "__WORKAROUND_SPECULATIVE_LOADS" is defined.
-mno-specld-anomaly
Don't generate extra code to prevent speculative loads from occurring.
-mcsync-anomaly
When enabled, the compiler will ensure that the generated code does not contain CSYNC or SSYNC instructions too soon after conditional branches. If this option is used, "__WORKAROUND_SPECULATIVE_SYNCS" is defined.
-mno-csync-anomaly
Don't generate extra code to prevent CSYNC or SSYNC instructions from occurring too soon after a conditional branch.
-mlow-64k
When enabled, the compiler is free to take advantage of the knowledge that the entire program fits into the low 64k of memory.
-mno-low-64k
Assume that the program is arbitrarily large. This is the default.
-mstack-check-l1
Do stack checking using information placed into L1 scratchpad memory by the uClinux kernel.
-mid-shared-library
Generate code that supports shared libraries via the library ID method. This allows for execute in place and shared libraries in an environment without virtual memory management. This option implies -fPIC. With a bfin-elf target, this option implies -msim.
-mno-id-shared-library
Generate code that doesn't assume ID based shared libraries are being used. This is the default.
-mleaf-id-shared-library
Generate code that supports shared libraries via the library ID method, but assumes that this library or executable won't link against any other ID shared libraries. That allows the compiler to use faster code for jumps and calls.
-mno-leaf-id-shared-library
Do not assume that the code being compiled won't link against any ID shared libraries. Slower code will be generated for jump and call insns.
-mshared-library-id=n
Specified the identification number of the ID based shared library being compiled. Specifying a value of 0 will generate more compact code, specifying other values will force the allocation of that number to the current library but is no more space or time efficient than omitting this option.
-msep-data
Generate code that allows the data segment to be located in a different area of memory from the text segment. This allows for execute in place in an environment without virtual memory management by eliminating relocations against the text section.
-mno-sep-data
Generate code that assumes that the data segment follows the text segment. This is the default.
-mlong-calls
-mno-long-calls
Tells the compiler to perform function calls by first loading the address of the function into a register and then performing a subroutine call on this register. This switch is needed if the target function will lie outside of the 24 bit addressing range of the offset based version of subroutine call instruction.
This feature is not enabled by default. Specifying -mno-long-calls will restore the default behavior. Note these switches have no effect on how the compiler generates code to handle function calls via function pointers.

-mfast-fp
Link with the fast floating-point library. This library relaxes some of the IEEE floating-point standard's rules for checking inputs against Not-a-Number ( NAN ), in the interest of performance.
-minline-plt
Enable inlining of PLT entries in function calls to functions that are not known to bind locally. It has no effect without -mfdpic.
-mmulticore
Build standalone application for multicore Blackfin processor. Proper start files and link scripts will be used to support multicore. This option defines "__BFIN_MULTICORE". It can only be used with -mcpu=bf561[-sirevision]. It can be used with -mcorea or -mcoreb. If it's used without -mcorea or -mcoreb, single application/dual core programming model is used. In this model, the main function of Core B should be named as coreb_main. If it's used with -mcorea or -mcoreb, one application per core programming model is used. If this option is not used, single core application programming model is used.
-mcorea
Build standalone application for Core A of BF561 when using one application per core programming model. Proper start files and link scripts will be used to support Core A. This option defines "__BFIN_COREA". It must be used with -mmulticore.
-mcoreb
Build standalone application for Core B of BF561 when using one application per core programming model. Proper start files and link scripts will be used to support Core B. This option defines "__BFIN_COREB". When this option is used, coreb_main should be used instead of main. It must be used with -mmulticore.
-msdram
Build standalone application for SDRAM . Proper start files and link scripts will be used to put the application into SDRAM . Loader should initialize SDRAM before loading the application into SDRAM . This option defines "__BFIN_SDRAM".
-micplb
Assume that ICPLBs are enabled at runtime. This has an effect on certain anomaly workarounds. For Linux targets, the default is to assume ICPLBs are enabled; for standalone applications the default is off.
CRIS Options

These options are defined specifically for the CRIS ports.
-march=architecture-type
-mcpu=architecture-type
Generate code for the specified architecture. The choices for architecture-type are v3, v8 and v10 for respectively ETRAX 4, ETRAX 100, and ETRAX 100 LX . Default is v0 except for cris-axis-linux-gnu, where the default is v10.
-mtune=architecture-type
Tune to architecture-type everything applicable about the generated code, except for the ABI and the set of available instructions. The choices for architecture-type are the same as for -march=architecture-type.
-mmax-stack-frame=n
Warn when the stack frame of a function exceeds n bytes.
-metrax4
-metrax100
The options -metrax4 and -metrax100 are synonyms for -march=v3 and -march=v8 respectively.
-mmul-bug-workaround
-mno-mul-bug-workaround
Work around a bug in the "muls" and "mulu" instructions for CPU models where it applies. This option is active by default.
-mpdebug
Enable CRIS-specific verbose debug-related information in the assembly code. This option also has the effect to turn off the #NO_APP formatted-code indicator to the assembler at the beginning of the assembly file.
-mcc-init
Do not use condition-code results from previous instruction; always emit compare and test instructions before use of condition codes.
-mno-side-effects
Do not emit instructions with side-effects in addressing modes other than post-increment.
-mstack-align
-mno-stack-align
-mdata-align
-mno-data-align
-mconst-align
-mno-const-align
These options (no-options) arranges (eliminate arrangements) for the stack-frame, individual data and constants to be aligned for the maximum single data access size for the chosen CPU model. The default is to arrange for 32-bit alignment. ABI details such as structure layout are not affected by these options.
-m32-bit
-m16-bit
-m8-bit
Similar to the stack- data- and const-align options above, these options arrange for stack-frame, writable data and constants to all be 32-bit, 16-bit or 8-bit aligned. The default is 32-bit alignment.
-mno-prologue-epilogue
-mprologue-epilogue
With -mno-prologue-epilogue, the normal function prologue and epilogue that sets up the stack-frame are omitted and no return instructions or return sequences are generated in the code. Use this option only together with visual inspection of the compiled code: no warnings or errors are generated when call-saved registers must be saved, or storage for local variable needs to be allocated.
-mno-gotplt
-mgotplt
With -fpic and -fPIC, don't generate (do generate) instruction sequences that load addresses for functions from the PLT part of the GOT rather than (traditional on other architectures) calls to the PLT . The default is -mgotplt.
-melf
Legacy no-op option only recognized with the cris-axis-elf and cris-axis-linux-gnu targets.
-mlinux
Legacy no-op option only recognized with the cris-axis-linux-gnu target.
-sim
This option, recognized for the cris-axis-elf arranges to link with input-output functions from a simulator library. Code, initialized data and zero-initialized data are allocated consecutively.
-sim2
Like -sim, but pass linker options to locate initialized data at 0x40000000 and zero-initialized data at 0x80000000.
CRX Options

These options are defined specifically for the CRX ports.
-mmac
Enable the use of multiply-accumulate instructions. Disabled by default.
-mpush-args
Push instructions will be used to pass outgoing arguments when functions are called. Enabled by default.
Darwin Options

These options are defined for all architectures running the Darwin operating system.
FSF GCC on Darwin does not create "fat" object files; it will create an object file for the single architecture that it was built to target. Apple's GCC on Darwin does create "fat" files if multiple -arch options are used; it does so by running the compiler or linker multiple times and joining the results together with lipo.

The subtype of the file created (like ppc7400 or ppc970 or i686) is determined by the flags that specify the ISA that GCC is targetting, like -mcpu or -march. The -force_cpusubtype_ALL option can be used to override this.

The Darwin tools vary in their behavior when presented with an ISA mismatch. The assembler, as, will only permit instructions to be used that are valid for the subtype of the file it is generating, so you cannot put 64-bit instructions in an ppc750 object file. The linker for shared libraries, /usr/bin/libtool, will fail and print an error if asked to create a shared library with a less restrictive subtype than its input files (for instance, trying to put a ppc970 object file in a ppc7400 library). The linker for executables, ld, will quietly give the executable the most restrictive subtype of any of its input files.

-Fdir
Add the framework directory dir to the head of the list of directories to be searched for header files. These directories are interleaved with those specified by -I options and are scanned in a left-to-right order.
A framework directory is a directory with frameworks in it. A framework is a directory with a "Headers" and/or "PrivateHeaders" directory contained directly in it that ends in ".framework". The name of a framework is the name of this directory excluding the ".framework". Headers associated with the framework are found in one of those two directories, with "Headers" being searched first. A subframework is a framework directory that is in a framework's "Frameworks" directory. Includes of subframework headers can only appear in a header of a framework that contains the subframework, or in a sibling subframework header. Two subframeworks are siblings if they occur in the same framework. A subframework should not have the same name as a framework, a warning will be issued if this is violated. Currently a subframework cannot have subframeworks, in the future, the mechanism may be extended to support this. The standard frameworks can be found in "/System/Library/Frameworks" and "/Library/Frameworks". An example include looks like "#include <Framework/header.h>", where Framework denotes the name of the framework and header.h is found in the "PrivateHeaders" or "Headers" directory.

-iframeworkdir
Like -F except the directory is a treated as a system directory. The main difference between this -iframework and -F is that with -iframework the compiler does not warn about constructs contained within header files found via dir. This option is valid only for the C family of languages.
-gused
Emit debugging information for symbols that are used. For STABS debugging format, this enables -feliminate-unused-debug-symbols. This is by default ON .
-gfull
Emit debugging information for all symbols and types.
-mmacosx-version-min=version
The earliest version of MacOS X that this executable will run on is version. Typical values of version include 10.1, 10.2, and 10.3.9.
If the compiler was built to use the system's headers by default, then the default for this option is the system version on which the compiler is running, otherwise the default is to make choices which are compatible with as many systems and code bases as possible.

-mkernel
Enable kernel development mode. The -mkernel option sets -static, -fno-common, -fno-cxa-atexit, -fno-exceptions, -fno-non-call-exceptions, -fapple-kext, -fno-weak and -fno-rtti where applicable. This mode also sets -mno-altivec, -msoft-float, -fno-builtin and -mlong-branch for PowerPC targets.
-mone-byte-bool
Override the defaults for bool so that sizeof(bool)==1. By default sizeof(bool) is 4 when compiling for Darwin/PowerPC and 1 when compiling for Darwin/x86, so this option has no effect on x86.
Warning: The -mone-byte-bool switch causes GCC to generate code that is not binary compatible with code generated without that switch. Using this switch may require recompiling all other modules in a program, including system libraries. Use this switch to conform to a non-default data model.

-mfix-and-continue
-ffix-and-continue
-findirect-data
Generate code suitable for fast turn around development. Needed to enable gdb to dynamically load ".o" files into already running programs. -findirect-data and -ffix-and-continue are provided for backwards compatibility.
-all_load
Loads all members of static archive libraries. See man ld(1) for more information.
-arch_errors_fatal
Cause the errors having to do with files that have the wrong architecture to be fatal.
-bind_at_load
Causes the output file to be marked such that the dynamic linker will bind all undefined references when the file is loaded or launched.
-bundle
Produce a Mach-o bundle format file. See man ld(1) for more information.
-bundle_loader executable
This option specifies the executable that will be loading the build output file being linked. See man ld(1) for more information.
-dynamiclib
When passed this option, GCC will produce a dynamic library instead of an executable when linking, using the Darwin libtool command.
-force_cpusubtype_ALL
This causes GCC 's output file to have the ALL subtype, instead of one controlled by the -mcpu or -march option.
-allowable_client client_name
-client_name
-compatibility_version
-current_version
-dead_strip
-dependency-file
-dylib_file
-dylinker_install_name
-dynamic
-exported_symbols_list
-filelist
-flat_namespace
-force_flat_namespace
-headerpad_max_install_names
-image_base
-init
-install_name
-keep_private_externs
-multi_module
-multiply_defined
-multiply_defined_unused
-noall_load
-no_dead_strip_inits_and_terms
-nofixprebinding
-nomultidefs
-noprebind
-noseglinkedit
-pagezero_size
-prebind
-prebind_all_twolevel_modules
-private_bundle
-read_only_relocs
-sectalign
-sectobjectsymbols
-whyload
-seg1addr
-sectcreate
-sectobjectsymbols
-sectorder
-segaddr
-segs_read_only_addr
-segs_read_write_addr
-seg_addr_table
-seg_addr_table_filename
-seglinkedit
-segprot
-segs_read_only_addr
-segs_read_write_addr
-single_module
-static
-sub_library
-sub_umbrella
-twolevel_namespace
-umbrella
-undefined
-unexported_symbols_list
-weak_reference_mismatches
-whatsloaded
These options are passed to the Darwin linker. The Darwin linker man page describes them in detail.
DEC Alpha Options

These -m options are defined for the DEC Alpha implementations:
-mno-soft-float
-msoft-float
Use (do not use) the hardware floating-point instructions for floating-point operations. When -msoft-float is specified, functions in libgcc.a will be used to perform floating-point operations. Unless they are replaced by routines that emulate the floating-point operations, or compiled in such a way as to call such emulations routines, these routines will issue floating-point operations. If you are compiling for an Alpha without floating-point operations, you must ensure that the library is built so as not to call them.
Note that Alpha implementations without floating-point operations are required to have floating-point registers.

-mfp-reg
-mno-fp-regs
Generate code that uses (does not use) the floating-point register set. -mno-fp-regs implies -msoft-float. If the floating-point register set is not used, floating point operands are passed in integer registers as if they were integers and floating-point results are passed in $0 instead of $f0. This is a non-standard calling sequence, so any function with a floating-point argument or return value called by code compiled with -mno-fp-regs must also be compiled with that option.
A typical use of this option is building a kernel that does not use, and hence need not save and restore, any floating-point registers.

-mieee
The Alpha architecture implements floating-point hardware optimized for maximum performance. It is mostly compliant with the IEEE floating point standard. However, for full compliance, software assistance is required. This option generates code fully IEEE compliant code except that the inexact-flag is not maintained (see below). If this option is turned on, the preprocessor macro "_IEEE_FP" is defined during compilation. The resulting code is less efficient but is able to correctly support denormalized numbers and exceptional IEEE values such as not-a-number and plus/minus infinity. Other Alpha compilers call this option -ieee_with_no_inexact.
-mieee-with-inexact
This is like -mieee except the generated code also maintains the IEEE inexact-flag. Turning on this option causes the generated code to implement fully-compliant IEEE math. In addition to "_IEEE_FP", "_IEEE_FP_EXACT" is defined as a preprocessor macro. On some Alpha implementations the resulting code may execute significantly slower than the code generated by default. Since there is very little code that depends on the inexact-flag, you should normally not specify this option. Other Alpha compilers call this option -ieee_with_inexact.
-mfp-trap-mode=trap-mode
This option controls what floating-point related traps are enabled. Other Alpha compilers call this option -fptm trap-mode. The trap mode can be set to one of four values:
n
This is the default (normal) setting. The only traps that are enabled are the ones that cannot be disabled in software (e.g., division by zero trap).

u

In addition to the traps enabled by n, underflow traps are enabled as well.

su

Like u, but the instructions are marked to be safe for software completion (see Alpha architecture manual for details).

sui

Like su, but inexact traps are enabled as well.

-mfp-rounding-mode=rounding-mode
Selects the IEEE rounding mode. Other Alpha compilers call this option -fprm rounding-mode. The rounding-mode can be one of:
n
Normal IEEE rounding mode. Floating point numbers are rounded towards the nearest machine number or towards the even machine number in case of a tie.

m

Round towards minus infinity.

c

Chopped rounding mode. Floating point numbers are rounded towards zero.

d

Dynamic rounding mode. A field in the floating point control register (fpcr, see Alpha architecture reference manual) controls the rounding mode in effect. The C library initializes this register for rounding towards plus infinity. Thus, unless your program modifies the fpcr, d corresponds to round towards plus infinity.

-mtrap-precision=trap-precision
In the Alpha architecture, floating point traps are imprecise. This means without software assistance it is impossible to recover from a floating trap and program execution normally needs to be terminated. GCC can generate code that can assist operating system trap handlers in determining the exact location that caused a floating point trap. Depending on the requirements of an application, different levels of precisions can be selected:
p
Program precision. This option is the default and means a trap handler can only identify which program caused a floating point exception.

f

Function precision. The trap handler can determine the function that caused a floating point exception.

i

Instruction precision. The trap handler can determine the exact instruction that caused a floating point exception.

Other Alpha compilers provide the equivalent options called -scope_safe and -resumption_safe.
-mieee-conformant
This option marks the generated code as IEEE conformant. You must not use this option unless you also specify -mtrap-precision=i and either -mfp-trap-mode=su or -mfp-trap-mode=sui. Its only effect is to emit the line .eflag 48 in the function prologue of the generated assembly file. Under DEC Unix, this has the effect that IEEE-conformant math library routines will be linked in.
-mbuild-constants
Normally GCC examines a 32- or 64-bit integer constant to see if it can construct it from smaller constants in two or three instructions. If it cannot, it will output the constant as a literal and generate code to load it from the data segment at runtime.
Use this option to require GCC to construct all integer constants using code, even if it takes more instructions (the maximum is six).

You would typically use this option to build a shared library dynamic loader. Itself a shared library, it must relocate itself in memory before it can find the variables and constants in its own data segment.

-malpha-as
-mgas
Select whether to generate code to be assembled by the vendor-supplied assembler (-malpha-as) or by the GNU assembler -mgas.
-mbwx
-mno-bwx
-mcix
-mno-cix
-mfix
-mno-fix
-mmax
-mno-max
Indicate whether GCC should generate code to use the optional BWX , CIX , FIX and MAX instruction sets. The default is to use the instruction sets supported by the CPU type specified via -mcpu= option or that of the CPU on which GCC was built if none was specified.
-mfloat-vax
-mfloat-ieee
Generate code that uses (does not use) VAX F and G floating point arithmetic instead of IEEE single and double precision.
-mexplicit-relocs
-mno-explicit-relocs
Older Alpha assemblers provided no way to generate symbol relocations except via assembler macros. Use of these macros does not allow optimal instruction scheduling. GNU binutils as of version 2.12 supports a new syntax that allows the compiler to explicitly mark which relocations should apply to which instructions. This option is mostly useful for debugging, as GCC detects the capabilities of the assembler when it is built and sets the default accordingly.
-msmall-data
-mlarge-data
When -mexplicit-relocs is in effect, static data is accessed via gp-relative relocations. When -msmall-data is used, objects 8 bytes long or smaller are placed in a small data area (the ".sdata" and ".sbss" sections) and are accessed via 16-bit relocations off of the $gp register. This limits the size of the small data area to 64KB, but allows the variables to be directly accessed via a single instruction.
The default is -mlarge-data. With this option the data area is limited to just below 2GB. Programs that require more than 2GB of data must use "malloc" or "mmap" to allocate the data in the heap instead of in the program's data segment.

When generating code for shared libraries, -fpic implies -msmall-data and -fPIC implies -mlarge-data.

-msmall-text
-mlarge-text
When -msmall-text is used, the compiler assumes that the code of the entire program (or shared library) fits in 4MB, and is thus reachable with a branch instruction. When -msmall-data is used, the compiler can assume that all local symbols share the same $gp value, and thus reduce the number of instructions required for a function call from 4 to 1.
The default is -mlarge-text.

-mcpu=cpu_type
Set the instruction set and instruction scheduling parameters for machine type cpu_type. You can specify either the EV style name or the corresponding chip number. GCC supports scheduling parameters for the EV4 , EV5 and EV6 family of processors and will choose the default values for the instruction set from the processor you specify. If you do not specify a processor type, GCC will default to the processor on which the compiler was built.
Supported values for cpu_type are

ev4
ev45
21064
Schedules as an EV4 and has no instruction set extensions.
ev5
21164
Schedules as an EV5 and has no instruction set extensions.
ev56
21164a
Schedules as an EV5 and supports the BWX extension.
pca56
21164pc
21164PC
Schedules as an EV5 and supports the BWX and MAX extensions.
ev6
21264
Schedules as an EV6 and supports the BWX , FIX , and MAX extensions.
ev67
21264a
Schedules as an EV6 and supports the BWX , CIX , FIX , and MAX extensions.
Native Linux/GNU toolchains also support the value native, which selects the best architecture option for the host processor. -mcpu=native has no effect if GCC does not recognize the processor.
-mtune=cpu_type
Set only the instruction scheduling parameters for machine type cpu_type. The instruction set is not changed.
Native Linux/GNU toolchains also support the value native, which selects the best architecture option for the host processor. -mtune=native has no effect if GCC does not recognize the processor.

-mmemory-latency=time
Sets the latency the scheduler should assume for typical memory references as seen by the application. This number is highly dependent on the memory access patterns used by the application and the size of the external cache on the machine.
Valid options for time are

number
A decimal number representing clock cycles.
L1
L2

L3

main
The compiler contains estimates of the number of clock cycles for "typical" EV4 & EV5 hardware for the Level 1, 2 & 3 caches (also called Dcache, Scache, and Bcache), as well as to main memory. Note that L3 is only valid for EV5 .
DEC Alpha/VMS Options

These -m options are defined for the DEC Alpha/VMS implementations:
-mvms-return-codes
Return VMS condition codes from main. The default is to return POSIX style condition (e.g. error) codes.
FR30 Options

These options are defined specifically for the FR30 port.
-msmall-model
Use the small address space model. This can produce smaller code, but it does assume that all symbolic values and addresses will fit into a 20-bit range.
-mno-lsim
Assume that run-time support has been provided and so there is no need to include the simulator library (libsim.a) on the linker command line.
FRV Options

-mgpr-32
Only use the first 32 general purpose registers.
-mgpr-64
Use all 64 general purpose registers.
-mfpr-32
Use only the first 32 floating point registers.
-mfpr-64
Use all 64 floating point registers
-mhard-float
Use hardware instructions for floating point operations.
-msoft-float
Use library routines for floating point operations.
-malloc-cc
Dynamically allocate condition code registers.
-mfixed-cc
Do not try to dynamically allocate condition code registers, only use "icc0" and "fcc0".
-mdword
Change ABI to use double word insns.
-mno-dword
Do not use double word instructions.
-mdouble
Use floating point double instructions.
-mno-double
Do not use floating point double instructions.
-mmedia
Use media instructions.
-mno-media
Do not use media instructions.
-mmuladd
Use multiply and add/subtract instructions.
-mno-muladd
Do not use multiply and add/subtract instructions.
-mfdpic
Select the FDPIC ABI , that uses function descriptors to represent pointers to functions. Without any PIC/PIE-related options, it implies -fPIE. With -fpic or -fpie, it assumes GOT entries and small data are within a 12-bit range from the GOT base address; with -fPIC or -fPIE, GOT offsets are computed with 32 bits. With a bfin-elf target, this option implies -msim.
-minline-plt
Enable inlining of PLT entries in function calls to functions that are not known to bind locally. It has no effect without -mfdpic. It's enabled by default if optimizing for speed and compiling for shared libraries (i.e., -fPIC or -fpic), or when an optimization option such as -O3 or above is present in the command line.
-mTLS
Assume a large TLS segment when generating thread-local code.
-mtls
Do not assume a large TLS segment when generating thread-local code.
-mgprel-ro
Enable the use of "GPREL" relocations in the FDPIC ABI for data that is known to be in read-only sections. It's enabled by default, except for -fpic or -fpie: even though it may help make the global offset table smaller, it trades 1 instruction for 4. With -fPIC or -fPIE, it trades 3 instructions for 4, one of which may be shared by multiple symbols, and it avoids the need for a GOT entry for the referenced symbol, so it's more likely to be a win. If it is not, -mno-gprel-ro can be used to disable it.
-multilib-library-pic
Link with the (library, not FD ) pic libraries. It's implied by -mlibrary-pic, as well as by -fPIC and -fpic without -mfdpic. You should never have to use it explicitly.
-mlinked-fp
Follow the EABI requirement of always creating a frame pointer whenever a stack frame is allocated. This option is enabled by default and can be disabled with -mno-linked-fp.
-mlong-calls
Use indirect addressing to call functions outside the current compilation unit. This allows the functions to be placed anywhere within the 32-bit address space.
-malign-labels
Try to align labels to an 8-byte boundary by inserting nops into the previous packet. This option only has an effect when VLIW packing is enabled. It doesn't create new packets; it merely adds nops to existing ones.
-mlibrary-pic
Generate position-independent EABI code.
-macc-4
Use only the first four media accumulator registers.
-macc-8
Use all eight media accumulator registers.
-mpack
Pack VLIW instructions.
-mno-pack
Do not pack VLIW instructions.
-mno-eflags
Do not mark ABI switches in e_flags.
-mcond-move
Enable the use of conditional-move instructions (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-cond-move
Disable the use of conditional-move instructions.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mscc
Enable the use of conditional set instructions (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-scc
Disable the use of conditional set instructions.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mcond-exec
Enable the use of conditional execution (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-cond-exec
Disable the use of conditional execution.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mvliw-branch
Run a pass to pack branches into VLIW instructions (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-vliw-branch
Do not run a pass to pack branches into VLIW instructions.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mmulti-cond-exec
Enable optimization of "&&" and "||" in conditional execution (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-multi-cond-exec
Disable optimization of "&&" and "||" in conditional execution.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mnested-cond-exec
Enable nested conditional execution optimizations (default).
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-mno-nested-cond-exec
Disable nested conditional execution optimizations.
This switch is mainly for debugging the compiler and will likely be removed in a future version.

-moptimize-membar
This switch removes redundant "membar" instructions from the compiler generated code. It is enabled by default.
-mno-optimize-membar
This switch disables the automatic removal of redundant "membar" instructions from the generated code.
-mtomcat-stats
Cause gas to print out tomcat statistics.
-mcpu=cpu
Select the processor type for which to generate code. Possible values are frv, fr550, tomcat, fr500, fr450, fr405, fr400, fr300 and simple.
GNU/Linux Options

These -m options are defined for GNU/Linux targets:
-mglibc
Use the GNU C library instead of uClibc. This is the default except on *-*-linux-*uclibc* targets.
-muclibc
Use uClibc instead of the GNU C library. This is the default on *-*-linux-*uclibc* targets.
H8/300 Options

These -m options are defined for the H8/300 implementations:
-mrelax
Shorten some address references at link time, when possible; uses the linker option -relax.
-mh
Generate code for the H8/300H.

-ms

Generate code for the H8S.

-mn

Generate code for the H8S and H8/300H in the normal mode. This switch must be used either with -mh or -ms.

-ms2600
Generate code for the H8S/2600. This switch must be used with -ms.
-mint32
Make "int" data 32 bits by default.
-malign-300
On the H8/300H and H8S, use the same alignment rules as for the H8/300. The default for the H8/300H and H8S is to align longs and floats on 4 byte boundaries. -malign-300 causes them to be aligned on 2 byte boundaries. This option has no effect on the H8/300.
HPPA Options

These -m options are defined for the HPPA family of computers:
-march=architecture-type
Generate code for the specified architecture. The choices for architecture-type are 1.0 for PA 1.0, 1.1 for PA 1.1, and 2.0 for PA 2.0 processors. Refer to /usr/lib/sched.models on an HP-UX system to determine the proper architecture option for your machine. Code compiled for lower numbered architectures will run on higher numbered architectures, but not the other way around.
-mpa-risc-1-0
-mpa-risc-1-1
-mpa-risc-2-0
Synonyms for -march=1.0, -march=1.1, and -march=2.0 respectively.
-mbig-switch
Generate code suitable for big switch tables. Use this option only if the assembler/linker complain about out of range branches within a switch table.
-mjump-in-delay
Fill delay slots of function calls with unconditional jump instructions by modifying the return pointer for the function call to be the target of the conditional jump.
-mdisable-fpregs
Prevent floating point registers from being used in any manner. This is necessary for compiling kernels which perform lazy context switching of floating point registers. If you use this option and attempt to perform floating point operations, the compiler will abort.
-mdisable-indexing
Prevent the compiler from using indexing address modes. This avoids some rather obscure problems when compiling MIG generated code under MACH .
-mno-space-regs
Generate code that assumes the target has no space registers. This allows GCC to generate faster indirect calls and use unscaled index address modes.
Such code is suitable for level 0 PA systems and kernels.

-mfast-indirect-calls
Generate code that assumes calls never cross space boundaries. This allows GCC to emit code which performs faster indirect calls.
This option will not work in the presence of shared libraries or nested functions.

-mfixed-range=register-range
Generate code treating the given register range as fixed registers. A fixed register is one that the register allocator can not use. This is useful when compiling kernel code. A register range is specified as two registers separated by a dash. Multiple register ranges can be specified separated by a comma.
-mlong-load-store
Generate 3-instruction load and store sequences as sometimes required by the HP-UX 10 linker. This is equivalent to the +k option to the HP compilers.
-mportable-runtime
Use the portable calling conventions proposed by HP for ELF systems.
-mgas
Enable the use of assembler directives only GAS understands.
-mschedule=cpu-type
Schedule code according to the constraints for the machine type cpu-type. The choices for cpu-type are 700 7100, 7100LC, 7200, 7300 and 8000. Refer to /usr/lib/sched.models on an HP-UX system to determine the proper scheduling option for your machine. The default scheduling is 8000.
-mlinker-opt
Enable the optimization pass in the HP-UX linker. Note this makes symbolic debugging impossible. It also triggers a bug in the HP-UX 8 and HP-UX 9 linkers in which they give bogus error messages when linking some programs.
-msoft-float
Generate output containing library calls for floating point. Warning: the requisite libraries are not available for all HPPA targets. Normally the facilities of the machine's usual C compiler are used, but this cannot be done directly in cross-compilation. You must make your own arrangements to provide suitable library functions for cross-compilation.
-msoft-float changes the calling convention in the output file; therefore, it is only useful if you compile all of a program with this option. In particular, you need to compile libgcc.a, the library that comes with GCC , with -msoft-float in order for this to work.

-msio
Generate the predefine, "_SIO", for server IO . The default is -mwsio. This generates the predefines, "__hp9000s700", "__hp9000s700__" and "_WSIO", for workstation IO . These options are available under HP-UX and HI-UX.
-mgnu-ld
Use GNU ld specific options. This passes -shared to ld when building a shared library. It is the default when GCC is configured, explicitly or implicitly, with the GNU linker. This option does not have any affect on which ld is called, it only changes what parameters are passed to that ld. The ld that is called is determined by the --with-ld configure option, GCC 's program search path, and finally by the user's PATH . The linker used by GCC can be printed using which 'gcc -print-prog-name=ld'. This option is only available on the 64 bit HP-UX GCC , i.e. configured with hppa*64*-*-hpux*.
-mhp-ld
Use HP ld specific options. This passes -b to ld when building a shared library and passes +Accept TypeMismatch to ld on all links. It is the default when GCC is configured, explicitly or implicitly, with the HP linker. This option does not have any affect on which ld is called, it only changes what parameters are passed to that ld. The ld that is called is determined by the --with-ld configure option, GCC 's program search path, and finally by the user's PATH . The linker used by GCC can be printed using which 'gcc -print-prog-name=ld'. This option is only available on the 64 bit HP-UX GCC , i.e. configured with hppa*64*-*-hpux*.
-mlong-calls
Generate code that uses long call sequences. This ensures that a call is always able to reach linker generated stubs. The default is to generate long calls only when the distance from the call site to the beginning of the function or translation unit, as the case may be, exceeds a predefined limit set by the branch type being used. The limits for normal calls are 7,600,000 and 240,000 bytes, respectively for the PA 2.0 and PA 1.X architectures. Sibcalls are always limited at 240,000 bytes.
Distances are measured from the beginning of functions when using the -ffunction-sections option, or when using the -mgas and -mno-portable-runtime options together under HP-UX with the SOM linker.

It is normally not desirable to use this option as it will degrade performance. However, it may be useful in large applications, particularly when partial linking is used to build the application.

The types of long calls used depends on the capabilities of the assembler and linker, and the type of code being generated. The impact on systems that support long absolute calls, and long pic symbol-difference or pc-relative calls should be relatively small. However, an indirect call is used on 32-bit ELF systems in pic code and it is quite long.

-munix=unix-std
Generate compiler predefines and select a startfile for the specified UNIX standard. The choices for unix-std are 93, 95 and 98. 93 is supported on all HP-UX versions. 95 is available on HP-UX 10.10 and later. 98 is available on HP-UX 11.11 and later. The default values are 93 for HP-UX 10.00, 95 for HP-UX 10.10 though to 11.00, and 98 for HP-UX 11.11 and later.
-munix=93 provides the same predefines as GCC 3.3 and 3.4. -munix=95 provides additional predefines for "XOPEN_UNIX" and "_XOPEN_SOURCE_EXTENDED", and the startfile unix95.o. -munix=98 provides additional predefines for "_XOPEN_UNIX", "_XOPEN_SOURCE_EXTENDED", "_INCLUDE__STDC_A1_SOURCE" and "_INCLUDE_XOPEN_SOURCE_500", and the startfile unix98.o.

It is important to note that this option changes the interfaces for various library routines. It also affects the operational behavior of the C library. Thus, extreme care is needed in using this option.

Library code that is intended to operate with more than one UNIX standard must test, set and restore the variable __xpg4_extended_mask as appropriate. Most GNU software doesn't provide this capability.

-nolibdld
Suppress the generation of link options to search libdld.sl when the -static option is specified on HP-UX 10 and later.
-static
The HP-UX implementation of setlocale in libc has a dependency on libdld.sl. There isn't an archive version of libdld.sl. Thus, when the -static option is specified, special link options are needed to resolve this dependency.
On HP-UX 10 and later, the GCC driver adds the necessary options to link with libdld.sl when the -static option is specified. This causes the resulting binary to be dynamic. On the 64-bit port, the linkers generate dynamic binaries by default in any case. The -nolibdld option can be used to prevent the GCC driver from adding these link options.

-threads
Add support for multithreading with the dce thread library under HP-UX. This option sets flags for both the preprocessor and linker.
Intel 386 and AMD x86-64 Options

These -m options are defined for the i386 and x86-64 family of computers:
-mtune=cpu-type
Tune to cpu-type everything applicable about the generated code, except for the ABI and the set of available instructions. The choices for cpu-type are:
generic
Produce code optimized for the most common IA32/AMD64/EM64T processors. If you know the CPU on which your code will run, then you should use the corresponding -mtune option instead of -mtune=generic. But, if you do not know exactly what CPU users of your application will have, then you should use this option.
As new processors are deployed in the marketplace, the behavior of this option will change. Therefore, if you upgrade to a newer version of GCC , the code generated option will change to reflect the processors that were most common when that version of GCC was released.

There is no -march=generic option because -march indicates the instruction set the compiler can use, and there is no generic instruction set applicable to all processors. In contrast, -mtune indicates the processor (or, in this case, collection of processors) for which the code is optimized.

native
This selects the CPU to tune for at compilation time by determining the processor type of the compiling machine. Using -mtune=native will produce code optimized for the local machine under the constraints of the selected instruction set. Using -march=native will enable all instruction subsets supported by the local machine (hence the result might not run on different machines).
i386
Original Intel's i386 CPU .
i486
Intel's i486 CPU . (No scheduling is implemented for this chip.)
i586, pentium
Intel Pentium CPU with no MMX support.
pentium-mmx
Intel PentiumMMX CPU based on Pentium core with MMX instruction set support.
pentiumpro
Intel PentiumPro CPU .
i686
Same as "generic", but when used as "march" option, PentiumPro instruction set will be used, so the code will run on all i686 family chips.
pentium2
Intel Pentium2 CPU based on PentiumPro core with MMX instruction set support.
pentium3, pentium3m
Intel Pentium3 CPU based on PentiumPro core with MMX and SSE instruction set support.
pentium-m
Low power version of Intel Pentium3 CPU with MMX , SSE and SSE2 instruction set support. Used by Centrino notebooks.
pentium4, pentium4m
Intel Pentium4 CPU with MMX , SSE and SSE2 instruction set support.
prescott
Improved version of Intel Pentium4 CPU with MMX , SSE , SSE2 and SSE3 instruction set support.
nocona
Improved version of Intel Pentium4 CPU with 64-bit extensions, MMX , SSE , SSE2 and SSE3 instruction set support.
core2
Intel Core2 CPU with 64-bit extensions, MMX , SSE , SSE2 , SSE3 and SSSE3 instruction set support.
k6
AMD K6 CPU with MMX instruction set support.

k6-2, k6-3
Improved versions of AMD K6 CPU with MMX and 3dNOW! instruction set support.
athlon, athlon-tbird
AMD Athlon CPU with MMX , 3dNOW!, enhanced 3dNOW! and SSE prefetch instructions support.
athlon-4, athlon-xp, athlon-mp
Improved AMD Athlon CPU with MMX , 3dNOW!, enhanced 3dNOW! and full SSE instruction set support.
k8, opteron, athlon64, athlon-fx
AMD K8 core based CPUs with x86-64 instruction set support. (This supersets MMX , SSE , SSE2 , 3dNOW!, enhanced 3dNOW! and 64-bit instruction set extensions.)
k8-sse3, opteron-sse3, athlon64-sse3
Improved versions of k8, opteron and athlon64 with SSE3 instruction set support.
amdfam10, barcelona
AMD Family 10h core based CPUs with x86-64 instruction set support. (This supersets MMX , SSE , SSE2 , SSE3 , SSE4A , 3dNOW!, enhanced 3dNOW!, ABM and 64-bit instruction set extensions.)
winchip-c6
IDT Winchip C6 CPU , dealt in same way as i486 with additional MMX instruction set support.
winchip2
IDT Winchip2 CPU , dealt in same way as i486 with additional MMX and 3dNOW! instruction set support.
c3
Via C3 CPU with MMX and 3dNOW! instruction set support. (No scheduling is implemented for this chip.)

c3-2
Via C3-2 CPU with MMX and SSE instruction set support. (No scheduling is implemented for this chip.)
geode
Embedded AMD CPU with MMX and 3dNOW! instruction set support.
While picking a specific cpu-type will schedule things appropriately for that particular chip, the compiler will not generate any code that does not run on the i386 without the -march=cpu-type option being used.
-march=cpu-type
Generate instructions for the machine type cpu-type. The choices for cpu-type are the same as for -mtune. Moreover, specifying -march=cpu-type implies -mtune=cpu-type.
-mcpu=cpu-type
A deprecated synonym for -mtune.
-mfpmath=unit
Generate floating point arithmetics for selected unit unit. The choices for unit are:
387
Use the standard 387 floating point coprocessor present majority of chips and emulated otherwise. Code compiled with this option will run almost everywhere. The temporary results are computed in 80bit precision instead of precision specified by the type resulting in slightly different results compared to most of other chips. See -ffloat-store for more detailed description.

This is the default choice for i386 compiler.
sse
Use scalar floating point instructions present in the SSE instruction set. This instruction set is supported by Pentium3 and newer chips, in the AMD line by Athlon-4, Athlon-xp and Athlon-mp chips. The earlier version of SSE instruction set supports only single precision arithmetics, thus the double and extended precision arithmetics is still done using 387. Later version, present only in Pentium4 and the future AMD x86-64 chips supports double precision arithmetics too.

For the i386 compiler, you need to use -march=cpu-type, -msse or -msse2 switches to enable SSE extensions and make this option effective. For the x86-64 compiler, these extensions are enabled by default.
The resulting code should be considerably faster in the majority of cases and avoid the numerical instability problems of 387 code, but may break some existing code that expects temporaries to be 80bit.

This is the default choice for the x86-64 compiler.

sse,387
sse+387
both
Attempt to utilize both instruction sets at once. This effectively double the amount of available registers and on chips with separate execution units for 387 and SSE the execution resources too. Use this option with care, as it is still experimental, because the GCC register allocator does not model separate functional units well resulting in instable performance.
-masm=dialect
Output asm instructions using selected dialect. Supported choices are intel or att (the default one). Darwin does not support intel.
-mieee-fp
-mno-ieee-fp
Control whether or not the compiler uses IEEE floating point comparisons. These handle correctly the case where the result of a comparison is unordered.
-msoft-float
Generate output containing library calls for floating point. Warning: the requisite libraries are not part of GCC . Normally the facilities of the machine's usual C compiler are used, but this can't be done directly in cross-compilation. You must make your own arrangements to provide suitable library functions for cross-compilation.
On machines where a function returns floating point results in the 80387 register stack, some floating point opcodes may be emitted even if -msoft-float is used.

-mno-fp-ret-in-387
Do not use the FPU registers for return values of functions.
The usual calling convention has functions return values of types "float" and "double" in an FPU register, even if there is no FPU . The idea is that the operating system should emulate an FPU .

The option -mno-fp-ret-in-387 causes such values to be returned in ordinary CPU registers instead.

-mno-fancy-math-387
Some 387 emulators do not support the "sin", "cos" and "sqrt" instructions for the 387. Specify this option to avoid generating those instructions. This option is the default on FreeBSD, OpenBSD and NetBSD. This option is overridden when -march indicates that the target cpu will always have an FPU and so the instruction will not need emulation. As of revision 2.6.1, these instructions are not generated unless you also use the -funsafe-math-optimizations switch.
-malign-double
-mno-align-double
Control whether GCC aligns "double", "long double", and "long long" variables on a two word boundary or a one word boundary. Aligning "double" variables on a two word boundary will produce code that runs somewhat faster on a Pentium at the expense of more memory.
On x86-64, -malign-double is enabled by default.

Warning: if you use the -malign-double switch, structures containing the above types will be aligned differently than the published application binary interface specifications for the 386 and will not be binary compatible with structures in code compiled without that switch.

-m96bit-long-double
-m128bit-long-double
These switches control the size of "long double" type. The i386 application binary interface specifies the size to be 96 bits, so -m96bit-long-double is the default in 32 bit mode.
Modern architectures (Pentium and newer) would prefer "long double" to be aligned to an 8 or 16 byte boundary. In arrays or structures conforming to the ABI , this would not be possible. So specifying a -m128bit-long-double will align "long double" to a 16 byte boundary by padding the "long double" with an additional 32 bit zero.

In the x86-64 compiler, -m128bit-long-double is the default choice as its ABI specifies that "long double" is to be aligned on 16 byte boundary.

Notice that neither of these options enable any extra precision over the x87 standard of 80 bits for a "long double".

Warning: if you override the default value for your target ABI , the structures and arrays containing "long double" variables will change their size as well as function calling convention for function taking "long double" will be modified. Hence they will not be binary compatible with arrays or structures in code compiled without that switch.

-mlarge-data-threshold=number
When -mcmodel=medium is specified, the data greater than threshold are placed in large data section. This value must be the same across all object linked into the binary and defaults to 65535.
-mrtd
Use a different function-calling convention, in which functions that take a fixed number of arguments return with the "ret" num instruction, which pops their arguments while returning. This saves one instruction in the caller since there is no need to pop the arguments there.
You can specify that an individual function is called with this calling sequence with the function attribute stdcall. You can also override the -mrtd option by using the function attribute cdecl.

Warning: this calling convention is incompatible with the one normally used on Unix, so you cannot use it if you need to call libraries compiled with the Unix compiler.

Also, you must provide function prototypes for all functions that take variable numbers of arguments (including "printf"); otherwise incorrect code will be generated for calls to those functions.

In addition, seriously incorrect code will result if you call a function with too many arguments. (Normally, extra arguments are harmlessly ignored.)

-mregparm=num
Control how many registers are used to pass integer arguments. By default, no registers are used to pass arguments, and at most 3 registers can be used. You can control this behavior for a specific function by using the function attribute regparm.
Warning: if you use this switch, and num is nonzero, then you must build all modules with the same value, including any libraries. This includes the system libraries and startup modules.

-msseregparm
Use SSE register passing conventions for float and double arguments and return values. You can control this behavior for a specific function by using the function attribute sseregparm.
Warning: if you use this switch then you must build all modules with the same value, including any libraries. This includes the system libraries and startup modules.

-mpc32
-mpc64
-mpc80
Set 80387 floating-point precision to 32, 64 or 80 bits. When -mpc32 is specified, the significands of results of floating-point operations are rounded to 24 bits (single precision); -mpc64 rounds the significands of results of floating-point operations to 53 bits (double precision) and -mpc80 rounds the significands of results of floating-point operations to 64 bits (extended double precision), which is the default. When this option is used, floating-point operations in higher precisions are not available to the programmer without setting the FPU control word explicitly.
Setting the rounding of floating-point operations to less than the default 80 bits can speed some programs by 2% or more. Note that some mathematical libraries assume that extended precision (80 bit) floating-point operations are enabled by default; routines in such libraries could suffer significant loss of accuracy, typically through so-called "catastrophic cancellation", when this option is used to set the precision to less than extended precision.

-mstackrealign
Realign the stack at entry. On the Intel x86, the -mstackrealign option will generate an alternate prologue and epilogue that realigns the runtime stack if necessary. This supports mixing legacy codes that keep a 4-byte aligned stack with modern codes that keep a 16-byte stack for SSE compatibility. See also the attribute "force_align_arg_pointer", applicable to individual functions.
-mpreferred-stack-boundary=num
Attempt to keep the stack boundary aligned to a 2 raised to num byte boundary. If -mpreferred-stack-boundary is not specified, the default is 4 (16 bytes or 128 bits).
-mincoming-stack-boundary=num
Assume the incoming stack is aligned to a 2 raised to num byte boundary. If -mincoming-stack-boundary is not specified, the one specified by -mpreferred-stack-boundary will be used.
On Pentium and PentiumPro, "double" and "long double" values should be aligned to an 8 byte boundary (see -malign-double) or suffer significant run time performance penalties. On Pentium III , the Streaming SIMD Extension ( SSE ) data type "__m128" may not work properly if it is not 16 byte aligned.

To ensure proper alignment of this values on the stack, the stack boundary must be as aligned as that required by any value stored on the stack. Further, every function must be generated such that it keeps the stack aligned. Thus calling a function compiled with a higher preferred stack boundary from a function compiled with a lower preferred stack boundary will most likely misalign the stack. It is recommended that libraries that use callbacks always use the default setting.

This extra alignment does consume extra stack space, and generally increases code size. Code that is sensitive to stack space usage, such as embedded systems and operating system kernels, may want to reduce the preferred alignment to -mpreferred-stack-boundary=2.

-mmmx
-mno-mmx
-msse
-mno-sse
-msse2
-mno-sse2
-msse3
-mno-sse3
-mssse3
-mno-ssse3
-msse4.1
-mno-sse4.1
-msse4.2
-mno-sse4.2
-msse4
-mno-sse4
-mavx
-mno-avx
-maes
-mno-aes
-mpclmul
-mno-pclmul
-mfsgsbase
-mno-fsgsbase
-mrdrnd
-mno-rdrnd
-mf16c
-mno-f16c
-msse4a
-mno-sse4a
-mfma4
-mno-fma4
-mxop
-mno-xop
-mlwp
-mno-lwp
-m3dnow
-mno-3dnow
-mpopcnt
-mno-popcnt
-mabm
-mno-abm
-mbmi
-mno-bmi
-mtbm
-mno-tbm
These switches enable or disable the use of instructions in the MMX , SSE , SSE2 , SSE3 , SSSE3 , SSE4 .1, AVX , AES , PCLMUL , FSGSBASE , RDRND , F16C, SSE4A , FMA4 , XOP , LWP , ABM , BMI , or 3DNow! extended instruction sets. These extensions are also available as built-in functions: see X86 Built-in Functions, for details of the functions enabled and disabled by these switches.
To have SSE/SSE2 instructions generated automatically from floating-point code (as opposed to 387 instructions), see -mfpmath=sse.

GCC depresses SSEx instructions when -mavx is used. Instead, it generates new AVX instructions or AVX equivalence for all SSEx instructions when needed.

These options will enable GCC to use these extended instructions in generated code, even without -mfpmath=sse. Applications which perform runtime CPU detection must compile separate files for each supported architecture, using the appropriate flags. In particular, the file containing the CPU detection code should be compiled without these options.

-mfused-madd
-mno-fused-madd
Do (don't) generate code that uses the fused multiply/add or multiply/subtract instructions. The default is to use these instructions.
-mcld
This option instructs GCC to emit a "cld" instruction in the prologue of functions that use string instructions. String instructions depend on the DF flag to select between autoincrement or autodecrement mode. While the ABI specifies the DF flag to be cleared on function entry, some operating systems violate this specification by not clearing the DF flag in their exception dispatchers. The exception handler can be invoked with the DF flag set which leads to wrong direction mode, when string instructions are used. This option can be enabled by default on 32-bit x86 targets by configuring GCC with the --enable-cld configure option. Generation of "cld" instructions can be suppressed with the -mno-cld compiler option in this case.
-mcx16
This option will enable GCC to use CMPXCHG16B instruction in generated code. CMPXCHG16B allows for atomic operations on 128-bit double quadword (or oword) data types. This is useful for high resolution counters that could be updated by multiple processors (or cores). This instruction is generated as part of atomic built-in functions: see Atomic Builtins for details.
-msahf
This option will enable GCC to use SAHF instruction in generated 64-bit code. Early Intel CPUs with Intel 64 lacked LAHF and SAHF instructions supported by AMD64 until introduction of Pentium 4 G1 step in December 2005. LAHF and SAHF are load and store instructions, respectively, for certain status flags. In 64-bit mode, SAHF instruction is used to optimize "fmod", "drem" or "remainder" built-in functions: see Other Builtins for details.
-mmovbe
This option will enable GCC to use movbe instruction to implement "__builtin_bswap32" and "__builtin_bswap64".
-mcrc32
This option will enable built-in functions, "__builtin_ia32_crc32qi", "__builtin_ia32_crc32hi". "__builtin_ia32_crc32si" and "__builtin_ia32_crc32di" to generate the crc32 machine instruction.
-mrecip
This option will enable GCC to use RCPSS and RSQRTSS instructions (and their vectorized variants RCPPS and RSQRTPS ) with an additional Newton-Raphson step to increase precision instead of DIVSS and SQRTSS (and their vectorized variants) for single precision floating point arguments. These instructions are generated only when -funsafe-math-optimizations is enabled together with -finite-math-only and -fno-trapping-math. Note that while the throughput of the sequence is higher than the throughput of the non-reciprocal instruction, the precision of the sequence can be decreased by up to 2 ulp (i.e. the inverse of 1.0 equals 0.99999994).
-mveclibabi=type
Specifies the ABI type to use for vectorizing intrinsics using an external library. Supported types are "svml" for the Intel short vector math library and "acml" for the AMD math core library style of interfacing. GCC will currently emit calls to "vmldExp2", "vmldLn2", "vmldLog102", "vmldLog102", "vmldPow2", "vmldTanh2", "vmldTan2", "vmldAtan2", "vmldAtanh2", "vmldCbrt2", "vmldSinh2", "vmldSin2", "vmldAsinh2", "vmldAsin2", "vmldCosh2", "vmldCos2", "vmldAcosh2", "vmldAcos2", "vmlsExp4", "vmlsLn4", "vmlsLog104", "vmlsLog104", "vmlsPow4", "vmlsTanh4", "vmlsTan4", "vmlsAtan4", "vmlsAtanh4", "vmlsCbrt4", "vmlsSinh4", "vmlsSin4", "vmlsAsinh4", "vmlsAsin4", "vmlsCosh4", "vmlsCos4", "vmlsAcosh4" and "vmlsAcos4" for corresponding function type when -mveclibabi=svml is used and "__vrd2_sin", "__vrd2_cos", "__vrd2_exp", "__vrd2_log", "__vrd2_log2", "__vrd2_log10", "__vrs4_sinf", "__vrs4_cosf", "__vrs4_expf", "__vrs4_logf", "__vrs4_log2f", "__vrs4_log10f" and "__vrs4_powf" for corresponding function type when -mveclibabi=acml is used. Both -ftree-vectorize and -funsafe-math-optimizations have to be enabled. A SVML or ACML ABI compatible library will have to be specified at link time.
-mpush-args
-mno-push-args
Use PUSH operations to store outgoing parameters. This method is shorter and usually equally fast as method using SUB/MOV operations and is enabled by default. In some cases disabling it may improve performance because of improved scheduling and reduced dependencies.
-maccumulate-outgoing-args
If enabled, the maximum amount of space required for outgoing arguments will be computed in the function prologue. This is faster on most modern CPUs because of reduced dependencies, improved scheduling and reduced stack usage when preferred stack boundary is not equal to 2. The drawback is a notable increase in code size. This switch implies -mno-push-args.
-mthreads
Support thread-safe exception handling on Mingw32. Code that relies on thread-safe exception handling must compile and link all code with the -mthreads option. When compiling, -mthreads defines -D_MT; when linking, it links in a special thread helper library -lmingwthrd which cleans up per thread exception handling data.
-mno-align-stringops
Do not align destination of inlined string operations. This switch reduces code size and improves performance in case the destination is already aligned, but GCC doesn't know about it.
-minline-all-stringops
By default GCC inlines string operations only when destination is known to be aligned at least to 4 byte boundary. This enables more inlining, increase code size, but may improve performance of code that depends on fast memcpy, strlen and memset for short lengths.
-minline-stringops-dynamically
For string operation of unknown size, inline runtime checks so for small blocks inline code is used, while for large blocks library call is used.
-mstringop-strategy=alg
Overwrite internal decision heuristic about particular algorithm to inline string operation with. The allowed values are "rep_byte", "rep_4byte", "rep_8byte" for expanding using i386 "rep" prefix of specified size, "byte_loop", "loop", "unrolled_loop" for expanding inline loop, "libcall" for always expanding library call.
-momit-leaf-frame-pointer
Don't keep the frame pointer in a register for leaf functions. This avoids the instructions to save, set up and restore frame pointers and makes an extra register available in leaf functions. The option -fomit-frame-pointer removes the frame pointer for all functions which might make debugging harder.
-mtls-direct-seg-refs
-mno-tls-direct-seg-refs
Controls whether TLS variables may be accessed with offsets from the TLS segment register (%gs for 32-bit, %fs for 64-bit), or whether the thread base pointer must be added. Whether or not this is legal depends on the operating system, and whether it maps the segment to cover the entire TLS area.
For systems that use GNU libc, the default is on.

-msse2avx
-mno-sse2avx
Specify that the assembler should encode SSE instructions with VEX prefix. The option -mavx turns this on by default.
These -m switches are supported in addition to the above on AMD x86-64 processors in 64-bit environments.
-m32
-m64
Generate code for a 32-bit or 64-bit environment. The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any i386 system. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits and generates code for AMD 's x86-64 architecture. For darwin only the -m64 option turns off the -fno-pic and -mdynamic-no-pic options.
-mno-red-zone
Do not use a so called red zone for x86-64 code. The red zone is mandated by the x86-64 ABI , it is a 128-byte area beyond the location of the stack pointer that will not be modified by signal or interrupt handlers and therefore can be used for temporary data without adjusting the stack pointer. The flag -mno-red-zone disables this red zone.
-mcmodel=small
Generate code for the small code model: the program and its symbols must be linked in the lower 2 GB of the address space. Pointers are 64 bits. Programs can be statically or dynamically linked. This is the default code model.
-mcmodel=kernel
Generate code for the kernel code model. The kernel runs in the negative 2 GB of the address space. This model has to be used for Linux kernel code.
-mcmodel=medium
Generate code for the medium model: The program is linked in the lower 2 GB of the address space. Small symbols are also placed there. Symbols with sizes larger than -mlarge-data-threshold are put into large data or bss sections and can be located above 2GB. Programs can be statically or dynamically linked.
-mcmodel=large
Generate code for the large model: This model makes no assumptions about addresses and sizes of sections.
i386 and x86-64 Windows Options

These additional options are available for Windows targets:
-mconsole
This option is available for Cygwin and MinGW targets. It specifies that a console application is to be generated, by instructing the linker to set the PE header subsystem type required for console applications. This is the default behaviour for Cygwin and MinGW targets.
-mcygwin
This option is available for Cygwin targets. It specifies that the Cygwin internal interface is to be used for predefined preprocessor macros, C runtime libraries and related linker paths and options. For Cygwin targets this is the default behaviour. This option is deprecated and will be removed in a future release.
-mno-cygwin
This option is available for Cygwin targets. It specifies that the MinGW internal interface is to be used instead of Cygwin's, by setting MinGW-related predefined macros and linker paths and default library options. This option is deprecated and will be removed in a future release.
-mdll
This option is available for Cygwin and MinGW targets. It specifies that a DLL - a dynamic link library - is to be generated, enabling the selection of the required runtime startup object and entry point.
-mnop-fun-dllimport
This option is available for Cygwin and MinGW targets. It specifies that the dllimport attribute should be ignored.
-mthread
This option is available for MinGW targets. It specifies that MinGW-specific thread support is to be used.
-mwin32
This option is available for Cygwin and MinGW targets. It specifies that the typical Windows pre-defined macros are to be set in the pre-processor, but does not influence the choice of runtime library/startup code.
-mwindows
This option is available for Cygwin and MinGW targets. It specifies that a GUI application is to be generated by instructing the linker to set the PE header subsystem type appropriately.
See also under i386 and x86-64 Options for standard options.
IA-64 Options

These are the -m options defined for the Intel IA-64 architecture.
-mbig-endian
Generate code for a big endian target. This is the default for HP-UX.
-mlittle-endian
Generate code for a little endian target. This is the default for AIX5 and GNU/Linux.
-mgnu-as
-mno-gnu-as
Generate (or don't) code for the GNU assembler. This is the default.
-mgnu-ld
-mno-gnu-ld
Generate (or don't) code for the GNU linker. This is the default.
-mno-pic
Generate code that does not use a global pointer register. The result is not position independent code, and violates the IA-64 ABI .
-mvolatile-asm-stop
-mno-volatile-asm-stop
Generate (or don't) a stop bit immediately before and after volatile asm statements.
-mregister-names
-mno-register-names
Generate (or don't) in, loc, and out register names for the stacked registers. This may make assembler output more readable.
-mno-sdata
-msdata
Disable (or enable) optimizations that use the small data section. This may be useful for working around optimizer bugs.
-mconstant-gp
Generate code that uses a single constant global pointer value. This is useful when compiling kernel code.
-mauto-pic
Generate code that is self-relocatable. This implies -mconstant-gp. This is useful when compiling firmware code.
-minline-float-divide-min-latency
Generate code for inline divides of floating point values using the minimum latency algorithm.
-minline-float-divide-max-throughput
Generate code for inline divides of floating point values using the maximum throughput algorithm.
-minline-int-divide-min-latency
Generate code for inline divides of integer values using the minimum latency algorithm.
-minline-int-divide-max-throughput
Generate code for inline divides of integer values using the maximum throughput algorithm.
-minline-sqrt-min-latency
Generate code for inline square roots using the minimum latency algorithm.
-minline-sqrt-max-throughput
Generate code for inline square roots using the maximum throughput algorithm.
-mno-dwarf2-asm
-mdwarf2-asm
Don't (or do) generate assembler code for the DWARF2 line number debugging info. This may be useful when not using the GNU assembler.
-mearly-stop-bits
-mno-early-stop-bits
Allow stop bits to be placed earlier than immediately preceding the instruction that triggered the stop bit. This can improve instruction scheduling, but does not always do so.
-mfixed-range=register-range
Generate code treating the given register range as fixed registers. A fixed register is one that the register allocator can not use. This is useful when compiling kernel code. A register range is specified as two registers separated by a dash. Multiple register ranges can be specified separated by a comma.
-mtls-size=tls-size
Specify bit size of immediate TLS offsets. Valid values are 14, 22, and 64.
-mtune=cpu-type
Tune the instruction scheduling for a particular CPU , Valid values are itanium, itanium1, merced, itanium2, and mckinley.
-mt
-pthread
Add support for multithreading using the POSIX threads library. This option sets flags for both the preprocessor and linker. It does not affect the thread safety of object code produced by the compiler or that of libraries supplied with it. These are HP-UX specific flags.
-milp32
-mlp64
Generate code for a 32-bit or 64-bit environment. The 32-bit environment sets int, long and pointer to 32 bits. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits. These are HP-UX specific flags.
-mno-sched-br-data-spec
-msched-br-data-spec
(Dis/En)able data speculative scheduling before reload. This will result in generation of the ld.a instructions and the corresponding check instructions (ld.c / chk.a). The default is 'disable'.
-msched-ar-data-spec
-mno-sched-ar-data-spec
(En/Dis)able data speculative scheduling after reload. This will result in generation of the ld.a instructions and the corresponding check instructions (ld.c / chk.a). The default is 'enable'.
-mno-sched-control-spec
-msched-control-spec
(Dis/En)able control speculative scheduling. This feature is available only during region scheduling (i.e. before reload). This will result in generation of the ld.s instructions and the corresponding check instructions chk.s . The default is 'disable'.
-msched-br-in-data-spec
-mno-sched-br-in-data-spec
(En/Dis)able speculative scheduling of the instructions that are dependent on the data speculative loads before reload. This is effective only with -msched-br-data-spec enabled. The default is 'enable'.
-msched-ar-in-data-spec
-mno-sched-ar-in-data-spec
(En/Dis)able speculative scheduling of the instructions that are dependent on the data speculative loads after reload. This is effective only with -msched-ar-data-spec enabled. The default is 'enable'.
-msched-in-control-spec
-mno-sched-in-control-spec
(En/Dis)able speculative scheduling of the instructions that are dependent on the control speculative loads. This is effective only with -msched-control-spec enabled. The default is 'enable'.
-msched-ldc
-mno-sched-ldc
(En/Dis)able use of simple data speculation checks ld.c . If disabled, only chk.a instructions will be emitted to check data speculative loads. The default is 'enable'.
-mno-sched-control-ldc
-msched-control-ldc
(Dis/En)able use of ld.c instructions to check control speculative loads. If enabled, in case of control speculative load with no speculatively scheduled dependent instructions this load will be emitted as ld.sa and ld.c will be used to check it. The default is 'disable'.
-mno-sched-spec-verbose
-msched-spec-verbose
(Dis/En)able printing of the information about speculative motions.
-mno-sched-prefer-non-data-spec-insns
-msched-prefer-non-data-spec-insns
If enabled, data speculative instructions will be chosen for schedule only if there are no other choices at the moment. This will make the use of the data speculation much more conservative. The default is 'disable'.
-mno-sched-prefer-non-control-spec-insns
-msched-prefer-non-control-spec-insns
If enabled, control speculative instructions will be chosen for schedule only if there are no other choices at the moment. This will make the use of the control speculation much more conservative. The default is 'disable'.
-mno-sched-count-spec-in-critical-path
-msched-count-spec-in-critical-path
If enabled, speculative dependencies will be considered during computation of the instructions priorities. This will make the use of the speculation a bit more conservative. The default is 'disable'.
M32C Options

-mcpu=name
Select the CPU for which code is generated. name may be one of r8c for the R8C/Tiny series, m16c for the M16C (up to /60) series, m32cm for the M16C/80 series, or m32c for the M32C/80 series.
-msim
Specifies that the program will be run on the simulator. This causes an alternate runtime library to be linked in which supports, for example, file I/O. You must not use this option when generating programs that will run on real hardware; you must provide your own runtime library for whatever I/O functions are needed.
-memregs=number
Specifies the number of memory-based pseudo-registers GCC will use during code generation. These pseudo-registers will be used like real registers, so there is a tradeoff between GCC 's ability to fit the code into available registers, and the performance penalty of using memory instead of registers. Note that all modules in a program must be compiled with the same value for this option. Because of that, you must not use this option with the default runtime libraries gcc builds.
M32R/D Options

These -m options are defined for Renesas M32R/D architectures:
-m32r2
Generate code for the M32R/2.
-m32rx
Generate code for the M32R/X.
-m32r
Generate code for the M32R. This is the default.
-mmodel=small
Assume all objects live in the lower 16MB of memory (so that their addresses can be loaded with the "ld24" instruction), and assume all subroutines are reachable with the "bl" instruction. This is the default.
The addressability of a particular object can be set with the "model" attribute.

-mmodel=medium
Assume objects may be anywhere in the 32-bit address space (the compiler will generate "seth/add3" instructions to load their addresses), and assume all subroutines are reachable with the "bl" instruction.
-mmodel=large
Assume objects may be anywhere in the 32-bit address space (the compiler will generate "seth/add3" instructions to load their addresses), and assume subroutines may not be reachable with the "bl" instruction (the compiler will generate the much slower "seth/add3/jl" instruction sequence).
-msdata=none
Disable use of the small data area. Variables will be put into one of .data, bss, or .rodata (unless the "section" attribute has been specified). This is the default.
The small data area consists of sections .sdata and .sbss. Objects may be explicitly put in the small data area with the "section" attribute using one of these sections.

-msdata=sdata
Put small global and static data in the small data area, but do not generate special code to reference them.
-msdata=use
Put small global and static data in the small data area, and generate special instructions to reference them.
-G num
Put global and static objects less than or equal to num bytes into the small data or bss sections instead of the normal data or bss sections. The default value of num is 8. The -msdata option must be set to one of sdata or use for this option to have any effect.
All modules should be compiled with the same -G num value. Compiling with different values of num may or may not work; if it doesn't the linker will give an error message---incorrect code will not be generated.

-mdebug
Makes the M32R specific code in the compiler display some statistics that might help in debugging programs.
-malign-loops
Align all loops to a 32-byte boundary.
-mno-align-loops
Do not enforce a 32-byte alignment for loops. This is the default.
-missue-rate=number
Issue number instructions per cycle. number can only be 1 or 2.
-mbranch-cost=number
number can only be 1 or 2. If it is 1 then branches will be preferred over conditional code, if it is 2, then the opposite will apply.
-mflush-trap=number
Specifies the trap number to use to flush the cache. The default is 12. Valid numbers are between 0 and 15 inclusive.
-mno-flush-trap
Specifies that the cache cannot be flushed by using a trap.
-mflush-func=name
Specifies the name of the operating system function to call to flush the cache. The default is _flush_cache, but a function call will only be used if a trap is not available.
-mno-flush-func
Indicates that there is no OS function for flushing the cache.
M680x0 Options

These are the -m options defined for M680x0 and ColdFire processors. The default settings depend on which architecture was selected when the compiler was configured; the defaults for the most common choices are given below.
-march=arch
Generate code for a specific M680x0 or ColdFire instruction set architecture. Permissible values of arch for M680x0 architectures are: 68000, 68010, 68020, 68030, 68040, 68060 and cpu32. ColdFire architectures are selected according to Freescale's ISA classification and the permissible values are: isaa, isaaplus, isab and isac.
gcc defines a macro __mcfarch__ whenever it is generating code for a ColdFire target. The arch in this macro is one of the -march arguments given above.

When used together, -march and -mtune select code that runs on a family of similar processors but that is optimized for a particular microarchitecture.

-mcpu=cpu
Generate code for a specific M680x0 or ColdFire processor. The M680x0 cpus are: 68000, 68010, 68020, 68030, 68040, 68060, 68302, 68332 and cpu32. The ColdFire cpus are given by the table below, which also classifies the CPUs into families:
Family : -mcpu arguments
51qe : 51qe
5206 : 5202 5204 5206
5206e : 5206e
5208 : 5207 5208
5211a : 5210a 5211a
5213 : 5211 5212 5213
5216 : 5214 5216
52235 : 52230 52231 52232 52233 52234 52235
5225 : 5224 5225
5235 : 5232 5233 5234 5235 523x
5249 : 5249
5250 : 5250
5271 : 5270 5271
5272 : 5272
5275 : 5274 5275
5282 : 5280 5281 5282 528x
5307 : 5307
5329 : 5327 5328 5329 532x
5373 : 5372 5373 537x
5407 : 5407
5475 : 5470 5471 5472 5473 5474 5475 547x 5480 5481 5482 5483 5484 5485
-mcpu=cpu overrides -march=arch if arch is compatible with cpu. Other combinations of -mcpu and -march are rejected.
gcc defines the macro __mcf_cpu_cpu when ColdFire target cpu is selected. It also defines __mcf_family_family, where the value of family is given by the table above.

-mtune=tune
Tune the code for a particular microarchitecture, within the constraints set by -march and -mcpu. The M680x0 microarchitectures are: 68000, 68010, 68020, 68030, 68040, 68060 and cpu32. The ColdFire microarchitectures are: cfv1, cfv2, cfv3, cfv4 and cfv4e.
You can also use -mtune=68020-40 for code that needs to run relatively well on 68020, 68030 and 68040 targets. -mtune=68020-60 is similar but includes 68060 targets as well. These two options select the same tuning decisions as -m68020-40 and -m68020-60 respectively.

gcc defines the macros __mcarch and __mcarch__ when tuning for 680x0 architecture arch. It also defines mcarch unless either -ansi or a non-GNU -std option is used. If gcc is tuning for a range of architectures, as selected by -mtune=68020-40 or -mtune=68020-60, it defines the macros for every architecture in the range.

gcc also defines the macro __muarch__ when tuning for ColdFire microarchitecture uarch, where uarch is one of the arguments given above.

-m68000
-mc68000
Generate output for a 68000. This is the default when the compiler is configured for 68000-based systems. It is equivalent to -march=68000.
Use this option for microcontrollers with a 68000 or EC000 core, including the 68008, 68302, 68306, 68307, 68322, 68328 and 68356.

-m68010
Generate output for a 68010. This is the default when the compiler is configured for 68010-based systems. It is equivalent to -march=68010.
-m68020
-mc68020
Generate output for a 68020. This is the default when the compiler is configured for 68020-based systems. It is equivalent to -march=68020.
-m68030
Generate output for a 68030. This is the default when the compiler is configured for 68030-based systems. It is equivalent to -march=68030.
-m68040
Generate output for a 68040. This is the default when the compiler is configured for 68040-based systems. It is equivalent to -march=68040.
This option inhibits the use of 68881/68882 instructions that have to be emulated by software on the 68040. Use this option if your 68040 does not have code to emulate those instructions.

-m68060
Generate output for a 68060. This is the default when the compiler is configured for 68060-based systems. It is equivalent to -march=68060.
This option inhibits the use of 68020 and 68881/68882 instructions that have to be emulated by software on the 68060. Use this option if your 68060 does not have code to emulate those instructions.

-mcpu32
Generate output for a CPU32 . This is the default when the compiler is configured for CPU32-based systems. It is equivalent to -march=cpu32.
Use this option for microcontrollers with a CPU32 or CPU32+ core, including the 68330, 68331, 68332, 68333, 68334, 68336, 68340, 68341, 68349 and 68360.

-m5200
Generate output for a 520X ColdFire CPU . This is the default when the compiler is configured for 520X-based systems. It is equivalent to -mcpu=5206, and is now deprecated in favor of that option.
Use this option for microcontroller with a 5200 core, including the MCF5202 , MCF5203 , MCF5204 and MCF5206 .

-m5206e
Generate output for a 5206e ColdFire CPU . The option is now deprecated in favor of the equivalent -mcpu=5206e.
-m528x
Generate output for a member of the ColdFire 528X family. The option is now deprecated in favor of the equivalent -mcpu=528x.
-m5307
Generate output for a ColdFire 5307 CPU . The option is now deprecated in favor of the equivalent -mcpu=5307.
-m5407
Generate output for a ColdFire 5407 CPU . The option is now deprecated in favor of the equivalent -mcpu=5407.
-mcfv4e
Generate output for a ColdFire V4e family CPU (e.g. 547x/548x). This includes use of hardware floating point instructions. The option is equivalent to -mcpu=547x, and is now deprecated in favor of that option.
-m68020-40
Generate output for a 68040, without using any of the new instructions. This results in code which can run relatively efficiently on either a 68020/68881 or a 68030 or a 68040. The generated code does use the 68881 instructions that are emulated on the 68040.
The option is equivalent to -march=68020 -mtune=68020-40.

-m68020-60
Generate output for a 68060, without using any of the new instructions. This results in code which can run relatively efficiently on either a 68020/68881 or a 68030 or a 68040. The generated code does use the 68881 instructions that are emulated on the 68060.
The option is equivalent to -march=68020 -mtune=68020-60.

-mhard-float
-m68881
Generate floating-point instructions. This is the default for 68020 and above, and for ColdFire devices that have an FPU . It defines the macro __HAVE_68881__ on M680x0 targets and __mcffpu__ on ColdFire targets.
-msoft-float
Do not generate floating-point instructions; use library calls instead. This is the default for 68000, 68010, and 68832 targets. It is also the default for ColdFire devices that have no FPU .
-mdiv
-mno-div
Generate (do not generate) ColdFire hardware divide and remainder instructions. If -march is used without -mcpu, the default is "on" for ColdFire architectures and "off" for M680x0 architectures. Otherwise, the default is taken from the target CPU (either the default CPU , or the one specified by -mcpu). For example, the default is "off" for -mcpu=5206 and "on" for -mcpu=5206e.
gcc defines the macro __mcfhwdiv__ when this option is enabled.

-mshort
Consider type "int" to be 16 bits wide, like "short int". Additionally, parameters passed on the stack are also aligned to a 16-bit boundary even on targets whose API mandates promotion to 32-bit.
-mno-short
Do not consider type "int" to be 16 bits wide. This is the default.
-mnobitfield
-mno-bitfield
Do not use the bit-field instructions. The -m68000, -mcpu32 and -m5200 options imply -mnobitfield.
-mbitfield
Do use the bit-field instructions. The -m68020 option implies -mbitfield. This is the default if you use a configuration designed for a 68020.
-mrtd
Use a different function-calling convention, in which functions that take a fixed number of arguments return with the "rtd" instruction, which pops their arguments while returning. This saves one instruction in the caller since there is no need to pop the arguments there.
This calling convention is incompatible with the one normally used on Unix, so you cannot use it if you need to call libraries compiled with the Unix compiler.

Also, you must provide function prototypes for all functions that take variable numbers of arguments (including "printf"); otherwise incorrect code will be generated for calls to those functions.

In addition, seriously incorrect code will result if you call a function with too many arguments. (Normally, extra arguments are harmlessly ignored.)

The "rtd" instruction is supported by the 68010, 68020, 68030, 68040, 68060 and CPU32 processors, but not by the 68000 or 5200.

-mno-rtd
Do not use the calling conventions selected by -mrtd. This is the default.
-malign-int
-mno-align-int
Control whether GCC aligns "int", "long", "long long", "float", "double", and "long double" variables on a 32-bit boundary (-malign-int) or a 16-bit boundary (-mno-align-int). Aligning variables on 32-bit boundaries produces code that runs somewhat faster on processors with 32-bit busses at the expense of more memory.
Warning: if you use the -malign-int switch, GCC will align structures containing the above types differently than most published application binary interface specifications for the m68k.

-mpcrel
Use the pc-relative addressing mode of the 68000 directly, instead of using a global offset table. At present, this option implies -fpic, allowing at most a 16-bit offset for pc-relative addressing. -fPIC is not presently supported with -mpcrel, though this could be supported for 68020 and higher processors.
-mno-strict-align
-mstrict-align
Do not (do) assume that unaligned memory references will be handled by the system.
-msep-data
Generate code that allows the data segment to be located in a different area of memory from the text segment. This allows for execute in place in an environment without virtual memory management. This option implies -fPIC.
-mno-sep-data
Generate code that assumes that the data segment follows the text segment. This is the default.
-mid-shared-library
Generate code that supports shared libraries via the library ID method. This allows for execute in place and shared libraries in an environment without virtual memory management. This option implies -fPIC.
-mno-id-shared-library
Generate code that doesn't assume ID based shared libraries are being used. This is the default.
-mshared-library-id=n
Specified the identification number of the ID based shared library being compiled. Specifying a value of 0 will generate more compact code, specifying other values will force the allocation of that number to the current library but is no more space or time efficient than omitting this option.
-mxgot
-mno-xgot
When generating position-independent code for ColdFire, generate code that works if the GOT has more than 8192 entries. This code is larger and slower than code generated without this option. On M680x0 processors, this option is not needed; -fPIC suffices.
GCC normally uses a single instruction to load values from the GOT . While this is relatively efficient, it only works if the GOT is smaller than about 64k. Anything larger causes the linker to report an error such as:

relocation truncated to fit: R_68K_GOT16O foobar
If this happens, you should recompile your code with -mxgot. It should then work with very large GOTs. However, code generated with -mxgot is less efficient, since it takes 4 instructions to fetch the value of a global symbol.
Note that some linkers, including newer versions of the GNU linker, can create multiple GOTs and sort GOT entries. If you have such a linker, you should only need to use -mxgot when compiling a single object file that accesses more than 8192 GOT entries. Very few do.

These options have no effect unless GCC is generating position-independent code.

M68hc1x Options

These are the -m options defined for the 68hc11 and 68hc12 microcontrollers. The default values for these options depends on which style of microcontroller was selected when the compiler was configured; the defaults for the most common choices are given below.
-m6811
-m68hc11
Generate output for a 68HC11. This is the default when the compiler is configured for 68HC11-based systems.
-m6812
-m68hc12
Generate output for a 68HC12. This is the default when the compiler is configured for 68HC12-based systems.
-m68S12
-m68hcs12
Generate output for a 68HCS12.
-mauto-incdec
Enable the use of 68HC12 pre and post auto-increment and auto-decrement addressing modes.
-minmax
-nominmax
Enable the use of 68HC12 min and max instructions.
-mlong-calls
-mno-long-calls
Treat all calls as being far away (near). If calls are assumed to be far away, the compiler will use the "call" instruction to call a function and the "rtc" instruction for returning.
-mshort
Consider type "int" to be 16 bits wide, like "short int".
-msoft-reg-count=count
Specify the number of pseudo-soft registers which are used for the code generation. The maximum number is 32. Using more pseudo-soft register may or may not result in better code depending on the program. The default is 4 for 68HC11 and 2 for 68HC12.
MCore Options

These are the -m options defined for the Motorola M*Core processors.
-mhardlit
-mno-hardlit
Inline constants into the code stream if it can be done in two instructions or less.
-mdiv
-mno-div
Use the divide instruction. (Enabled by default).
-mrelax-immediate
-mno-relax-immediate
Allow arbitrary sized immediates in bit operations.
-mwide-bitfields
-mno-wide-bitfields
Always treat bit-fields as int-sized.
-m4byte-functions
-mno-4byte-functions
Force all functions to be aligned to a four byte boundary.
-mcallgraph-data
-mno-callgraph-data
Emit callgraph information.
-mslow-bytes
-mno-slow-bytes
Prefer word access when reading byte quantities.
-mlittle-endian
-mbig-endian
Generate code for a little endian target.
-m210
-m340
Generate code for the 210 processor.
-mno-lsim
Assume that run-time support has been provided and so omit the simulator library (libsim.a) from the linker command line.
-mstack-increment=size
Set the maximum amount for a single stack increment operation. Large values can increase the speed of programs which contain functions that need a large amount of stack space, but they can also trigger a segmentation fault if the stack is extended too much. The default value is 0x1000.
MIPS Options

-EB
Generate big-endian code.

-EL

Generate little-endian code. This is the default for mips*el-*-* configurations.

-march=arch
Generate code that will run on arch, which can be the name of a generic MIPS ISA , or the name of a particular processor. The ISA names are: mips1, mips2, mips3, mips4, mips32, mips32r2, mips64 and mips64r2. The processor names are: 4kc, 4km, 4kp, 4ksc, 4kec, 4kem, 4kep, 4ksd, 5kc, 5kf, 20kc, 24kc, 24kf2_1, 24kf1_1, 24kec, 24kef2_1, 24kef1_1, 34kc, 34kf2_1, 34kf1_1, 74kc, 74kf2_1, 74kf1_1, 74kf3_2, loongson2e, loongson2f, m4k, octeon, orion, r2000, r3000, r3900, r4000, r4400, r4600, r4650, r6000, r8000, rm7000, rm9000, r10000, r12000, r14000, r16000, sb1, sr71000, vr4100, vr4111, vr4120, vr4130, vr4300, vr5000, vr5400, vr5500 and xlr. The special value from-abi selects the most compatible architecture for the selected ABI (that is, mips1 for 32-bit ABIs and mips3 for 64-bit ABIs).
Native Linux/GNU toolchains also support the value native, which selects the best architecture option for the host processor. -march=native has no effect if GCC does not recognize the processor.

In processor names, a final 000 can be abbreviated as k (for example, -march=r2k). Prefixes are optional, and vr may be written r.

Names of the form nf2_1 refer to processors with FPUs clocked at half the rate of the core, names of the form nf1_1 refer to processors with FPUs clocked at the same rate as the core, and names of the form nf3_2 refer to processors with FPUs clocked a ratio of 3:2 with respect to the core. For compatibility reasons, nf is accepted as a synonym for nf2_1 while nx and bfx are accepted as synonyms for nf1_1.

GCC defines two macros based on the value of this option. The first is _MIPS_ARCH, which gives the name of target architecture, as a string. The second has the form _MIPS_ARCH_foo, where foo is the capitalized value of _MIPS_ARCH. For example, -march=r2000 will set _MIPS_ARCH to "r2000" and define the macro _MIPS_ARCH_R2000.

Note that the _MIPS_ARCH macro uses the processor names given above. In other words, it will have the full prefix and will not abbreviate 000 as k. In the case of from-abi, the macro names the resolved architecture (either "mips1" or "mips3"). It names the default architecture when no -march option is given.

-mtune=arch
Optimize for arch. Among other things, this option controls the way instructions are scheduled, and the perceived cost of arithmetic operations. The list of arch values is the same as for -march.
When this option is not used, GCC will optimize for the processor specified by -march. By using -march and -mtune together, it is possible to generate code that will run on a family of processors, but optimize the code for one particular member of that family.

-mtune defines the macros _MIPS_TUNE and _MIPS_TUNE_foo, which work in the same way as the -march ones described above.

-mips1
Equivalent to -march=mips1.
-mips2
Equivalent to -march=mips2.
-mips3
Equivalent to -march=mips3.
-mips4
Equivalent to -march=mips4.
-mips32
Equivalent to -march=mips32.
-mips32r2
Equivalent to -march=mips32r2.
-mips64
Equivalent to -march=mips64.
-mips64r2
Equivalent to -march=mips64r2.
-mips16
-mno-mips16
Generate (do not generate) MIPS16 code. If GCC is targetting a MIPS32 or MIPS64 architecture, it will make use of the MIPS16e ASE .
MIPS16 code generation can also be controlled on a per-function basis by means of "mips16" and "nomips16" attributes.

-mflip-mips16
Generate MIPS16 code on alternating functions. This option is provided for regression testing of mixed MIPS16/non-MIPS16 code generation, and is not intended for ordinary use in compiling user code.
-minterlink-mips16
-mno-interlink-mips16
Require (do not require) that non-MIPS16 code be link-compatible with MIPS16 code.
For example, non-MIPS16 code cannot jump directly to MIPS16 code; it must either use a call or an indirect jump. -minterlink-mips16 therefore disables direct jumps unless GCC knows that the target of the jump is not MIPS16 .

-mabi=32
-mabi=o64
-mabi=n32
-mabi=64
-mabi=eabi
Generate code for the given ABI .
Note that the EABI has a 32-bit and a 64-bit variant. GCC normally generates 64-bit code when you select a 64-bit architecture, but you can use -mgp32 to get 32-bit code instead.

For information about the O64 ABI , see <http://gcc.gnu.org/projects/mipso64-abi.html>.

GCC supports a variant of the o32 ABI in which floating-point registers are 64 rather than 32 bits wide. You can select this combination with -mabi=32 -mfp64. This ABI relies on the mthc1 and mfhc1 instructions and is therefore only supported for MIPS32R2 processors.

The register assignments for arguments and return values remain the same, but each scalar value is passed in a single 64-bit register rather than a pair of 32-bit registers. For example, scalar floating-point values are returned in $f0 only, not a $f0/$f1 pair. The set of call-saved registers also remains the same, but all 64 bits are saved.

-mabicalls
-mno-abicalls
Generate (do not generate) code that is suitable for SVR4-style dynamic objects. -mabicalls is the default for SVR4-based systems.
-mshared
-mno-shared
Generate (do not generate) code that is fully position-independent, and that can therefore be linked into shared libraries. This option only affects -mabicalls.
All -mabicalls code has traditionally been position-independent, regardless of options like -fPIC and -fpic. However, as an extension, the GNU toolchain allows executables to use absolute accesses for locally-binding symbols. It can also use shorter GP initialization sequences and generate direct calls to locally-defined functions. This mode is selected by -mno-shared.

-mno-shared depends on binutils 2.16 or higher and generates objects that can only be linked by the GNU linker. However, the option does not affect the ABI of the final executable; it only affects the ABI of relocatable objects. Using -mno-shared will generally make executables both smaller and quicker.

-mshared is the default.

-mplt
-mno-plt
Assume (do not assume) that the static and dynamic linkers support PLTs and copy relocations. This option only affects -mno-shared -mabicalls. For the n64 ABI , this option has no effect without -msym32.
You can make -mplt the default by configuring GCC with --with-mips-plt. The default is -mno-plt otherwise.

-mxgot
-mno-xgot
Lift (do not lift) the usual restrictions on the size of the global offset table.
GCC normally uses a single instruction to load values from the GOT . While this is relatively efficient, it will only work if the GOT is smaller than about 64k. Anything larger will cause the linker to report an error such as:

relocation truncated to fit: R_MIPS_GOT16 foobar
If this happens, you should recompile your code with -mxgot. It should then work with very large GOTs, although it will also be less efficient, since it will take three instructions to fetch the value of a global symbol.
Note that some linkers can create multiple GOTs. If you have such a linker, you should only need to use -mxgot when a single object file accesses more than 64k's worth of GOT entries. Very few do.

These options have no effect unless GCC is generating position independent code.

-mgp32
Assume that general-purpose registers are 32 bits wide.
-mgp64
Assume that general-purpose registers are 64 bits wide.
-mfp32
Assume that floating-point registers are 32 bits wide.
-mfp64
Assume that floating-point registers are 64 bits wide.
-mhard-float
Use floating-point coprocessor instructions.
-msoft-float
Do not use floating-point coprocessor instructions. Implement floating-point calculations using library calls instead.
-msingle-float
Assume that the floating-point coprocessor only supports single-precision operations.
-mdouble-float
Assume that the floating-point coprocessor supports double-precision operations. This is the default.
-mllsc
-mno-llsc
Use (do not use) ll, sc, and sync instructions to implement atomic memory built-in functions. When neither option is specified, GCC will use the instructions if the target architecture supports them.
-mllsc is useful if the runtime environment can emulate the instructions and -mno-llsc can be useful when compiling for nonstandard ISAs. You can make either option the default by configuring GCC with --with-llsc and --without-llsc respectively. --with-llsc is the default for some configurations; see the installation documentation for details.

-mdsp
-mno-dsp
Use (do not use) revision 1 of the MIPS DSP ASE . This option defines the preprocessor macro __mips_dsp. It also defines __mips_dsp_rev to 1.
-mdspr2
-mno-dspr2
Use (do not use) revision 2 of the MIPS DSP ASE . This option defines the preprocessor macros __mips_dsp and __mips_dspr2. It also defines __mips_dsp_rev to 2.
-msmartmips
-mno-smartmips
Use (do not use) the MIPS SmartMIPS ASE .
-mpaired-single
-mno-paired-single
Use (do not use) paired-single floating-point instructions. This option requires hardware floating-point support to be enabled.
-mdmx
-mno-mdmx
Use (do not use) MIPS Digital Media Extension instructions. This option can only be used when generating 64-bit code and requires hardware floating-point support to be enabled.
-mips3d
-mno-mips3d
Use (do not use) the MIPS-3D ASE . The option -mips3d implies -mpaired-single.
-mmt
-mno-mt
Use (do not use) MT Multithreading instructions.
-mlong64
Force "long" types to be 64 bits wide. See -mlong32 for an explanation of the default and the way that the pointer size is determined.
-mlong32
Force "long", "int", and pointer types to be 32 bits wide.
The default size of "int"s, "long"s and pointers depends on the ABI . All the supported ABIs use 32-bit "int"s. The n64 ABI uses 64-bit "long"s, as does the 64-bit EABI ; the others use 32-bit "long"s. Pointers are the same size as "long"s, or the same size as integer registers, whichever is smaller.

-msym32
-mno-sym32
Assume (do not assume) that all symbols have 32-bit values, regardless of the selected ABI . This option is useful in combination with -mabi=64 and -mno-abicalls because it allows GCC to generate shorter and faster references to symbolic addresses.
-G num
Put definitions of externally-visible data in a small data section if that data is no bigger than num bytes. GCC can then access the data more efficiently; see -mgpopt for details.
The default -G option depends on the configuration.

-mlocal-sdata
-mno-local-sdata
Extend (do not extend) the -G behavior to local data too, such as to static variables in C. -mlocal-sdata is the default for all configurations.
If the linker complains that an application is using too much small data, you might want to try rebuilding the less performance-critical parts with -mno-local-sdata. You might also want to build large libraries with -mno-local-sdata, so that the libraries leave more room for the main program.

-mextern-sdata
-mno-extern-sdata
Assume (do not assume) that externally-defined data will be in a small data section if that data is within the -G limit. -mextern-sdata is the default for all configurations.
If you compile a module Mod with -mextern-sdata -G num -mgpopt, and Mod references a variable Var that is no bigger than num bytes, you must make sure that Var is placed in a small data section. If Var is defined by another module, you must either compile that module with a high-enough -G setting or attach a "section" attribute to Var's definition. If Var is common, you must link the application with a high-enough -G setting.

The easiest way of satisfying these restrictions is to compile and link every module with the same -G option. However, you may wish to build a library that supports several different small data limits. You can do this by compiling the library with the highest supported -G setting and additionally using -mno-extern-sdata to stop the library from making assumptions about externally-defined data.

-mgpopt
-mno-gpopt
Use (do not use) GP-relative accesses for symbols that are known to be in a small data section; see -G, -mlocal-sdata and -mextern-sdata. -mgpopt is the default for all configurations.
-mno-gpopt is useful for cases where the $gp register might not hold the value of "_gp". For example, if the code is part of a library that might be used in a boot monitor, programs that call boot monitor routines will pass an unknown value in $gp. (In such situations, the boot monitor itself would usually be compiled with -G0.)

-mno-gpopt implies -mno-local-sdata and -mno-extern-sdata.

-membedded-data
-mno-embedded-data
Allocate variables to the read-only data section first if possible, then next in the small data section if possible, otherwise in data. This gives slightly slower code than the default, but reduces the amount of RAM required when executing, and thus may be preferred for some embedded systems.
-muninit-const-in-rodata
-mno-uninit-const-in-rodata
Put uninitialized "const" variables in the read-only data section. This option is only meaningful in conjunction with -membedded-data.
-mcode-readable=setting
Specify whether GCC may generate code that reads from executable sections. There are three possible settings:
-mcode-readable=yes
Instructions may freely access executable sections. This is the default setting.
-mcode-readable=pcrel
MIPS16 PC-relative load instructions can access executable sections, but other instructions must not do so. This option is useful on 4KSc and 4KSd processors when the code TLBs have the Read Inhibit bit set. It is also useful on processors that can be configured to have a dual instruction/data SRAM interface and that, like the M4K, automatically redirect PC-relative loads to the instruction RAM .
-mcode-readable=no
Instructions must not access executable sections. This option can be useful on targets that are configured to have a dual instruction/data SRAM interface but that (unlike the M4K) do not automatically redirect PC-relative loads to the instruction RAM .
-msplit-addresses
-mno-split-addresses
Enable (disable) use of the "%hi()" and "%lo()" assembler relocation operators. This option has been superseded by -mexplicit-relocs but is retained for backwards compatibility.
-mexplicit-relocs
-mno-explicit-relocs
Use (do not use) assembler relocation operators when dealing with symbolic addresses. The alternative, selected by -mno-explicit-relocs, is to use assembler macros instead.
-mexplicit-relocs is the default if GCC was configured to use an assembler that supports relocation operators.

-mcheck-zero-division
-mno-check-zero-division
Trap (do not trap) on integer division by zero.
The default is -mcheck-zero-division.

-mdivide-traps
-mdivide-breaks
MIPS systems check for division by zero by generating either a conditional trap or a break instruction. Using traps results in smaller code, but is only supported on MIPS II and later. Also, some versions of the Linux kernel have a bug that prevents trap from generating the proper signal ("SIGFPE"). Use -mdivide-traps to allow conditional traps on architectures that support them and -mdivide-breaks to force the use of breaks.
The default is usually -mdivide-traps, but this can be overridden at configure time using --with-divide=breaks. Divide-by-zero checks can be completely disabled using -mno-check-zero-division.

-mmemcpy
-mno-memcpy
Force (do not force) the use of "memcpy()" for non-trivial block moves. The default is -mno-memcpy, which allows GCC to inline most constant-sized copies.
-mlong-calls
-mno-long-calls
Disable (do not disable) use of the "jal" instruction. Calling functions using "jal" is more efficient but requires the caller and callee to be in the same 256 megabyte segment.
This option has no effect on abicalls code. The default is -mno-long-calls.

-mmad
-mno-mad
Enable (disable) use of the "mad", "madu" and "mul" instructions, as provided by the R4650 ISA .
-mfused-madd
-mno-fused-madd
Enable (disable) use of the floating point multiply-accumulate instructions, when they are available. The default is -mfused-madd.
When multiply-accumulate instructions are used, the intermediate product is calculated to infinite precision and is not subject to the FCSR Flush to Zero bit. This may be undesirable in some circumstances.

-nocpp
Tell the MIPS assembler to not run its preprocessor over user assembler files (with a .s suffix) when assembling them.
-mfix-r4000
-mno-fix-r4000
Work around certain R4000 CPU errata:
-
A double-word or a variable shift may give an incorrect result if executed immediately after starting an integer division.

-

A double-word or a variable shift may give an incorrect result if executed while an integer multiplication is in progress.

-

An integer division may give an incorrect result if started in a delay slot of a taken branch or a jump.

-mfix-r4400
-mno-fix-r4400
Work around certain R4400 CPU errata:
-
A double-word or a variable shift may give an incorrect result if executed immediately after starting an integer division.

-mfix-r10000
-mno-fix-r10000
Work around certain R10000 errata:
-
"ll"/"sc" sequences may not behave atomically on revisions prior to 3.0. They may deadlock on revisions 2.6 and earlier.

This option can only be used if the target architecture supports branch-likely instructions. -mfix-r10000 is the default when -march=r10000 is used; -mno-fix-r10000 is the default otherwise.
-mfix-vr4120
-mno-fix-vr4120
Work around certain VR4120 errata:
-
"dmultu" does not always produce the correct result.

-

"div" and "ddiv" do not always produce the correct result if one of the operands is negative.

The workarounds for the division errata rely on special functions in libgcc.a. At present, these functions are only provided by the "mips64vr*-elf" configurations.
Other VR4120 errata require a nop to be inserted between certain pairs of instructions. These errata are handled by the assembler, not by GCC itself.

-mfix-vr4130
Work around the VR4130 "mflo"/"mfhi" errata. The workarounds are implemented by the assembler rather than by GCC , although GCC will avoid using "mflo" and "mfhi" if the VR4130 "macc", "macchi", "dmacc" and "dmacchi" instructions are available instead.
-mfix-sb1
-mno-fix-sb1
Work around certain SB-1 CPU core errata. (This flag currently works around the SB-1 revision 2 "F1" and "F2" floating point errata.)
-mr10k-cache-barrier=setting
Specify whether GCC should insert cache barriers to avoid the side-effects of speculation on R10K processors.
In common with many processors, the R10K tries to predict the outcome of a conditional branch and speculatively executes instructions from the "taken" branch. It later aborts these instructions if the predicted outcome was wrong. However, on the R10K, even aborted instructions can have side effects.

This problem only affects kernel stores and, depending on the system, kernel loads. As an example, a speculatively-executed store may load the target memory into cache and mark the cache line as dirty, even if the store itself is later aborted. If a DMA operation writes to the same area of memory before the "dirty" line is flushed, the cached data will overwrite the DMA-ed data. See the R10K processor manual for a full description, including other potential problems.

One workaround is to insert cache barrier instructions before every memory access that might be speculatively executed and that might have side effects even if aborted. -mr10k-cache-barrier=setting controls GCC 's implementation of this workaround. It assumes that aborted accesses to any byte in the following regions will not have side effects:

1.
the memory occupied by the current function's stack frame;

2.

the memory occupied by an incoming stack argument;

3.

the memory occupied by an object with a link-time-constant address.

It is the kernel's responsibility to ensure that speculative accesses to these regions are indeed safe.
If the input program contains a function declaration such as:

void foo (void);
then the implementation of "foo" must allow "j foo" and "jal foo" to be executed speculatively. GCC honors this restriction for functions it compiles itself. It expects non-GCC functions (such as hand-written assembly code) to do the same.
The option has three forms:

-mr10k-cache-barrier=load-store
Insert a cache barrier before a load or store that might be speculatively executed and that might have side effects even if aborted.
-mr10k-cache-barrier=store
Insert a cache barrier before a store that might be speculatively executed and that might have side effects even if aborted.
-mr10k-cache-barrier=none
Disable the insertion of cache barriers. This is the default setting.
-mflush-func=func
-mno-flush-func
Specifies the function to call to flush the I and D caches, or to not call any such function. If called, the function must take the same arguments as the common "_flush_func()", that is, the address of the memory range for which the cache is being flushed, the size of the memory range, and the number 3 (to flush both caches). The default depends on the target GCC was configured for, but commonly is either _flush_func or __cpu_flush.
mbranch-cost=num
Set the cost of branches to roughly num "simple" instructions. This cost is only a heuristic and is not guaranteed to produce consistent results across releases. A zero cost redundantly selects the default, which is based on the -mtune setting.
-mbranch-likely
-mno-branch-likely
Enable or disable use of Branch Likely instructions, regardless of the default for the selected architecture. By default, Branch Likely instructions may be generated if they are supported by the selected architecture. An exception is for the MIPS32 and MIPS64 architectures and processors which implement those architectures; for those, Branch Likely instructions will not be generated by default because the MIPS32 and MIPS64 architectures specifically deprecate their use.
-mfp-exceptions
-mno-fp-exceptions
Specifies whether FP exceptions are enabled. This affects how we schedule FP instructions for some processors. The default is that FP exceptions are enabled.
For instance, on the SB-1 , if FP exceptions are disabled, and we are emitting 64-bit code, then we can use both FP pipes. Otherwise, we can only use one FP pipe.

-mvr4130-align
-mno-vr4130-align
The VR4130 pipeline is two-way superscalar, but can only issue two instructions together if the first one is 8-byte aligned. When this option is enabled, GCC will align pairs of instructions that it thinks should execute in parallel.
This option only has an effect when optimizing for the VR4130 . It normally makes code faster, but at the expense of making it bigger. It is enabled by default at optimization level -O3.

MMIX Options

These options are defined for the MMIX:
-mlibfuncs
-mno-libfuncs
Specify that intrinsic library functions are being compiled, passing all values in registers, no matter the size.
-mepsilon
-mno-epsilon
Generate floating-point comparison instructions that compare with respect to the "rE" epsilon register.
-mabi=mmixware
-mabi=gnu
Generate code that passes function parameters and return values that (in the called function) are seen as registers $0 and up, as opposed to the GNU ABI which uses global registers $231 and up.
-mzero-extend
-mno-zero-extend
When reading data from memory in sizes shorter than 64 bits, use (do not use) zero-extending load instructions by default, rather than sign-extending ones.
-mknuthdiv
-mno-knuthdiv
Make the result of a division yielding a remainder have the same sign as the divisor. With the default, -mno-knuthdiv, the sign of the remainder follows the sign of the dividend. Both methods are arithmetically valid, the latter being almost exclusively used.
-mtoplevel-symbols
-mno-toplevel-symbols
Prepend (do not prepend) a : to all global symbols, so the assembly code can be used with the "PREFIX" assembly directive.
-melf
Generate an executable in the ELF format, rather than the default mmo format used by the mmix simulator.
-mbranch-predict
-mno-branch-predict
Use (do not use) the probable-branch instructions, when static branch prediction indicates a probable branch.
-mbase-addresses
-mno-base-addresses
Generate (do not generate) code that uses base addresses. Using a base address automatically generates a request (handled by the assembler and the linker) for a constant to be set up in a global register. The register is used for one or more base address requests within the range 0 to 255 from the value held in the register. The generally leads to short and fast code, but the number of different data items that can be addressed is limited. This means that a program that uses lots of static data may require -mno-base-addresses.
-msingle-exit
-mno-single-exit
Force (do not force) generated code to have a single exit point in each function.
MN10300 Options

These -m options are defined for Matsushita MN10300 architectures:
-mmult-bug
Generate code to avoid bugs in the multiply instructions for the MN10300 processors. This is the default.
-mno-mult-bug
Do not generate code to avoid bugs in the multiply instructions for the MN10300 processors.
-mam33
Generate code which uses features specific to the AM33 processor.
-mno-am33
Do not generate code which uses features specific to the AM33 processor. This is the default.
-mreturn-pointer-on-d0
When generating a function which returns a pointer, return the pointer in both "a0" and "d0". Otherwise, the pointer is returned only in a0, and attempts to call such functions without a prototype would result in errors. Note that this option is on by default; use -mno-return-pointer-on-d0 to disable it.
-mno-crt0
Do not link in the C run-time initialization object file.
-mrelax
Indicate to the linker that it should perform a relaxation optimization pass to shorten branches, calls and absolute memory addresses. This option only has an effect when used on the command line for the final link step.
This option makes symbolic debugging impossible.

PDP-11 Options

These options are defined for the PDP-11:
-mfpu
Use hardware FPP floating point. This is the default. ( FIS floating point on the PDP-11/40 is not supported.)
-msoft-float
Do not use hardware floating point.
-mac0
Return floating-point results in ac0 (fr0 in Unix assembler syntax).
-mno-ac0
Return floating-point results in memory. This is the default.
-m40
Generate code for a PDP-11/40 .
-m45
Generate code for a PDP-11/45 . This is the default.
-m10
Generate code for a PDP-11/10 .
-mbcopy-builtin
Use inline "movmemhi" patterns for copying memory. This is the default.
-mbcopy
Do not use inline "movmemhi" patterns for copying memory.
-mint16
-mno-int32
Use 16-bit "int". This is the default.
-mint32
-mno-int16
Use 32-bit "int".
-mfloat64
-mno-float32
Use 64-bit "float". This is the default.
-mfloat32
-mno-float64
Use 32-bit "float".
-mabshi
Use "abshi2" pattern. This is the default.
-mno-abshi
Do not use "abshi2" pattern.
-mbranch-expensive
Pretend that branches are expensive. This is for experimenting with code generation only.
-mbranch-cheap
Do not pretend that branches are expensive. This is the default.
-msplit
Generate code for a system with split I&D.
-mno-split
Generate code for a system without split I&D. This is the default.
-munix-asm
Use Unix assembler syntax. This is the default when configured for pdp11-*-bsd.
-mdec-asm
Use DEC assembler syntax. This is the default when configured for any PDP-11 target other than pdp11-*-bsd.
picoChip Options

These -m options are defined for picoChip implementations:
-mae=ae_type
Set the instruction set, register set, and instruction scheduling parameters for array element type ae_type. Supported values for ae_type are ANY , MUL , and MAC .
-mae=ANY selects a completely generic AE type. Code generated with this option will run on any of the other AE types. The code will not be as efficient as it would be if compiled for a specific AE type, and some types of operation (e.g., multiplication) will not work properly on all types of AE .

-mae=MUL selects a MUL AE type. This is the most useful AE type for compiled code, and is the default.

-mae=MAC selects a DSP-style MAC AE . Code compiled with this option may suffer from poor performance of byte (char) manipulation, since the DSP AE does not provide hardware support for byte load/stores.

-msymbol-as-address
Enable the compiler to directly use a symbol name as an address in a load/store instruction, without first loading it into a register. Typically, the use of this option will generate larger programs, which run faster than when the option isn't used. However, the results vary from program to program, so it is left as a user option, rather than being permanently enabled.
-mno-inefficient-warnings
Disables warnings about the generation of inefficient code. These warnings can be generated, for example, when compiling code which performs byte-level memory operations on the MAC AE type. The MAC AE has no hardware support for byte-level memory operations, so all byte load/stores must be synthesized from word load/store operations. This is inefficient and a warning will be generated indicating to the programmer that they should rewrite the code to avoid byte operations, or to target an AE type which has the necessary hardware support. This option enables the warning to be turned off.
PowerPC Options

These are listed under
IBM RS/6000 and PowerPC Options

These -m options are defined for the IBM RS/6000 and PowerPC:
-mpower
-mno-power
-mpower2
-mno-power2
-mpowerpc
-mno-powerpc
-mpowerpc-gpopt
-mno-powerpc-gpopt
-mpowerpc-gfxopt
-mno-powerpc-gfxopt
-mpowerpc64
-mno-powerpc64
-mmfcrf
-mno-mfcrf
-mpopcntb
-mno-popcntb
-mpopcntd
-mno-popcntd
-mfprnd
-mno-fprnd
-mcmpb
-mno-cmpb
-mmfpgpr
-mno-mfpgpr
-mhard-dfp
-mno-hard-dfp
GCC supports two related instruction set architectures for the RS/6000 and PowerPC. The POWER instruction set are those instructions supported by the rios chip set used in the original RS/6000 systems and the PowerPC instruction set is the architecture of the Freescale MPC5xx, MPC6xx, MPC8xx microprocessors, and the IBM 4xx, 6xx, and follow-on microprocessors.
Neither architecture is a subset of the other. However there is a large common subset of instructions supported by both. An MQ register is included in processors supporting the POWER architecture.

You use these options to specify which instructions are available on the processor you are using. The default value of these options is determined when configuring GCC . Specifying the -mcpu=cpu_type overrides the specification of these options. We recommend you use the -mcpu=cpu_type option rather than the options listed above.

The -mpower option allows GCC to generate instructions that are found only in the POWER architecture and to use the MQ register. Specifying -mpower2 implies -power and also allows GCC to generate instructions that are present in the POWER2 architecture but not the original POWER architecture.

The -mpowerpc option allows GCC to generate instructions that are found only in the 32-bit subset of the PowerPC architecture. Specifying -mpowerpc-gpopt implies -mpowerpc and also allows GCC to use the optional PowerPC architecture instructions in the General Purpose group, including floating-point square root. Specifying -mpowerpc-gfxopt implies -mpowerpc and also allows GCC to use the optional PowerPC architecture instructions in the Graphics group, including floating-point select.

The -mmfcrf option allows GCC to generate the move from condition register field instruction implemented on the POWER4 processor and other processors that support the PowerPC V2.01 architecture. The -mpopcntb option allows GCC to generate the popcount and double precision FP reciprocal estimate instruction implemented on the POWER5 processor and other processors that support the PowerPC V2.02 architecture. The -mpopcntd option allows GCC to generate the popcount instruction implemented on the POWER7 processor and other processors that support the PowerPC V2.06 architecture. The -mfprnd option allows GCC to generate the FP round to integer instructions implemented on the POWER5+ processor and other processors that support the PowerPC V2.03 architecture. The -mcmpb option allows GCC to generate the compare bytes instruction implemented on the POWER6 processor and other processors that support the PowerPC V2.05 architecture. The -mmfpgpr option allows GCC to generate the FP move to/from general purpose register instructions implemented on the POWER6X processor and other processors that support the extended PowerPC V2.05 architecture. The -mhard-dfp option allows GCC to generate the decimal floating point instructions implemented on some POWER processors.

The -mpowerpc64 option allows GCC to generate the additional 64-bit instructions that are found in the full PowerPC64 architecture and to treat GPRs as 64-bit, doubleword quantities. GCC defaults to -mno-powerpc64.

If you specify both -mno-power and -mno-powerpc, GCC will use only the instructions in the common subset of both architectures plus some special AIX common-mode calls, and will not use the MQ register. Specifying both -mpower and -mpowerpc permits GCC to use any instruction from either architecture and to allow use of the MQ register; specify this for the Motorola MPC601 .

-mnew-mnemonics
-mold-mnemonics
Select which mnemonics to use in the generated assembler code. With -mnew-mnemonics, GCC uses the assembler mnemonics defined for the PowerPC architecture. With -mold-mnemonics it uses the assembler mnemonics defined for the POWER architecture. Instructions defined in only one architecture have only one mnemonic; GCC uses that mnemonic irrespective of which of these options is specified.
GCC defaults to the mnemonics appropriate for the architecture in use. Specifying -mcpu=cpu_type sometimes overrides the value of these option. Unless you are building a cross-compiler, you should normally not specify either -mnew-mnemonics or -mold-mnemonics, but should instead accept the default.

-mcpu=cpu_type
Set architecture type, register usage, choice of mnemonics, and instruction scheduling parameters for machine type cpu_type. Supported values for cpu_type are 401, 403, 405, 405fp, 440, 440fp, 464, 464fp, 505, 601, 602, 603, 603e, 604, 604e, 620, 630, 740, 7400, 7450, 750, 801, 821, 823, 860, 970, 8540, e300c2, e300c3, e500mc, ec603e, G3, G4, G5, power, power2, power3, power4, power5, power5+, power6, power6x, power7, common, powerpc, powerpc64, rios, rios1, rios2, rsc, and rs64.
-mcpu=common selects a completely generic processor. Code generated under this option will run on any POWER or PowerPC processor. GCC will use only the instructions in the common subset of both architectures, and will not use the MQ register. GCC assumes a generic processor model for scheduling purposes.

-mcpu=power, -mcpu=power2, -mcpu=powerpc, and -mcpu=powerpc64 specify generic POWER , POWER2 , pure 32-bit PowerPC (i.e., not MPC601 ), and 64-bit PowerPC architecture machine types, with an appropriate, generic processor model assumed for scheduling purposes.

The other options specify a specific processor. Code generated under those options will run best on that processor, and may not run at all on others.

The -mcpu options automatically enable or disable the following options:

-maltivec -mfprnd -mhard-float -mmfcrf -mmultiple -mnew-mnemonics -mpopcntb -mpopcntd -mpower -mpower2 -mpowerpc64 -mpowerpc-gpopt -mpowerpc-gfxopt -msingle-float -mdouble-float -msimple-fpu -mstring -mmulhw -mdlmzb -mmfpgpr -mvsx

The particular options set for any particular CPU will vary between compiler versions, depending on what setting seems to produce optimal code for that CPU ; it doesn't necessarily reflect the actual hardware's capabilities. If you wish to set an individual option to a particular value, you may specify it after the -mcpu option, like -mcpu=970 -mno-altivec.

On AIX , the -maltivec and -mpowerpc64 options are not enabled or disabled by the -mcpu option at present because AIX does not have full support for these options. You may still enable or disable them individually if you're sure it'll work in your environment.

-mtune=cpu_type
Set the instruction scheduling parameters for machine type cpu_type, but do not set the architecture type, register usage, or choice of mnemonics, as -mcpu=cpu_type would. The same values for cpu_type are used for -mtune as for -mcpu. If both are specified, the code generated will use the architecture, registers, and mnemonics set by -mcpu, but the scheduling parameters set by -mtune.
-mcmodel=small
Generate PowerPC64 code for the small model: The TOC is limited to 64k.
-mcmodel=medium
Generate PowerPC64 code for the medium model: The TOC and other static data may be up to a total of 4G in size.
-mcmodel=large
Generate PowerPC64 code for the large model: The TOC may be up to 4G in size. Other data and code is only limited by the 64-bit address space.
-mswdiv
-mno-swdiv
Generate code to compute division as reciprocal estimate and iterative refinement, creating opportunities for increased throughput. This feature requires: optional PowerPC Graphics instruction set for single precision and FRE instruction for double precision, assuming divides cannot generate user-visible traps, and the domain values not include Infinities, denormals or zero denominator.
-maltivec
-mno-altivec
Generate code that uses (does not use) AltiVec instructions, and also enable the use of built-in functions that allow more direct access to the AltiVec instruction set. You may also need to set -mabi=altivec to adjust the current ABI with AltiVec ABI enhancements.
-mvrsave
-mno-vrsave
Generate VRSAVE instructions when generating AltiVec code.
-mgen-cell-microcode
Generate Cell microcode instructions
-mwarn-cell-microcode
Warning when a Cell microcode instruction is going to emitted. An example of a Cell microcode instruction is a variable shift.
-msecure-plt
Generate code that allows ld and ld.so to build executables and shared libraries with non-exec .plt and .got sections. This is a PowerPC 32-bit SYSV ABI option.
-mbss-plt
Generate code that uses a BSS .plt section that ld.so fills in, and requires .plt and .got sections that are both writable and executable. This is a PowerPC 32-bit SYSV ABI option.
-misel
-mno-isel
This switch enables or disables the generation of ISEL instructions.
-misel=yes/no
This switch has been deprecated. Use -misel and -mno-isel instead.
-mspe
-mno-spe
This switch enables or disables the generation of SPE simd instructions.
-mpaired
-mno-paired
This switch enables or disables the generation of PAIRED simd instructions.
-mspe=yes/no
This option has been deprecated. Use -mspe and -mno-spe instead.
-mvsx
-mno-vsx
Generate code that uses (does not use) vector/scalar ( VSX ) instructions, and also enable the use of built-in functions that allow more direct access to the VSX instruction set.
-mfloat-gprs=yes/single/double/no
-mfloat-gprs
This switch enables or disables the generation of floating point operations on the general purpose registers for architectures that support it.
The argument yes or single enables the use of single-precision floating point operations.

The argument double enables the use of single and double-precision floating point operations.

The argument no disables floating point operations on the general purpose registers.

This option is currently only available on the MPC854x.

-m32
-m64
Generate code for 32-bit or 64-bit environments of Darwin and SVR4 targets (including GNU/Linux). The 32-bit environment sets int, long and pointer to 32 bits and generates code that runs on any PowerPC variant. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits, and generates code for PowerPC64, as for -mpowerpc64.
-mfull-toc
-mno-fp-in-toc
-mno-sum-in-toc
-mminimal-toc
Modify generation of the TOC (Table Of Contents), which is created for every executable file. The -mfull-toc option is selected by default. In that case, GCC will allocate at least one TOC entry for each unique non-automatic variable reference in your program. GCC will also place floating-point constants in the TOC . However, only 16,384 entries are available in the TOC .
If you receive a linker error message that saying you have overflowed the available TOC space, you can reduce the amount of TOC space used with the -mno-fp-in-toc and -mno-sum-in-toc options. -mno-fp-in-toc prevents GCC from putting floating-point constants in the TOC and -mno-sum-in-toc forces GCC to generate code to calculate the sum of an address and a constant at run-time instead of putting that sum into the TOC . You may specify one or both of these options. Each causes GCC to produce very slightly slower and larger code at the expense of conserving TOC space.

If you still run out of space in the TOC even when you specify both of these options, specify -mminimal-toc instead. This option causes GCC to make only one TOC entry for every file. When you specify this option, GCC will produce code that is slower and larger but which uses extremely little TOC space. You may wish to use this option only on files that contain less frequently executed code.

-maix64
-maix32
Enable 64-bit AIX ABI and calling convention: 64-bit pointers, 64-bit "long" type, and the infrastructure needed to support them. Specifying -maix64 implies -mpowerpc64 and -mpowerpc, while -maix32 disables the 64-bit ABI and implies -mno-powerpc64. GCC defaults to -maix32.
-mxl-compat
-mno-xl-compat
Produce code that conforms more closely to IBM XL compiler semantics when using AIX-compatible ABI . Pass floating-point arguments to prototyped functions beyond the register save area ( RSA ) on the stack in addition to argument FPRs. Do not assume that most significant double in 128-bit long double value is properly rounded when comparing values and converting to double. Use XL symbol names for long double support routines.
The AIX calling convention was extended but not initially documented to handle an obscure K&R C case of calling a function that takes the address of its arguments with fewer arguments than declared. IBM XL compilers access floating point arguments which do not fit in the RSA from the stack when a subroutine is compiled without optimization. Because always storing floating-point arguments on the stack is inefficient and rarely needed, this option is not enabled by default and only is necessary when calling subroutines compiled by IBM XL compilers without optimization.

-mpe
Support IBM RS/6000 SP Parallel Environment ( PE ). Link an application written to use message passing with special startup code to enable the application to run. The system must have PE installed in the standard location (/usr/lpp/ppe.poe/), or the specs file must be overridden with the -specs= option to specify the appropriate directory location. The Parallel Environment does not support threads, so the -mpe option and the -pthread option are incompatible.
-malign-natural
-malign-power
On AIX , 32-bit Darwin, and 64-bit PowerPC GNU/Linux, the option -malign-natural overrides the ABI-defined alignment of larger types, such as floating-point doubles, on their natural size-based boundary. The option -malign-power instructs GCC to follow the ABI-specified alignment rules. GCC defaults to the standard alignment defined in the ABI .
On 64-bit Darwin, natural alignment is the default, and -malign-power is not supported.

-msoft-float
-mhard-float
Generate code that does not use (uses) the floating-point register set. Software floating point emulation is provided if you use the -msoft-float option, and pass the option to GCC when linking.
-msingle-float
-mdouble-float
Generate code for single or double-precision floating point operations. -mdouble-float implies -msingle-float.
-msimple-fpu
Do not generate sqrt and div instructions for hardware floating point unit.
-mfpu
Specify type of floating point unit. Valid values are sp_lite (equivalent to -msingle-float -msimple-fpu), dp_lite (equivalent to -mdouble-float -msimple-fpu), sp_full (equivalent to -msingle-float), and dp_full (equivalent to -mdouble-float).
-mxilinx-fpu
Perform optimizations for floating point unit on Xilinx PPC 405/440.
-mmultiple
-mno-multiple
Generate code that uses (does not use) the load multiple word instructions and the store multiple word instructions. These instructions are generated by default on POWER systems, and not generated on PowerPC systems. Do not use -mmultiple on little endian PowerPC systems, since those instructions do not work when the processor is in little endian mode. The exceptions are PPC740 and PPC750 which permit the instructions usage in little endian mode.
-mstring
-mno-string
Generate code that uses (does not use) the load string instructions and the store string word instructions to save multiple registers and do small block moves. These instructions are generated by default on POWER systems, and not generated on PowerPC systems. Do not use -mstring on little endian PowerPC systems, since those instructions do not work when the processor is in little endian mode. The exceptions are PPC740 and PPC750 which permit the instructions usage in little endian mode.
-mupdate
-mno-update
Generate code that uses (does not use) the load or store instructions that update the base register to the address of the calculated memory location. These instructions are generated by default. If you use -mno-update, there is a small window between the time that the stack pointer is updated and the address of the previous frame is stored, which means code that walks the stack frame across interrupts or signals may get corrupted data.
-mavoid-indexed-addresses
-mno-avoid-indexed-addresses
Generate code that tries to avoid (not avoid) the use of indexed load or store instructions. These instructions can incur a performance penalty on Power6 processors in certain situations, such as when stepping through large arrays that cross a 16M boundary. This option is enabled by default when targetting Power6 and disabled otherwise.
-mfused-madd
-mno-fused-madd
Generate code that uses (does not use) the floating point multiply and accumulate instructions. These instructions are generated by default if hardware floating is used.
-mmulhw
-mno-mulhw
Generate code that uses (does not use) the half-word multiply and multiply-accumulate instructions on the IBM 405, 440 and 464 processors. These instructions are generated by default when targetting those processors.
-mdlmzb
-mno-dlmzb
Generate code that uses (does not use) the string-search dlmzb instruction on the IBM 405, 440 and 464 processors. This instruction is generated by default when targetting those processors.
-mno-bit-align
-mbit-align
On System V.4 and embedded PowerPC systems do not (do) force structures and unions that contain bit-fields to be aligned to the base type of the bit-field.
For example, by default a structure containing nothing but 8 "unsigned" bit-fields of length 1 would be aligned to a 4 byte boundary and have a size of 4 bytes. By using -mno-bit-align, the structure would be aligned to a 1 byte boundary and be one byte in size.

-mno-strict-align
-mstrict-align
On System V.4 and embedded PowerPC systems do not (do) assume that unaligned memory references will be handled by the system.
-mrelocatable
-mno-relocatable
On embedded PowerPC systems generate code that allows (does not allow) the program to be relocated to a different address at runtime. If you use -mrelocatable on any module, all objects linked together must be compiled with -mrelocatable or -mrelocatable-lib.
-mrelocatable-lib
-mno-relocatable-lib
On embedded PowerPC systems generate code that allows (does not allow) the program to be relocated to a different address at runtime. Modules compiled with -mrelocatable-lib can be linked with either modules compiled without -mrelocatable and -mrelocatable-lib or with modules compiled with the -mrelocatable options.
-mno-toc
-mtoc
On System V.4 and embedded PowerPC systems do not (do) assume that register 2 contains a pointer to a global area pointing to the addresses used in the program.
-mlittle
-mlittle-endian
On System V.4 and embedded PowerPC systems compile code for the processor in little endian mode. The -mlittle-endian option is the same as -mlittle.
-mbig
-mbig-endian
On System V.4 and embedded PowerPC systems compile code for the processor in big endian mode. The -mbig-endian option is the same as -mbig.
-mdynamic-no-pic
On Darwin and Mac OS X systems, compile code so that it is not relocatable, but that its external references are relocatable. The resulting code is suitable for applications, but not shared libraries.
-mprioritize-restricted-insns=priority
This option controls the priority that is assigned to dispatch-slot restricted instructions during the second scheduling pass. The argument priority takes the value 0/1/2 to assign no/highest/second-highest priority to dispatch slot restricted instructions.
-msched-costly-dep=dependence_type
This option controls which dependences are considered costly by the target during instruction scheduling. The argument dependence_type takes one of the following values: no: no dependence is costly, all: all dependences are costly, true_store_to_load: a true dependence from store to load is costly, store_to_load: any dependence from store to load is costly, number: any dependence which latency >= number is costly.
-minsert-sched-nops=scheme
This option controls which nop insertion scheme will be used during the second scheduling pass. The argument scheme takes one of the following values: no: Don't insert nops. pad: Pad with nops any dispatch group which has vacant issue slots, according to the scheduler's grouping. regroup_exact: Insert nops to force costly dependent insns into separate groups. Insert exactly as many nops as needed to force an insn to a new group, according to the estimated processor grouping. number: Insert nops to force costly dependent insns into separate groups. Insert number nops to force an insn to a new group.
-mcall-sysv
On System V.4 and embedded PowerPC systems compile code using calling conventions that adheres to the March 1995 draft of the System V Application Binary Interface, PowerPC processor supplement. This is the default unless you configured GCC using powerpc-*-eabiaix.
-mcall-sysv-eabi
Specify both -mcall-sysv and -meabi options.
-mcall-sysv-noeabi
Specify both -mcall-sysv and -mno-eabi options.
-mcall-solaris
On System V.4 and embedded PowerPC systems compile code for the Solaris operating system.
-mcall-linux
On System V.4 and embedded PowerPC systems compile code for the Linux-based GNU system.
-mcall-gnu
On System V.4 and embedded PowerPC systems compile code for the Hurd-based GNU system.
-mcall-netbsd
On System V.4 and embedded PowerPC systems compile code for the NetBSD operating system.
-maix-struct-return
Return all structures in memory (as specified by the AIX ABI ).
-msvr4-struct-return
Return structures smaller than 8 bytes in registers (as specified by the SVR4 ABI ).
-mabi=abi-type
Extend the current ABI with a particular extension, or remove such extension. Valid values are altivec, no-altivec, spe, no-spe, ibmlongdouble, ieeelongdouble.
-mabi=spe
Extend the current ABI with SPE ABI extensions. This does not change the default ABI , instead it adds the SPE ABI extensions to the current ABI .
-mabi=no-spe
Disable Booke SPE ABI extensions for the current ABI .
-mabi=ibmlongdouble
Change the current ABI to use IBM extended precision long double. This is a PowerPC 32-bit SYSV ABI option.
-mabi=ieeelongdouble
Change the current ABI to use IEEE extended precision long double. This is a PowerPC 32-bit Linux ABI option.
-mprototype
-mno-prototype
On System V.4 and embedded PowerPC systems assume that all calls to variable argument functions are properly prototyped. Otherwise, the compiler must insert an instruction before every non prototyped call to set or clear bit 6 of the condition code register ( CR ) to indicate whether floating point values were passed in the floating point registers in case the function takes a variable arguments. With -mprototype, only calls to prototyped variable argument functions will set or clear the bit.
-msim
On embedded PowerPC systems, assume that the startup module is called sim-crt0.o and that the standard C libraries are libsim.a and libc.a. This is the default for powerpc-*-eabisim configurations.
-mmvme
On embedded PowerPC systems, assume that the startup module is called crt0.o and the standard C libraries are libmvme.a and libc.a.
-mads
On embedded PowerPC systems, assume that the startup module is called crt0.o and the standard C libraries are libads.a and libc.a.
-myellowknife
On embedded PowerPC systems, assume that the startup module is called crt0.o and the standard C libraries are libyk.a and libc.a.
-mvxworks
On System V.4 and embedded PowerPC systems, specify that you are compiling for a VxWorks system.
-memb
On embedded PowerPC systems, set the PPC_EMB bit in the ELF flags header to indicate that eabi extended relocations are used.
-meabi
-mno-eabi
On System V.4 and embedded PowerPC systems do (do not) adhere to the Embedded Applications Binary Interface (eabi) which is a set of modifications to the System V.4 specifications. Selecting -meabi means that the stack is aligned to an 8 byte boundary, a function "__eabi" is called to from "main" to set up the eabi environment, and the -msdata option can use both "r2" and "r13" to point to two separate small data areas. Selecting -mno-eabi means that the stack is aligned to a 16 byte boundary, do not call an initialization function from "main", and the -msdata option will only use "r13" to point to a single small data area. The -meabi option is on by default if you configured GCC using one of the powerpc*-*-eabi* options.
-msdata=eabi
On System V.4 and embedded PowerPC systems, put small initialized "const" global and static data in the .sdata2 section, which is pointed to by register "r2". Put small initialized non-"const" global and static data in the .sdata section, which is pointed to by register "r13". Put small uninitialized global and static data in the .sbss section, which is adjacent to the .sdata section. The -msdata=eabi option is incompatible with the -mrelocatable option. The -msdata=eabi option also sets the -memb option.
-msdata=sysv
On System V.4 and embedded PowerPC systems, put small global and static data in the .sdata section, which is pointed to by register "r13". Put small uninitialized global and static data in the .sbss section, which is adjacent to the .sdata section. The -msdata=sysv option is incompatible with the -mrelocatable option.
-msdata=default
-msdata
On System V.4 and embedded PowerPC systems, if -meabi is used, compile code the same as -msdata=eabi, otherwise compile code the same as -msdata=sysv.
-msdata=data
On System V.4 and embedded PowerPC systems, put small global data in the .sdata section. Put small uninitialized global data in the .sbss section. Do not use register "r13" to address small data however. This is the default behavior unless other -msdata options are used.
-msdata=none
-mno-sdata
On embedded PowerPC systems, put all initialized global and static data in the .data section, and all uninitialized data in the .bss section.
-G num
On embedded PowerPC systems, put global and static items less than or equal to num bytes into the small data or bss sections instead of the normal data or bss section. By default, num is 8. The -G num switch is also passed to the linker. All modules should be compiled with the same -G num value.
-mregnames
-mno-regnames
On System V.4 and embedded PowerPC systems do (do not) emit register names in the assembly language output using symbolic forms.
-mlongcall
-mno-longcall
By default assume that all calls are far away so that a longer more expensive calling sequence is required. This is required for calls further than 32 megabytes (33,554,432 bytes) from the current location. A short call will be generated if the compiler knows the call cannot be that far away. This setting can be overridden by the "shortcall" function attribute, or by "#pragma longcall(0)".
Some linkers are capable of detecting out-of-range calls and generating glue code on the fly. On these systems, long calls are unnecessary and generate slower code. As of this writing, the AIX linker can do this, as can the GNU linker for PowerPC/64. It is planned to add this feature to the GNU linker for 32-bit PowerPC systems as well.

On Darwin/PPC systems, "#pragma longcall" will generate "jbsr callee, L42", plus a "branch island" (glue code). The two target addresses represent the callee and the "branch island". The Darwin/PPC linker will prefer the first address and generate a "bl callee" if the PPC "bl" instruction will reach the callee directly; otherwise, the linker will generate "bl L42" to call the "branch island". The "branch island" is appended to the body of the calling function; it computes the full 32-bit address of the callee and jumps to it.

On Mach-O (Darwin) systems, this option directs the compiler emit to the glue for every direct call, and the Darwin linker decides whether to use or discard it.

In the future, we may cause GCC to ignore all longcall specifications when the linker is known to generate glue.

-pthread
Adds support for multithreading with the pthreads library. This option sets flags for both the preprocessor and linker.
S/390 and zSeries Options

These are the -m options defined for the S/390 and zSeries architecture.
-mhard-float
-msoft-float
Use (do not use) the hardware floating-point instructions and registers for floating-point operations. When -msoft-float is specified, functions in libgcc.a will be used to perform floating-point operations. When -mhard-float is specified, the compiler generates IEEE floating-point instructions. This is the default.
-mhard-dfp
-mno-hard-dfp
Use (do not use) the hardware decimal-floating-point instructions for decimal-floating-point operations. When -mno-hard-dfp is specified, functions in libgcc.a will be used to perform decimal-floating-point operations. When -mhard-dfp is specified, the compiler generates decimal-floating-point hardware instructions. This is the default for -march=z9-ec or higher.
-mlong-double-64
-mlong-double-128
These switches control the size of "long double" type. A size of 64bit makes the "long double" type equivalent to the "double" type. This is the default.
-mbackchain
-mno-backchain
Store (do not store) the address of the caller's frame as backchain pointer into the callee's stack frame. A backchain may be needed to allow debugging using tools that do not understand DWARF-2 call frame information. When -mno-packed-stack is in effect, the backchain pointer is stored at the bottom of the stack frame; when -mpacked-stack is in effect, the backchain is placed into the topmost word of the 96/160 byte register save area.
In general, code compiled with -mbackchain is call-compatible with code compiled with -mmo-backchain; however, use of the backchain for debugging purposes usually requires that the whole binary is built with -mbackchain. Note that the combination of -mbackchain, -mpacked-stack and -mhard-float is not supported. In order to build a linux kernel use -msoft-float.

The default is to not maintain the backchain.

-mpacked-stack
-mno-packed-stack
Use (do not use) the packed stack layout. When -mno-packed-stack is specified, the compiler uses the all fields of the 96/160 byte register save area only for their default purpose; unused fields still take up stack space. When -mpacked-stack is specified, register save slots are densely packed at the top of the register save area; unused space is reused for other purposes, allowing for more efficient use of the available stack space. However, when -mbackchain is also in effect, the topmost word of the save area is always used to store the backchain, and the return address register is always saved two words below the backchain.
As long as the stack frame backchain is not used, code generated with -mpacked-stack is call-compatible with code generated with -mno-packed-stack. Note that some non-FSF releases of GCC 2.95 for S/390 or zSeries generated code that uses the stack frame backchain at run time, not just for debugging purposes. Such code is not call-compatible with code compiled with -mpacked-stack. Also, note that the combination of -mbackchain, -mpacked-stack and -mhard-float is not supported. In order to build a linux kernel use -msoft-float.

The default is to not use the packed stack layout.

-msmall-exec
-mno-small-exec
Generate (or do not generate) code using the "bras" instruction to do subroutine calls. This only works reliably if the total executable size does not exceed 64k. The default is to use the "basr" instruction instead, which does not have this limitation.
-m64
-m31
When -m31 is specified, generate code compliant to the GNU/Linux for S/390 ABI . When -m64 is specified, generate code compliant to the GNU/Linux for zSeries ABI . This allows GCC in particular to generate 64-bit instructions. For the s390 targets, the default is -m31, while the s390x targets default to -m64.
-mzarch
-mesa
When -mzarch is specified, generate code using the instructions available on z/Architecture. When -mesa is specified, generate code using the instructions available on ESA/390 . Note that -mesa is not possible with -m64. When generating code compliant to the GNU/Linux for S/390 ABI , the default is -mesa. When generating code compliant to the GNU/Linux for zSeries ABI , the default is -mzarch.
-mmvcle
-mno-mvcle
Generate (or do not generate) code using the "mvcle" instruction to perform block moves. When -mno-mvcle is specified, use a "mvc" loop instead. This is the default unless optimizing for size.
-mdebug
-mno-debug
Print (or do not print) additional debug information when compiling. The default is to not print debug information.
-march=cpu-type
Generate code that will run on cpu-type, which is the name of a system representing a certain processor type. Possible values for cpu-type are g5, g6, z900, z990, z9-109, z9-ec and z10. When generating code using the instructions available on z/Architecture, the default is -march=z900. Otherwise, the default is -march=g5.
-mtune=cpu-type
Tune to cpu-type everything applicable about the generated code, except for the ABI and the set of available instructions. The list of cpu-type values is the same as for -march. The default is the value used for -march.
-mtpf-trace
-mno-tpf-trace
Generate code that adds (does not add) in TPF OS specific branches to trace routines in the operating system. This option is off by default, even when compiling for the TPF OS .
-mfused-madd
-mno-fused-madd
Generate code that uses (does not use) the floating point multiply and accumulate instructions. These instructions are generated by default if hardware floating point is used.
-mwarn-framesize=framesize
Emit a warning if the current function exceeds the given frame size. Because this is a compile time check it doesn't need to be a real problem when the program runs. It is intended to identify functions which most probably cause a stack overflow. It is useful to be used in an environment with limited stack size e.g. the linux kernel.
-mwarn-dynamicstack
Emit a warning if the function calls alloca or uses dynamically sized arrays. This is generally a bad idea with a limited stack size.
-mstack-guard=stack-guard
-mstack-size=stack-size
If these options are provided the s390 back end emits additional instructions in the function prologue which trigger a trap if the stack size is stack-guard bytes above the stack-size (remember that the stack on s390 grows downward). If the stack-guard option is omitted the smallest power of 2 larger than the frame size of the compiled function is chosen. These options are intended to be used to help debugging stack overflow problems. The additionally emitted code causes only little overhead and hence can also be used in production like systems without greater performance degradation. The given values have to be exact powers of 2 and stack-size has to be greater than stack-guard without exceeding 64k. In order to be efficient the extra code makes the assumption that the stack starts at an address aligned to the value given by stack-size. The stack-guard option can only be used in conjunction with stack-size.
Score Options

These options are defined for Score implementations:
-meb
Compile code for big endian mode. This is the default.
-mel
Compile code for little endian mode.
-mnhwloop
Disable generate bcnz instruction.
-muls
Enable generate unaligned load and store instruction.
-mmac
Enable the use of multiply-accumulate instructions. Disabled by default.
-mscore5
Specify the SCORE5 as the target architecture.
-mscore5u
Specify the SCORE5U of the target architecture.
-mscore7
Specify the SCORE7 as the target architecture. This is the default.
-mscore7d
Specify the SCORE7D as the target architecture.
SH Options

These -m options are defined for the SH implementations:
-m1
Generate code for the SH1 .

-m2

Generate code for the SH2 .

-m2e
Generate code for the SH2e.
-m3
Generate code for the SH3 .

-m3e
Generate code for the SH3e.
-m4-nofpu
Generate code for the SH4 without a floating-point unit.
-m4-single-only
Generate code for the SH4 with a floating-point unit that only supports single-precision arithmetic.
-m4-single
Generate code for the SH4 assuming the floating-point unit is in single-precision mode by default.
-m4
Generate code for the SH4 .

-m4a-nofpu
Generate code for the SH4al-dsp, or for a SH4a in such a way that the floating-point unit is not used.
-m4a-single-only
Generate code for the SH4a, in such a way that no double-precision floating point operations are used.
-m4a-single
Generate code for the SH4a assuming the floating-point unit is in single-precision mode by default.
-m4a
Generate code for the SH4a.
-m4al
Same as -m4a-nofpu, except that it implicitly passes -dsp to the assembler. GCC doesn't generate any DSP instructions at the moment.
-mb
Compile code for the processor in big endian mode.

-ml

Compile code for the processor in little endian mode.

-mdalign
Align doubles at 64-bit boundaries. Note that this changes the calling conventions, and thus some functions from the standard C library will not work unless you recompile it first with -mdalign.
-mrelax
Shorten some address references at link time, when possible; uses the linker option -relax.
-mbigtable
Use 32-bit offsets in "switch" tables. The default is to use 16-bit offsets.
-mbitops
Enable the use of bit manipulation instructions on SH2A .
-mfmovd
Enable the use of the instruction "fmovd".
-mhitachi
Comply with the calling conventions defined by Renesas.
-mrenesas
Comply with the calling conventions defined by Renesas.
-mno-renesas
Comply with the calling conventions defined for GCC before the Renesas conventions were available. This option is the default for all targets of the SH toolchain except for sh-symbianelf.
-mnomacsave
Mark the "MAC" register as call-clobbered, even if -mhitachi is given.
-mieee
Increase IEEE-compliance of floating-point code. At the moment, this is equivalent to -fno-finite-math-only. When generating 16 bit SH opcodes, getting IEEE-conforming results for comparisons of NANs / infinities incurs extra overhead in every floating point comparison, therefore the default is set to -ffinite-math-only.
-minline-ic_invalidate
Inline code to invalidate instruction cache entries after setting up nested function trampolines. This option has no effect if -musermode is in effect and the selected code generation option (e.g. -m4) does not allow the use of the icbi instruction. If the selected code generation option does not allow the use of the icbi instruction, and -musermode is not in effect, the inlined code will manipulate the instruction cache address array directly with an associative write. This not only requires privileged mode, but it will also fail if the cache line had been mapped via the TLB and has become unmapped.
-misize
Dump instruction size and location in the assembly code.
-mpadstruct
This option is deprecated. It pads structures to multiple of 4 bytes, which is incompatible with the SH ABI .
-mspace
Optimize for space instead of speed. Implied by -Os.
-mprefergot
When generating position-independent code, emit function calls using the Global Offset Table instead of the Procedure Linkage Table.
-musermode
Don't generate privileged mode only code; implies -mno-inline-ic_invalidate if the inlined code would not work in user mode. This is the default when the target is "sh-*-linux*".
-multcost=number
Set the cost to assume for a multiply insn.
-mdiv=strategy
Set the division strategy to use for SHmedia code. strategy must be one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp . "fp" performs the operation in floating point. This has a very high latency, but needs only a few instructions, so it might be a good choice if your code has enough easily exploitable ILP to allow the compiler to schedule the floating point instructions together with other instructions. Division by zero causes a floating point exception. "inv" uses integer operations to calculate the inverse of the divisor, and then multiplies the dividend with the inverse. This strategy allows cse and hoisting of the inverse calculation. Division by zero calculates an unspecified result, but does not trap. "inv:minlat" is a variant of "inv" where if no cse / hoisting opportunities have been found, or if the entire operation has been hoisted to the same place, the last stages of the inverse calculation are intertwined with the final multiply to reduce the overall latency, at the expense of using a few more instructions, and thus offering fewer scheduling opportunities with other code. "call" calls a library function that usually implements the inv:minlat strategy. This gives high code density for m5-*media-nofpu compilations. "call2" uses a different entry point of the same library function, where it assumes that a pointer to a lookup table has already been set up, which exposes the pointer load to cse / code hoisting optimizations. "inv:call", "inv:call2" and "inv:fp" all use the "inv" algorithm for initial code generation, but if the code stays unoptimized, revert to the "call", "call2", or "fp" strategies, respectively. Note that the potentially-trapping side effect of division by zero is carried by a separate instruction, so it is possible that all the integer instructions are hoisted out, but the marker for the side effect stays where it is. A recombination to fp operations or a call is not possible in that case. "inv20u" and "inv20l" are variants of the "inv:minlat" strategy. In the case that the inverse calculation was nor separated from the multiply, they speed up division where the dividend fits into 20 bits (plus sign where applicable), by inserting a test to skip a number of operations in this case; this test slows down the case of larger dividends. inv20u assumes the case of a such a small dividend to be unlikely, and inv20l assumes it to be likely.
-mdivsi3_libfunc=name
Set the name of the library function used for 32 bit signed division to name. This only affect the name used in the call and inv:call division strategies, and the compiler will still expect the same sets of input/output/clobbered registers as if this option was not present.
-mfixed-range=register-range
Generate code treating the given register range as fixed registers. A fixed register is one that the register allocator can not use. This is useful when compiling kernel code. A register range is specified as two registers separated by a dash. Multiple register ranges can be specified separated by a comma.
-madjust-unroll
Throttle unrolling to avoid thrashing target registers. This option only has an effect if the gcc code base supports the TARGET_ADJUST_UNROLL_MAX target hook.
-mindexed-addressing
Enable the use of the indexed addressing mode for SHmedia32/SHcompact. This is only safe if the hardware and/or OS implement 32 bit wrap-around semantics for the indexed addressing mode. The architecture allows the implementation of processors with 64 bit MMU , which the OS could use to get 32 bit addressing, but since no current hardware implementation supports this or any other way to make the indexed addressing mode safe to use in the 32 bit ABI , the default is -mno-indexed-addressing.
-mgettrcost=number
Set the cost assumed for the gettr instruction to number. The default is 2 if -mpt-fixed is in effect, 100 otherwise.
-mpt-fixed
Assume pt* instructions won't trap. This will generally generate better scheduled code, but is unsafe on current hardware. The current architecture definition says that ptabs and ptrel trap when the target anded with 3 is 3. This has the unintentional effect of making it unsafe to schedule ptabs / ptrel before a branch, or hoist it out of a loop. For example, __do_global_ctors, a part of libgcc that runs constructors at program startup, calls functions in a list which is delimited by -1. With the -mpt-fixed option, the ptabs will be done before testing against -1. That means that all the constructors will be run a bit quicker, but when the loop comes to the end of the list, the program crashes because ptabs loads -1 into a target register. Since this option is unsafe for any hardware implementing the current architecture specification, the default is -mno-pt-fixed. Unless the user specifies a specific cost with -mgettrcost, -mno-pt-fixed also implies -mgettrcost=100; this deters register allocation using target registers for storing ordinary integers.
-minvalid-symbols
Assume symbols might be invalid. Ordinary function symbols generated by the compiler will always be valid to load with movi/shori/ptabs or movi/shori/ptrel, but with assembler and/or linker tricks it is possible to generate symbols that will cause ptabs / ptrel to trap. This option is only meaningful when -mno-pt-fixed is in effect. It will then prevent cross-basic-block cse, hoisting and most scheduling of symbol loads. The default is -mno-invalid-symbols.
SPARC Options

These -m options are supported on the SPARC:
-mno-app-regs
-mapp-regs
Specify -mapp-regs to generate output using the global registers 2 through 4, which the SPARC SVR4 ABI reserves for applications. This is the default.
To be fully SVR4 ABI compliant at the cost of some performance loss, specify -mno-app-regs. You should compile libraries and system software with this option.

-mfpu
-mhard-float
Generate output containing floating point instructions. This is the default.
-mno-fpu
-msoft-float
Generate output containing library calls for floating point. Warning: the requisite libraries are not available for all SPARC targets. Normally the facilities of the machine's usual C compiler are used, but this cannot be done directly in cross-compilation. You must make your own arrangements to provide suitable library functions for cross-compilation. The embedded targets sparc-*-aout and sparclite-*-* do provide software floating point support.
-msoft-float changes the calling convention in the output file; therefore, it is only useful if you compile all of a program with this option. In particular, you need to compile libgcc.a, the library that comes with GCC , with -msoft-float in order for this to work.

-mhard-quad-float
Generate output containing quad-word (long double) floating point instructions.
-msoft-quad-float
Generate output containing library calls for quad-word (long double) floating point instructions. The functions called are those specified in the SPARC ABI . This is the default.
As of this writing, there are no SPARC implementations that have hardware support for the quad-word floating point instructions. They all invoke a trap handler for one of these instructions, and then the trap handler emulates the effect of the instruction. Because of the trap handler overhead, this is much slower than calling the ABI library routines. Thus the -msoft-quad-float option is the default.

-mno-unaligned-doubles
-munaligned-doubles
Assume that doubles have 8 byte alignment. This is the default.
With -munaligned-doubles, GCC assumes that doubles have 8 byte alignment only if they are contained in another type, or if they have an absolute address. Otherwise, it assumes they have 4 byte alignment. Specifying this option avoids some rare compatibility problems with code generated by other compilers. It is not the default because it results in a performance loss, especially for floating point code.

-mno-faster-structs
-mfaster-structs
With -mfaster-structs, the compiler assumes that structures should have 8 byte alignment. This enables the use of pairs of "ldd" and "std" instructions for copies in structure assignment, in place of twice as many "ld" and "st" pairs. However, the use of this changed alignment directly violates the SPARC ABI . Thus, it's intended only for use on targets where the developer acknowledges that their resulting code will not be directly in line with the rules of the ABI .
-mimpure-text
-mimpure-text, used in addition to -shared, tells the compiler to not pass -z text to the linker when linking a shared object. Using this option, you can link position-dependent code into a shared object.
-mimpure-text suppresses the "relocations remain against allocatable but non-writable sections" linker error message. However, the necessary relocations will trigger copy-on-write, and the shared object is not actually shared across processes. Instead of using -mimpure-text, you should compile all source code with -fpic or -fPIC.

This option is only available on SunOS and Solaris.

-mcpu=cpu_type
Set the instruction set, register set, and instruction scheduling parameters for machine type cpu_type. Supported values for cpu_type are v7, cypress, v8, supersparc, sparclite, f930, f934, hypersparc, sparclite86x, sparclet, tsc701, v9, ultrasparc, ultrasparc3, niagara and niagara2.
Default instruction scheduling parameters are used for values that select an architecture and not an implementation. These are v7, v8, sparclite, sparclet, v9.

Here is a list of each supported architecture and their supported implementations.

v7:             cypress
v8:             supersparc, hypersparc
sparclite:      f930, f934, sparclite86x
sparclet:       tsc701
v9:             ultrasparc, ultrasparc3, niagara, niagara2
By default (unless configured otherwise), GCC generates code for the V7 variant of the SPARC architecture. With -mcpu=cypress, the compiler additionally optimizes it for the Cypress CY7C602 chip, as used in the SPARCStation/SPARCServer 3xx series. This is also appropriate for the older SPARCStation 1, 2, IPX etc.
With -mcpu=v8, GCC generates code for the V8 variant of the SPARC architecture. The only difference from V7 code is that the compiler emits the integer multiply and integer divide instructions which exist in SPARC-V8 but not in SPARC-V7 . With -mcpu=supersparc, the compiler additionally optimizes it for the SuperSPARC chip, as used in the SPARCStation 10, 1000 and 2000 series.

With -mcpu=sparclite, GCC generates code for the SPARClite variant of the SPARC architecture. This adds the integer multiply, integer divide step and scan ("ffs") instructions which exist in SPARClite but not in SPARC-V7 . With -mcpu=f930, the compiler additionally optimizes it for the Fujitsu MB86930 chip, which is the original SPARClite, with no FPU . With -mcpu=f934, the compiler additionally optimizes it for the Fujitsu MB86934 chip, which is the more recent SPARClite with FPU .

With -mcpu=sparclet, GCC generates code for the SPARClet variant of the SPARC architecture. This adds the integer multiply, multiply/accumulate, integer divide step and scan ("ffs") instructions which exist in SPARClet but not in SPARC-V7 . With -mcpu=tsc701, the compiler additionally optimizes it for the TEMIC SPARClet chip.

With -mcpu=v9, GCC generates code for the V9 variant of the SPARC architecture. This adds 64-bit integer and floating-point move instructions, 3 additional floating-point condition code registers and conditional move instructions. With -mcpu=ultrasparc, the compiler additionally optimizes it for the Sun UltraSPARC I/II/IIi chips. With -mcpu=ultrasparc3, the compiler additionally optimizes it for the Sun UltraSPARC III/III+/IIIi/IIIi+/IV/IV+ chips. With -mcpu=niagara, the compiler additionally optimizes it for Sun UltraSPARC T1 chips. With -mcpu=niagara2, the compiler additionally optimizes it for Sun UltraSPARC T2 chips.

-mtune=cpu_type
Set the instruction scheduling parameters for machine type cpu_type, but do not set the instruction set or register set that the option -mcpu=cpu_type would.
The same values for -mcpu=cpu_type can be used for -mtune=cpu_type, but the only useful values are those that select a particular cpu implementation. Those are cypress, supersparc, hypersparc, f930, f934, sparclite86x, tsc701, ultrasparc, ultrasparc3, niagara, and niagara2.

-mv8plus
-mno-v8plus
With -mv8plus, GCC generates code for the SPARC-V8+ ABI . The difference from the V8 ABI is that the global and out registers are considered 64-bit wide. This is enabled by default on Solaris in 32-bit mode for all SPARC-V9 processors.
-mvis
-mno-vis
With -mvis, GCC generates code that takes advantage of the UltraSPARC Visual Instruction Set extensions. The default is -mno-vis.
These -m options are supported in addition to the above on SPARC-V9 processors in 64-bit environments:
-mlittle-endian
Generate code for a processor running in little-endian mode. It is only available for a few configurations and most notably not on Solaris and Linux.
-m32
-m64
Generate code for a 32-bit or 64-bit environment. The 32-bit environment sets int, long and pointer to 32 bits. The 64-bit environment sets int to 32 bits and long and pointer to 64 bits.
-mcmodel=medlow
Generate code for the Medium/Low code model: 64-bit addresses, programs must be linked in the low 32 bits of memory. Programs can be statically or dynamically linked.
-mcmodel=medmid
Generate code for the Medium/Middle code model: 64-bit addresses, programs must be linked in the low 44 bits of memory, the text and data segments must be less than 2GB in size and the data segment must be located within 2GB of the text segment.
-mcmodel=medany
Generate code for the Medium/Anywhere code model: 64-bit addresses, programs may be linked anywhere in memory, the text and data segments must be less than 2GB in size and the data segment must be located within 2GB of the text segment.
-mcmodel=embmedany
Generate code for the Medium/Anywhere code model for embedded systems: 64-bit addresses, the text and data segments must be less than 2GB in size, both starting anywhere in memory (determined at link time). The global register %g4 points to the base of the data segment. Programs are statically linked and PIC is not supported.
-mstack-bias
-mno-stack-bias
With -mstack-bias, GCC assumes that the stack pointer, and frame pointer if present, are offset by -2047 which must be added back when making stack frame references. This is the default in 64-bit mode. Otherwise, assume no such offset is present.
These switches are supported in addition to the above on Solaris:
-threads
Add support for multithreading using the Solaris threads library. This option sets flags for both the preprocessor and linker. This option does not affect the thread safety of object code produced by the compiler or that of libraries supplied with it.
-pthreads
Add support for multithreading using the POSIX threads library. This option sets flags for both the preprocessor and linker. This option does not affect the thread safety of object code produced by the compiler or that of libraries supplied with it.
-pthread
This is a synonym for -pthreads.
SPU Options

These -m options are supported on the SPU:
-mwarn-reloc
-merror-reloc
The loader for SPU does not handle dynamic relocations. By default, GCC will give an error when it generates code that requires a dynamic relocation. -mno-error-reloc disables the error, -mwarn-reloc will generate a warning instead.
-msafe-dma
-munsafe-dma
Instructions which initiate or test completion of DMA must not be reordered with respect to loads and stores of the memory which is being accessed. Users typically address this problem using the volatile keyword, but that can lead to inefficient code in places where the memory is known to not change. Rather than mark the memory as volatile we treat the DMA instructions as potentially effecting all memory. With -munsafe-dma users must use the volatile keyword to protect memory accesses.
-mbranch-hints
By default, GCC will generate a branch hint instruction to avoid pipeline stalls for always taken or probably taken branches. A hint will not be generated closer than 8 instructions away from its branch. There is little reason to disable them, except for debugging purposes, or to make an object a little bit smaller.
-msmall-mem
-mlarge-mem
By default, GCC generates code assuming that addresses are never larger than 18 bits. With -mlarge-mem code is generated that assumes a full 32 bit address.
-mstdmain
By default, GCC links against startup code that assumes the SPU-style main function interface (which has an unconventional parameter list). With -mstdmain, GCC will link your program against startup code that assumes a C99-style interface to "main", including a local copy of "argv" strings.
-mfixed-range=register-range
Generate code treating the given register range as fixed registers. A fixed register is one that the register allocator can not use. This is useful when compiling kernel code. A register range is specified as two registers separated by a dash. Multiple register ranges can be specified separated by a comma.
-mdual-nops
-mdual-nops=n
By default, GCC will insert nops to increase dual issue when it expects it to increase performance. n can be a value from 0 to 10. A smaller n will insert fewer nops. 10 is the default, 0 is the same as -mno-dual-nops. Disabled with -Os.
-mhint-max-nops=n
Maximum number of nops to insert for a branch hint. A branch hint must be at least 8 instructions away from the branch it is effecting. GCC will insert up to n nops to enforce this, otherwise it will not generate the branch hint.
-mhint-max-distance=n
The encoding of the branch hint instruction limits the hint to be within 256 instructions of the branch it is effecting. By default, GCC makes sure it is within 125.
-msafe-hints
Work around a hardware bug which causes the SPU to stall indefinitely. By default, GCC will insert the "hbrp" instruction to make sure this stall won't happen.
Options for System V

These additional options are available on System V Release 4 for compatibility with other compilers on those systems:
-G
Create a shared object. It is recommended that -symbolic or -shared be used instead.

-Qy

Identify the versions of each tool used by the compiler, in a ".ident" assembler directive in the output.

-Qn

Refrain from adding ".ident" directives to the output file (this is the default).

-YP,dirs
Search the directories dirs, and no others, for libraries specified with -l.
-Ym,dir
Look in the directory dir to find the M4 preprocessor. The assembler uses this option.
V850 Options

These -m options are defined for V850 implementations:
-mlong-calls
-mno-long-calls
Treat all calls as being far away (near). If calls are assumed to be far away, the compiler will always load the functions address up into a register, and call indirect through the pointer.
-mno-ep
-mep
Do not optimize (do optimize) basic blocks that use the same index pointer 4 or more times to copy pointer into the "ep" register, and use the shorter "sld" and "sst" instructions. The -mep option is on by default if you optimize.
-mno-prolog-function
-mprolog-function
Do not use (do use) external functions to save and restore registers at the prologue and epilogue of a function. The external functions are slower, but use less code space if more than one function saves the same number of registers. The -mprolog-function option is on by default if you optimize.
-mspace
Try to make the code as small as possible. At present, this just turns on the -mep and -mprolog-function options.
-mtda=n
Put static or global variables whose size is n bytes or less into the tiny data area that register "ep" points to. The tiny data area can hold up to 256 bytes in total (128 bytes for byte references).
-msda=n
Put static or global variables whose size is n bytes or less into the small data area that register "gp" points to. The small data area can hold up to 64 kilobytes.
-mzda=n
Put static or global variables whose size is n bytes or less into the first 32 kilobytes of memory.
-mv850
Specify that the target processor is the V850.
-mbig-switch
Generate code suitable for big switch tables. Use this option only if the assembler/linker complain about out of range branches within a switch table.
-mapp-regs
This option will cause r2 and r5 to be used in the code generated by the compiler. This setting is the default.
-mno-app-regs
This option will cause r2 and r5 to be treated as fixed registers.
-mv850e1
Specify that the target processor is the V850E1. The preprocessor constants __v850e1__ and __v850e__ will be defined if this option is used.
-mv850e
Specify that the target processor is the V850E. The preprocessor constant __v850e__ will be defined if this option is used.
If neither -mv850 nor -mv850e nor -mv850e1 are defined then a default target processor will be chosen and the relevant __v850*__ preprocessor constant will be defined.

The preprocessor constants __v850 and __v851__ are always defined, regardless of which processor variant is the target.

-mdisable-callt
This option will suppress generation of the CALLT instruction for the v850e and v850e1 flavors of the v850 architecture. The default is -mno-disable-callt which allows the CALLT instruction to be used.
VAX Options

These -m options are defined for the VAX:
-munix
Do not output certain jump instructions ("aobleq" and so on) that the Unix assembler for the VAX cannot handle across long ranges.
-mgnu
Do output those jump instructions, on the assumption that you will assemble with the GNU assembler.
-mg
Output code for g-format floating point numbers instead of d-format.

VxWorks Options

The options in this section are defined for all VxWorks targets. Options specific to the target hardware are listed with the other options for that target.
-mrtp
GCC can generate code for both VxWorks kernels and real time processes (RTPs). This option switches from the former to the latter. It also defines the preprocessor macro "__RTP__".
-non-static
Link an RTP executable against shared libraries rather than static libraries. The options -static and -shared can also be used for RTPs; -static is the default.
-Bstatic
-Bdynamic
These options are passed down to the linker. They are defined for compatibility with Diab.
-Xbind-lazy
Enable lazy binding of function calls. This option is equivalent to -Wl,-z,now and is defined for compatibility with Diab.
-Xbind-now
Disable lazy binding of function calls. This option is the default and is defined for compatibility with Diab.
x86-64 Options

These are listed under
Xstormy16 Options

These options are defined for Xstormy16:
-msim
Choose startup files and linker script suitable for the simulator.
Xtensa Options

These options are supported for Xtensa targets:
-mconst16
-mno-const16
Enable or disable use of "CONST16" instructions for loading constant values. The "CONST16" instruction is currently not a standard option from Tensilica. When enabled, "CONST16" instructions are always used in place of the standard "L32R" instructions. The use of "CONST16" is enabled by default only if the "L32R" instruction is not available.
-mfused-madd
-mno-fused-madd
Enable or disable use of fused multiply/add and multiply/subtract instructions in the floating-point option. This has no effect if the floating-point option is not also enabled. Disabling fused multiply/add and multiply/subtract instructions forces the compiler to use separate instructions for the multiply and add/subtract operations. This may be desirable in some cases where strict IEEE 754-compliant results are required: the fused multiply add/subtract instructions do not round the intermediate result, thereby producing results with more bits of precision than specified by the IEEE standard. Disabling fused multiply add/subtract instructions also ensures that the program output is not sensitive to the compiler's ability to combine multiply and add/subtract operations.
-mserialize-volatile
-mno-serialize-volatile
When this option is enabled, GCC inserts "MEMW" instructions before "volatile" memory references to guarantee sequential consistency. The default is -mserialize-volatile. Use -mno-serialize-volatile to omit the "MEMW" instructions.
-mtext-section-literals
-mno-text-section-literals
Control the treatment of literal pools. The default is -mno-text-section-literals, which places literals in a separate section in the output file. This allows the literal pool to be placed in a data RAM/ROM , and it also allows the linker to combine literal pools from separate object files to remove redundant literals and improve code size. With -mtext-section-literals, the literals are interspersed in the text section in order to keep them as close as possible to their references. This may be necessary for large assembly files.
-mtarget-align
-mno-target-align
When this option is enabled, GCC instructs the assembler to automatically align instructions to reduce branch penalties at the expense of some code density. The assembler attempts to widen density instructions to align branch targets and the instructions following call instructions. If there are not enough preceding safe density instructions to align a target, no widening will be performed. The default is -mtarget-align. These options do not affect the treatment of auto-aligned instructions like "LOOP", which the assembler will always align, either by widening density instructions or by inserting no-op instructions.
-mlongcalls
-mno-longcalls
When this option is enabled, GCC instructs the assembler to translate direct calls to indirect calls unless it can determine that the target of a direct call is in the range allowed by the call instruction. This translation typically occurs for calls to functions in other source files. Specifically, the assembler translates a direct "CALL" instruction into an "L32R" followed by a "CALLX" instruction. The default is -mno-longcalls. This option should be used in programs where the call target can potentially be out of range. This option is implemented in the assembler, not the compiler, so the assembly code generated by GCC will still show direct call instructions---look at the disassembled object code to see the actual instructions. Note that the assembler will use an indirect call for every cross-file call, not just those that really will be out of range.
zSeries Options

These are listed under
Options for Code Generation Conventions

These machine-independent options control the interface conventions used in code generation.
Most of them have both positive and negative forms; the negative form of -ffoo would be -fno-foo. In the table below, only one of the forms is listed---the one which is not the default. You can figure out the other form by either removing no- or adding it.

-fbounds-check
For front-ends that support it, generate additional code to check that indices used to access arrays are within the declared range. This is currently only supported by the Java and Fortran front-ends, where this option defaults to true and false respectively.
-ftrapv
This option generates traps for signed overflow on addition, subtraction, multiplication operations.
-fwrapv
This option instructs the compiler to assume that signed arithmetic overflow of addition, subtraction and multiplication wraps around using twos-complement representation. This flag enables some optimizations and disables others. This option is enabled by default for the Java front-end, as required by the Java language specification.
-fexceptions
Enable exception handling. Generates extra code needed to propagate exceptions. For some targets, this implies GCC will generate frame unwind information for all functions, which can produce significant data size overhead, although it does not affect execution. If you do not specify this option, GCC will enable it by default for languages like C ++ which normally require exception handling, and disable it for languages like C that do not normally require it. However, you may need to enable this option when compiling C code that needs to interoperate properly with exception handlers written in C ++ . You may also wish to disable this option if you are compiling older C ++ programs that don't use exception handling.
-fnon-call-exceptions
Generate code that allows trapping instructions to throw exceptions. Note that this requires platform-specific runtime support that does not exist everywhere. Moreover, it only allows trapping instructions to throw exceptions, i.e. memory references or floating point instructions. It does not allow exceptions to be thrown from arbitrary signal handlers such as "SIGALRM".
-funwind-tables
Similar to -fexceptions, except that it will just generate any needed static data, but will not affect the generated code in any other way. You will normally not enable this option; instead, a language processor that needs this handling would enable it on your behalf.
-fasynchronous-unwind-tables
Generate unwind table in dwarf2 format, if supported by target machine. The table is exact at each instruction boundary, so it can be used for stack unwinding from asynchronous events (such as debugger or garbage collector).
-fpcc-struct-return
Return "short" "struct" and "union" values in memory like longer ones, rather than in registers. This convention is less efficient, but it has the advantage of allowing intercallability between GCC-compiled files and files compiled with other compilers, particularly the Portable C Compiler (pcc).
The precise convention for returning structures in memory depends on the target configuration macros.

Short structures and unions are those whose size and alignment match that of some integer type.

Warning: code compiled with the -fpcc-struct-return switch is not binary compatible with code compiled with the -freg-struct-return switch. Use it to conform to a non-default application binary interface.

-freg-struct-return
Return "struct" and "union" values in registers when possible. This is more efficient for small structures than -fpcc-struct-return.
If you specify neither -fpcc-struct-return nor -freg-struct-return, GCC defaults to whichever convention is standard for the target. If there is no standard convention, GCC defaults to -fpcc-struct-return, except on targets where GCC is the principal compiler. In those cases, we can choose the standard, and we chose the more efficient register return alternative.

Warning: code compiled with the -freg-struct-return switch is not binary compatible with code compiled with the -fpcc-struct-return switch. Use it to conform to a non-default application binary interface.

-fshort-enums
Allocate to an "enum" type only as many bytes as it needs for the declared range of possible values. Specifically, the "enum" type will be equivalent to the smallest integer type which has enough room.
Warning: the -fshort-enums switch causes GCC to generate code that is not binary compatible with code generated without that switch. Use it to conform to a non-default application binary interface.

-fshort-double
Use the same size for "double" as for "float".
Warning: the -fshort-double switch causes GCC to generate code that is not binary compatible with code generated without that switch. Use it to conform to a non-default application binary interface.

-fshort-wchar
Override the underlying type for wchar_t to be short unsigned int instead of the default for the target. This option is useful for building programs to run under WINE .
Warning: the -fshort-wchar switch causes GCC to generate code that is not binary compatible with code generated without that switch. Use it to conform to a non-default application binary interface.

-fno-common
In C code, controls the placement of uninitialized global variables. Unix C compilers have traditionally permitted multiple definitions of such variables in different compilation units by placing the variables in a common block. This is the behavior specified by -fcommon, and is the default for GCC on most targets. On the other hand, this behavior is not required by ISO C, and on some targets may carry a speed or code size penalty on variable references. The -fno-common option specifies that the compiler should place uninitialized global variables in the data section of the object file, rather than generating them as common blocks. This has the effect that if the same variable is declared (without "extern") in two different compilations, you will get a multiple-definition error when you link them. In this case, you must compile with -fcommon instead. Compiling with -fno-common is useful on targets for which it provides better performance, or if you wish to verify that the program will work on other systems which always treat uninitialized variable declarations this way.
-fno-ident
Ignore the #ident directive.
-finhibit-size-directive
Don't output a ".size" assembler directive, or anything else that would cause trouble if the function is split in the middle, and the two halves are placed at locations far apart in memory. This option is used when compiling crtstuff.c; you should not need to use it for anything else.
-fverbose-asm
Put extra commentary information in the generated assembly code to make it more readable. This option is generally only of use to those who actually need to read the generated assembly code (perhaps while debugging the compiler itself).
-fno-verbose-asm, the default, causes the extra information to be omitted and is useful when comparing two assembler files.

-frecord-gcc-switches
This switch causes the command line that was used to invoke the compiler to be recorded into the object file that is being created. This switch is only implemented on some targets and the exact format of the recording is target and binary file format dependent, but it usually takes the form of a section containing ASCII text. This switch is related to the -fverbose-asm switch, but that switch only records information in the assembler output file as comments, so it never reaches the object file.
-fpic
Generate position-independent code ( PIC ) suitable for use in a shared library, if supported for the target machine. Such code accesses all constant addresses through a global offset table ( GOT ). The dynamic loader resolves the GOT entries when the program starts (the dynamic loader is not part of GCC ; it is part of the operating system). If the GOT size for the linked executable exceeds a machine-specific maximum size, you get an error message from the linker indicating that -fpic does not work; in that case, recompile with -fPIC instead. (These maximums are 8k on the SPARC and 32k on the m68k and RS/6000 . The 386 has no such limit.)
Position-independent code requires special support, and therefore works only on certain machines. For the 386, GCC supports PIC for System V but not for the Sun 386i. Code generated for the IBM RS/6000 is always position-independent.

When this flag is set, the macros "__pic__" and "__PIC__" are defined to 1.

-fPIC
If supported for the target machine, emit position-independent code, suitable for dynamic linking and avoiding any limit on the size of the global offset table. This option makes a difference on the m68k, PowerPC and SPARC .
Position-independent code requires special support, and therefore works only on certain machines.

When this flag is set, the macros "__pic__" and "__PIC__" are defined to 2.

-fpie
-fPIE
These options are similar to -fpic and -fPIC, but generated position independent code can be only linked into executables. Usually these options are used when -pie GCC option will be used during linking.
-fpie and -fPIE both define the macros "__pie__" and "__PIE__". The macros have the value 1 for -fpie and 2 for -fPIE.

-fno-jump-tables
Do not use jump tables for switch statements even where it would be more efficient than other code generation strategies. This option is of use in conjunction with -fpic or -fPIC for building code which forms part of a dynamic linker and cannot reference the address of a jump table. On some targets, jump tables do not require a GOT and this option is not needed.
-ffixed-reg
Treat the register named reg as a fixed register; generated code should never refer to it (except perhaps as a stack pointer, frame pointer or in some other fixed role).
reg must be the name of a register. The register names accepted are machine-specific and are defined in the "REGISTER_NAMES" macro in the machine description macro file.

This flag does not have a negative form, because it specifies a three-way choice.

-fcall-used-reg
Treat the register named reg as an allocable register that is clobbered by function calls. It may be allocated for temporaries or variables that do not live across a call. Functions compiled this way will not save and restore the register reg.
It is an error to used this flag with the frame pointer or stack pointer. Use of this flag for other registers that have fixed pervasive roles in the machine's execution model will produce disastrous results.

This flag does not have a negative form, because it specifies a three-way choice.

-fcall-saved-reg
Treat the register named reg as an allocable register saved by functions. It may be allocated even for temporaries or variables that live across a call. Functions compiled this way will save and restore the register reg if they use it.
It is an error to used this flag with the frame pointer or stack pointer. Use of this flag for other registers that have fixed pervasive roles in the machine's execution model will produce disastrous results.

A different sort of disaster will result from the use of this flag for a register in which function values may be returned.

This flag does not have a negative form, because it specifies a three-way choice.

-fpack-struct[=n]
Without a value specified, pack all structure members together without holes. When a value is specified (which must be a small power of two), pack structure members according to this value, representing the maximum alignment (that is, objects with default alignment requirements larger than this will be output potentially unaligned at the next fitting location.
Warning: the -fpack-struct switch causes GCC to generate code that is not binary compatible with code generated without that switch. Additionally, it makes the code suboptimal. Use it to conform to a non-default application binary interface.

-finstrument-functions
Generate instrumentation calls for entry and exit to functions. Just after function entry and just before function exit, the following profiling functions will be called with the address of the current function and its call site. (On some platforms, "__builtin_return_address" does not work beyond the current function, so the call site information may not be available to the profiling functions otherwise.)
void __cyg_profile_func_enter (void *this_fn,
                               void *call_site);
void __cyg_profile_func_exit  (void *this_fn,
                               void *call_site);
The first argument is the address of the start of the current function, which may be looked up exactly in the symbol table.
This instrumentation is also done for functions expanded inline in other functions. The profiling calls will indicate where, conceptually, the inline function is entered and exited. This means that addressable versions of such functions must be available. If all your uses of a function are expanded inline, this may mean an additional expansion of code size. If you use extern inline in your C code, an addressable version of such functions must be provided. (This is normally the case anyways, but if you get lucky and the optimizer always expands the functions inline, you might have gotten away without providing static copies.)

A function may be given the attribute "no_instrument_function", in which case this instrumentation will not be done. This can be used, for example, for the profiling functions listed above, high-priority interrupt routines, and any functions from which the profiling functions cannot safely be called (perhaps signal handlers, if the profiling routines generate output or allocate memory).

-finstrument-functions-exclude-file-list=file,file,...
Set the list of functions that are excluded from instrumentation (see the description of "-finstrument-functions"). If the file that contains a function definition matches with one of file, then that function is not instrumented. The match is done on substrings: if the file parameter is a substring of the file name, it is considered to be a match.
For example, "-finstrument-functions-exclude-file-list=/bits/stl,include/sys" will exclude any inline function defined in files whose pathnames contain "/bits/stl" or "include/sys".

If, for some reason, you want to include letter ',' in one of sym, write ','. For example, "-finstrument-functions-exclude-file-list=',,tmp'" (note the single quote surrounding the option).

-finstrument-functions-exclude-function-list=sym,sym,...
This is similar to "-finstrument-functions-exclude-file-list", but this option sets the list of function names to be excluded from instrumentation. The function name to be matched is its user-visible name, such as "vector<int> blah(const vector<int> &)", not the internal mangled name (e.g., "_Z4blahRSt6vectorIiSaIiEE"). The match is done on substrings: if the sym parameter is a substring of the function name, it is considered to be a match.
-fstack-check
Generate code to verify that you do not go beyond the boundary of the stack. You should specify this flag if you are running in an environment with multiple threads, but only rarely need to specify it in a single-threaded environment since stack overflow is automatically detected on nearly all systems if there is only one stack.
Note that this switch does not actually cause checking to be done; the operating system or the language runtime must do that. The switch causes generation of code to ensure that they see the stack being extended.

You can additionally specify a string parameter: "no" means no checking, "generic" means force the use of old-style checking, "specific" means use the best checking method and is equivalent to bare -fstack-check.

Old-style checking is a generic mechanism that requires no specific target support in the compiler but comes with the following drawbacks:

1.
Modified allocation strategy for large objects: they will always be allocated dynamically if their size exceeds a fixed threshold.

2.

Fixed limit on the size of the static frame of functions: when it is topped by a particular function, stack checking is not reliable and a warning is issued by the compiler.

3.

Inefficiency: because of both the modified allocation strategy and the generic implementation, the performances of the code are hampered.

Note that old-style stack checking is also the fallback method for "specific" if no target support has been added in the compiler.
-fstack-limit-register=reg
-fstack-limit-symbol=sym
-fno-stack-limit
Generate code to ensure that the stack does not grow beyond a certain value, either the value of a register or the address of a symbol. If the stack would grow beyond the value, a signal is raised. For most targets, the signal is raised before the stack overruns the boundary, so it is possible to catch the signal without taking special precautions.
For instance, if the stack starts at absolute address 0x80000000 and grows downwards, you can use the flags -fstack-limit-symbol=__stack_limit and -Wl,--defsym,__stack_limit=0x7ffe0000 to enforce a stack limit of 128KB. Note that this may only work with the GNU linker.

-fargument-alias
-fargument-noalias
-fargument-noalias-global
-fargument-noalias-anything
Specify the possible relationships among parameters and between parameters and global data.
-fargument-alias specifies that arguments (parameters) may alias each other and may alias global storage.-fargument-noalias specifies that arguments do not alias each other, but may alias global storage.-fargument-noalias-global specifies that arguments do not alias each other and do not alias global storage. -fargument-noalias-anything specifies that arguments do not alias any other storage.

Each language will automatically use whatever option is required by the language standard. You should not need to use these options yourself.

-fleading-underscore
This option and its counterpart, -fno-leading-underscore, forcibly change the way C symbols are represented in the object file. One use is to help link with legacy assembly code.
Warning: the -fleading-underscore switch causes GCC to generate code that is not binary compatible with code generated without that switch. Use it to conform to a non-default application binary interface. Not all targets provide complete support for this switch.

-ftls-model=model
Alter the thread-local storage model to be used. The model argument should be one of "global-dynamic", "local-dynamic", "initial-exec" or "local-exec".
The default without -fpic is "initial-exec"; with -fpic the default is "global-dynamic".

-fvisibility=default|internal|hidden|protected
Set the default ELF image symbol visibility to the specified option---all symbols will be marked with this unless overridden within the code. Using this feature can very substantially improve linking and load times of shared object libraries, produce more optimized code, provide near-perfect API export and prevent symbol clashes. It is strongly recommended that you use this in any shared objects you distribute.
Despite the nomenclature, "default" always means public ie; available to be linked against from outside the shared object. "protected" and "internal" are pretty useless in real-world usage so the only other commonly used option will be "hidden". The default if -fvisibility isn't specified is "default", i.e., make every symbol public---this causes the same behavior as previous versions of GCC .

A good explanation of the benefits offered by ensuring ELF symbols have the correct visibility is given by "How To Write Shared Libraries" by Ulrich Drepper (which can be found at <http://people.redhat.com/~drepper/>)---however a superior solution made possible by this option to marking things hidden when the default is public is to make the default hidden and mark things public. This is the norm with DLL 's on Windows and with -fvisibility=hidden and "__attribute__ ((visibility("default")))" instead of "__declspec(dllexport)" you get almost identical semantics with identical syntax. This is a great boon to those working with cross-platform projects.

For those adding visibility support to existing code, you may find #pragma GCC visibility of use. This works by you enclosing the declarations you wish to set visibility for with (for example) #pragma GCC visibility push(hidden) and #pragma GCC visibility pop. Bear in mind that symbol visibility should be viewed as part of the API interface contract and thus all new code should always specify visibility when it is not the default ie; declarations only for use within the local DSO should always be marked explicitly as hidden as so to avoid PLT indirection overheads---making this abundantly clear also aids readability and self-documentation of the code. Note that due to ISO C ++ specification requirements, operator new and operator delete must always be of default visibility.

Be aware that headers from outside your project, in particular system headers and headers from any other library you use, may not be expecting to be compiled with visibility other than the default. You may need to explicitly say #pragma GCC visibility push(default) before including any such headers.

extern declarations are not affected by -fvisibility, so a lot of code can be recompiled with -fvisibility=hidden with no modifications. However, this means that calls to extern functions with no explicit visibility will use the PLT , so it is more effective to use __attribute ((visibility)) and/or #pragma GCC visibility to tell the compiler which extern declarations should be treated as hidden.

Note that -fvisibility does affect C ++ vague linkage entities. This means that, for instance, an exception class that will be thrown between DSOs must be explicitly marked with default visibility so that the type_info nodes will be unified between the DSOs.

An overview of these techniques, their benefits and how to use them is at <http://gcc.gnu.org/wiki/Visibility>.

Environment

This section describes several environment variables that affect how GCC operates. Some of them work by specifying directories or prefixes to use when searching for various kinds of files. Some are used to specify other aspects of the compilation environment.

Note that you can also specify places to search using options such as -B, -I and -L. These take precedence over places specified using environment variables, which in turn take precedence over those specified by the configuration of GCC .

LANG
LC_CTYPE
LC_MESSAGES
LC_ALL
These environment variables control the way that GCC uses localization information that allow GCC to work with different national conventions. GCC inspects the locale categories LC_CTYPE and LC_MESSAGES if it has been configured to do so. These locale categories can be set to any value supported by your installation. A typical value is en_GB.UTF-8 for English in the United Kingdom encoded in UTF-8 .
The LC_CTYPE environment variable specifies character classification. GCC uses it to determine the character boundaries in a string; this is needed for some multibyte encodings that contain quote and escape characters that would otherwise be interpreted as a string end or escape.

The LC_MESSAGES environment variable specifies the language to use in diagnostic messages.

If the LC_ALL environment variable is set, it overrides the value of LC_CTYPE and LC_MESSAGES ; otherwise, LC_CTYPE and LC_MESSAGES default to the value of the LANG environment variable. If none of these variables are set, GCC defaults to traditional C English behavior.

TMPDIR
If TMPDIR is set, it specifies the directory to use for temporary files. GCC uses temporary files to hold the output of one stage of compilation which is to be used as input to the next stage: for example, the output of the preprocessor, which is the input to the compiler proper.
GCC_EXEC_PREFIX
If GCC_EXEC_PREFIX is set, it specifies a prefix to use in the names of the subprograms executed by the compiler. No slash is added when this prefix is combined with the name of a subprogram, but you can specify a prefix that ends with a slash if you wish.
If GCC_EXEC_PREFIX is not set, GCC will attempt to figure out an appropriate prefix to use based on the pathname it was invoked with.

If GCC cannot find the subprogram using the specified prefix, it tries looking in the usual places for the subprogram.

The default value of GCC_EXEC_PREFIX is prefix/lib/gcc/ where prefix is the prefix to the installed compiler. In many cases prefix is the value of "prefix" when you ran the configure script.

Other prefixes specified with -B take precedence over this prefix.

This prefix is also used for finding files such as crt0.o that are used for linking.

In addition, the prefix is used in an unusual way in finding the directories to search for header files. For each of the standard directories whose name normally begins with /usr/local/lib/gcc (more precisely, with the value of GCC_INCLUDE_DIR ), GCC tries replacing that beginning with the specified prefix to produce an alternate directory name. Thus, with -Bfoo/, GCC will search foo/bar where it would normally search /usr/local/lib/bar. These alternate directories are searched first; the standard directories come next. If a standard directory begins with the configured prefix then the value of prefix is replaced by GCC_EXEC_PREFIX when looking for header files.

COMPILER_PATH
The value of COMPILER_PATH is a colon-separated list of directories, much like PATH . GCC tries the directories thus specified when searching for subprograms, if it can't find the subprograms using GCC_EXEC_PREFIX .
LIBRARY_PATH
The value of LIBRARY_PATH is a colon-separated list of directories, much like PATH . When configured as a native compiler, GCC tries the directories thus specified when searching for special linker files, if it can't find them using GCC_EXEC_PREFIX . Linking using GCC also uses these directories when searching for ordinary libraries for the -l option (but directories specified with -L come first).
LANG
This variable is used to pass locale information to the compiler. One way in which this information is used is to determine the character set to be used when character literals, string literals and comments are parsed in C and C ++ . When the compiler is configured to allow multibyte characters, the following values for LANG are recognized:
C-JIS
Recognize JIS characters.
C-SJIS
Recognize SJIS characters.
C-EUCJP
Recognize EUCJP characters.
If LANG is not defined, or if it has some other value, then the compiler will use mblen and mbtowc as defined by the default locale to recognize and translate multibyte characters.
Some additional environments variables affect the behavior of the preprocessor.
CPATH
C_INCLUDE_PATH
CPLUS_INCLUDE_PATH
OBJC_INCLUDE_PATH
Each variable's value is a list of directories separated by a special character, much like PATH , in which to look for header files. The special character, "PATH_SEPARATOR", is target-dependent and determined at GCC build time. For Microsoft Windows-based targets it is a semicolon, and for almost all other targets it is a colon.
CPATH specifies a list of directories to be searched as if specified with -I, but after any paths given with -I options on the command line. This environment variable is used regardless of which language is being preprocessed.

The remaining environment variables apply only when preprocessing the particular language indicated. Each specifies a list of directories to be searched as if specified with -isystem, but after any paths given with -isystem options on the command line.

In all these variables, an empty element instructs the compiler to search its current working directory. Empty elements can appear at the beginning or end of a path. For instance, if the value of CPATH is ":/special/include", that has the same effect as -I. -I/special/include.

DEPENDENCIES_OUTPUT
If this variable is set, its value specifies how to output dependencies for Make based on the non-system header files processed by the compiler. System header files are ignored in the dependency output.
The value of DEPENDENCIES_OUTPUT can be just a file name, in which case the Make rules are written to that file, guessing the target name from the source file name. Or the value can have the form file target, in which case the rules are written to file file using target as the target name.

In other words, this environment variable is equivalent to combining the options -MM and -MF, with an optional -MT switch too.

SUNPRO_DEPENDENCIES
This variable is the same as DEPENDENCIES_OUTPUT (see above), except that system header files are not ignored, so it implies -M rather than -MM. However, the dependence on the main input file is omitted.
Bugs

For instructions on reporting bugs, see <http://bugzilla.redhat.com/bugzilla>.

Footnotes

1.
On some systems, gcc -shared needs to build supplementary stub code for constructors to work. On multi-libbed systems, gcc -shared must select the correct support libraries to link against. Failing to supply the correct flags may lead to subtle defects. Supplying them in cases where they are not necessary is innocuous.

See Also

gpl(7), gfdl(7), fsf-funding(7), cpp(1), gcov(1), as(1), ld(1), gdb(1), adb(1), dbx(1), sdb(1) and the Info entries for gcc, cpp, as, ld, binutils and gdb.

Author

See the Info entry for gcc, or <http://gcc.gnu.org/onlinedocs/gcc/Contributors.html>, for contributors to GCC .

Copyright

Copyright © 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software Foundation, Inc.

Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with the Invariant Sections being " GNU General Public License" and "Funding Free Software", the Front-Cover texts being (a) (see below), and with the Back-Cover Texts being (b) (see below). A copy of the license is included in the gfdl(7) man page.

(a) The FSF 's Front-Cover Text is:

A GNU Manual
(b) The FSF 's Back-Cover Text is:
You have freedom to copy and modify this GNU Manual, like GNU
software.  Copies published by the Free Software Foundation raise
funds for GNU development.

 
	29.2

30. IDE


	30.1 Eclipse CDT

		30.1.1  Troubleshoot

			30.1.1.1  Eclipse says: “Workspace in use or cannot be created, chose a different one.” How do I unlock a workspace?
've seen 3 other fixes so far:

in .metadata/, rm .lock file
ex: [yizaq@pmbu-dev-vm58:Tue Dec 10:503:4:~]$ rm /users/yizaq/workspace1box/.metadata/.lock 
rm: remove regular empty file `/users/yizaq/workspace1box/.metadata/.lock'? y

if 1) doesn't work, try end process javaw.exe etc. then rm .lock file
if 1)&2) doesn't work, try rm .log file in .metadata/, and double check .plugin/.
This always worked for me: relocate .metadata/, open and close eclipse, then overwrite .metadata back
			30.1.1.2
		30.1.2

	30.2

31. Idioms

	31.1 Iteration

		31.1.1 std vector
- Normal
for(std::vector<T>::iterator it = v.begin(); it != v.end(); ++it) {
    /* std::cout << *it; ... */
}
Important is, always use the prefix increment form for iterators whose definitions you don't know. That will ensure your code runs as generic as possible.

- Using indices
for(std::vector<int>::size_type i = 0; i != v.size(); i++) {
    /* std::cout << someVector[i]; ... */
}

- Read only

-
for(std::vector<T>::const_iterator it = v.begin(); it != v.end(); ++it) {
    /* std::cout << *it; ... */
}
		31.1.2

	31.2

32. functors

	32.1 http://stackoverflow.com/questions/356950/c-functors-and-their-uses
Q:I keep hearing a lot about functors in C++, can someone give me an overview as to what they are and in what cases they would be useful?	

A1: A functor is pretty much just a class which defines the operator(). That lets you create objects which "look like" a function:

// this is a functor
struct add_x {
  add_x(int x) : x(x) {}
  int operator()(int y) { return x + y; }

private:
  int x;
};

// Now you can use it like this:
add_x add42(42); // create an instance of the functor class
int i = add42(8); // and "call" it
assert(i == 50); // and it added 42 to its argument

std::vector<int> in; // assume this contains a bunch of values)
std::vector<int> out;
// Pass a functor to std::transform, which calls the functor on every element 
// in the input sequence, and stores the result to the output sequence
std::transform(in.begin(), in.end(), out.begin(), add_x(1)); 
assert(out[i] == in[i] + 1); // for all i
There are a couple of nice things about functors. One is that unlike regular functions, they can contain state. The above example creates a function which adds 42 to whatever you give it. But that value 42 is not hardcoded, it was specified as a constructor argument when we created our functor instance. I could create another adder, which added 27, just by calling the constructor with a different value. This makes them nicely customizable.

As the last lines show, you often pass functors as arguments to other functions such as std::transform or the other standard library algorithms. You could do the same with a regular function pointer except, as I said above, functors can be "customized" because they contain state, making them more flexible (If I wanted to use a function pointer, I'd have to write a function which added exactly 1 to its argument. The functor is general, and adds whatever you initialized it with), and they are also potentially more efficient. In the above example, the compiler knows exactly which function std::transform should call. It should call add_x::operator(). That means it can inline that function call. And that makes it just as efficient as if I had manually called the function on each value of the vector.

If I had passed a function pointer instead, the compiler couldn't immediately see which function it points to, so unless it performs some fairly complex global optimizations, it'd have to dereference the pointer at runtime, and then make the call.

A2: Little addition. You can use boost::function, to create functors from functions and methods, like this:

class Foo
{
    void operator () (int i) { printf("Foo %d", i); }
};
void Bar(int i) { printf("Bar %d", i); }
Foo foo;
boost::function<void (int)> f(foo);//wrap functor
f(1);//prints "Foo 1"
boost::function<void (int)> b(&Bar);//wrap normal function
b(1);//prints "Bar 1"
and you can use boost::bind to add state to this functor

boost::function<void ()> f1 = boost::bind(foo, 2);
f1();//no more argument, function argument stored in f1
//and this print "Foo 2" (:
//and normal function
boost::function<void ()> b1 = boost::bind(&Bar, 2);
b1();// print "Bar 2"
and most useful, with boost::bind and boost::function you can create functor from class method, actually this is a delegate:

class SomeClass
{
    std::string state_;
public:
    SomeClass(const char* s) : state_(s) {}

    void method( std::string param )
    {
        std::cout << state_ << param << std::endl;
    }
};
SomeClass *inst = new SomeClass("Hi, i am ");
boost::function< void (std::string) > callback;
callback = boost::bind(&SomeClass::method, inst, _1);//create delegate
//_1 is a placeholder it holds plase for parameter
callback("useless");//prints "Hi, i am useless"
You can create list or vector of functors

std::list< boost::function<void (EventArg e)> > events;
//add some events
....
//call them
std::for_each(
        events.begin(), events.end(), 
        boost::bind( boost::apply<void>(), _1, e));
There is one problem with all this stuff, compiler error messages is not human readable :)

A3: Used instead of plain function:

Pros:

Functor may have state
Functor fits into OOP
Cons:

There is more typing, a bit longer compilation time etc.
Used instead of function pointer:

Pros:

Functor often may be inlined
Cons:

Functor can not be swapped with other functor type during runtime (at least unless it extends some base class, which therefore gives some overhead)
Used instead of polymorphism:

Pros:

Functor (non-virtual) doesn't require vtable and runtime dispatching, thus it is more efficient in most cases
Cons:

Functor can not be swapped with other functor type during runtime (at least unless it extends some base class, which therefore gives some overhead)

	32.2

33. C11

	33.1 Top differences vs C99


		33.1.1 auto
Before C++11 the auto keyword was used for storage duration specification. In the new standard its purpose was changed towards type inference. auto is now a sort of placeholder for a type, telling the compiler it has to deduce the actual type of a variable that is being declared from its initializer. It can be used when declaring variables in different scopes such as namespaces, blocks or initialization statement of for loops.

auto i = 42;        // i is an int
auto l = 42LL;      // l is an long long
auto p = new foo(); // p is a foo*
Using auto usually means less code (unless your type is int which is one letter shorter). Think of iterators in STL that you always had to write while iterating over containers. It makes obsolete creating typedefs just for the sake of simplicity.

std::map<std::string, std::vector<int>> map;
for(auto it = begin(map); it != end(map); ++it) 
{
}
You should note that auto cannot be used as the return type of a function. However, you can use auto in place of the return type of function, but in this case the function must have a trailing return type. In this case auto does not tell the compiler it has to infer the type, it only instructs it to look for the return type at the end of the function. In the example below the return type of function compose is the return type of operator+ that sums values of types T1 and T2.

template <typename T1, typename T2>
auto compose(T1 t1, T2 t2) -> decltype(t1 + t2)
{
   return t1+t2;
}
auto v = compose(2, 3.14); // v's type is double

/*
 * =====================================================================================
 *
 *       Filename:  add.cpp
 *
 *    Description:  
 *
 *        Version:  1.0
 *        Created:  12/31/14 18:15:07
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  Yosi Izaq
 *   Organization:  
 *
 * =====================================================================================
 */
#include <iostream>

int main(){
	auto n1=0;
	auto n2=0;
	std::cout<<"enter 1st num"<<std::endl;
	std::cin>>n1;
	std::cout<<"enter 2nd num"<<std::endl;
	std::cin>>n2;

	std::cout<<"sum: "<<n1+n2<<std::endl;
	return 0;
}


[yizaq@YIZAQ-M-D1BW:Wed Dec 31:~/Desktop/Work/code/C11:]$ g++ add.cpp 
add.cpp:21:2: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]
        auto n1=0;
        ^
add.cpp:22:2: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]
        auto n2=0;
        ^
2 warnings generated.
[yizaq@YIZAQ-M-D1BW:Wed Dec 31:~/Desktop/Work/code/C11:]$ a.out 
enter 1st num
2
enter 2nd num
1
sum: 3
[yizaq@YIZAQ-M-D1BW:Wed Dec 31:~/Desktop/Work/code/C11:]$ clang++ -std=c++11 -stdlib=libc++ -Weverything add.cpp 
add.cpp:21:2: warning: 'auto' type specifier is incompatible with C++98 [-Wc++98-compat]
        auto n1=0;
        ^~~~
add.cpp:22:2: warning: 'auto' type specifier is incompatible with C++98 [-Wc++98-compat]
        auto n2=0;
        ^~~~
2 warnings generated.


/*
 * =====================================================================================
 *
 *       Filename:  auto.cpp
 *
 *    Description:  Demo auto C11 keyword 
 *
 *        Version:  1.0
 *        Created:  12/31/14 18:38:09
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  Yosi Izaq
 *   Organization:  
 *
[yizaq@YIZAQ-M-D1BW:Sun Jan 04:~/Desktop/Work/code/C11:]$ clang++ -std=c++11 -stdlib=libc++ -Weverything auto.cpp 
auto.cpp:27:23: warning: consecutive right angle brackets are incompatible with C++98 (use '> >') [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                      ^~
                      > >
auto.cpp:27:37: warning: constructor call from initializer list is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                    ^~~~~~~~~~~~~~~~
auto.cpp:27:45: warning: initialization of initializer_list object is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                            ^~~~~~~
auto.cpp:27:56: warning: constructor call from initializer list is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                                       ^~~~~~~~~~~~~~~~~~~
auto.cpp:27:64: warning: initialization of initializer_list object is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                                               ^~~~~~~~~~
auto.cpp:27:77: warning: constructor call from initializer list is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                                                            ^~~~~~~~~~~~~~~~~~~~~~
auto.cpp:27:85: warning: initialization of initializer_list object is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                                                                    ^~~~~~~~~~~~~
auto.cpp:27:35: warning: initialization of initializer_list object is incompatible with C++98 [-Wc++98-compat]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
auto.cpp:27:26: warning: no previous extern declaration for non-static variable 'my_map' [-Wmissing-variable-declarations]
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
                         ^
auto.cpp:27:26: warning: declaration requires an exit-time destructor [-Wexit-time-destructors]
auto.cpp:27:26: warning: declaration requires a global destructor [-Wglobal-constructors]
auto.cpp:31:10: warning: 'auto' type specifier is incompatible with C++98 [-Wc++98-compat]
    for (auto itr = begin(my_map) ; itr != end(my_map) ; ++itr)
         ^~~~
auto.cpp:35:18: warning: 'auto' type specifier is incompatible with C++98 [-Wc++98-compat]
            for (auto vitr = begin(itr->second) ; vitr != end(itr->second) ; ++vitr)
                 ^~~~
13 warnings generated.
[yizaq@YIZAQ-M-D1BW:Sun Jan 04:~/Desktop/Work/code/C11:]$ a.out 
{{"1st",{1,2,3,},{"2nd",{9,2,3,10,},{"3rd",{2,2,2,1,2,3,},}
 * =====================================================================================
 */
#include <stdlib.h>
#include <stdlib.h>
#include <map>
#include <vector>
#include <string>

using namespace std;

// init in this form is available in C11
map<string, vector<int>> my_map = { {"1st", {1,2,3}} , {"2nd", {9,2,3,10}}, {"3rd", {2,2,2,1,2,3}}};
 
template <typename T1, typename T2>
auto compose(T1 t1, T2 t2) -> decltype(t1 + t2)
{
	   return t1+t2;
}

int main(){
    printf("{");
    for (auto itr = begin(my_map) ; itr != end(my_map) ; ++itr)
    {
    	printf("{\"%s\",", (itr->first).c_str());
    	printf("{");
            for (auto vitr = begin(itr->second) ; vitr != end(itr->second) ; ++vitr)
    	{
    		printf("%d,", *vitr);
    	}
            printf("},");
    }
    
    printf("}\n");

    auto v = compose(2, 3.14); // v's type is double
    printf("Result: %f\n",v);
    return 0;
}

		33.1.2 nullptr 
		Zero used to be the value of null pointers, and that has drawbacks due to the implicit conversion to integral types. The keyword nullptr denotes a value of type std::nullptr_t that represents the null pointer literal. Implicit conversions exists from nullptr to null pointer value of any pointer type and any pointer-to-member types, but also to bool (as false). But no implicit conversion to integral types exist.

		 void foo(int* p) {}

		 void bar(std::shared_ptr<int> p) {}

		 int* p1 = NULL;
		 int* p2 = nullptr;   
		 if(p1 == p2)
{
}

foo(nullptr);
bar(nullptr);

bool f = nullptr;
int i = nullptr; // error: A native nullptr can only be converted to bool or, using reinterpret_cast, to an integral type
For backward compatibility 0 is still a valid null pointer value.


		33.1.3 Range-based for loops
		C++11 augmented the for statement to support the "foreach" paradigm of iterating over collections. In the new form, it is possible to iterate over C-like arrays, initializer lists and anything for which the non-member begin() and end() functions are overloaded.

		This for each for is useful when you just want to get and do something with the elements of a collection/array and don't care about indexes, iterators or number of elements.

		 std::map<std::string, std::vector<int>> map;
		 std::vector<int> v;
		 v.push_back(1);
		 v.push_back(2);
		 v.push_back(3);
		 map["one"] = v;

		 for(const auto& kvp : map) 
{
	  std::cout << kvp.first << std::endl;

	    for(auto v : kvp.second)
		      {
			           std::cout << v << std::endl;
				     }
}

int arr[] = {1,2,3,4,5};
for(int& e : arr) 
{
	  e = e*e;
}

		33.1.4 Override and final
		I always founded the virtual methods badly designed in C++ because there wasn't (and still isn't) a mandatory mechanism to mark virtual methods as overridden in derived classes. The virtual keyword is optional and that makes reading code a bit harder, because you may have to look through the top of the hierarchy to check if the method is virtual. I have always used, and encouraged people to use the virtual keyword on derived classes also, to make the code easier to read. However, there are subtle errors that can still arise. Take for instance the following example:

		 class B 
{
	public:
		   virtual void f(short) {std::cout << "B::f" << std::endl;}
};

class D : public B
{
	public:
		   virtual void f(int) {std::cout << "D::f" << std::endl;}
};
D::f is supposed to override B::f. However, the signature differ, one takes a short, one takes an int, therefor B::f is just another method with the same name (and overload) and not an override. You may call f() through a pointer to B and expect to print D::f, but it's printing B::f. 

Here is another subtle error: the parameters are the same, but the method in the base class is marked const, while me method in the derived is not.

 class B 
{
	public:
		   virtual void f(int) const {std::cout << "B::f " << std::endl;}
};

class D : public B
{
	public:
		   virtual void f(int) {std::cout << "D::f" << std::endl;}
};
Again, these two are overloads and not overrides, so if you call f() through a pointer to B it will print B::f and not D::f. 

Fortunately there is now a way to describe your intentions. Two new special identifiers (not keywords) have been added: override, to indicate that a method is supposed to be an override of a virtual method in a base class, and final, to indicate that a derived class shall not override a virtual method. The first example would become:

 class B 
{
	public:
		   virtual void f(short) {std::cout << "B::f" << std::endl;}
};

class D : public B
{
	public:
		   virtual void f(int) override {std::cout << "D::f" << std::endl;}
};
This now triggers a compiler error (the same error you'd get for the second example too, if using the override specifier):

	'D::f' : method with override specifier 'override' did not override any base class methods
	On the other hand if you intend to make a method impossible to override any more (down the hierarchy) mark it as final. That can be in the base class, or any derived class. If it's in a derived classes you can use both the override and final specifiers. 

	 class B 
{
	public:
		   virtual void f(int) {std::cout << "B::f" << std::endl;}
};

class D : public B
{
	public:
		   virtual void f(int) override final {std::cout << "D::f" << std::endl;}
};

class F : public D
{
	public:
		   virtual void f(int) override {std::cout << "F::f" << std::endl;}
};
function declared as 'final' cannot be overridden by 'F::f'

		33.1.5 Strongly-typed enums
		"Traditional" enums in C++ have some drawbacks: they export their enumerators in the surrounding scope (which can lead to name collisions, if two different enums in the same have scope define enumerators with the same name), they are implicitly converted to integral types and cannot have a user-specified underlying type.

		These issues have been fixed in C++ 11 with the introduction of a new category of enums, called strongly-typed enums. They are specified with the enum class keywords. They no longer export their enumerators in the surrounding scope, are no longer implicitly converted to integral types and can have a user-specified underlying type (a feature also added for traditional enums).

		 enum class Options {None, One, All};
Options o = Options::All;

		33.1.6 Smart pointers
		There have been tons of articles written on this subject, therefore I just want to mention the smart pointers with reference counting and auto releasing of owned memory that are available:

		unique_ptr: should be used when ownership of a memory resource does not have to be shared (it doesn't have a copy constructor), but it can be transferred to another unique_ptr (move constructor exists).
		shared_ptr: should be used when ownership of a memory resource should be shared (hence the name).
		weak_ptr: holds a reference to an object managed by a shared_ptr, but does not contribute to the reference count; it is used to break dependency cycles (think of a tree where the parent holds an owning reference (shared_ptr) to its children, but the children also must hold a reference to the parent; if this second reference was also an owning one, a cycle would be created and no object would ever be released).
		On the other hand the auto_ptr is obsolete and should no longer be used.

		When you should unique_ptr and when you should use shared_ptr depends on the ownership requirements and I recommend reading this discussion.

		The first example below shows unique_ptr. If you want to transfer ownership of an object to another unique_ptr use std::move (I'll discuss this function in the last paragraph). After the ownership transfer, the smart pointer that ceded the ownership becomes null and get() returns nullptr.

		 void foo(int* p)
{
	   std::cout << *p << std::endl;
}
std::unique_ptr<int> p1(new int(42));
std::unique_ptr<int> p2 = std::move(p1); // transfer ownership

if(p1)
	  foo(p1.get());

	  (*p2)++;

	  if(p2)
	  foo(p2.get());
	  The second example shows shared_ptr. Usage is similar, though the semantics are different since ownership is shared.

	   void foo(int* p)
{
}
void bar(std::shared_ptr<int> p)
{
	   ++(*p);
}
std::shared_ptr<int> p1(new int(42));
std::shared_ptr<int> p2 = p1;
   
bar(p1);   
foo(p2.get());
The first declaration is equivalent to this one

 auto p3 = std::make_shared<int>(42);
 make_shared<T> is a non-member function and has the advantage of allocating memory for the shared object and the smart pointer with a single allocation, as opposed to the explicit construction of a shared_ptr via the contructor, that requires at least two allocations. In addition to possible overhead, there can be situations where memory leaks can occur because of that. In the next example memory leaks could occur if seed() throws an error.
  void foo(std::shared_ptr<int> p, int init)
{
	   *p = init;
}
foo(std::shared_ptr<int>(new int(42)), seed());
No such problem exists if using make_shared. The third sample shows usage of weak_ptr. Notice that you always must get a shared_ptr to the referred object by calling lock(), in order to access the object.
 auto p = std::make_shared<int>(42);
 std::weak_ptr<int> wp = p;

{
	  auto sp = wp.lock();
	    std::cout << *sp << std::endl;
}

p.reset();

if(wp.expired())
	  std::cout << "expired" << std::endl;
	  If you try to lock on an expired weak_ptr (the object is weakly reference has been released) you get an empty shared_ptr.


		33.1.7 Lambdas
		Anonymous functions, called lambda, have been added to C++ and quickly rose to prominence. It is a powerful feature borrowed from functional programming, that in turned enabled other features or powered libraries. You can use lambdas wherever a function object or a functor or a std::function is expected. You can read about the syntax here.

		 std::vector<int> v;
		 v.push_back(1);
		 v.push_back(2);
		 v.push_back(3);

		 std::for_each(std::begin(v), std::end(v), [](int n) {std::cout << n << std::endl;});

		 auto is_odd = [](int n) {return n%2==1;};
auto pos = std::find_if(std::begin(v), std::end(v), is_odd);
if(pos != std::end(v))
	  std::cout << *pos << std::endl;
	  A bit trickier are recursive lambdas. Imagine a lambda that represents a Fibonacci function. If you attempt to write it using auto you get compilation error:

	   auto fib = [&fib](int n) {return n < 2 ? 1 : fib(n-1) + fib(n-2);};
 error C3533: 'auto &': a parameter cannot have a type that contains 'auto'
 error C3531: 'fib': a symbol whose type contains 'auto' must have an initializer
 error C3536: 'fib': cannot be used before it is initialized
 error C2064: term does not evaluate to a function taking 1 arguments
 The problem is auto means the type of the object is inferred from its initializer, yet the initializer contains a reference to it, therefore needs to know its type. This is a cyclic problem. The key is to break this dependency cycle and explicitly specify the function's type using std::function.

  std::function<int(int)> lfib = [&lfib](int n) {return n < 2 ? 1 : lfib(n-1) + lfib(n-2);};

		33.1.8 non-member begin() and end()
	You probably noticed I have used in the samples above non-member begin() and end() functions. These are a new addition to the standard library, promoting uniformity, consistency and enabling more generic programming. They work with all STL containers, but more than that they are overloadable, so they can be extended to work with any type. Overloads for C-like arrays are also provided.

	Let's take for instance the previous example where I was printing a vector and then looking for its first odd element. If the std::vector was instead a C-like array, the code might have looked like this:

	 int arr[] = {1,2,3};
std::for_each(&arr[0], &arr[0]+sizeof(arr)/sizeof(arr[0]), [](int n) {std::cout << n << std::endl;});

auto is_odd = [](int n) {return n%2==1;};
auto begin = &arr[0];
auto end = &arr[0]+sizeof(arr)/sizeof(arr[0]);
auto pos = std::find_if(begin, end, is_odd);
if(pos != end)
	  std::cout << *pos << std::endl;
	  With non-member begin() and end() it could be put as this:

	   int arr[] = {1,2,3};
std::for_each(std::begin(arr), std::end(arr), [](int n) {std::cout << n << std::endl;});

auto is_odd = [](int n) {return n%2==1;};
auto pos = std::find_if(std::begin(arr), std::end(arr), is_odd);
if(pos != std::end(arr))
	  std::cout << *pos << std::endl;
	  This is basically identical code to the std::vector version. That means we can write a single generic method for all types supported by begin() and end().
	   template <typename Iterator>
	   void bar(Iterator begin, Iterator end) 
{
	   std::for_each(begin, end, [](int n) {std::cout << n << std::endl;});

	      auto is_odd = [](int n) {return n%2==1;};
	         auto pos = std::find_if(begin, end, is_odd);
		    if(pos != end)
			          std::cout << *pos << std::endl;
}

template <typename C>
void foo(C c)
{
	   bar(std::begin(c), std::end(c));
}

template <typename T, size_t N>
void foo(T(&arr)[N])
{
	   bar(std::begin(arr), std::end(arr));
}

int arr[] = {1,2,3};
foo(arr);

std::vector<int> v;
v.push_back(1);
v.push_back(2);
v.push_back(3);
foo(v);

		33.1.9 static_assert and type traits
static_assert performs an assertion check at compile-time. If the assertion is true, nothing happens. If the assertion is false, the compiler displays the specified error message.

template <typename T, size_t Size>
class Vector
{
   static_assert(Size < 3, "Size is too small");
   T _points[Size];
};

int main()
{
   Vector<int, 16> a1;
   Vector<double, 2> a2;
   return 0;
}
error C2338: Size is too small
see reference to class template instantiation 'Vector<T,Size>' being compiled
   with
   [
      T=double,
      Size=2
   ]
static_assert becomes more useful when used together with type traits. These are a series of classes that provide information about types at compile time. They are available in the <type_traits> header. There are several categories of classes in this header: helper classes, for creating compile-time constants, type traits classes, to get type information at compile time, and type transformation classes, for getting new types by applying transformation on existing types.

In the following example function add is supposed to work only with integral types.

template <typename T1, typename T2>
auto add(T1 t1, T2 t2) -> decltype(t1 + t2)
{
   return t1 + t2;
}
However, there are no compiler errors if one writes

std::cout << add(1, 3.14) << std::endl;
std::cout << add("one", 2) << std::endl;
The program actually prints 4.14 and "e". But if we add some compile-time asserts, both these lines would generate compiler errors.

template <typename T1, typename T2>
auto add(T1 t1, T2 t2) -> decltype(t1 + t2)
{
   static_assert(std::is_integral<T1>::value, "Type T1 must be integral");
   static_assert(std::is_integral<T2>::value, "Type T2 must be integral");

   return t1 + t2;
}
error C2338: Type T2 must be integral
see reference to function template instantiation 'T2 add<int,double>(T1,T2)' being compiled
   with
   [
      T2=double,
      T1=int
   ]
error C2338: Type T1 must be integral
see reference to function template instantiation 'T1 add<const char*,int>(T1,T2)' being compiled
   with
   [
      T1=const char *,
      T2=int
   ]

		33.1.10 Move semantics
This is yet another important and well covered topic from C++11, that one could write a series of articles, not just a paragraph. Therefore I will not get into too many details, but encourage you to find additional readings, if you're not already familiar with the topic.

C++11 has introduced the concept of rvalue references (specified with &&) to differentiate a reference to an lvalue or an rvalue. An lvalue is an object that has a name, while an rvalue is an object that does not have a name (a temporary object). The move semantics allow modifying rvalues (previously considered immutable and indistinguishable from const T& types).

A C++ class/struct used to have some implicit member functions: default constructor (only if another constructor is not explicitly defined) and copy constructor, a destructor and a copy assignment operator. The copy constructor and the copy assignment operator perform a bit-wise (or shallow) copy, i.e. copying the variables bitwise. That means if you have a class that contains pointers to some objects, they just copy the value of the pointers and not the objects they point to. This might be OK in some cases, but for many cases you actually want a deep-copy, meaning that you want to copy the objects pointers refer to, and not the values of the pointers. In this case you have to explicitly write copy constructor and copy assignment operator to perform a deep-copy.

What if the object you initialize or copy from is an rvalue (a temporary). You still have to copy its value, but soon after the rvalue goes away. That means an overhead of operations, including allocations and memory copying that after all, should not be necessary.

Enter the move constructor and move assignment operator. These two special functions take a T&& argument, which is an rvalue. Knowing that fact, they can modify the object, such as "stealing" the objects their pointers refer to. For instance, a container implementation (such as a vector or a queue) may have a pointer to an array of elements. When an object is instantiating from a temporary, instead of allocating another array, copying the values from the temporary, and then deleting the memory from the temporary when that is destroyed, we just copy the value of the pointer that refers to the allocated array, thus saving an allocation, copying a sequence of elements, and a later de-allocation.

The following example shows a dummy buffer implementation. The buffer is identified by a name (just for the sake of showing a point revealed below), has a pointer (wrapper in an std::unique_ptr) to an array of elements of type T and variable that tells the size of the array.

template <typename T>
class Buffer 
{
   std::string          _name;
   size_t               _size;
   std::unique_ptr<T[]> _buffer;

public:
   // default constructor
   Buffer():
      _size(16),
      _buffer(new T[16])
   {}

   // constructor
   Buffer(const std::string& name, size_t size):
      _name(name),
      _size(size),
      _buffer(new T[size])
   {}

   // copy constructor
   Buffer(const Buffer& copy):
      _name(copy._name),
      _size(copy._size),
      _buffer(new T[copy._size])
   {
      T* source = copy._buffer.get();
      T* dest = _buffer.get();
      std::copy(source, source + copy._size, dest);
   }

   // copy assignment operator
   Buffer& operator=(const Buffer& copy)
   {
      if(this != &copy)
      {
         _name = copy._name;

         if(_size != copy._size)
         {
            _buffer = nullptr;
            _size = copy._size;
            _buffer = _size > 0 > new T[_size] : nullptr;
         }

         T* source = copy._buffer.get();
         T* dest = _buffer.get();
         std::copy(source, source + copy._size, dest);
      }

      return *this;
   }

   // move constructor
   Buffer(Buffer&& temp):
      _name(std::move(temp._name)),
      _size(temp._size),
      _buffer(std::move(temp._buffer))
   {
      temp._buffer = nullptr;
      temp._size = 0;
   }

   // move assignment operator
   Buffer& operator=(Buffer&& temp)
   {
      assert(this != &temp); // assert if this is not a temporary

      _buffer = nullptr;
      _size = temp._size;
      _buffer = std::move(temp._buffer);

      _name = std::move(temp._name);

      temp._buffer = nullptr;
      temp._size = 0;
      
      return *this;
   }
};

template <typename T>
Buffer<T> getBuffer(const std::string& name) 
{
   Buffer<T> b(name, 128);
   return b;
}
int main()
{
   Buffer<int> b1;
   Buffer<int> b2("buf2", 64);
   Buffer<int> b3 = b2;
   Buffer<int> b4 = getBuffer<int>("buf4");
   b1 = getBuffer<int>("buf5");
   return 0;
}
The default copy constructor and copy assignment operator should look familiar. What's new to C++11 is the move constructor and move assignment operator, implemented in the spirit of the aforementioned move semantics. If you run this code you'll see that when b4 is constructed, the move constructor is called. Also, when b1 is assigned a value, the move assignment operator is called. The reason is the value returned by getBuffer() is a temporary, i.e. an rvalue.   

You probably noticed the use of std::move in the move constructor, when initializing the name variable and the pointer to the buffer. The name is actually a string, and std::string also implements move semantics. Same for the std::unique_ptr. However, if we just said _name(temp._name) the copy constructor would have been called. For _buffer that would not have been even possible because std::unique_ptr does not have a copy constructor. But why wasn't the move constructor for std::string called in this case? Because even if the object the move constructor for Buffer is called with is an rvalue, inside the constructor it is actually an lvalue. Why? Because it has a name, "temp" and a named object is an lvalue. To make it again an rvalue (and be able to invoke the appropriate move constructor) one must use std::move. This function just turns an lvalue reference into an rvalue reference.

UPDATE: Though the purpose of this example was to show how move constructor and move assignment operator should be implemented, the exact details of an implementation may vary. An alternative implementation was provided by Member 7805758 in the comments. To be easier to see it I will show it here:

template <typename T>
class Buffer
{
   std::string          _name;
   size_t               _size;
   std::unique_ptr<T[]> _buffer;
 
public:
   // constructor
   Buffer(const std::string& name = "", size_t size = 16):
      _name(name),
      _size(size),
      _buffer(size? new T[size] : nullptr)
   {}
 
   // copy constructor
   Buffer(const Buffer& copy):
      _name(copy._name),
      _size(copy._size),
      _buffer(copy._size? new T[copy._size] : nullptr)
   {
      T* source = copy._buffer.get();
      T* dest = _buffer.get();
      std::copy(source, source + copy._size, dest);
   }
 
   // copy assignment operator
   Buffer& operator=(Buffer copy)
   {
       swap(*this, copy);
       return *this;
   }
 
   // move constructor
   Buffer(Buffer&& temp):Buffer()
   {
      swap(*this, temp);
   }
 
   friend void swap(Buffer& first, Buffer& second) noexcept
   {
       using std::swap;
       swap(first._name  , second._name);
       swap(first._size  , second._size);
       swap(first._buffer, second._buffer);
   }
};

		33.1.11
	33.2
34. Boost

	34.1 lexical_cast , convert number to string (like itoa in C) 


		34.1.1 My example

#include <boost/lexical_cast.hpp>
using boost::lexical_cast;
using boost::bad_lexical_cast;
test_res.s_remediation += ". Total number of servers: "+boost::lexical_cast<std::string>(iNumberOfGCs);

	34.2

35. C++11, C++14

	35.1 FAQ 

		35.1.1 What does T&& (double ampersand) mean in C++11?

			35.1.1.1  stackoverflow answer


It declares an rvalue reference (standards proposal doc).

Here's an introduction to rvalue references: http://www.artima.com/cppsource/rvalue.html.
Here's a fantastic in-depth look at rvalue references by one of Microsoft's standard library developers: http://blogs.msdn.com/b/vcblog/archive/2009/02/03/rvalue-references-c-0x-features-in-vc10-part-2.aspx.

The biggest difference between a C++03 reference (now called an lvalue reference in C++0x) is that it can bind to an rvalue like a temporary without having to be const. Thus, this syntax is now legal:

T&& r = T();

rvalue references primarily provide for the following:

Move semantics. A move constructor and move assignment operator can now be defined that takes an rvalue reference instead of the usual const-lvalue reference. A move functions like a copy, except it is not obliged to keep the source unchanged; in fact, it usually modifies the source such that it no longer owns the moved resources. This is great for eliminating extraneous copies, especially in standard library implementations.

For example, a copy constructor might look like this:

foo(foo const& other)
{
    this->length = other.length;
    this->ptr = new int[other.length];
    copy(other.ptr, other.ptr + other.length, this->ptr);
}

If this constructor was passed a temporary, the copy would be unnecessary because we know the temporary will just be destroyed; why not make use of the resources the temporary already allocated? In C++03, there's no way to prevent the copy as we cannot determine we were passed a temporary. In C++0x, we can overload a move constructor:

foo(foo&& other)
{
   this->length = other.length;
   this->ptr = other.ptr;
   other.length = 0;
   other.ptr = nullptr;
}

Notice the big difference here: the move constructor actually modifies its argument. This would effectively "move" the temporary into the object being constructed, thereby eliminating the unnecessary copy.

The move constructor would be used for temporaries and for non-const lvalue references that are explicitly converted to rvalue references using the std::move function (it just performs the conversion). The following code both invoke the move constructor for f1 and f2:

foo f1((foo())); // Move a temporary into f1; temporary becomes "empty"
foo f2 = std::move(f1); // Move f1 into f2; f1 is now "empty"

Perfect forwarding. rvalue references allow us to properly forward arguments for templated functions. Take for example this factory function:

template <typename T, typename A1>
std::unique_ptr<T> factory(A1& a1)
{
    return std::unique_ptr<T>(new T(a1));
}

If we called factory<foo>(5), the argument will be deduced to be int&, which will not bind to a literal 5, even if foo's constructor takes an int. Well, we could instead use A1 const&, but what if foo takes the constructor argument by non-const reference? To make a truly generic factory function, we would have to overload factory on A1& and on A1 const&. That might be fine if factory takes 1 parameter type, but each additional parameter type would multiply the necessary overload set by 2. That's very quickly unmaintainable.

rvalue references fix this problem by allowing the standard library to define a std::forward function that can properly forward lvalue/rvalue references. For more information about how std::forward works, see this excellent answer.

This enables us to define the factory function like this:

template <typename T, typename A1>
std::unique_ptr<T> factory(A1&& a1)
{
    return std::unique_ptr<T>(new T(std::forward<A1>(a1)));
}

Now the argument's rvalue/lvalue-ness is preserved when passed to T's constructor. That means that if factory is called with an rvalue, T's constructor is called with an rvalue. If factory is called with an lvalue, T's constructor is called with an lvalue. The improved factory function works because of one special rule:

    When the function parameter type is of the form T&& where T is a template parameter, and the function argument is an lvalue of type A, the type A& is used for template argument deduction.

Thus, we can use factory like so:

auto p1 = factory<foo>(foo()); // calls foo(foo&&)
auto p2 = factory<foo>(*p1);   // calls foo(foo const&)

Important rvalue reference properties:

    For overload resolution, lvalues prefer binding to lvalue references and rvalues prefer binding to rvalue references. Hence why temporaries prefer invoking a move constructor / move assignment operator over a copy constructor / assignment operator.
    rvalue references will implicitly bind to rvalues and to temporaries that are the result of an implicit conversion. i.e. float f = 0f; int&& i = f; is well formed because float is implicitly convertible to int; the reference would be to a temporary that is the result of the conversion.
    Named rvalue references are lvalues. Unnamed rvalue references are rvalues. This is important to understand why the std::move call is necessary in: foo&& r = foo(); foo f = std::move(r);


			35.1.1.2 My answer
&& aka in "effective modern c++" universal reference. quote:

Item 24: Distinguish universal references from rvalue references.

It’s been said that the truth shall set you free, but under the right circumstances, a well-chosen lie can be equally liberating. This Item is such a lie. Because we’re dealing with software, however, let’s eschew the word “lie” and instead say that this Item comprises an “abstraction.”  

To declare an rvalue reference to some type T, you write T&&. It thus seems reasonable to assume that if you see “T&&” in source code, you’re looking at an rvalue reference. Alas, it’s not quite that simple:

void f(Widget&& param);             // rvalue reference

Widget&& var1 = Widget();           // rvalue reference

auto&& var2 = var1;                 // not rvalue reference

template<typename T>
void f(std::vector<T>&& param);     // rvalue reference

template<typename T>
void f(T&& param);                  // not rvalue reference

In fact, “T&&” has two different meanings. One is rvalue reference, of course. Such references behave exactly the way you expect: they bind only to rvalues, and their primary raison d’être is to identify objects that may be moved from.

The other meaning for “T&&” is either rvalue reference or lvalue reference. Such references look like rvalue references in the source code (i.e., “T&&”), but they can behave as if they were lvalue references (i.e., “T&”). Their dual nature permits them to bind to rvalues (like rvalue references) as well as lvalues (like lvalue references). Furthermore, they can bind to const or non-const objects, to volatile or non-volatile objects, even to objects that are both const and volatile. They can bind to virtually anything. Such unprecedentedly flexible references deserve a name of their own. I call them universal references.1

Universal references arise in two contexts. The most common is function template parameters, such as this example from the sample code above:

template<typename T>
void f(T&& param);             // param is a universal reference

The second context is auto declarations, including this one from the sample code above:

auto&& var2 = var1;            // var2 is a universal reference

What these contexts have in common is the presence of type deduction. In the template f, the type of param is being deduced, and in the declaration for var2, var2’s type is being deduced. Compare that with the following examples (also from the sample code above), where type deduction is missing. If you see “T&&” without type deduction, you’re looking at an rvalue reference:

void f(Widget&& param);        // no type deduction;
                               // param is an rvalue reference

Widget&& var1 = Widget();      // no type deduction;
                               // var1 is an rvalue reference

Because universal references are references, they must be initialized. The initializer for a universal reference determines whether it represents an rvalue reference or an lvalue reference. If the initializer is an rvalue, the universal reference corresponds to an rvalue reference. If the initializer is an lvalue, the universal reference corresponds to an lvalue reference. For universal references that are function parameters, the initializer is provided at the call site:

template<typename T>
void f(T&& param);     // param is a universal reference

Widget w;
f(w);                  // lvalue passed to f; param's type is
                       // Widget& (i.e., an lvalue reference)

f(std::move(w));       // rvalue passed to f; param's type is
                       // Widget&& (i.e., an rvalue reference)

For a reference to be universal, type deduction is necessary, but it’s not sufficient. The form of the reference declaration must also be correct, and that form is quite constrained. It must be precisely “T&&”. Look again at this example from the sample code we saw earlier:

template<typename T>
void f(std::vector<T>&& param);  // param is an rvalue reference

When f is invoked, the type T will be deduced (unless the caller explicitly specifies it, an edge case we’ll not concern ourselves with). But the form of param’s type declaration isn’t “T&&”, it’s “std::vector<T>&&”. That rules out the possibility that param is a universal reference. param is therefore an rvalue reference, something that your compilers will be happy to confirm for you if you try to pass an lvalue to f:

std::vector<int> v;
f(v);                             // error! can't bind lvalue to
                                  // rvalue reference

Even the simple presence of a const qualifier is enough to disqualify a reference from being universal:

template<typename T>
void f(const T&& param);         // param is an rvalue reference

If you’re in a template and you see a function parameter of type “T&&”, you might think you can assume that it’s a universal reference. You can’t. That’s because being in a template doesn’t guarantee the presence of type deduction. Consider this push_back member function in std::vector:

template<class T, class Allocator = allocator<T>>  // from C++
class vector {                                     // Standards
public:
  void push_back(T&& x);
  …
};

push_back’s parameter certainly has the right form for a universal reference, but there’s no type deduction in this case. That’s because push_back can’t exist without a particular vector instantiation for it to be part of, and the type of that instantiation fully determines the declaration for push_back. That is, saying

std::vector<Widget> v;

causes the std::vector template to be instantiated as follows:

class vector<Widget, allocator<Widget>> {
public:
  void push_back(Widget&& x);               // rvalue reference
  …
};

Now you can see clearly that push_back employs no type deduction. This push_back for vector<T> (there are two—the function is overloaded) always declares a parameter of type rvalue-reference-to-T.

In contrast, the conceptually similar emplace_back member function in std::vector does employ type deduction:

template<class T, class Allocator = allocator<T>>  // still from
class vector {                                     // C++
public:                                            // Standards
  template <class... Args>
  void emplace_back(Args&&... args);
  …
};

Here, the type parameter Args is independent of vector’s type parameter T, so Args must be deduced each time emplace_back is called. (Okay, Args is really a parameter pack, not a type parameter, but for purposes of this discussion, we can treat it as if it were a type parameter.)

The fact that emplace_back’s type parameter is named Args, yet it’s still a universal reference, reinforces my earlier comment that it’s the form of a universal reference that must be “T&&”. There’s no requirement that you use the name T. For example, the following template takes a universal reference, because the form (“type&&”) is right, and param’s type will be deduced (again, excluding the corner case where the caller explicitly specifies the type):

template<typename MyTemplateType>         // param is a
void someFunc(MyTemplateType&& param);    // universal reference

I remarked earlier that auto variables can also be universal references. To be more precise, variables declared with the type auto&& are universal references, because type deduction takes place and they have the correct form (“T&&”). auto universal references are not as common as universal references used for function template parameters, but they do crop up from time to time in C++11. They crop up a lot more in C++14, because C++14 lambda expressions may declare auto&& parameters. For example, if you wanted to write a C++14 lambda to record the time taken in an arbitrary function invocation, you could do this:

auto timeFuncInvocation =
  [](auto&& func, auto&&... params)               // C++14
  {
    start timer;
    std::forward<decltype(func)>(func)(           // invoke func
      std::forward<decltype(params)>(params)...   // on params
      );                              
    stop timer and record elapsed time;
  };

If your reaction to the “std::forward<decltype(blah blah blah)>” code inside the lambda is, “What the…?!”, that probably just means you haven’t yet read Item 33. Don’t worry about it. The important thing in this Item is the auto&& parameters that the lambda declares. func is a universal reference that can be bound to any callable object, lvalue or rvalue. params is zero or more universal references (i.e., a universal reference parameter pack) that can be bound to any number of objects of arbitrary types. The result, thanks to auto universal references, is that timeFuncInvocation can time pretty much any function execution. (For information on the difference between “any” and “pretty much any,” turn to Item 30.)

Bear in mind that this entire Item—the foundation of universal references—is a lie…er, an “abstraction.” The underlying truth is known as reference collapsing, a topic to which Item 28 is dedicated. But the truth doesn’t make the abstraction any less useful. Distinguishing between rvalue references and universal references will help you read source code more accurately (“Does that T&& I’m looking at bind to rvalues only or to everything?”), and it will avoid ambiguities when you communicate with your colleagues (“I’m using a universal reference here, not an rvalue reference…”). It will also allow you to make sense of Items 25 and 26, which rely on the distinction. So embrace the abstraction. Revel in it. Just as Newton’s laws of motion (which are technically incorrect) are typically just as useful as and easier to apply than Einstein’s theory of general relativity (“the truth”), so is the notion of universal references normally preferable to working through the details of reference collapsing.
Things to Remember

    If a function template parameter has type T&& for a deduced type T, or if an object is declared using auto&&, the parameter or object is a universal reference.

    If the form of the type declaration isn’t precisely type&&, or if type deduction does not occur, type&& denotes an rvalue reference.

    Universal references correspond to rvalue references if they’re initialized with rvalues. They correspond to lvalue references if they’re initialized with lvalues.  



			35.1.1.3


		35.1.2  books

			35.1.2.1  Effective modern c++

				35.1.2.1.1   auto

Item 5: Prefer auto to explicit type declarations.

Ah, the simple joy of

int x;

Wait. Damn. I forgot to initialize x, so its value is indeterminate. Maybe. It might actually be initialized to zero. Depends on the context. Sigh.

Never mind. Let’s move on to the simple joy of declaring a local variable to be initialized by dereferencing an iterator:

template<typename It>    // algorithm to dwim ("do what I mean")
void dwim(It b, It e)    // for all elements in range from
{                        // b to e
  for (; b != e; ++b) {
    typename std::iterator_traits<It>::value_type
      currValue = *b;
    …
  }
}

Ugh. “typename std::iterator_traits<It>::value_type” to express the type of the value pointed to by an iterator? Really? I must have blocked out the memory of how much fun that is. Damn. Wait—didn’t I already say that?

Okay, simple joy (take three): the delight of declaring a local variable whose type is that of a closure. Oh, right. The type of a closure is known only to the compiler, hence can’t be written out. Sigh. Damn.

Damn, damn, damn! Programming in C++ is not the joyous experience it should be!

Well, it didn’t used to be. But as of C++11, all these issues go away, courtesy of auto. auto variables have their type deduced from their initializer, so they must be initialized. That means you can wave goodbye to a host of uninitialized variable problems as you speed by on the modern C++ superhighway:

int x1;                     // potentially uninitialized

auto x2;                    // error! initializer required

auto x3 = 0;                // fine, x3's value is well-defined

Said highway lacks the potholes associated with declaring a local variable whose value is that of a dereferenced iterator:

template<typename It>       // as before
void dwim(It b, It e)
{
  for (; b != e; ++b) {
    auto currValue = *b;
    …
  }
}

And because auto uses type deduction (see Item 2), it can represent types known only to compilers:

auto derefUPLess =                        // comparison func.
  [](const std::unique_ptr<Widget>& p1,   // for Widgets
     const std::unique_ptr<Widget>& p2)   // pointed to by
  { return *p1 < *p2; };                  // std::unique_ptrs

Very cool. In C++14, the temperature drops further, because parameters to lambda expressions may involve auto:

auto derefLess =                          // C++14 comparison
  [](const auto& p1,                      // function for
     const auto& p2)                      // values pointed
  { return *p1 < *p2; };                  // to by anything
                                          // pointer-like

Coolness notwithstanding, perhaps you’re thinking we don’t really need auto to declare a variable that holds a closure, because we can use a std::function object. It’s true, we can, but possibly that’s not what you were thinking. And maybe now you’re thinking “What’s a std::function object?” So let’s clear that up.

std::function is a template in the C++11 Standard Library that generalizes the idea of a function pointer. Whereas function pointers can point only to functions, however, std::function objects can refer to any callable object, i.e., to anything that can be invoked like a function. Just as you must specify the type of function to point to when you create a function pointer (i.e., the signature of the functions you want to point to), you must specify the type of function to refer to when you create a std::function object. You do that through std::function’s template parameter. For example, to declare a std::function object named func that could refer to any callable object acting as if it had this signature,

bool(const std::unique_ptr<Widget>&,  // C++11 signature for
     const std::unique_ptr<Widget>&)  // std::unique_ptr<Widget>
                                      // comparison function

you’d write this:

std::function<bool(const std::unique_ptr<Widget>&,
                   const std::unique_ptr<Widget>&)> func;

Because lambda expressions yield callable objects, closures can be stored in std::function objects. That means we could declare the C++11 version of derefUPLess without using auto as follows:

std::function<bool(const std::unique_ptr<Widget>&,
                   const std::unique_ptr<Widget>&)>
  derefUPLess = [](const std::unique_ptr<Widget>& p1,
                   const std::unique_ptr<Widget>& p2)
                  { return *p1 < *p2; };

It’s important to recognize that even setting aside the syntactic verbosity and need to repeat the parameter types, using std::function is not the same as using auto. An auto-declared variable holding a closure has the same type as the closure, and as such it uses only as much memory as the closure requires. The type of a std::function-declared variable holding a closure is an instantiation of the std::function template, and that has a fixed size for any given signature. This size may not be adequate for the closure it’s asked to store, and when that’s the case, the std::function constructor will allocate heap memory to store the closure. The result is that the std::function object typically uses more memory than the auto-declared object. And, thanks to implementation details that restrict inlining and yield indirect function calls, invoking a closure via a std::function object is almost certain to be slower than calling it via an auto-declared object. In other words, the std::function approach is generally bigger and slower than the auto approach, and it may yield out-of-memory exceptions, too. Plus, as you can see in the examples above, writing “auto” is a whole lot less work than writing the type of the std::function instantiation. In the competition between auto and std::function for holding a closure, it’s pretty much game, set, and match for auto. (A similar argument can be made for auto over std::function for holding the result of calls to std::bind, but in Item 34, I do my best to convince you to use lambdas instead of std::bind, anyway.)

The advantages of auto extend beyond the avoidance of uninitialized variables, verbose variable declarations, and the ability to directly hold closures. One is the ability to avoid what I call problems related to “type shortcuts.” Here’s something you’ve probably seen—possibly even written:

std::vector<int> v;
…
unsigned sz = v.size();

The official return type of v.size() is std::vector<int>::size_type, but few developers are aware of that. std::vector<int>::size_type is specified to be an unsigned integral type, so a lot of programmers figure that unsigned is good enough and write code such as the above. This can have some interesting consequences. On 32-bit Windows, for example, both unsigned and std::vector<int>::size_type are the same size, but on 64-bit Windows, unsigned is 32 bits, while std::vector<int>::size_type is 64 bits. This means that code that works under 32-bit Windows may behave incorrectly under 64-bit Windows, and when porting your application from 32 to 64 bits, who wants to spend time on issues like that?

Using auto ensures that you don’t have to:

auto sz = v.size();  // sz's type is std::vector<int>::size_type

Still unsure about the wisdom of using auto? Then consider this code:

std::unordered_map<std::string, int> m;
…

for (const std::pair<std::string, int>& p : m)
{
  …                   // do something with p
}

This looks perfectly reasonable, but there’s a problem. Do you see it?

Recognizing what’s amiss requires remembering that the key part of a std::unordered_map is const, so the type of std::pair in the hash table (which is what a std::unordered_map is) isn’t std::pair<std::string, int>, it’s std::pair<const std::string, int>. But that’s not the type declared for the variable p in the loop above. As a result, compilers will strive to find a way to convert std::pair<const std::string, int> objects (i.e., what’s in the hash table) to std::pair<std::string, int> objects (the declared type for p). They’ll succeed by creating a temporary object of the type that p wants to bind to by copying each object in m, then binding the reference p to that temporary object. At the end of each loop iteration, the temporary object will be destroyed. If you wrote this loop, you’d likely be surprised by this behavior, because you’d almost certainly intend to simply bind the reference p to each element in m.

Such unintentional type mismatches can be autoed away:

for (const auto& p : m)
{
  …                             // as before
}

This is not only more efficient, it’s also easier to type. Furthermore, this code has the very attractive characteristic that if you take p’s address, you’re sure to get a pointer to an element within m. In the code not using auto, you’d get a pointer to a temporary object—an object that would be destroyed at the end of the loop iteration.

The last two examples—writing unsigned when you should have written std::vector<int>::size_type and writing std::pair<std::string, int> when you should have written std::pair<const std::string, int>—demonstrate how explicitly specifying types can lead to implicit conversions that you neither want nor expect. If you use auto as the type of the target variable, you need not worry about mismatches between the type of variable you’re declaring and the type of the expression used to initialize it.

There are thus several reasons to prefer auto over explicit type declarations. Yet auto isn’t perfect. The type for each auto variable is deduced from its initializing expression, and some initializing expressions have types that are neither anticipated nor desired. The conditions under which such cases arise, and what you can do about them, are discussed in Items 2 and 6, so I won’t address them here. Instead, I’ll turn my attention to a different concern you may have about using auto in place of traditional type declarations: the readability of the resulting source code.

First, take a deep breath and relax. auto is an option, not a mandate. If, in your professional judgment, your code will be clearer or more maintainable or in some other way better by using explicit type declarations, you’re free to continue using them. But bear in mind that C++ breaks no new ground in adopting what is generally known in the programming languages world as type inference. Other statically typed procedural languages (e.g., C#, D, Scala, Visual Basic) have a more or less equivalent feature, to say nothing of a variety of statically typed functional languages (e.g., ML, Haskell, OCaml, F#, etc.). In part, this is due to the success of dynamically typed languages such as Perl, Python, and Ruby, where variables are rarely explicitly typed. The software development community has extensive experience with type inference, and it has demonstrated that there is nothing contradictory about such technology and the creation and maintenance of large, industrial-strength code bases.

Some developers are disturbed by the fact that using auto eliminates the ability to determine an object’s type by a quick glance at the source code. However, IDEs’ ability to show object types often mitigates this problem (even taking into account the IDE type-display issues mentioned in Item 4), and, in many cases, a somewhat abstract view of an object’s type is just as useful as the exact type. It often suffices, for example, to know that an object is a container or a counter or a smart pointer, without knowing exactly what kind of container, counter, or smart pointer it is. Assuming well-chosen variable names, such abstract type information should almost always be at hand.

The fact of the matter is that writing types explicitly often does little more than introduce opportunities for subtle errors, either in correctness or efficiency or both. Furthermore, auto types automatically change if the type of their initializing expression changes, and that means that some refactorings are facilitated by the use of auto. For example, if a function is declared to return an int, but you later decide that a long would be better, the calling code automatically updates itself the next time you compile if the results of calling the function are stored in auto variables. If the results are stored in variables explicitly declared to be int, you’ll need to find all the call sites so that you can revise them.
Things to Remember

    auto variables must be initialized, are generally immune to type mismatches that can lead to portability or efficiency problems, can ease the process of refactoring, and typically require less typing than variables with explicitly specified types.

    auto-typed variables are subject to the pitfalls described in Items 2 and 6.


				35.1.2.1.2    Distinguish between () and {} when creating objects.

Depending on your perspective, syntax choices for object initialization in C++11 embody either an embarrassment of riches or a confusing mess. As a general rule, initialization values may be specified with parentheses, an equals sign, or braces:

int x(0);             // initializer is in parentheses

int y = 0;            // initializer follows "="

int z{ 0 };           // initializer is in braces

In many cases, it’s also possible to use an equals sign and braces together:

int z = { 0 };        // initializer uses "=" and braces

For the remainder of this Item, I’ll generally ignore the equals-sign-plus-braces syntax, because C++ usually treats it the same as the braces-only version.

The “confusing mess” lobby points out that the use of an equals sign for initialization often misleads C++ newbies into thinking that an assignment is taking place, even though it’s not. For built-in types like int, the difference is academic, but for user-defined types, it’s important to distinguish initialization from assignment, because different function calls are involved:

Widget w1;            // call default constructor

Widget w2 = w1;       // not an assignment; calls copy ctor

w1 = w2;              // an assignment; calls copy operator=

Even with several initialization syntaxes, there were some situations where C++98 had no way to express a desired initialization. For example, it wasn’t possible to directly indicate that an STL container should be created holding a particular set of values (e.g., 1, 3, and 5).

To address the confusion of multiple initialization syntaxes, as well as the fact that they don’t cover all initialization scenarios, C++11 introduces uniform initialization: a single initialization syntax that can, at least in concept, be used anywhere and express everything. It’s based on braces, and for that reason I prefer the term braced initialization. “Uniform initialization” is an idea. “Braced initialization” is a syntactic construct.

Braced initialization lets you express the formerly inexpressible. Using braces, specifying the initial contents of a container is easy:

std::vector<int> v{ 1, 3, 5 }; // v's initial content is 1, 3, 5

Braces can also be used to specify default initialization values for non-static data members. This capability—new to C++11—is shared with the “=” initialization syntax, but not with parentheses:

class Widget {
  …

private:
  int x{ 0 };                  // fine, x's default value is 0
  int y = 0;                   // also fine
  int z(0);                    // error!
};

On the other hand, uncopyable objects (e.g., std::atomics—see Item 40) may be initialized using braces or parentheses, but not using “=”: 

std::atomic<int> ai1{ 0 };     // fine

std::atomic<int> ai2(0);       // fine

std::atomic<int> ai3 = 0;      // error!

It’s thus easy to understand why braced initialization is called “uniform.” Of C++’s three ways to designate an initializing expression, only braces can be used everywhere.

A novel feature of braced initialization is that it prohibits implicit narrowing conversions among built-in types. If the value of an expression in a braced initializer isn’t guaranteed to be expressible by the type of the object being initialized, compilers are required to complain:

double x, y, z;

…

int sum1{ x + y + z };       // error! sum of doubles may
                             // not be expressible as int

Initialization using parentheses and “=” doesn’t check for narrowing conversions, because that could break too much legacy code:

int sum2(x + y + z);         // okay (value of expression
                             // truncated to an int)

int sum3 = x + y + z;        // ditto

Another noteworthy characteristic of braced initialization is its immunity to C++’s most vexing parse. A side effect of C++’s rule that anything that can be parsed as a declaration must be interpreted as one, the most vexing parse most frequently afflicts developers when they want to default-construct an object, but inadvertently end up declaring a function instead. The root of the problem is that if you want to call a constructor with an argument, you can do it like this,

Widget w1(10);     // call Widget ctor with argument 10

but if you try to call a Widget constructor with zero arguments using the analogous syntax, you declare a function instead of an object:

Widget w2();       // most vexing parse! declares a function
                   // named w2 that returns a Widget!

Functions can’t be declared using braces for the parameter list, so default-constructing an object using braces doesn’t have this problem:

Widget w3{};       // calls Widget ctor with no args

There’s thus a lot to be said for braced initialization. It’s the syntax that can be used in the widest variety of contexts, it prevents implicit narrowing conversions, and it’s immune to C++’s most vexing parse. A trifecta of goodness! So why isn’t this Item entitled something like “Prefer braced initialization syntax”?

The drawback to braced initialization is the sometimes-surprising behavior that accompanies it. Such behavior grows out of the unusually tangled relationship among braced initializers, std::initializer_lists, and constructor overload resolution. Their interactions can lead to code that seems like it should do one thing, but actually does another. For example, Item 2 explains that when an auto-declared variable has a braced initializer, the type deduced is std::initializer_list, even though other ways of declaring a variable with the same initializer would yield a more intuitive type. As a result, the more you like auto, the less enthusiastic you’re likely to be about braced initialization.

In constructor calls, parentheses and braces have the same meaning as long as std::initializer_list parameters are not involved:

class Widget {
public:
  Widget(int i, bool b);      // ctors not declaring
  Widget(int i, double d);    // std::initializer_list params
  …
};

Widget w1(10, true);          // calls first ctor

Widget w2{10, true};          // also calls first ctor

Widget w3(10, 5.0);           // calls second ctor

Widget w4{10, 5.0};           // also calls second ctor

If, however, one or more constructors declare a parameter of type std::initializer_list, calls using the braced initialization syntax strongly prefer the overloads taking std::initializer_lists. Strongly. If there’s any way for compilers to construe a call using a braced initializer to be to a constructor taking a std::initializer_list, compilers will employ that interpretation. If the Widget class above is augmented with a constructor taking a std::initializer_list<long double>, for example,

class Widget {
public:
  Widget(int i, bool b);                           // as before
  Widget(int i, double d);                         // as before

  Widget(std::initializer_list<long double> il);   // added

  …
};

Widgets w2 and w4 will be constructed using the new constructor, even though the type of the std::initializer_list elements (long double) is, compared to the non-std::initializer_list constructors, a worse match for both arguments! Look:

Widget w1(10, true);     // uses parens and, as before,
                         // calls first ctor

Widget w2{10, true};     // uses braces, but now calls
                         // std::initializer_list ctor
                         // (10 and true convert to long double)

Widget w3(10, 5.0);      // uses parens and, as before,
                         // calls second ctor

Widget w4{10, 5.0};      // uses braces, but now calls
                         // std::initializer_list ctor
                         // (10 and 5.0 convert to long double)

Even what would normally be copy and move construction can be hijacked by std::initializer_list constructors:

class Widget {
public:
  Widget(int i, bool b);                           // as before
  Widget(int i, double d);                         // as before
  Widget(std::initializer_list<long double> il);   // as before

  operator float() const;                          // convert
  …                                                // to float

};

Widget w5(w4);               // uses parens, calls copy ctor

Widget w6{w4};               // uses braces, calls
                             // std::initializer_list ctor
                             // (w4 converts to float, and float
                             // converts to long double)

Widget w7(std::move(w4));    // uses parens, calls move ctor

Widget w8{std::move(w4)};    // uses braces, calls
                             // std::initializer_list ctor
                             // (for same reason as w6)

Compilers’ determination to match braced initializers with constructors taking std::initializer_lists is so strong, it prevails even if the best-match std::initializer_list constructor can’t be called. For example:

class Widget {
public:
  Widget(int i, bool b);                   // as before
  Widget(int i, double d);                 // as before

  Widget(std::initializer_list<bool> il);  // element type is
                                           // now bool

  …                                        // no implicit
};                                         // conversion funcs

Widget w{10, 5.0};      // error! requires narrowing conversions

Here, compilers will ignore the first two constructors (the second of which offers an exact match on both argument types) and try to call the constructor taking a std::initializer_list<bool>. Calling that constructor would require converting an int (10) and a double (5.0) to bools. Both conversions would be narrowing (bool can’t exactly represent either value), and narrowing conversions are prohibited inside braced initializers, so the call is invalid, and the code is rejected.

Only if there’s no way to convert the types of the arguments in a braced initializer to the type in a std::initializer_list do compilers fall back on normal overload resolution. For example, if we replace the std::initializer_list<bool> constructor with one taking a std::initializer_list<std::string>, the non-std::initializer_list constructors become candidates again, because there is no way to convert ints and bools to std::strings:

class Widget {
public:
  Widget(int i, bool b);               // as before
  Widget(int i, double d);             // as before

  // std::initializer_list element type is now std::string
  Widget(std::initializer_list<std::string> il);
  …                                    // no implicit
};                                     // conversion funcs

Widget w1(10, true);     // uses parens, still calls first ctor

Widget w2{10, true};     // uses braces, now calls first ctor

Widget w3(10, 5.0);      // uses parens, still calls second ctor

Widget w4{10, 5.0};      // uses braces, now calls second ctor

This brings us near the end of our examination of braced initializers and constructor overloading, but there’s an interesting edge case that needs to be addressed. Suppose you use an empty set of braces to construct an object that supports default construction and also supports std::initializer_list construction. What do your empty braces mean? If they mean “no arguments,” you get default construction, but if they mean “empty std::initializer_list,” you get construction from a std::initializer_list with no elements.

The rule is that you get default construction. Empty braces mean no arguments, not an empty std::initializer_list:

class Widget {
public:
  Widget();                                // default ctor

  Widget(std::initializer_list<int> il);   // std::initializer
                                           // _list ctor

  …                                        // no implicit
};                                         // conversion funcs

Widget w1;            // calls default ctor

Widget w2{};          // also calls default ctor

Widget w3();          // most vexing parse! declares a function!

If you want to call a std::initializer_list constructor with an empty std::initializer_list, you do it by making the empty braces a constructor argument—by putting the empty braces inside the parentheses or braces demarcating what you’re passing:

Widget w4({});        // calls std::initializer_list ctor
                      // with empty list

Widget w5{{}};        // ditto

At this point, with seemingly arcane rules about braced initializers, std::initializer_lists, and constructor overloading burbling about in your brain, you may be wondering how much of this information matters in day-to-day programming. More than you might think, because one of the classes directly affected is std::vector. std::vector has a non-std::initializer_list constructor that allows you to specify the initial size of the container and a value each of the initial elements should have, but it also has a constructor taking a std::initializer_list that permits you to specify the initial values in the container. If you create a std::vector of a numeric type (e.g., a std::vector<int>) and you pass two arguments to the constructor, whether you enclose those arguments in parentheses or braces makes a tremendous difference:

std::vector<int> v1(10, 20);  // use non-std::initializer_list
                              // ctor: create 10-element
                              // std::vector, all elements have
                              // value of 20

std::vector<int> v2{10, 20};  // use std::initializer_list ctor:
                              // create 2-element std::vector,
                              // element values are 10 and 20

But let’s step back from std::vector and also from the details of parentheses, braces, and constructor overloading resolution rules. There are two primary takeaways from this discussion. First, as a class author, you need to be aware that if your set of overloaded constructors includes one or more functions taking a std::initializer_list, client code using braced initialization may see only the std::initializer_list overloads. As a result, it’s best to design your constructors so that the overload called isn’t affected by whether clients use parentheses or braces. In other words, learn from what is now viewed as an error in the design of the std::vector interface, and design your classes to avoid it.

An implication is that if you have a class with no std::initializer_list constructor, and you add one, client code using braced initialization may find that calls that used to resolve to non-std::initializer_list constructors now resolve to the new function. Of course, this kind of thing can happen any time you add a new function to a set of overloads: calls that used to resolve to one of the old overloads might start calling the new one. The difference with std::initializer_list constructor overloads is that a std::initializer_list overload doesn’t just compete with other overloads, it overshadows them to the point where the other overloads may hardly be considered. So add such overloads only with great deliberation.

The second lesson is that as a class client, you must choose carefully between parentheses and braces when creating objects. Most developers end up choosing one kind of delimiter as a default, using the other only when they have to. Braces-by-default folks are attracted by their unrivaled breadth of applicability, their prohibition of narrowing conversions, and their immunity to C++’s most vexing parse. Such folks understand that in some cases (e.g., creation of a std::vector with a given size and initial element value), parentheses are required. On the other hand, the go-parentheses-go crowd embraces parentheses as their default argument delimiter. They’re attracted to its consistency with the C++98 syntactic tradition, its avoidance of the auto-deduced-a-std::initializer_list problem, and the knowledge that their object creation calls won’t be inadvertently waylaid by std::initializer_list constructors. They concede that sometimes only braces will do (e.g., when creating a container with particular values). There’s no consensus that either approach is better than the other, so my advice is to pick one and apply it consistently.

If you’re a template author, the tension between parentheses and braces for object creation can be especially frustrating, because, in general, it’s not possible to know which should be used. For example, suppose you’d like to create an object of an arbitrary type from an arbitrary number of arguments. A variadic template makes this conceptually straightforward:

template<typename T,                // type of object to create
         typename... Ts>            // types of arguments to use
void doSomeWork(Ts&&... params)
{

  create local T object from params...
  …

}

There are two ways to turn the line of pseudocode into real code (see Item 25 for information about std::forward):

T localObject(std::forward<Ts>(params)...);    // using parens

T localObject{std::forward<Ts>(params)...};    // using braces

So consider this calling code:

std::vector<int> v;
…
doSomeWork<std::vector<int>>(10, 20);

If doSomeWork uses parentheses when creating localObject, the result is a std::vector with 10 elements. If doSomeWork uses braces, the result is a std::vector with 2 elements. Which is correct? The author of doSomeWork can’t know. Only the caller can.

This is precisely the problem faced by the Standard Library functions std::make_unique and std::make_shared (see Item 21). These functions resolve the problem by internally using parentheses and by documenting this decision as part of their interfaces.1
Things to Remember

    Braced initialization is the most widely usable initialization syntax, it prevents narrowing conversions, and it’s immune to C++’s most vexing parse.

    During constructor overload resolution, braced initializers are matched to std::initializer_list parameters if at all possible, even if other constructors offer seemingly better matches.

    An example of where the choice between parentheses and braces can make a significant difference is creating a std::vector<numeric type> with two arguments.

    Choosing between parentheses and braces for object creation inside templates can be challenging.

				35.1.2.1.3   Prefer nullptr to 0 and NULL.

So here’s the deal: the literal 0 is an int, not a pointer. If C++ finds itself looking at 0 in a context where only a pointer can be used, it’ll grudgingly interpret 0 as a null pointer, but that’s a fallback position. C++’s primary policy is that 0 is an int, not a pointer.

Practically speaking, the same is true of NULL. There is some uncertainty in the details in NULL’s case, because implementations are allowed to give NULL an integral type other than int (e.g., long). That’s not common, but it doesn’t really matter, because the issue here isn’t the exact type of NULL, it’s that neither 0 nor NULL has a pointer type.

In C++98, the primary implication of this was that overloading on pointer and integral types could lead to surprises. Passing 0 or NULL to such overloads never called a pointer overload:

void f(int);        // three overloads of f
void f(bool);
void f(void*);

f(0);               // calls f(int), not f(void*)

f(NULL);            // might not compile, but typically calls
                    // f(int). Never calls f(void*)

The uncertainty regarding the behavior of f(NULL) is a reflection of the leeway granted to implementations regarding the type of NULL. If NULL is defined to be, say, 0L (i.e., 0 as a long), the call is ambiguous, because conversion from long to int, long to bool, and 0L to void* are considered equally good. The interesting thing about that call is the contradiction between the apparent meaning of the source code (“I’m calling f with NULL—the null pointer”) and its actual meaning (“I’m calling f with some kind of integer—not the null pointer”). This counterintuitive behavior is what led to the guideline for C++98 programmers to avoid overloading on pointer and integral types. That guideline remains valid in C++11, because, the advice of this Item notwithstanding, it’s likely that some developers will continue to use 0 and NULL, even though nullptr is a better choice.

nullptr’s advantage is that it doesn’t have an integral type. To be honest, it doesn’t have a pointer type, either, but you can think of it as a pointer of all types. nullptr’s actual type is std::nullptr_t, and, in a wonderfully circular definition, std::nullptr_t is defined to be the type of nullptr. The type std::nullptr_t implicitly converts to all raw pointer types, and that’s what makes nullptr act as if it were a pointer of all types.

Calling the overloaded function f with nullptr calls the void* overload (i.e., the pointer overload), because nullptr can’t be viewed as anything integral:

f(nullptr);         // calls f(void*) overload

Using nullptr instead of 0 or NULL thus avoids overload resolution surprises, but that’s not its only advantage. It can also improve code clarity, especially when auto variables are involved. For example, suppose you encounter this in a code base:

auto result = findRecord( /* arguments */ );

if (result == 0) {
  …
}

If you don’t happen to know (or can’t easily find out) what findRecord returns, it may not be clear whether result is a pointer type or an integral type. After all, 0 (what result is tested against) could go either way. If you see the following, on the other hand,

auto result = findRecord( /* arguments */ );

if (result == nullptr) {
  …
}

there’s no ambiguity: result must be a pointer type.

nullptr shines especially brightly when templates enter the picture. Suppose you have some functions that should be called only when the appropriate mutex has been locked. Each function takes a different kind of pointer:

int    f1(std::shared_ptr<Widget> spw);  // call these only when
double f2(std::unique_ptr<Widget> upw);  // the appropriate
bool   f3(Widget* pw);                   // mutex is locked

Calling code that wants to pass null pointers could look like this:

std::mutex f1m, f2m, f3m;         // mutexes for f1, f2, and f3

using MuxGuard =                  // C++11 typedef; see Item 9
  std::lock_guard<std::mutex>;
…

{
  MuxGuard g(f1m);            // lock mutex for f1
  auto result = f1(0);        // pass 0 as null ptr to f1
}                             // unlock mutex

…

{
  MuxGuard g(f2m);            // lock mutex for f2
  auto result = f2(NULL);     // pass NULL as null ptr to f2
}                             // unlock mutex

…

{
  MuxGuard g(f3m);            // lock mutex for f3
  auto result = f3(nullptr);  // pass nullptr as null ptr to f3
}                             // unlock mutex

The failure to use nullptr in the first two calls in this code is sad, but the code works, and that counts for something. However, the repeated pattern in the calling code—lock mutex, call function, unlock mutex—is more than sad. It’s disturbing. This kind of source code duplication is one of the things that templates are designed to avoid, so let’s templatize the pattern:

template<typename FuncType,
         typename MuxType,
         typename PtrType>
auto lockAndCall(FuncType func,
                 MuxType& mutex,
                 PtrType ptr) -> decltype(func(ptr))
{
  using MuxGuard = std::lock_guard<MuxType>;

  MuxGuard g(mutex);
  return func(ptr);
}

If the return type of this function (auto … -> decltype(func(ptr)) has you scratching your head, do your head a favor and navigate to Item 3, which explains what’s going on. There you’ll see that in C++14, the return type could be reduced to a simple decltype(auto):

template<typename FuncType,
         typename MuxType,
         typename PtrType>
decltype(auto) lockAndCall(FuncType func,        // C++14
                           MuxType& mutex,
                           PtrType ptr)
{
  using MuxGuard = std::lock_guard<MuxType>;
  
  MuxGuard g(mutex);
  return func(ptr);
}

Given the lockAndCall template (either version), callers can write code like this:

auto result1 = lockAndCall(f1, f1m, 0);          // error!

…

auto result2 = lockAndCall(f2, f2m, NULL);       // error!

…

auto result3 = lockAndCall(f3, f3m, nullptr);    // fine

Well, they can write it, but, as the comments indicate, in two of the three cases, the code won’t compile. The problem in the first call is that when 0 is passed to lockAndCall, template type deduction kicks in to figure out its type. The type of 0 is, was, and always will be int, so that’s the type of the parameter ptr inside the instantiation of this call to lockAndCall. Unfortunately, this means that in the call to func inside lockAndCall, an int is being passed, and that’s not compatible with the std::shared_ptr<Widget> parameter that f1 expects. The 0 passed in the call to lockAndCall was intended to represent a null pointer, but what actually got passed was a run-of-the-mill int. Trying to pass this int to f1 as a std::shared_ptr<Widget> is a type error. The call to lockAndCall with 0 fails because inside the template, an int is being passed to a function that requires a std::shared_ptr<Widget>.

The analysis for the call involving NULL is essentially the same. When NULL is passed to lockAndCall, an integral type is deduced for the parameter ptr, and a type error occurs when ptr—an int or int-like type—is passed to f2, which expects to get a std::unique_ptr<Widget>.

In contrast, the call involving nullptr has no trouble. When nullptr is passed to lockAndCall, the type for ptr is deduced to be std::nullptr_t. When ptr is passed to f3, there’s an implicit conversion from std::nullptr_t to Widget*, because std::nullptr_t implicitly converts to all pointer types.

The fact that template type deduction deduces the “wrong” types for 0 and NULL (i.e., their true types, rather than their fallback meaning as a representation for a null pointer) is the most compelling reason to use nullptr instead of 0 or NULL when you want to refer to a null pointer. With nullptr, templates pose no special challenge. Combined with the fact that nullptr doesn’t suffer from the overload resolution surprises that 0 and NULL are susceptible to, the case is ironclad. When you want to refer to a null pointer, use nullptr, not 0 or NULL.
Things to Remember

    Prefer nullptr to 0 and NULL.

    Avoid overloading on integral and pointer types.

				35.1.2.1.4   
Prefer alias declarations to typedefs.

I’m confident we can agree that using STL containers is a good idea, and I hope that Item 18 convinces you that using std::unique_ptr is a good idea, but my guess is that neither of us is fond of writing types like “std::unique_ptr<std::unordered_map<std::string, std::string>>” more than once. Just thinking about it probably increases the risk of carpal tunnel syndrome.

Avoiding such medical tragedies is easy. Introduce a typedef:

typedef
  std::unique_ptr<std::unordered_map<std::string, std::string>>
  UPtrMapSS;

But typedefs are soooo C++98. They work in C++11, sure, but C++11 also offers alias declarations:

using UPtrMapSS =
  std::unique_ptr<std::unordered_map<std::string, std::string>>;

Given that the typedef and the alias declaration do exactly the same thing, it’s reasonable to wonder whether there is a solid technical reason for preferring one over the other.

There is, but before I get to it, I want to mention that many people find the alias declaration easier to swallow when dealing with types involving function pointers:

// FP is a synonym for a pointer to a function taking an int and
// a const std::string& and returning nothing
typedef void (*FP)(int, const std::string&);      // typedef

// same meaning as above
using FP = void (*)(int, const std::string&);     // alias
                                                  // declaration

Of course, neither form is particularly easy to choke down, and few people spend much time dealing with synonyms for function pointer types, anyway, so this is hardly a compelling reason to choose alias declarations over typedefs.

But a compelling reason does exist: templates. In particular, alias declarations may be templatized (in which case they’re called alias templates), while typedefs cannot. This gives C++11 programmers a straightforward mechanism for expressing things that in C++98 had to be hacked together with typedefs nested inside templatized structs. For example, consider defining a synonym for a linked list that uses a custom allocator, MyAlloc. With an alias template, it’s a piece of cake:

template<typename T>                           // MyAllocList<T>
using MyAllocList = std::list<T, MyAlloc<T>>;  // is synonym for
                                               // std::list<T,
                                               //   MyAlloc<T>>

MyAllocList<Widget> lw;                        // client code

With a typedef, you pretty much have to create the cake from scratch:

template<typename T>                     // MyAllocList<T>::type
struct MyAllocList {                     // is synonym for
  typedef std::list<T, MyAlloc<T>> type; // std::list<T,
};                                       //   MyAlloc<T>>

MyAllocList<Widget>::type lw;            // client code

It gets worse. If you want to use the typedef inside a template for the purpose of creating a linked list holding objects of a type specified by a template parameter, you have to precede the typedef name with typename:

template<typename T>
class Widget {                         // Widget<T> contains
private:                               // a MyAllocList<T>
  typename MyAllocList<T>::type list;  // as a data member
  …
};

Here, MyAllocList<T>::type refers to a type that’s dependent on a template type parameter (T). MyAllocList<T>::type is thus a dependent type, and one of C++’s many endearing rules is that the names of dependent types must be preceded by typename.

If MyAllocList is defined as an alias template, this need for typename vanishes (as does the cumbersome “::type” suffix):

template<typename T>
using MyAllocList = std::list<T, MyAlloc<T>>;  // as before

template<typename T>
class Widget {
private:
  MyAllocList<T> list;                         // no "typename",
  …                                            // no "::type"
};

To you, MyAllocList<T> (i.e., use of the alias template) may look just as dependent on the template parameter T as MyAllocList<T>::type (i.e., use of the nested typedef), but you’re not a compiler. When compilers process the Widget template and encounter the use of MyAllocList<T> (i.e., use of the alias template), they know that MyAllocList<T> is the name of a type, because MyAllocList is an alias template: it must name a type. MyAllocList<T> is thus a non-dependent type, and a typename specifier is neither required nor permitted.

When compilers see MyAllocList<T>::type (i.e., use of the nested typedef) in the Widget template, on the other hand, they can’t know for sure that it names a type, because there might be a specialization of MyAllocList that they haven’t yet seen where MyAllocList<T>::type refers to something other than a type. That sounds crazy, but don’t blame compilers for this possibility. It’s the humans who have been known to produce such code.

 For example, some misguided soul may have concocted something like this:

class Wine { … };

template<>                       // MyAllocList specialization
class MyAllocList<Wine> {        // for when T is Wine
private:
  enum class WineType            // see Item 10 for info on
  { White, Red, Rose };          // "enum class"

  WineType type;                 // in this class, type is
  …                              // a data member!
};

As you can see, MyAllocList<Wine>::type doesn’t refer to a type. If Widget were to be instantiated with Wine, MyAllocList<T>::type inside the Widget template would refer to a data member, not a type. Inside the Widget template, then, whether MyAllocList<T>::type refers to a type is honestly dependent on what T is, and that’s why compilers insist on your asserting that it is a type by preceding it with typename.

If you’ve done any template metaprogramming (TMP), you’ve almost certainly bumped up against the need to take template type parameters and create revised types from them. For example, given some type T, you might want to strip off any const- or reference-qualifiers that T contains, e.g., you might want to turn const std::string& into std::string. Or you might want to add const to a type or turn it into an lvalue reference, e.g., turn Widget into const Widget or into Widget&. (If you haven’t done any TMP, that’s too bad, because if you want to be a truly effective C++ programmer, you need to be familiar with at least the basics of this facet of C++. You can see examples of TMP in action, including the kinds of type transformations I just mentioned, in Items 23 and 27.)

C++11 gives you the tools to perform these kinds of transformations in the form of type traits, an assortment of templates inside the header <type_traits>. There are dozens of type traits in that header, and not all of them perform type transformations, but the ones that do offer a predictable interface. Given a type T to which you’d like to apply a transformation, the resulting type is std::transformation<T>::type. For example:

std::remove_const<T>::type           // yields T from const T

std::remove_reference<T>::type       // yields T from T& and T&&

std::add_lvalue_reference<T>::type   // yields T& from T

The comments merely summarize what these transformations do, so don’t take them too literally. Before using them on a project, you’d look up the precise specifications, I know.

My motivation here isn’t to give you a tutorial on type traits, anyway. Rather, note that application of these transformations entails writing “::type” at the end of each use. If you apply them to a type parameter inside a template (which is virtually always how you employ them in real code), you’d also have to precede each use with typename. The reason for both of these syntactic speed bumps is that the C++11 type traits are implemented as nested typedefs inside templatized structs. That’s right, they’re implemented using the type synonym technology I’ve been trying to convince you is inferior to alias templates!

There’s a historical reason for that, but we’ll skip over it (it’s dull, I promise), because the Standardization Committee belatedly recognized that alias templates are the better way to go, and they included such templates in C++14 for all the C++11 type transformations. The aliases have a common form: for each C++11 transformation std::transformation<T>::type, there’s a corresponding C++14 alias template named std::transformation_t. Examples will clarify what I mean:

std::remove_const<T>::type           // C++11: const T → T
std::remove_const_t<T>               // C++14 equivalent

std::remove_reference<T>::type       // C++11: T&/T&& → T
std::remove_reference_t<T>           // C++14 equivalent

std::add_lvalue_reference<T>::type   // C++11: T → T&
std::add_lvalue_reference_t<T>       // C++14 equivalent

The C++11 constructs remain valid in C++14, but I don’t know why you’d want to use them. Even if you don’t have access to C++14, writing the alias templates yourself is child’s play. Only C++11 language features are required, and even children can mimic a pattern, right? If you happen to have access to an electronic copy of the C++14 Standard, it’s easier still, because all that’s required is some copying and pasting. Here, I’ll get you started:

template <class T>
using remove_const_t = typename remove_const<T>::type;

template <class T>
using remove_reference_t = typename remove_reference<T>::type;

template <class T>
using add_lvalue_reference_t =
  typename add_lvalue_reference<T>::type;

See? Couldn’t be easier.
Things to Remember

    typedefs don’t support templatization, but alias declarations do.

    Alias templates avoid the “::type” suffix and, in templates, the “typename” prefix often required to refer to typedefs.

    C++14 offers alias templates for all the C++11 type traits transformations.

				35.1.2.1.5   Prefer deleted functions to private undefined ones.

If you’re providing code to other developers, and you want to prevent them from calling a particular function, you generally just don’t declare the function. No function declaration, no function to call. Easy, peasy. But sometimes C++ declares functions for you, and if you want to prevent clients from calling those functions, the peasy isn’t quite so easy any more.

The situation arises only for the “special member functions,” i.e., the member functions that C++ automatically generates when they’re needed. Item 17 discusses these functions in detail, but for now, we’ll worry only about the copy constructor and the copy assignment operator. This chapter is largely devoted to common practices in C++98 that have been superseded by better practices in C++11, and in C++98, if you want to suppress use of a member function, it’s almost always the copy constructor, the assignment operator, or both.

The C++98 approach to preventing use of these functions is to declare them private and not define them. For example, near the base of the iostreams hierarchy in the C++ Standard Library is the class template basic_ios. All istream and ostream classes inherit (possibly indirectly) from this class. Copying istreams and ostreams is undesirable, because it’s not really clear what such operations should do. An istream object, for example, represents a stream of input values, some of which may have already been read, and some of which will potentially be read later. If an istream were to be copied, would that entail copying all the values that had already been read as well as all the values that would be read in the future? The easiest way to deal with such questions is to define them out of existence. Prohibiting the copying of streams does just that.

To render istream and ostream classes uncopyable, basic_ios is specified in C++98 as follows (including the comments):

template <class charT, class traits = char_traits<charT> >
class basic_ios : public ios_base {
public:
  …

private:
  basic_ios(const basic_ios& );            // not defined
  basic_ios& operator=(const basic_ios&);  // not defined
};

Declaring these functions private prevents clients from calling them. Deliberately failing to define them means that if code that still has access to them (i.e., member functions or friends of the class) uses them, linking will fail due to missing function definitions.

In C++11, there’s a better way to achieve essentially the same end: use “= delete” to mark the copy constructor and the copy assignment operator as deleted functions. Here’s the same part of basic_ios as it’s specified in C++11:

template <class charT, class traits = char_traits<charT> >
class basic_ios : public ios_base {
public:
  …
  basic_ios(const basic_ios& ) = delete;
  basic_ios& operator=(const basic_ios&) = delete;
  …
};

The difference between deleting these functions and declaring them private may seem more a matter of fashion than anything else, but there’s greater substance here than you might think. Deleted functions may not be used in any way, so even code that’s in member and friend functions will fail to compile if it tries to copy basic_ios objects. That’s an improvement over the C++98 behavior, where such improper usage wouldn’t be diagnosed until link-time.

By convention, deleted functions are declared public, not private. There’s a reason for that. When client code tries to use a member function, C++ checks accessibility before deleted status. When client code tries to use a deleted private function, some compilers complain only about the function being private, even though the function’s accessibility doesn’t really affect whether it can be used. It’s worth bearing this in mind when revising legacy code to replace private-and-not-defined member functions with deleted ones, because making the new functions public will generally result in better error messages.

An important advantage of deleted functions is that any function may be deleted, while only member functions may be private. For example, suppose we have a non-member function that takes an integer and returns whether it’s a lucky number:

bool isLucky(int number);

C++’s C heritage means that pretty much any type that can be viewed as vaguely numerical will implicitly convert to int, but some calls that would compile might not make sense:

if (isLucky('a')) …            // is 'a' a lucky number?

if (isLucky(true)) …           // is "true"?

if (isLucky(3.5)) …            // should we truncate to 3
                               // before checking for luckiness?

If lucky numbers must really be integers, we’d like to prevent calls such as these from compiling.

One way to accomplish that is to create deleted overloads for the types we want to filter out:

bool isLucky(int number);            // original function

bool isLucky(char) = delete;         // reject chars

bool isLucky(bool) = delete;         // reject bools

bool isLucky(double) = delete;       // reject doubles and
                                     // floats

(The comment on the double overload that says that both doubles and floats will be rejected may surprise you, but your surprise will dissipate once you recall that, given a choice between converting a float to an int or to a double, C++ prefers the conversion to double. Calling isLucky with a float will therefore call the double overload, not the int one. Well, it’ll try to. The fact that that overload is deleted will prevent the call from compiling.)

Although deleted functions can’t be used, they are part of your program. As such, they are taken into account during overload resolution. That’s why, with the deleted function declarations above, the undesirable calls to isLucky will be rejected:

if (isLucky('a')) …           // error! call to deleted function

if (isLucky(true)) …          // error!

if (isLucky(3.5f)) …          // error!

Another trick that deleted functions can perform (and that private member functions can’t) is to prevent use of template instantiations that should be disabled. For example, suppose you need a template that works with built-in pointers (Chapter 4’s advice to prefer smart pointers to raw pointers notwithstanding):

template<typename T>
void processPointer(T* ptr);

There are two special cases in the world of pointers. One is void* pointers, because there is no way to dereference them, to increment or decrement them, etc. The other is char* pointers, because they typically represent pointers to C-style strings, not pointers to individual characters. These special cases often call for special handling, and, in the case of the processPointer template, let’s assume the proper handling is to reject calls using those types. That is, it should not be possible to call processPointer with void* or char* pointers.

That’s easily enforced. Just delete those instantiations:

template<>
void processPointer<void>(void*) = delete;

template<>
void processPointer<char>(char*) = delete;

Now, if calling processPointer with a void* or a char* is invalid, it’s probably also invalid to call it with a const void* or a const char*, so those instantiations will typically need to be deleted, too:

template<>
void processPointer<const void>(const void*) = delete;

template<>
void processPointer<const char>(const char*) = delete;

And if you really want to be thorough, you’ll also delete the const volatile void* and const volatile char* overloads, and then you’ll get to work on the overloads for pointers to the other standard character types: wchar_t, char16_t, and char32_t.

Interestingly, if you have a function template inside a class, and you’d like to disable some instantiations by declaring them private (à la classic C++98 convention), you can’t, because it’s not possible to give a member function template specialization a different access level from that of the main template. If processPointer were a member function template inside Widget, for example, and you wanted to disable calls for void* pointers, this would be the C++98 approach, though it would not compile:

class Widget {
public:
  …
  template<typename T>
  void processPointer(T* ptr)
  { … }

private:
  template<>                                 // error!
  void processPointer<void>(void*);

};

The problem is that template specializations must be written at namespace scope, not class scope. This issue doesn’t arise for deleted functions, because they don’t need a different access level. They can be deleted outside the class (hence at namespace scope):

class Widget {
public:
  …
  template<typename T>
  void processPointer(T* ptr)
  { … }
  …

};

template<>                                          // still
void Widget::processPointer<void>(void*) = delete;  // public,
                                                    // but
                                                    // deleted

The truth is that the C++98 practice of declaring functions private and not defining them was really an attempt to achieve what C++11’s deleted functions actually accomplish. As an emulation, the C++98 approach is not as good as the real thing. It doesn’t work outside classes, it doesn’t always work inside classes, and when it does work, it may not work until link-time. So stick to deleted functions.
Things to Remember

    Prefer deleted functions to private undefined ones.

    Any function may be deleted, including non-member functions and template instantiations.

				35.1.2.1.6   Declare overriding functions override.

The world of object-oriented programming in C++ revolves around classes, inheritance, and virtual functions. Among the most fundamental ideas in this world is that virtual function implementations in derived classes override the implementations of their base class counterparts. It’s disheartening, then, to realize just how easily virtual function overriding can go wrong. It’s almost as if this part of the language were designed with the idea that Murphy’s Law wasn’t just to be obeyed, it was to be honored.

Because “overriding” sounds a lot like “overloading,” yet is completely unrelated, let me make clear that virtual function overriding is what makes it possible to invoke a derived class function through a base class interface:

class Base {
public:
  virtual void doWork();         // base class virtual function
  …
};

class Derived: public Base {
public:
  virtual void doWork();         // overrides Base::doWork
  …                              // ("virtual" is optional
};                               // here)

std::unique_ptr<Base> upb =      // create base class pointer
  std::make_unique<Derived>();   // to derived class object;
                                 // see Item 21 for info on
…                                // std::make_unique

upb->doWork();                   // call doWork through base
                                 // class ptr; derived class
                                 // function is invoked

For overriding to occur, several requirements must be met:

    The base class function must be virtual.

    The base and derived function names must be identical (except in the case of destructors).

    The parameter types of the base and derived functions must be identical.

    The constness of the base and derived functions must be identical.

    The return types and exception specifications of the base and derived functions must be compatible.

To these constraints, which were also part of C++98, C++11 adds one more:

    The functions’ reference qualifiers must be identical. Member function reference qualifiers are one of C++11’s less-publicized features, so don’t be surprised if you’ve never heard of them. They make it possible to limit use of a member function to lvalues only or to rvalues only. Member functions need not be virtual to use them:

    class Widget {
    public:
      …
      void doWork() &;       // this version of doWork applies
                             // only when *this is an lvalue

      void doWork() &&;      // this version of doWork applies
    };                       // only when *this is an rvalue

    …

    Widget makeWidget();     // factory function (returns rvalue)

    Widget w;                // normal object (an lvalue)

    …

    w.doWork();              // calls Widget::doWork for lvalues
                             // (i.e., Widget::doWork &)

    makeWidget().doWork();   // calls Widget::doWork for rvalues
                             // (i.e., Widget::doWork &&)

    I’ll say more about member functions with reference qualifiers later, but for now, simply note that if a virtual function in a base class has a reference qualifier, derived class overrides of that function must have exactly the same reference qualifier. If they don’t, the declared functions will still exist in the derived class, but they won’t override anything in the base class.

All these requirements for overriding mean that small mistakes can make a big difference. Code containing overriding errors is typically valid, but its meaning isn’t what you intended. You therefore can’t rely on compilers notifying you if you do something wrong. For example, the following code is completely legal and, at first sight, looks reasonable, but it contains no virtual function overrides—not a single derived class function that is tied to a base class function. Can you identify the problem in each case, i.e., why each derived class function doesn’t override the base class function with the same name?

class Base {
public:
  virtual void mf1() const;
  virtual void mf2(int x);
  virtual void mf3() &;
  void mf4() const;
};

class Derived: public Base {
public:
  virtual void mf1();
  virtual void mf2(unsigned int x);
  virtual void mf3() &&;
  void mf4() const;
};

Need some help?

    mf1 is declared const in Base, but not in Derived.

    mf2 takes an int in Base, but an unsigned int in Derived.

    mf3 is lvalue-qualified in Base, but rvalue-qualified in Derived.

    mf4 isn’t declared virtual in Base.

You may think, “Hey, in practice, these things will elicit compiler warnings, so I don’t need to worry.” Maybe that’s true. But maybe it’s not. With two of the compilers I checked, the code was accepted without complaint, and that was with all warnings enabled. (Other compilers provided warnings about some of the issues, but not all of them.)

Because declaring derived class overrides is important to get right, but easy to get wrong, C++11 gives you a way to make explicit that a derived class function is supposed to override a base class version: declare it override. Applying this to the example above would yield this derived class:

class Derived: public Base {
public:
  virtual void mf1() override;
  virtual void mf2(unsigned int x) override;
  virtual void mf3() && override;
  virtual void mf4() const override;
};

This won’t compile, of course, because when written this way, compilers will kvetch about all the overriding-related problems. That’s exactly what you want, and it’s why you should declare all your overriding functions override.

The code using override that does compile looks as follows (assuming that the goal is for all functions in Derived to override virtuals in Base):

class Base {
public:
  virtual void mf1() const;
  virtual void mf2(int x);
  virtual void mf3() &;
  virtual void mf4() const;
};

class Derived: public Base {
public:
  virtual void mf1() const override;
  virtual void mf2(int x) override;
  virtual void mf3() & override;
  void mf4() const override;          // adding "virtual" is OK,
};                                    // but not necessary

Note that in this example, part of getting things to work involves declaring mf4 virtual in Base. Most overriding-related errors occur in derived classes, but it’s possible for things to be incorrect in base classes, too.

A policy of using override on all your derived class overrides can do more than just enable compilers to tell you when would-be overrides aren’t overriding anything. It can also help you gauge the ramifications if you’re contemplating changing the signature of a virtual function in a base class. If derived classes use override everywhere, you can just change the signature, recompile your system, see how much damage you’ve caused (i.e., how many derived classes fail to compile), then decide whether the signature change is worth the trouble. Without override, you’d have to hope you have comprehensive unit tests in place, because, as we’ve seen, derived class virtuals that are supposed to override base class functions, but don’t, need not elicit compiler diagnostics.

C++ has always had keywords, but C++11 introduces two contextual keywords, override and final.2 These keywords have the characteristic that they are reserved, but only in certain contexts. In the case of override, it has a reserved meaning only when it occurs at the end of a member function declaration. That means that if you have legacy code that already uses the name override, you don’t need to change it for C++11:

class Warning {           // potential legacy class from C++98
public:
  …
  void override();        // legal in both C++98 and C++11
  …                       // (with the same meaning)
};

That’s all there is to say about override, but it’s not all there is to say about member function reference qualifiers. I promised I’d provide more information on them later, and now it’s later.

If we want to write a function that accepts only lvalue arguments, we declare a non-const lvalue reference parameter:

void doSomething(Widget& w);      // accepts only lvalue Widgets

If we want to write a function that accepts only rvalue arguments, we declare an rvalue reference parameter:

void doSomething(Widget&& w);     // accepts only rvalue Widgets

Member function reference qualifiers simply make it possible to draw the same distinction for the object on which a member function is invoked, i.e., *this. It’s precisely analogous to the const at the end of a member function declaration, which indicates that the object on which the member function is invoked (i.e., *this) is const.

The need for reference-qualified member functions is not common, but it can arise. For example, suppose our Widget class has a std::vector data member, and we offer an accessor function that gives clients direct access to it:

class Widget {
public:
  using DataType = std::vector<double>;      // see Item 9 for
  …                                          // info on "using"

  DataType& data() { return values; }
  …

private:
  DataType values;
};

This is hardly the most encapsulated design that’s seen the light of day, but set that aside and consider what happens in this client code:

Widget w;
…

auto vals1 = w.data();               // copy w.values into vals1

The return type of Widget::data is an lvalue reference (a std::vector<double>&, to be precise), and because lvalue references are defined to be lvalues, we’re initializing vals1 from an lvalue. vals1 is thus copy constructed from w.values, just as the comment says.

Now suppose we have a factory function that creates Widgets,

Widget makeWidget();

and we want to initialize a variable with the std::vector inside the Widget returned from makeWidget:

auto vals2 = makeWidget().data();    // copy values inside the
                                     // Widget into vals2

Again, Widgets::data returns an lvalue reference, and, again, the lvalue reference is an lvalue, so, again, our new object (vals2) is copy constructed from values inside the Widget. This time, though, the Widget is the temporary object returned from makeWidget (i.e., an rvalue), so copying the std::vector inside it is a waste of time. It’d be preferable to move it, but, because data is returning an lvalue reference, the rules of C++ require that compilers generate code for a copy. (There’s some wiggle room for optimization through what is known as the “as if rule,” but you’d be foolish to rely on your compilers finding a way to take advantage of it.)

What’s needed is a way to specify that when data is invoked on an rvalue Widget, the result should also be an rvalue. Using reference qualifiers to overload data for lvalue and rvalue Widgets makes that possible:

class Widget {
public:
  using DataType = std::vector<double>;
  …

  DataType& data() &                // for lvalue Widgets, 
  { return values; }                // return lvalue

  DataType&& data() &&              // for rvalue Widgets,
  { return std::move(values); }     // return rvalue
  …

private:
  DataType values;
};

Notice the differing return types from the data overloads. The lvalue reference overload returns an lvalue reference (i.e., an lvalue), and the rvalue reference overload returns an rvalue reference (which, as a function return type, is an rvalue). This means that client code now behaves as we’d like:

auto vals1 = w.data();             // calls lvalue overload for
                                   // Widget::data, copy-
                                   // constructs vals1

auto vals2 = makeWidget().data();  // calls rvalue overload for
                                   // Widget::data, move-
                                   // constructs vals2

This is certainly nice, but don’t let the warm glow of this happy ending distract you from the true point of this Item. That point is that whenever you declare a function in a derived class that’s meant to override a virtual function in a base class, be sure to declare that function override.

By the way, if a member function is reference qualified, all overloads of that function must be reference qualified. That’s because a non-reference-qualified overload may be invoked on both lvalue and rvalue objects. Such an overload would compete with reference-qualified overloads, and all calls to the function would be ambiguous.
Things to Remember

    Declare overriding functions override.

    Member function reference qualifiers make it possible to treat lvalue and rvalue objects (*this) differently.

				35.1.2.1.7   Prefer const_iterators to iterators.

const_iterators are the STL equivalent of pointers-to-const. They point to values that may not be modified. The standard practice of using const whenever possible dictates that you should use const_iterators any time you need an iterator, yet have no need to modify what the iterator points to.

That’s as true for C++98 as for C++11, but in C++98, const_iterators had only halfhearted support. It wasn’t that easy to create them, and once you had one, the ways you could use it were limited. For example, suppose you want to search a std::vector<int> for the first occurrence of 1983 (the year “C++” replaced “C with Classes” as the name of the programming language), then insert the value 1998 (the year the first ISO C++ Standard was adopted) at that location. If there’s no 1983 in the vector, the insertion should go at the end of the vector. Using iterators in C++98, that was easy:

std::vector<int> values;

…

std::vector<int>::iterator it =
  std::find(values.begin(),values.end(), 1983);
values.insert(it, 1998);

But iterators aren’t really the proper choice here, because this code never modifies what an iterator points to. Revising the code to use const_iterators should be trivial, but in C++98, it was anything but. Here’s one approach that’s conceptually sound, though still not correct:

typedef std::vector<int>::iterator IterT;             // type-
typedef std::vector<int>::const_iterator ConstIterT;  // defs

std::vector<int> values;

…

ConstIterT ci =
  std::find(static_cast<ConstIterT>(values.begin()),  // cast
            static_cast<ConstIterT>(values.end()),    // cast
            1983);

values.insert(static_cast<IterT>(ci), 1998);    // may not
                                                // compile; see
                                                // below

The typedefs aren’t required, of course, but they make the casts in the code easier to write. (If you’re wondering why I’m showing typedefs instead of following the advice of Item 9 to use alias declarations, it’s because this example shows C++98 code, and alias declarations are a feature new to C++11.)

The casts in the call to std::find are present because values is a non-const container and in C++98, there was no simple way to get a const_iterator from a non-const container. The casts aren’t strictly necessary, because it was possible to get const_iterators in other ways (e.g., you could bind values to a reference-to-const variable, then use that variable in place of values in your code), but one way or another, the process of getting const_iterators to elements of a non-const container involved some amount of contorting.

Once you had the const_iterators, matters often got worse, because in C++98, locations for insertions (and erasures) could be specified only by iterators. const_iterators weren’t acceptable. That’s why, in the code above, I cast the const_iterator (that I was so careful to get from std::find) into an iterator: passing a const_iterator to insert wouldn’t compile.

To be honest, the code I’ve shown might not compile, either, because there’s no portable conversion from a const_iterator to an iterator, not even with a static_cast. Even the semantic sledgehammer known as reinterpret_cast can’t do the job. (That’s not a C++98 restriction. It’s true in C++11, too. const_iterators simply don’t convert to iterators, no matter how much it might seem like they should.) There are some portable ways to generate iterators that point where const_iterators do, but they’re not obvious, not universally applicable, and not worth discussing in this book. Besides, I hope that by now my point is clear: const_iterators were so much trouble in C++98, they were rarely worth the bother. At the end of the day, developers don’t use const whenever possible, they use it whenever practical, and in C++98, const_iterators just weren’t very practical.

All that changed in C++11. Now const_iterators are both easy to get and easy to use. The container member functions cbegin and cend produce const_iterators, even for non-const containers, and STL member functions that use iterators to identify positions (e.g., insert and erase) actually use const_iterators. Revising the original C++98 code that uses iterators to use const_iterators in C++11 is truly trivial:

std::vector<int> values;                           // as before

…

auto it =                                          // use cbegin
  std::find(values.cbegin(),values.cend(), 1983);  // and cend

values.insert(it, 1998);

Now that’s code using const_iterators that’s practical!

About the only situation in which C++11’s support for const_iterators comes up a bit short is when you want to write maximally generic library code. Such code takes into account that some containers and container-like data structures offer begin and end (plus cbegin, cend, rbegin, etc.) as non-member functions, rather than members. This is the case for built-in arrays, for example, and it’s also the case for some third-party libraries with interfaces consisting only of free functions. Maximally generic code thus uses non-member functions rather than assuming the existence of member versions.

For example, we could generalize the code we’ve been working with into a findAndInsert template as follows:

template<typename C, typename V>
void findAndInsert(C& container,          // in container, find
                   const V& targetVal,    // first occurrence
                   const V& insertVal)    // of targetVal, then
{                                         // insert insertVal
  using std::cbegin;                      // there
  using std::cend;

  auto it = std::find(cbegin(container),  // non-member cbegin
                      cend(container),    // non-member cend
                      targetVal);

  container.insert(it, insertVal);
}

This works fine in C++14, but, sadly, not in C++11. Through an oversight during standardization, C++11 added the non-member functions begin and end, but it failed to add cbegin, cend, rbegin, rend, crbegin, and crend. C++14 rectifies that oversight.

If you’re using C++11, you want to write maximally generic code, and none of the libraries you’re using provides the missing templates for non-member cbegin and friends, you can throw your own implementations together with ease. For example, here’s an implementation of non-member cbegin:

template <class C>
auto cbegin(const C& container)->decltype(std::begin(container))
{
  return std::begin(container);         // see explanation below
}

You’re surprised to see that non-member cbegin doesn’t call member cbegin, aren’t you? So was I. But follow the logic. This cbegin template accepts any type of argument representing a container-like data structure, C, and it accesses this argument through its reference-to-const parameter, container. If C is a conventional container type (e.g., a std::vector<int>), container will be a reference to a const version of that container (e.g., a const std::vector<int>&). Invoking the non-member begin function (provided by C++11) on a const container yields a const_iterator, and that iterator is what this template returns. The advantage of implementing things this way is that it works even for containers that offer a begin member function (which, for containers, is what C++11’s non-member begin calls), but fail to offer a cbegin member. You can thus use this non-member cbegin on containers that directly support only begin.

This template also works if C is a built-in array type. In that case, container becomes a reference to a const array. C++11 provides a specialized version of non-member begin for arrays that returns a pointer to the array’s first element. The elements of a const array are const, so the pointer that non-member begin returns for a const array is a pointer-to-const, and a pointer-to-const is, in fact, a const_iterator for an array. (For insight into how a template can be specialized for built-in arrays, consult Item 1’s discussion of type deduction in templates that take reference parameters to arrays.)

But back to basics. The point of this Item is to encourage you to use const_iterators whenever you can. The fundamental motivation—using const whenever it’s meaningful—predates C++11, but in C++98, it simply wasn’t practical when working with iterators. In C++11, it’s eminently practical, and C++14 tidies up the few bits of unfinished business that C++11 left behind.
Things to Remember

    Prefer const_iterators to iterators.

    In maximally generic code, prefer non-member versions of begin, end, rbegin, etc., over their member function counterparts.

				35.1.2.1.8    Declare functions noexcept if they won’t emit exceptions.

In C++98, exception specifications were rather temperamental beasts. You had to summarize the exception types a function might emit, so if the function’s implementation was modified, the exception specification might require revision, too. Changing an exception specification could break client code, because callers might be dependent on the original exception specification. Compilers typically offered no help in maintaining consistency among function implementations, exception specifications, and client code. Most programmers ultimately decided that C++98 exception specifications weren’t worth the trouble.

During work on C++11, a consensus emerged that the truly meaningful information about a function’s exception-emitting behavior was whether it had any. Black or white, either a function might emit an exception or it guaranteed that it wouldn’t. This maybe-or-never dichotomy forms the basis of C++11’s exception specifications, which essentially replace C++98’s. (C++98-style exception specifications remain valid, but they’re deprecated.) In C++11, unconditional noexcept is for functions that guarantee they won’t emit exceptions.

Whether a function should be so declared is a matter of interface design. The exception-emitting behavior of a function is of key interest to clients. Callers can query a function’s noexcept status, and the results of such a query can affect the exception safety or efficiency of the calling code. As such, whether a function is noexcept is as important a piece of information as whether a member function is const. Failure to declare a function noexcept when you know that it won’t emit an exception is simply poor interface specification.

But there’s an additional incentive to apply noexcept to functions that won’t produce exceptions: it permits compilers to generate better object code. To understand why, it helps to examine the difference between the C++98 and C++11 ways of saying that a function won’t emit exceptions. Consider a function f that promises callers they’ll never receive an exception. The two ways of expressing that are:

int f(int x) throw();     // no exceptions from f: C++98 style

int f(int x) noexcept;    // no exceptions from f: C++11 style

If, at runtime, an exception leaves f, f’s exception specification is violated. With the C++98 exception specification, the call stack is unwound to f’s caller, and, after some actions not relevant here, program execution is terminated. With the C++11 exception specification, runtime behavior is slightly different: the stack is only possibly unwound before program execution is terminated.

The difference between unwinding the call stack and possibly unwinding it has a surprisingly large impact on code generation. In a noexcept function, optimizers need not keep the runtime stack in an unwindable state if an exception would propagate out of the function, nor must they ensure that objects in a noexcept function are destroyed in the inverse order of construction should an exception leave the function. Functions with “throw()” exception specifications lack such optimization flexibility, as do functions with no exception specification at all. The situation can be summarized this way:

RetType function(params) noexcept;     // most optimizable

RetType function(params) throw();      // less optimizable

RetType function(params);              // less optimizable

This alone is sufficient reason to declare functions noexcept whenever you know they won’t produce exceptions.

For some functions, the case is even stronger. The move operations are the preeminent example. Suppose you have a C++98 code base making use of a std::vector<Widget>. Widgets are added to the std::vector from time to time via push_back:

std::vector<Widget> vw;

…

Widget w;

…                        // work with w

vw.push_back(w);         // add w to vw

…

Assume this code works fine, and you have no interest in modifying it for C++11. However, you do want to take advantage of the fact that C++11’s move semantics can improve the performance of legacy code when move-enabled types are involved. You therefore ensure that Widget has move operations, either by writing them yourself or by seeing to it that the conditions for their automatic generation are fulfilled (see Item 17).

When a new element is added to a std::vector, it’s possible that the std::vector lacks space for it, i.e., that the std::vector’s size is equal to its capacity. When that happens, the std::vector allocates a new, larger, chunk of memory to hold its elements, and it transfers the elements from the existing chunk of memory to the new one. In C++98, the transfer was accomplished by copying each element from the old memory to the new memory, then destroying the objects in the old memory. This approach enabled push_back to offer the strong exception safety guarantee: if an exception was thrown during the copying of the elements, the state of the std::vector remained unchanged, because none of the elements in the old memory were destroyed until all elements had been successfully copied into the new memory.

In C++11, a natural optimization would be to replace the copying of std::vector elements with moves. Unfortunately, doing this runs the risk of violating push_back’s exception safety guarantee. If n elements have been moved from the old memory and an exception is thrown moving element n+1, the push_back operation can’t run to completion. But the original std::vector has been modified: n of its elements have been moved from. Restoring their original state may not be possible, because attempting to move each object back into the original memory may itself yield an exception.

This is a serious problem, because the behavior of legacy code could depend on push_back’s strong exception safety guarantee. Therefore, C++11 implementations can’t silently replace copy operations inside push_back with moves unless it’s known that the move operations won’t emit exceptions. In that case, having moves replace copies would be safe, and the only side effect would be improved performance.

std::vector::push_back takes advantage of this “move if you can, but copy if you must” strategy, and it’s not the only function in the Standard Library that does. Other functions sporting the strong exception safety guarantee in C++98 (e.g., std::vector::reserve, std::deque::insert, etc.) behave the same way. All these functions replace calls to copy operations in C++98 with calls to move operations in C++11 only if the move operations are known to not emit exceptions. But how can a function know if a move operation won’t produce an exception? The answer is obvious: it checks to see if the operation  is declared noexcept.3

swap functions comprise another case where noexcept is particularly desirable. swap is a key component of many STL algorithm implementations, and it’s commonly employed in copy assignment operators, too. Its widespread use renders the optimizations that noexcept affords especially worthwhile. Interestingly, whether swaps in the Standard Library are noexcept is sometimes dependent on whether user-defined swaps are noexcept. For example, the declarations for the Standard Library’s swaps for arrays and std::pair are:

template <class T, size_t N>
void swap(T (&a)[N],                                    // see
          T (&b)[N]) noexcept(noexcept(swap(*a, *b)));  // below

template <class T1, class T2>
struct pair {
  …
  void swap(pair& p) noexcept(noexcept(swap(first, p.first)) &&
                              noexcept(swap(second, p.second)));
  …
};

These functions are conditionally noexcept: whether they are noexcept depends on whether the expressions inside the noexcept clauses are noexcept. Given two arrays of Widget, for example, swapping them is noexcept only if swapping individual elements in the arrays is noexcept, i.e., if swap for Widget is noexcept. The author of Widget’s swap thus determines whether swapping arrays of Widget is noexcept. That, in turn, determines whether other swaps, such as the one for arrays of arrays of Widget, are noexcept. Similarly, whether swapping two std::pair objects containing Widgets is noexcept depends on whether swap for Widgets is noexcept. The fact that swapping higher-level data structures can generally be noexcept only if swapping their lower-level constituents is noexcept should motivate you to offer noexcept swap functions whenever you can.

By now, I hope you’re excited about the optimization opportunities that noexcept affords. Alas, I must temper your enthusiasm. Optimization is important, but correctness is more important. I noted at the beginning of this Item that noexcept is part of a function’s interface, so you should declare a function noexcept only if you are willing to commit to a noexcept implementation over the long term. If you declare a function noexcept and later regret that decision, your options are bleak. You can remove noexcept from the function’s declaration (i.e., change its interface), thus running the risk of breaking client code. You can change the implementation such that an exception could escape, yet keep the original (now incorrect) exception specification. If you do that, your program will be terminated if an exception tries to leave the function. Or you can resign yourself to your existing implementation, abandoning whatever kindled your desire to change the implementation in the first place. None of these options is appealing.

The fact of the matter is that most functions are exception-neutral. Such functions throw no exceptions themselves, but functions they call might emit one. When that happens, the exception-neutral function allows the emitted exception to pass through on its way to a handler further up the call chain. Exception-neutral functions are never noexcept, because they may emit such “just passing through” exceptions. Most functions, therefore, quite properly lack the noexcept designation.

Some functions, however, have natural implementations that emit no exceptions, and for a few more—notably the move operations and swap—being noexcept can have such a significant payoff, it’s worth implementing them in a noexcept manner if at all possible.4 When you can honestly say that a function should never emit exceptions, you should definitely declare it noexcept.

Please note that I said some functions have natural noexcept implementations. Twisting a function’s implementation to permit a noexcept declaration is the tail wagging the dog. Is putting the cart before the horse. Is not seeing the forest for the trees. Is…choose your favorite metaphor. If a straightforward function implementation might yield exceptions (e.g., by invoking a function that might throw), the hoops you’ll jump through to hide that from callers (e.g., catching all exceptions and replacing them with status codes or special return values) will not only complicate your function’s implementation, it will typically complicate code at call sites, too. For example, callers may have to check for status codes or special return values. The runtime cost of those complications (e.g., extra branches, larger functions that put more pressure on instruction caches, etc.) could exceed any speedup you’d hope to achieve via noexcept, plus you’d be saddled with source code that’s more difficult to comprehend and maintain. That’d be poor software engineering.

For some functions, being noexcept is so important, they’re that way by default. In C++98, it was considered bad style to permit the memory deallocation functions (i.e., operator delete and operator delete[]) and destructors to emit exceptions, and in C++11, this style rule has been all but upgraded to a language rule. By default, all memory deallocation functions and all destructors—both user-defined and compiler-generated—are implicitly noexcept. There’s thus no need to declare them noexcept. (Doing so doesn’t hurt anything, it’s just unconventional.) The only time a destructor is not implicitly noexcept is when a data member of the class (including inherited members and those contained inside other data members) is of a type that expressly states that its destructor may emit exceptions (e.g., declares it “noexcept(false)”). Such destructors are uncommon. There are none in the Standard Library, and if the destructor for an object being used by the Standard Library (e.g., because it’s in a container or was passed to an algorithm) emits an exception, the behavior of the program is undefined.

It’s worth noting that some library interface designers distinguish functions with wide contracts from those with narrow contracts. A function with a wide contract has no preconditions. Such a function may be called regardless of the state of the program, and it imposes no constraints on the arguments that callers pass it.5 Functions with wide contracts never exhibit undefined behavior.

Functions without wide contracts have narrow contracts. For such functions, if a precondition is violated, results are undefined.

If you’re writing a function with a wide contract and you know it won’t emit exceptions, following the advice of this Item and declaring it noexcept is easy. For functions with narrow contracts, the situation is trickier. For example, suppose you’re writing a function f taking a std::string parameter, and suppose f’s natural implementation never yields an exception. That suggests that f should be declared noexcept.

Now suppose that f has a precondition: the length of its std::string parameter doesn’t exceed 32 characters. If f were to be called with a std::string whose length is greater than 32, behavior would be undefined, because a precondition violation by definition results in undefined behavior. f is under no obligation to check this precondition, because functions may assume that their preconditions are satisfied. (Callers are responsible for ensuring that such assumptions are valid.) Even with a precondition, then, declaring f noexcept seems appropriate:

void f(const std::string& s) noexcept;    // precondition:
                                          // s.length() <= 32

But suppose that f’s implementer chooses to check for precondition violations. Checking isn’t required, but it’s also not forbidden, and checking the precondition could be useful, e.g., during system testing. Debugging an exception that’s been thrown is generally easier than trying to track down the cause of undefined behavior. But how should a precondition violation be reported such that a test harness or a client error handler could detect it? A straightforward approach would be to throw a “precondition was violated” exception, but if f is declared noexcept, that would be impossible; throwing an exception would lead to program termination. For this reason, library designers who distinguish wide from narrow contracts generally reserve noexcept for functions with wide contracts.

As a final point, let me elaborate on my earlier observation that compilers typically offer no help in identifying inconsistencies between function implementations and their exception specifications. Consider this code, which is perfectly legal:

void setup();           // functions defined elsewhere
void cleanup();

void doWork() noexcept
{
  setup();              // set up work to be done

  …                     // do the actual work

  cleanup();            // perform cleanup actions
}

Here, doWork is declared noexcept, even though it calls the non-noexcept functions setup and cleanup. This seems contradictory, but it could be that setup and cleanup document that they never emit exceptions, even though they’re not declared that way. There could be good reasons for their non-noexcept declarations. For example, they might be part of a library written in C. (Even functions from the C Standard Library that have been moved into the std namespace lack exception specifications, e.g., std::strlen isn’t declared noexcept.) Or they could be part of a C++98 library that decided not to use C++98 exception specifications and hasn’t yet been revised for C++11.

Because there are legitimate reasons for noexcept functions to rely on code lacking the noexcept guarantee, C++ permits such code, and compilers generally don’t issue warnings about it.
Things to Remember

    noexcept is part of a function’s interface, and that means that callers may depend on it.

    noexcept functions are more optimizable than non-noexcept functions.

    noexcept is particularly valuable for the move operations, swap, memory deallocation functions, and destructors.

    Most functions are exception-neutral rather than noexcept.

				35.1.2.1.9   Use constexpr whenever possible.

If there were an award for the most confusing new word in C++11, constexpr would probably win it. When applied to objects, it’s essentially a beefed-up form of const, but when applied to functions, it has a quite different meaning. Cutting through the confusion is worth the trouble, because when constexpr corresponds to what you want to express, you definitely want to use it.

Conceptually, constexpr indicates a value that’s not only constant, it’s known during compilation. The concept is only part of the story, though, because when constexpr is applied to functions, things are more nuanced than this suggests. Lest I ruin the surprise ending, for now I’ll just say that you can’t assume that the results of constexpr functions are const, nor can you take for granted that their values are known during compilation. Perhaps most intriguingly, these things are features. It’s good that constexpr functions need not produce results that are const or known during compilation!

But let’s begin with constexpr objects. Such objects are, in fact, const, and they do, in fact, have values that are known at compile time. (Technically, their values are determined during translation, and translation consists not just of compilation but also of linking. Unless you write compilers or linkers for C++, however, this has no effect on you, so you can blithely program as if the values of constexpr objects were determined during compilation.)

Values known during compilation are privileged. They may be placed in read-only memory, for example, and, especially for developers of embedded systems, this can be a feature of considerable importance. Of broader applicability is that integral values that are constant and known during compilation can be used in contexts where C++ requires an integral constant expression. Such contexts include specification of array sizes, integral template arguments (including lengths of std::array objects), enumerator values, alignment specifiers, and more. If you want to use a variable for these kinds of things, you certainly want to declare it constexpr, because then compilers will ensure that it has a compile-time value:

int sz;                             // non-constexpr variable

…

constexpr auto arraySize1 = sz;     // error! sz's value not
                                    // known at compilation

std::array<int, sz> data1;          // error! same problem

constexpr auto arraySize2 = 10;     // fine, 10 is a
                                    // compile-time constant

std::array<int, arraySize2> data2;  // fine, arraySize2
                                    // is constexpr

Note that const doesn’t offer the same guarantee as constexpr, because const objects need not be initialized with values known during compilation:

int sz;                             // as before

…

const auto arraySize = sz;          // fine, arraySize is
                                    // const copy of sz

std::array<int, arraySize> data;    // error! arraySize's value
                                    // not known at compilation

Simply put, all constexpr objects are const, but not all const objects are constexpr. If you want compilers to guarantee that a variable has a value that can be used in contexts requiring compile-time constants, the tool to reach for is constexpr, not const.

Usage scenarios for constexpr objects become more interesting when constexpr functions are involved. Such functions produce compile-time constants when they are called with compile-time constants. If they’re called with values not known until runtime, they produce runtime values. This may sound as if you don’t know what they’ll do, but that’s the wrong way to think about it. The right way to view it is this:

    constexpr functions can be used in contexts that demand compile-time constants. If the values of the arguments you pass to a constexpr function in such a context are known during compilation, the result will be computed during compilation. If any of the arguments’ values is not known during compilation, your code will be rejected.

    When a constexpr function is called with one or more values that are not known during compilation, it acts like a normal function, computing its result at runtime. This means you don’t need two functions to perform the same operation, one for compile-time constants and one for all other values. The constexpr function does it all.

Suppose we need a data structure to hold the results of an experiment that can be run in a variety of ways. For example, the lighting level can be high, low, or off during the course of the experiment, as can the fan speed and the temperature, etc. If there are n environmental conditions relevant to the experiment, each of which has three possible states, the number of combinations is 3n. Storing experimental results for all combinations of conditions thus requires a data structure with enough room for 3n values. Assuming each result is an int and that n is known (or can be computed) during compilation, a std::array could be a reasonable data structure choice. But we’d need a way to compute 3n during compilation. The C++ Standard Library provides std::pow, which is the mathematical functionality we need, but, for our purposes, there are two problems with it. First, std::pow works on floating-point types, and we need an integral result. Second, std::pow isn’t constexpr (i.e., isn’t guaranteed to return a compile-time result when called with compile-time values), so we can’t use it to specify a std::array’s size.

Fortunately, we can write the pow we need. I’ll show how to do that in a moment, but first let’s look at how it could be declared and used:

constexpr                              // pow's a constexpr func
int pow(int base, int exp) noexcept    // that never throws
{
  …                                    // impl is below
}

constexpr auto numConds = 5;                 // # of conditions

std::array<int, pow(3, numConds)> results;   // results has
                                             // 3^numConds
                                             // elements

Recall that the constexpr in front of pow doesn’t say that pow returns a const value, it says that if base and exp are compile-time constants, pow’s result may be used as a compile-time constant. If base and/or exp are not compile-time constants, pow’s result will be computed at runtime. That means that pow can not only be called to do things like compile-time-compute the size of a std::array, it can also be called in runtime contexts such as this:

auto base = readFromDB("base");       // get these values
auto exp = readFromDB("exponent");    // at runtime

auto baseToExp = pow(base, exp);      // call pow function
                                      // at runtime

Because constexpr functions must be able to return compile-time results when called with compile-time values, restrictions are imposed on their implementations. The restrictions differ between C++11 and C++14.

In C++11, constexpr functions may contain no more than a single executable statement: a return. That sounds more limiting than it is, because two tricks can be used to extend the expressiveness of constexpr functions beyond what you might think. First, the conditional “?:” operator can be used in place of if-else statements, and second, recursion can be used instead of loops. pow can therefore be implemented like this:

constexpr int pow(int base, int exp) noexcept
{
  return (exp == 0 ? 1 : base * pow(base, exp - 1));
}

This works, but it’s hard to imagine that anybody except a hard-core functional programmer would consider it pretty. In C++14, the restrictions on constexpr functions are substantially looser, so the following implementation becomes possible:

constexpr int pow(int base, int exp) noexcept       // C++14
{
  auto result = 1;
  for (int i = 0; i < exp; ++i) result *= base;

  return result;
}

constexpr functions are limited to taking and returning literal types, which essentially means types that can have values determined during compilation. In C++11, all built-in types except void qualify, but user-defined types may be literal, too, because constructors and other member functions may be constexpr:

class Point {
public:
  constexpr Point(double xVal = 0, double yVal = 0) noexcept
  : x(xVal), y(yVal)
  {}

  constexpr double xValue() const noexcept { return x; }
  constexpr double yValue() const noexcept { return y; }

  void setX(double newX) noexcept { x = newX; }
  void setY(double newY) noexcept { y = newY; }

private:
  double x, y;
};

Here, the Point constructor can be declared constexpr, because if the arguments passed to it are known during compilation, the value of the data members of the constructed Point can also be known during compilation. Points so initialized could thus be constexpr:

constexpr Point p1(9.4, 27.7);      // fine, "runs" constexpr
                                    // ctor during compilation

constexpr Point p2(28.8, 5.3);      // also fine

Similarly, the getters xValue and yValue can be constexpr, because if they’re invoked on a Point object with a value known during compilation (e.g., a constexpr Point object), the values of the data members x and y can be known during compilation. That makes it possible to write constexpr functions that call Point’s getters and to initialize constexpr objects with the results of such functions:

constexpr
Point midpoint(const Point& p1, const Point& p2) noexcept
{
  return { (p1.xValue() + p2.xValue()) / 2,    // call constexpr
           (p1.yValue() + p2.yValue()) / 2 };  // member funcs
}

constexpr auto mid= midpoint(p1, p2);     // init constexpr
                                           // object w/result of
                                           // constexpr function

This is very exciting. It means that the object mid, though its initialization involves calls to constructors, getters, and a non-member function, can be created in read-only memory! It means you could use an expression like mid.xValue() * 10 in an argument to a template or in an expression specifying the value of an enumerator!6 It means that the traditionally fairly strict line between work done during compilation and work done at runtime begins to blur, and some computations traditionally done at runtime can migrate to compile time. The more code taking part in the migration, the faster your software will run. (Compilation may take longer, however.)

In C++11, two restrictions prevent Point’s member functions setX and setY from being declared constexpr. First, they modify the object they operate on, and in C++11, constexpr member functions are implicitly const. Second, they have void return types, and void isn’t a literal type in C++11. Both these restrictions are lifted in C++14, so in C++14, even Point’s setters can be constexpr:

class Point {
public:
  …

  constexpr void setX(double newX) noexcept     // C++14
  { x = newX; }

  constexpr void setY(double newY) noexcept     // C++14
  { y = newY; }

  …

};

That makes it possible to write functions like this:

// return reflection of p with respect to the origin (C++14)
constexpr Point reflection(const Point& p) noexcept
{
  Point result;                       // create non-const Point

  result.setX(-p.xValue());           // set its x and y values
  result.setY(-p.yValue());

  return result;                      // return copy of it
}

Client code could look like this:

constexpr Point p1(9.4, 27.7);        // as above
constexpr Point p2(28.8, 5.3);
constexpr auto mid= midpoint(p1, p2);

constexpr auto reflectedMid=         // reflectedMid's value is
  reflection(mid);                    // (-19.1 -16.5) and known
                                      // during compilation

The advice of this Item is to use constexpr whenever possible, and by now I hope it’s clear why: both constexpr objects and constexpr functions can be employed in a wider range of contexts than non-constexpr objects and functions. By using constexpr whenever possible, you maximize the range of situations in which your objects and functions may be used.

It’s important to note that constexpr is part of an object’s or function’s interface. constexpr proclaims “I can be used in a context where C++ requires a constant expression.” If you declare an object or function constexpr, clients may use it in such contexts. If you later decide that your use of constexpr was a mistake and you remove it, you may cause arbitrarily large amounts of client code to stop compiling. (The simple act of adding I/O to a function for debugging or performance tuning could lead to such a problem, because I/O statements are generally not permitted in constexpr functions.) Part of “whenever possible” in “Use constexpr whenever possible” is your willingness to make a long-term commitment to the constraints it imposes on the objects and functions you apply it to.
Things to Remember

    constexpr objects are const and are initialized with values known during compilation.

    constexpr functions can produce compile-time results when called with arguments whose values are known during compilation.

    constexpr objects and functions may be used in a wider range of contexts than non-constexpr objects and functions.

    constexpr is part of an object’s or function’s interface.

				35.1.2.1.10  Make const member functions thread safe.

If we’re working in a mathematical domain, we might find it convenient to have a class representing polynomials. Within this class, it would probably be useful to have a function to compute the root(s) of a polynomial, i.e., values where the polynomial evaluates to zero. Such a function would not modify the polynomial, so it’d be natural to  declare it const:

class Polynomial {
public:
  using RootsType =          // data structure holding values
    std::vector<double>;     // where polynomial evals to zero
  …                          // (see Item 9 for info on "using")

  RootsType roots() const;

  …

};

Computing the roots of a polynomial can be expensive, so we don’t want to do it if we don’t have to. And if we do have to do it, we certainly don’t want to do it more than once. We’ll thus cache the root(s) of the polynomial if we have to compute them, and we’ll implement roots to return the cached value. Here’s the basic approach:

class Polynomial {
public:
  using RootsType = std::vector<double>;

  RootsType roots() const
  {
    if (!rootsAreValid) {            // if cache not valid

      …                              // compute roots,
                                     // store them in rootVals
      rootsAreValid= true;
    }

    return rootVals;
  }

private:
  mutable bool rootsAreValid{ false };    // see Item 7 for info
  mutable RootsType rootVals{};           // on initializers
};

Conceptually, roots doesn’t change the Polynomial object on which it operates, but, as part of its caching activity, it may need to modify rootVals and rootsAreValid. That’s a classic use case for mutable, and that’s why it’s part of the declarations for these data members.

Imagine now that two threads simultaneously call roots on a Polynomial object:

Polynomial p;

…


/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */

auto rootsOfP = p.roots();      auto valsGivingZero = p.roots();

This client code is perfectly reasonable. roots is a const member function, and that means it represents a read operation. Having multiple threads perform a read operation without synchronization is safe. At least it’s supposed to be. In this case, it’s not, because inside roots, one or both of these threads might try to modify the data members rootsAreValid and rootVals. That means that this code could have different threads reading and writing the same memory without synchronization, and that’s the definition of a data race. This code has undefined behavior.

The problem is that roots is declared const, but it’s not thread safe. The const declaration is as correct in C++11 as it would be in C++98 (retrieving the roots of a polynomial doesn’t change the value of the polynomial), so what requires rectification is the lack of thread safety.

The easiest way to address the issue is the usual one: employ a mutex:

class Polynomial {
public:
  using RootsType = std::vector<double>;

  RootsType roots() const
  {
    std::lock_guard<std::mutex> g(m);     // lock mutex

    if (!rootsAreValid) {                 // if cache not valid

      …                                   // compute/store roots

      rootsAreValid= true;
    }

    return rootVals;
  }                                       // unlock mutex

private:
  mutable std::mutex m;
  mutable bool rootsAreValid{ false };
  mutable RootsType rootVals{};
};

The std::mutex m is declared mutable, because locking and unlocking it are non-const member functions, and within roots (a const member function), m would otherwise be considered a const object.

It’s worth noting that because std::mutex can be neither copied nor moved, a side effect of adding m to Polynomial is that Polynomial loses the ability to be copied and moved.

In some situations, a mutex is overkill. For example, if all you’re doing is counting how many times a member function is called, a std::atomic counter (i.e, one where other threads are guaranteed to see its operations occur indivisibly—see Item 40) will often be a less expensive way to go. (Whether it actually is less expensive depends on the hardware you’re running on and the implementation of mutexes in your Standard Library.) Here’s how you can employ a std::atomic to count calls:

class Point {                                // 2D point
public:
  …

  double distanceFromOrigin() const noexcept     // see Item 14
  {                                              // for noexcept

    ++callCount;                             // atomic increment

    return std::hypot(x, y);                 // std::hypot is
  }                                          // new in C++11

private:
  mutable std::atomic<unsigned> callCount{ 0 };
  double x, y;
};

Like std::mutexes, std::atomics are uncopyable and unmovable, so the existence of callCount in Point means that Point is also neither copyable nor movable.

Because operations on std::atomic variables are often less expensive than mutex acquisition and release, you may be tempted to lean on std::atomics more heavily than you should. For example, in a class caching an expensive-to-compute int, you might try to use a pair of std::atomic variables instead of a mutex:

class Widget {
public:
  …

  int magicValue() const
  {
    if (cacheValid) return cachedValue;
    else {
      auto val1 = expensiveComputation1();
      auto val2 = expensiveComputation2();
      cachedValue = val1 + val2;               // uh oh, part 1
      cacheValid= true;                       // uh oh, part 2
      return cachedValue;
    }
  }

private:
  mutable std::atomic<bool> cacheValid{ false };
  mutable std::atomic<int> cachedValue;
};

This will work, but sometimes it will work a lot harder than it should. Consider:

    A thread calls Widget::magicValue, sees cacheValid as false, performs the two expensive computations, and assigns their sum to cachedValue.

    At that point, a second thread calls Widget::magicValue, also sees cacheValid as false, and thus carries out the same expensive computations that the first thread has just finished. (This “second thread” may in fact be several other threads.)

To eliminate this problem, you might consider reversing the order of the assignments to cachedValue and cacheValid, but you’d soon realize that (1) multiple threads could still compute val1 and val2 before cacheValid is set to true, thus defeating the point of the exercise, and (2) it would actually make things worse. Consider:

class Widget {
public:
  …

  int magicValue() const
  {
    if (cacheValid) return cachedValue;
    else {
      auto val1 = expensiveComputation1();
      auto val2 = expensiveComputation2();
      cacheValid= true;                        // uh oh, part 1
      return cachedValue = val1 + val2;         // uh oh, part 2
    }
  }

  …

};

Imagine that cacheValid is false, and then:

    One thread calls Widget::magicValue and executes through the point where cacheValid is set to true.

    At that moment, a second thread calls Widget::magicValue and checks cacheValid. Seeing it true, the thread returns cachedValue, even though the first thread has not yet made an assignment to it. The returned value is therefore incorrect.

There’s a lesson here. For a single variable or memory location requiring synchronization, use of a std::atomic is adequate, but once you get to two or more variables or memory locations that require manipulation as a unit, you should reach for a mutex. For Widget::magicValue, that would look like this:

class Widget {
public:
  …

  int magicValue() const
  {
    std::lock_guard<std::mutex> guard(m);   // lock m

    if (cacheValid) return cachedValue;
    else {
      auto val1 = expensiveComputation1();
      auto val2 = expensiveComputation2();
      cachedValue = val1 + val2;
      cacheValid= true;
      return cachedValue;
    }
  }                                         // unlock m
  …

private:
  mutable std::mutex m;
  mutable int cachedValue;                  // no longer atomic
  mutable bool cacheValid{ false };         // no longer atomic
};

Now, this Item is predicated on the assumption that multiple threads may simultaneously execute a const member function on an object. If you’re writing a const member function where that’s not the case—where you can guarantee that there will never be more than one thread executing that member function on an object—the thread safety of the function is immaterial. For example, it’s unimportant whether member functions of classes designed for exclusively single-threaded use are thread safe. In such cases, you can avoid the costs associated with mutexes and std::atomics, as well as the side effect of their rendering the classes containing them uncopyable and unmovable. However, such threading-free scenarios are increasingly uncommon, and they’re likely to become rarer still. The safe bet is that const member functions will be subject to concurrent execution, and that’s why you should ensure that your const member functions are thread safe.

 
Things to Remember

    Make const member functions thread safe unless you’re certain they’ll never be used in a concurrent context.

    Use of std::atomic variables may offer better performance than a mutex, but they’re suited for manipulation of only a single variable or memory location.

				35.1.2.1.11  Understand special member function generation.

In official C++ parlance, the special member functions are the ones that C++ is willing to generate on its own. C++98 has four such functions: the default constructor, the destructor, the copy constructor, and the copy assignment operator. There’s fine print, of course. These functions are generated only if they’re needed, i.e., if some code uses them without their being expressly declared in the class. A default constructor is generated only if the class declares no constructors at all. (This prevents compilers from creating a default constructor for a class where you’ve specified that constructor arguments are required.) Generated special member functions are implicitly public and inline, and they’re nonvirtual unless the function in question is a destructor in a derived class inheriting from a base class with a virtual destructor. In that case, the compiler-generated destructor for the derived class is also virtual.

But you already know these things. Yes, yes, ancient history: Mesopotamia, the Shang dynasty, FORTRAN, C++98. But times have changed, and the rules for special member function generation in C++ have changed with them. It’s important to be aware of the new rules, because few things are as central to effective C++ programming as knowing when compilers silently insert member functions into your classes.

As of C++11, the special member functions club has two more inductees: the move constructor and the move assignment operator. Their signatures are:

class Widget {
public:
  …
  Widget(Widget&& rhs);              // move constructor

  Widget& operator=(Widget&& rhs);   // move assignment operator
  …
};

The rules governing their generation and behavior are analogous to those for their copying siblings. The move operations are generated only if they’re needed, and if they are generated, they perform “memberwise moves” on the non-static data members of the class. That means that the move constructor move-constructs each non-static data member of the class from the corresponding member of its parameter rhs, and the move assignment operator move-assigns each non-static data member from its parameter. The move constructor also move-constructs its base class parts (if there are any), and the move assignment operator move-assigns its base class parts.

Now, when I refer to a move operation move-constructing or move-assigning a data member or base class, there is no guarantee that a move will actually take place. “Memberwise moves” are, in reality, more like memberwise move requests, because types that aren’t move-enabled (i.e., that offer no special support for move operations, e.g., most C++98 legacy classes) will be “moved” via their copy operations. The heart of each memberwise “move” is application of std::move to the object to be moved from, and the result is used during function overload resolution to determine whether a move or a copy should be performed. Item 23 covers this process in detail. For this Item, simply remember that a memberwise move consists of move operations on data members and base classes that support move operations, but a copy operation for those that don’t.

As is the case with the copy operations, the move operations aren’t generated if you declare them yourself. However, the precise conditions under which they are generated differ a bit from those for the copy operations.

The two copy operations are independent: declaring one doesn’t prevent compilers from generating the other. So if you declare a copy constructor, but no copy assignment operator, then write code that requires copy assignment, compilers will generate the copy assignment operator for you. Similarly, if you declare a copy assignment operator, but no copy constructor, yet your code requires copy construction, compilers will generate the copy constructor for you. That was true in C++98, and it’s still true in C++11.

The two move operations are not independent. If you declare either, that prevents compilers from generating the other. The rationale is that if you declare, say, a move constructor for your class, you’re indicating that there’s something about how move construction should be implemented that’s different from the default memberwise move that compilers would generate. And if there’s something wrong with memberwise move construction, there’d probably be something wrong with memberwise move assignment, too. So declaring a move constructor prevents a move assignment operator from being generated, and declaring a move assignment operator prevents compilers from generating a move constructor.

Furthermore, move operations won’t be generated for any class that explicitly declares a copy operation. The justification is that declaring a copy operation (construction or assignment) indicates that the normal approach to copying an object (memberwise copy) isn’t appropriate for the class, and compilers figure that if memberwise copy isn’t appropriate for the copy operations, memberwise move probably isn’t appropriate for the move operations.

This goes in the other direction, too. Declaring a move operation (construction or assignment) in a class causes compilers to disable the copy operations. (The copy operations are disabled by deleting them—see Item 11). After all, if memberwise move isn’t the proper way to move an object, there’s no reason to expect that memberwise copy is the proper way to copy it. This may sound like it could break C++98 code, because the conditions under which the copy operations are enabled are more constrained in C++11 than in C++98, but this is not the case. C++98 code can’t have move operations, because there was no such thing as “moving” objects in C++98. The only way a legacy class can have user-declared move operations is if they were added for C++11, and classes that are modified to take advantage of move semantics have to play by the C++11 rules for special member function generation.

Perhaps you’ve heard of a guideline known as the Rule of Three. The Rule of Three states that if you declare any of a copy constructor, copy assignment operator, or destructor, you should declare all three. It grew out of the observation that the need to take over the meaning of a copy operation almost always stemmed from the class performing some kind of resource management, and that almost always implied that (1) whatever resource management was being done in one copy operation probably needed to be done in the other copy operation and (2) the class destructor would also be participating in management of the resource (usually releasing it). The classic resource to be managed was memory, and this is why all Standard Library classes that manage memory (e.g., the STL containers that perform dynamic memory management) all declare “the big three”: both copy operations and a destructor. 

A consequence of the Rule of Three is that the presence of a user-declared destructor indicates that simple memberwise copy is unlikely to be appropriate for the copying operations in the class. That, in turn, suggests that if a class declares a destructor, the copy operations probably shouldn’t be automatically generated, because they wouldn’t do the right thing. At the time C++98 was adopted, the significance of this line of reasoning was not fully appreciated, so in C++98, the existence of a user-declared destructor had no impact on compilers’ willingness to generate copy operations. That continues to be the case in C++11, but only because restricting the conditions under which the copy operations are generated would break too much legacy code.

The reasoning behind the Rule of Three remains valid, however, and that, combined with the observation that declaration of a copy operation precludes the implicit generation of the move operations, motivates the fact that C++11 does not generate move operations for a class with a user-declared destructor.

So move operations are generated for classes (when needed) only if these three things are true:

    No copy operations are declared in the class.

    No move operations are declared in the class.

    No destructor is declared in the class.

At some point, analogous rules may be extended to the copy operations, because C++11 deprecates the automatic generation of copy operations for classes declaring copy operations or a destructor. This means that if you have code that depends on the generation of copy operations in classes declaring a destructor or one of the copy operations, you should consider upgrading these classes to eliminate the dependence. Provided the behavior of the compiler-generated functions is correct (i.e, if memberwise copying of the class’s non-static data members is what you want), your job is easy, because C++11’s “= default” lets you say that explicitly:

class Widget {
public:
  …
  ~Widget();                             // user-declared dtor

  …                                      // default copy ctor
  Widget(const Widget&) = default;       // behavior is OK

  Widget&                                // default copy assign
    operator=(const Widget&) = default;  // behavior is OK
  …
};

This approach is often useful in polymorphic base classes, i.e., classes defining interfaces through which derived class objects are manipulated. Polymorphic base classes normally have virtual destructors, because if they don’t, some operations (e.g., the use of delete or typeid on a derived class object through a base class pointer or reference) yield undefined or misleading results. Unless a class inherits a destructor that’s already virtual, the only way to make a destructor virtual is to explicitly declare it that way. Often, the default implementation would be correct, and “= default” is a good way to express that. However, a user-declared destructor suppresses generation of the move operations, so if movability is to be supported, “= default” often finds a second application. Declaring the move operations disables the copy operations, so if copyability is also desired, one more round of “= default” does the job:

class Base {
public:
  virtual ~Base() = default;                // make dtor virtual

  Base(Base&&) = default;                   // support moving
  Base& operator=(Base&&) = default;

  Base(const Base&) = default;              // support copying
  Base& operator=(const Base&) = default;

  …

};

In fact, even if you have a class where compilers are willing to generate the copy and move operations and where the generated functions would behave as you want, you may choose to adopt a policy of declaring them yourself and using “= default” for their definitions. It’s more work, but it makes your intentions clearer, and it can help you sidestep some fairly subtle bugs. For example, suppose you have a class representing a string table, i.e., a data structure that permits fast lookups of string values via an integer ID:

class StringTable {
public:
  StringTable() {}
  …                 // functions for insertion, erasure, lookup,
                    // etc., but no copy/move/dtor functionality

private:
  std::map<int, std::string> values;
};

Assuming that the class declares no copy operations, no move operations, and no destructor, compilers will automatically generate these functions if they are used. That’s very convenient.

But suppose that sometime later, it’s decided that logging the default construction and the destruction of such objects would be useful. Adding that functionality is easy:

class StringTable {
public:
  StringTable()
  { makeLogEntry("Creating StringTable object"); }     // added
  
  ~StringTable()                                       // also
  { makeLogEntry("Destroying StringTable object"); }   // added

  …                                     // other funcs as before

private:
  std::map<int, std::string> values;    // as before
};

This looks reasonable, but declaring a destructor has a potentially significant side effect: it prevents the move operations from being generated. However, creation of the class’s copy operations is unaffected. The code is therefore likely to compile, run, and pass its functional testing. That includes testing its move functionality, because even though this class is no longer move-enabled, requests to move it will compile and run. Such requests will, as noted earlier in this Item, cause copies to be made. Which means that code “moving” StringTable objects actually copies them, i.e., copies the underlying std::map<int, std::string> objects. And copying a std::map<int, std::string> is likely to be orders of magnitude slower than moving it. The simple act of adding a destructor to the class could thereby have introduced a significant performance problem! Had the copy and move operations been explicitly defined using “= default”, the problem would not have arisen.

Now, having endured my endless blathering about the rules governing the copy and move operations in C++11, you may wonder when I’ll turn my attention to the two other special member functions, the default constructor and the destructor. That time is now, but only for this sentence, because almost nothing has changed for these member functions: the rules in C++11 are nearly the same as in C++98.

The C++11 rules governing the special member functions are thus:

    Default constructor: Same rules as C++98. Generated only if the class contains no user-declared constructors.

    Destructor: Essentially same rules as C++98; sole difference is that destructors are noexcept by default (see Item 14). As in C++98, virtual only if a base class destructor is virtual.

    Copy constructor: Same runtime behavior as C++98: memberwise copy construction of non-static data members. Generated only if the class lacks a user-declared copy constructor. Deleted if the class declares a move operation. Generation of this function in a class with a user-declared copy assignment operator or destructor is deprecated.

    Copy assignment operator: Same runtime behavior as C++98: memberwise copy assignment of non-static data members. Generated only if the class lacks a user-declared copy assignment operator. Deleted if the class declares a move operation. Generation of this function in a class with a user-declared copy constructor or destructor is deprecated.

    Move constructor and move assignment operator: Each performs memberwise moving of non-static data members. Generated only if the class contains no user-declared copy operations, move operations, or destructor.

Note that there’s nothing in the rules about the existence of a member function template preventing compilers from generating the special member functions. That means that if Widget looks like this,

class Widget {
  …
  template<typename T>                // construct Widget
  Widget(const T& rhs);               // from anything

  template<typename T>                // assign Widget
  Widget& operator=(const T& rhs);    // from anything
  …
};

compilers will still generate copy and move operations for Widget (assuming the usual conditions governing their generation are fulfilled), even though these templates could be instantiated to produce the signatures for the copy constructor and copy assignment operator. (That would be the case when T is Widget.) In all likelihood, this will strike you as an edge case barely worth acknowledging, but there’s a reason I’m mentioning it. Item 26 demonstrates that it can have important consequences.
Things to Remember

    The special member functions are those compilers may generate on their own: default constructor, destructor, copy operations, and move operations.

    Move operations are generated only for classes lacking explicitly declared move operations, copy operations, or a destructor.

    The copy constructor is generated only for classes lacking an explicitly declared copy constructor, and it’s deleted if a move operation is declared. The copy assignment operator is generated only for classes lacking an explicitly declared copy assignment operator, and it’s deleted if a move operation is declared. Generation of the copy operations in classes with an explicitly declared destructor is deprecated.

    Member function templates never suppress generation of special member functions.

1 More flexible designs—ones that permit callers to determine whether parentheses or braces should be used in functions generated from a template—are possible. For details, see the 5 June 2013 entry of Andrzej’s C++ blog, “Intuitive interface — Part I.”

2 Applying final to a virtual function prevents the function from being overridden in derived classes. final may also be applied to a class, in which case the class is prohibited from being used as a base class.

3 The checking is typically rather roundabout. Functions like std::vector::push_back call std::move_if_noexcept, a variation of std::move that conditionally casts to an rvalue (see Item 23), depending on whether the type’s move constructor is noexcept. In turn, std::move_if_noexcept consults std::is_nothrow_move_constructible, and the value of this type trait (see Item 9) is set by compilers, based on whether the move constructor has a noexcept (or throw()) designation.

4 The interface specifications for move operations on containers in the Standard Library lack noexcept. However, implementers are permitted to strengthen exception specifications for Standard Library functions, and, in practice, it is common for at least some container move operations to be declared noexcept. That practice exemplifies this Item’s advice. Having found that it’s possible to write container move operations such that exceptions aren’t thrown, implementers often declare the operations noexcept, even though the Standard does not require them to do so.

5 “Regardless of the state of the program” and “no constraints” doesn’t legitimize programs whose behavior is already undefined. For example, std::vector::size has a wide contract, but that doesn’t require that it behave reasonably if you invoke it on a random chunk of memory that you’ve cast to a std::vector. The result of the cast is undefined, so there are no behavioral guarantees for the program containing the cast.

6 Because Point::xValue returns double, the type of mid.xValue() * 10 is also double. Floating-point types can’t be used to instantiate templates or to specify enumerator values, but they can be used as part of larger expressions that yield integral types. For example, static_cast<int>(mid.xValue() * 10) could be used to instantiate a template or to specify an enumerator value.

				35.1.2.1.12  Smart Pointers

Poets and songwriters have a thing about love. And sometimes about counting. Occasionally both. Inspired by the rather different takes on love and counting by Elizabeth Barrett Browning (“How do I love thee? Let me count the ways.”) and Paul Simon (“There must be 50 ways to leave your lover.”), we might try to enumerate the reasons why a raw pointer is hard to love:

    Its declaration doesn’t indicate whether it points to a single object or to an array.

    Its declaration reveals nothing about whether you should destroy what it points to when you’re done using it, i.e., if the pointer owns the thing it points to.

    If you determine that you should destroy what the pointer points to, there’s no way to tell how. Should you use delete, or is there a different destruction mechanism (e.g., a dedicated destruction function the pointer should be passed to)?

    If you manage to find out that delete is the way to go, Reason 1 means it may not be possible to know whether to use the single-object form (“delete”) or the array form (“delete []”). If you use the wrong form, results are undefined.

    Assuming you ascertain that the pointer owns what it points to and you discover how to destroy it, it’s difficult to ensure that you perform the destruction exactly once along every path in your code (including those due to exceptions). Missing a path leads to resource leaks, and doing the destruction more than once leads to undefined behavior.

    There’s typically no way to tell if the pointer dangles, i.e., points to memory that no longer holds the object the pointer is supposed to point to. Dangling pointers arise when objects are destroyed while pointers still point to them.

Raw pointers are powerful tools, to be sure, but decades of experience have demonstrated that with only the slightest lapse in concentration or discipline, these tools can turn on their ostensible masters.

Smart pointers are one way to address these issues. Smart pointers are wrappers around raw pointers that act much like the raw pointers they wrap, but that avoid many of their pitfalls. You should therefore prefer smart pointers to raw pointers. Smart pointers can do virtually everything raw pointers can, but with far fewer opportunities for error.

There are four smart pointers in C++11: std::auto_ptr, std::unique_ptr, std::shared_ptr, and std::weak_ptr. All are designed to help manage the lifetimes of dynamically allocated objects, i.e., to avoid resource leaks by ensuring that such objects are destroyed in the appropriate manner at the appropriate time (including in the event of exceptions).

std::auto_ptr is a deprecated leftover from C++98. It was an attempt to standardize what later became C++11’s std::unique_ptr. Doing the job right required move semantics, but C++98 didn’t have them. As a workaround, std::auto_ptr co-opted its copy operations for moves. This led to surprising code (copying a std::auto_ptr sets it to null!) and frustrating usage restrictions (e.g., it’s not possible to store std::auto_ptrs in containers).

std::unique_ptr does everything std::auto_ptr does, plus more. It does it as efficiently, and it does it without warping what it means to copy an object. It’s better than std::auto_ptr in every way. The only legitimate use case for std::auto_ptr is a need to compile code with C++98 compilers. Unless you have that constraint, you should replace std::auto_ptr with std::unique_ptr and never look back.

The smart pointer APIs are remarkably varied. About the only functionality common to all is default construction. Because comprehensive references for these APIs are widely available, I’ll focus my discussions on information that’s often missing from API overviews, e.g., noteworthy use cases, runtime cost analyses, etc. Mastering such information can be the difference between merely using these smart pointers and using them effectively.

					35.1.2.1.12.1  Use std::unique_ptr for exclusive-ownership resource management.

When you reach for a smart pointer, std::unique_ptr should generally be the one closest at hand. It’s reasonable to assume that, by default, std::unique_ptrs are the same size as raw pointers, and for most operations (including dereferencing), they execute exactly the same instructions. This means you can use them even in situations where memory and cycles are tight. If a raw pointer is small enough and fast enough for you, a std::unique_ptr almost certainly is, too.

std::unique_ptr embodies exclusive ownership semantics. A non-null std::unique_ptr always owns what it points to. Moving a std::unique_ptr transfers ownership from the source pointer to the destination pointer. (The source pointer is set to null.) Copying a std::unique_ptr isn’t allowed, because if you could copy a std::unique_ptr, you’d end up with two std::unique_ptrs to the same resource, each thinking it owned (and should therefore destroy) that resource. std::unique_ptr is thus a move-only type. Upon destruction, a non-null std::unique_ptr destroys its resource. By default, resource destruction is accomplished by applying delete to the raw pointer inside the std::unique_ptr.

A common use for std::unique_ptr is as a factory function return type for objects in a hierarchy. Suppose we have a hierarchy for types of investments (e.g., stocks, bonds, real estate, etc.) with a base class Investment.

class Investment { … };

class Stock:
  public Investment { … };

class Bond:
  public Investment { … };

class RealEstate:
  public Investment { … };

Image

A factory function for such a hierarchy typically allocates an object on the heap and returns a pointer to it, with the caller being responsible for deleting the object when it’s no longer needed. That’s a perfect match for std::unique_ptr, because the caller acquires responsibility for the resource returned by the factory (i.e., exclusive ownership of it), and the std::unique_ptr automatically deletes what it points to when the std::unique_ptr is destroyed. A factory function for the Investment hierarchy could be declared like this:

template<typename... Ts>              // return std::unique_ptr
std::unique_ptr<Investment>           // to an object created
makeInvestment(Ts&&... params);       // from the given args

Callers could use the returned std::unique_ptr in a single scope as follows,

{
  …
  auto pInvestment =              // pInvestment is of type
    makeInvestment( arguments );  // std::unique_ptr<Investment>

  …

}                                 // destroy *pInvestment

but they could also use it in ownership-migration scenarios, such as when the std::unique_ptr returned from the factory is moved into a container, the container element is subsequently moved into a data member of an object, and that object is later destroyed. When that happens, the object’s std::unique_ptr data member would also be destroyed, and its destruction would cause the resource returned from the factory to be destroyed. If the ownership chain got interrupted due to an exception or other atypical control flow (e.g., early function return or break from a loop), the std::unique_ptr owning the managed resource would eventually have its destructor called,1 and the resource it was managing would thereby be destroyed.

By default, that destruction would take place via delete, but, during construction, std::unique_ptr objects can be configured to use custom deleters: arbitrary functions (or function objects, including those arising from lambda expressions) to be invoked when it’s time for their resources to be destroyed. If the object created by makeInvestment shouldn’t be directly deleted, but instead should first have a log entry written, makeInvestment could be implemented as follows. (An explanation follows the code, so don’t worry if you see something whose motivation is less than obvious.)

auto delInvmt = [](Investment* pInvestment)       // custom
                {                                 // deleter
                  makeLogEntry(pInvestment);      // (a lambda
                  delete pInvestment;             // expression)
                };

template<typename... Ts>                          // revised
std::unique_ptr<Investment, decltype(delInvmt)>   // return type
makeInvestment(Ts&&... params)
{
  std::unique_ptr<Investment, decltype(delInvmt)> // ptr to be
    pInv(nullptr, delInvmt);                      // returned

  if ( /* a Stock object should be created */ )
  {
    pInv.reset(new Stock(std::forward<Ts>(params)...));
  }
  else if ( /* a Bond object should be created */ )
  {
    pInv.reset(new Bond(std::forward<Ts>(params)...));
  }
  else if ( /* a RealEstate object should be created */ )
  {
    pInv.reset(new RealEstate(std::forward<Ts>(params)...));
  }

  return pInv;
}

In a moment, I’ll explain how this works, but first consider how things look if you’re a caller. Assuming you store the result of the makeInvestment call in an auto variable, you frolic in blissful ignorance of the fact that the resource you’re using requires special treatment during deletion. In fact, you veritably bathe in bliss, because the use of std::unique_ptr means you need not concern yourself with when the resource should be destroyed, much less ensure that the destruction happens exactly once along every path through the program. std::unique_ptr takes care of all those things automatically. From a client’s perspective, makeInvestment’s interface is sweet.

The implementation is pretty nice, too, once you understand the following:

    delInvmt is the custom deleter for the object returned from makeInvestment. All custom deletion functions accept a raw pointer to the object to be destroyed, then do what is necessary to destroy that object. In this case, the action is to call makeLogEntry and then apply delete. Using a lambda expression to create delInvmt is convenient, but, as we’ll see shortly, it’s also more efficient than writing a conventional function.

    When a custom deleter is to be used, its type must be specified as the second type argument to std::unique_ptr. In this case, that’s the type of delInvmt, and that’s why the return type of makeInvestment is std::unique_ptr<Investment, decltype(delInvmt)>. (For information about decltype, see Item 3.)

    The basic strategy of makeInvestment is to create a null std::unique_ptr, make it point to an object of the appropriate type, and then return it. To associate the custom deleter delInvmt with pInv, we pass that as its second constructor argument.

    Attempting to assign a raw pointer (e.g., from new) to a std::unique_ptr won’t compile, because it would constitute an implicit conversion from a raw to a smart pointer. Such implicit conversions can be problematic, so C++11’s smart pointers prohibit them. That’s why reset is used to have pInv assume ownership of the object created via new.

    With each use of new, we use std::forward to perfect-forward the arguments passed to makeInvestment (see Item 25). This makes all the information provided by callers available to the constructors of the objects being created.

    The custom deleter takes a parameter of type Investment*. Regardless of the actual type of object created inside makeInvestment (i.e., Stock, Bond, or RealEstate), it will ultimately be deleted inside the lambda expression as an Investment* object. This means we’ll be deleting a derived class object via a base class pointer. For that to work, the base class—Investment—must have a virtual destructor:

    class Investment {
    public:
      …                                             // essential
      virtual ~Investment();                        // design
      …                                             // component!
    };

In C++14, the existence of function return type deduction (see Item 3) means that makeInvestment could be implemented in this simpler and more encapsulated fashion:

template<typename... Ts>
auto makeInvestment(Ts&&... params)              // C++14
{
  auto delInvmt = [](Investment* pInvestment)    // this is now
                  {                              // inside
                    makeLogEntry(pInvestment);   // make-
                    delete pInvestment;          // Investment
                  };

  std::unique_ptr<Investment, decltype(delInvmt)>   // as
    pInv(nullptr, delInvmt);                        // before

  if ( … )                                          // as before
  {
    pInv.reset(new Stock(std::forward<Ts>(params)...));
  }
  else if ( … )                                     // as before
  {
    pInv.reset(new Bond(std::forward<Ts>(params)...));
  }
  else if ( … )                                     // as before
  {
    pInv.reset(new RealEstate(std::forward<Ts>(params)...));
  }
  return pInv;                                      // as before
}

I remarked earlier that, when using the default deleter (i.e., delete), you can reasonably assume that std::unique_ptr objects are the same size as raw pointers. When custom deleters enter the picture, this may no longer be the case. Deleters that are function pointers generally cause the size of a std::unique_ptr to grow from one word to two. For deleters that are function objects, the change in size depends on how much state is stored in the function object. Stateless function objects (e.g., from lambda expressions with no captures) incur no size penalty, and this means that when a custom deleter can be implemented as either a function or a captureless lambda expression, the lambda is preferable:

auto delInvmt1 = [](Investment* pInvestment)      // custom
                 {                                // deleter
                   makeLogEntry(pInvestment);     // as
                   delete pInvestment;            // stateless
                 };                               // lambda

template<typename... Ts>                          // return type
std::unique_ptr<Investment, decltype(delInvmt1)>  // has size of
makeInvestment(Ts&&... args);                     // Investment*

void delInvmt2(Investment* pInvestment)           // custom
{                                                 // deleter
  makeLogEntry(pInvestment);                      // as function
  delete pInvestment;
}

template<typename... Ts>                 // return type has
std::unique_ptr<Investment,              // size of Investment*
                void (*)(Investment*)>   // plus at least size
makeInvestment(Ts&&... params);          // of function pointer!

Function object deleters with extensive state can yield std::unique_ptr objects of significant size. If you find that a custom deleter makes your std::unique_ptrs unacceptably large, you probably need to change your design.

Factory functions are not the only common use case for std::unique_ptrs. They’re even more popular as a mechanism for implementing the Pimpl Idiom. The code for that isn’t complicated, but in some cases it’s less than straightforward, so I’ll refer you to Item 22, which is dedicated to the topic.

std::unique_ptr comes in two forms, one for individual objects (std::unique_ptr<T>) and one for arrays (std::unique_ptr<T[]>). As a result, there’s never any ambiguity about what kind of entity a std::unique_ptr points to. The std::unique_ptr API is designed to match the form you’re using. For example, there’s no indexing operator (operator[]) for the single-object form, while the array form lacks dereferencing operators (operator* and operator->).

The existence of std::unique_ptr for arrays should be of only intellectual interest to you, because std::array, std::vector, and std::string are virtually always better data structure choices than raw arrays. About the only situation I can conceive of when a std::unique_ptr<T[]> would make sense would be when you’re using a C-like API that returns a raw pointer to a heap array that you assume ownership of.

std::unique_ptr is the C++11 way to express exclusive ownership, but one of its most attractive features is that it easily and efficiently converts to a std::shared_ptr:

std::shared_ptr<Investment> sp =    // converts std::unique_ptr
  makeInvestment( arguments );      // to std::shared_ptr

This is a key part of why std::unique_ptr is so well suited as a factory function return type. Factory functions can’t know whether callers will want to use exclusive-ownership semantics for the object they return or whether shared ownership (i.e., std::shared_ptr) would be more appropriate. By returning a std::unique_ptr, factories provide callers with the most efficient smart pointer, but they don’t hinder callers from replacing it with its more flexible sibling. (For information about std::shared_ptr, proceed to Item 19.)
Things to Remember

    std::unique_ptr is a small, fast, move-only smart pointer for managing resources with exclusive-ownership semantics.

    By default, resource destruction takes place via delete, but custom deleters can be specified. Stateful deleters and function pointers as deleters increase the size of std::unique_ptr objects.

    Converting a std::unique_ptr to a std::shared_ptr is easy.


- My example
r ~/Desktop/Work/code/C11/smartPtrs.cpp
/*
 * =====================================================================================
 *
 *       Filename:  smartPtrs.cpp
 *
 *    Description:  :Demo smart C11 pointers
 *
 *        Version:  1.0
 *        Created:  01/04/15 16:02:48
 *       Revision:  none
 *       Compiler:  gcc
 *
 *         Author:  YOSI IZAQ
 *   Organization:  
 *
 * =====================================================================================
 */
#include <stdlib.h>
#include <stdio.h>
#include <map>
#include <vector>
#include <string>
#include <iostream>

using namespace std;

class B 
{
	public:
		   virtual void f(int) {std::cout << "B::f" << std::endl;}
};

class D : public B
{
	public:
		   virtual void f(int) override final {std::cout << "D::f" << std::endl;}
};

//class F : public D
//{
//	public:
//		   virtual void f(int) override {std::cout << "F::f" << std::endl;}
//		   // Produces error :smartPtrs.cpp:42:19: error: declaration of 'f' overrides a 'final' function virtual void f(int) override {std::cout << "F::f" << std::endl;}
//};

enum class Options {None, One, All}; // scoped enum aka class enum
int main()
{
auto o = Options::All;
cout<<"Print scoped enum value: "<< static_cast<int>(o)<<endl; 

unique_ptr<int> iP;
iP.reset( new int{5}) ; // new universal initialization syntax
cout<<"Created unique_ptr to int, used reset to copy raw ptr: "<< *iP<<endl; 

auto iP2 = move(iP);
cout<<"Moved unique_ptr ownership, value: "<< *iP2<<endl; 

//"Custome delete function " 
auto delInt = [] (int * ip) {
	cout <<"Custome delete function called "<<endl;
	delete ip;
       };
unique_ptr<int, decltype(delInt)> iPD(nullptr, delInt);
iPD.reset( new int{4}) ; // new universal initialization syntax
cout<<"Created unique_ptr to int that has custome delete, value: "<< *iPD<<endl; 

}

[yizaq@YIZAQ-M-D1BW:Wed Sep 30:~/Desktop/Work/code/C11:]$ clang++ -std=c++14 -stdlib=libc++ -Weverything smartPtrs.cpp -o smartPtrs
[yizaq@YIZAQ-M-D1BW:Wed Sep 30:~/Desktop/Work/code/C11:]$ ./smartPtrs 
Print scoped enum value: 2
Created unique_ptr to int, used reset to copy raw ptr: 5
Moved unique_ptr ownership, value: 5
Created unique_ptr to int that has custome delete, value: 4
Custome delete function
					35.1.2.1.12.2  Use std::shared_ptr for shared-ownership resource management.

Programmers using languages with garbage collection point and laugh at what C++ programmers go through to prevent resource leaks. “How primitive!” they jeer. “Didn’t you get the memo from Lisp in the 1960s? Machines should manage resource lifetimes, not humans.” C++ developers roll their eyes. “You mean the memo where the only resource is memory and the timing of resource reclamation is nondeterministic? We prefer the generality and predictability of destructors, thank you.” But our bravado is part bluster. Garbage collection really is convenient, and manual lifetime management really can seem akin to constructing a mnemonic memory circuit using stone knives and bear skins.  Why can’t we have the best of both worlds: a system that works automatically (like garbage collection), yet applies to all resources and has predictable timing (like destructors)?

std::shared_ptr is the C++11 way of binding these worlds together. An object accessed via std::shared_ptrs has its lifetime managed by those pointers through shared ownership. No specific std::shared_ptr owns the object. Instead, all std::shared_ptrs pointing to it collaborate to ensure its destruction at the point where it’s no longer needed. When the last std::shared_ptr pointing to an object stops pointing there (e.g., because the std::shared_ptr is destroyed or made to point to a different object), that std::shared_ptr destroys the object it points to. As with garbage collection, clients need not concern themselves with managing the lifetime of pointed-to objects, but as with destructors, the timing of the objects’ destruction is deterministic.

A std::shared_ptr can tell whether it’s the last one pointing to a resource by consulting the resource’s reference count, a value associated with the resource that keeps track of how many std::shared_ptrs point to it. std::shared_ptr constructors increment this count (usually—see below), std::shared_ptr destructors decrement it, and copy assignment operators do both. (If sp1 and sp2 are std::shared_ptrs to different objects, the assignment “sp1 = sp2;” modifies sp1 such that it points to the object pointed to by sp2. The net effect of the assignment is that the reference count for the object originally pointed to by sp1 is decremented, while that for the object pointed to by sp2 is incremented.) If a std::shared_ptr sees a reference count of zero after performing a decrement, no more std::shared_ptrs point to the resource, so the std::shared_ptr destroys it.

The existence of the reference count has performance implications:

    std::shared_ptrs are twice the size of a raw pointer, because they internally contain a raw pointer to the resource as well as a raw pointer to the resource’s reference count.2

    Memory for the reference count must be dynamically allocated. Conceptually, the reference count is associated with the object being pointed to, but pointed-to objects know nothing about this. They thus have no place to store a reference count. (A pleasant implication is that any object—even those of built-in types—may be managed by std::shared_ptrs.) Item 21 explains that the cost of the dynamic allocation is avoided when the std::shared_ptr is created by std::make_shared, but there are situations where std::make_shared can’t be used. Either way, the reference count is stored as dynamically allocated data.

    Increments and decrements of the reference count must be atomic, because there can be simultaneous readers and writers in different threads. For example, a std::shared_ptr pointing to a resource in one thread could be executing its destructor (hence decrementing the reference count for the resource it points to), while, in a different thread, a std::shared_ptr to the same object could be copied (and therefore incrementing the same reference count). Atomic operations are typically slower than non-atomic operations, so even though reference counts are usually only a word in size, you should assume that reading and writing them is comparatively costly.

Did I pique your curiosity when I wrote that std::shared_ptr constructors only “usually” increment the reference count for the object they point to? Creating a std::shared_ptr pointing to an object always yields one more std::shared_ptr pointing to that object, so why mustn’t we always increment the reference count?

Move construction, that’s why. Move-constructing a std::shared_ptr from another std::shared_ptr sets the source std::shared_ptr to null, and that means that the old std::shared_ptr stops pointing to the resource at the moment the new std::shared_ptr starts. As a result, no reference count manipulation is required. Moving std::shared_ptrs is therefore faster than copying them: copying requires incrementing the reference count, but moving doesn’t. This is as true for assignment as for construction, so move construction is faster than copy construction, and move assignment is faster than copy assignment.

Like std::unique_ptr (see Item 18), std::shared_ptr uses delete as its default resource-destruction mechanism, but it also supports custom deleters. The design of this support differs from that for std::unique_ptr, however. For std::unique_ptr, the type of the deleter is part of the type of the smart pointer. For std::shared_ptr, it’s not:

auto loggingDel = [](Widget *pw)        // custom deleter
                  {                     // (as in Item 18)
                    makeLogEntry(pw);
                    delete pw;
                  };

std::unique_ptr<                        // deleter type is
  Widget, decltype(loggingDel)          // part of ptr type
  > upw(new Widget, loggingDel);

std::shared_ptr<Widget>                 // deleter type is not
  spw(new Widget, loggingDel);          // part of ptr type

The std::shared_ptr design is more flexible. Consider two std::shared_ptr<Widget>s, each with a custom deleter of a different type (e.g., because the custom deleters are specified via lambda expressions):

auto customDeleter1 = [](Widget *pw) { … };    // custom deleters,
auto customDeleter2 = [](Widget *pw) { … };    // each with a
                                               // different type

std::shared_ptr<Widget> pw1(new Widget, customDeleter1);
std::shared_ptr<Widget> pw2(new Widget, customDeleter2);

Because pw1 and pw2 have the same type, they can be placed in a container of objects of that type:

std::vector<std::shared_ptr<Widget>> vpw{ pw1, pw2 };

They could also be assigned to one another, and they could each be passed to a function taking a parameter of type std::shared_ptr<Widget>. None of these things can be done with std::unique_ptrs that differ in the types of their custom deleters, because the type of the custom deleter would affect the type of the std::unique_ptr.

In another difference from std::unique_ptr, specifying a custom deleter doesn’t change the size of a std::shared_ptr object. Regardless of deleter, a std::shared_ptr object is two pointers in size. That’s great news, but it should make you vaguely uneasy. Custom deleters can be function objects, and function objects can contain arbitrary amounts of data. That means they can be arbitrarily large. How can a std::shared_ptr refer to a deleter of arbitrary size without using any more memory?

It can’t. It may have to use more memory. However, that memory isn’t part of the std::shared_ptr object. It’s on the heap or, if the creator of the std::shared_ptr took advantage of std::shared_ptr support for custom allocators, it’s wherever the memory managed by the allocator is located. I remarked earlier that a std::shared_ptr object contains a pointer to the reference count for the object it points to. That’s true, but it’s a bit misleading, because the reference count is part of a larger data structure known as the control block. There’s a control block for each object managed by std::shared_ptrs. The control block contains, in addition to the reference count, a copy of the custom deleter, if one has been specified. If a custom allocator was specified, the control block contains a copy of that, too. The control block may also contain additional data, including, as Item 21 explains, a secondary reference count known as the weak count, but we’ll ignore such data in this Item. We can envision the memory associated with a std::shared_ptr<T> object as looking like this:
Image

An object’s control block is set up by the function creating the first std::shared_ptr to the object. At least that’s what’s supposed to happen. In general, it’s impossible for a function creating a std::shared_ptr to an object to know whether some other std::shared_ptr already points to that object, so the following rules for control block creation are used:

    std::make_shared (see Item 21) always creates a control block. It manufactures a new object to point to, so there is certainly no control block for that object at the time std::make_shared is called.

    A control block is created when a std::shared_ptr is constructed from a unique-ownership pointer (i.e., a std::unique_ptr or std::auto_ptr). Unique-ownership pointers don’t use control blocks, so there should be no control block for the pointed-to object. (As part of its construction, the std::shared_ptr assumes ownership of the pointed-to object, so the unique-ownership pointer is set to null.)

    When a std::shared_ptr constructor is called with a raw pointer, it creates a control block. If you wanted to create a std::shared_ptr from an object that already had a control block, you’d presumably pass a std::shared_ptr or a std::weak_ptr (see Item 20) as a constructor argument, not a raw pointer. std::shared_ptr constructors taking std::shared_ptrs or std::weak_ptrs as constructor arguments don’t create new control blocks, because they can rely on the smart pointers passed to them to point to any necessary control blocks.

A consequence of these rules is that constructing more than one std::shared_ptr from a single raw pointer gives you a complimentary ride on the particle accelerator of undefined behavior, because the pointed-to object will have multiple control blocks. Multiple control blocks means multiple reference counts, and multiple reference counts means the object will be destroyed multiple times (once for each reference count). That means that code like this is bad, bad, bad:

auto pw = new Widget;                          // pw is raw ptr

…

std::shared_ptr<Widget> spw1(pw, loggingDel);  // create control
                                               // block for *pw
…

std::shared_ptr<Widget> spw2(pw, loggingDel);  // create 2nd
                                               // control block
                                               // for *pw!

The creation of the raw pointer pw to a dynamically allocated object is bad, because it runs contrary to the advice behind this entire chapter: to prefer smart pointers to raw pointers. (If you’ve forgotten the motivation for that advice, refresh your memory here.) But set that aside. The line creating pw is a stylistic abomination, but at least it doesn’t cause undefined program behavior.

Now, the constructor for spw1 is called with a raw pointer, so it creates a control block (and thereby a reference count) for what’s pointed to. In this case, that’s *pw (i.e., the object pointed to by pw). In and of itself, that’s okay, but the constructor for spw2 is called with the same raw pointer, so it also creates a control block (hence a reference count) for *pw. *pw thus has two reference counts, each of which will eventually become zero, and that will ultimately lead to an attempt to destroy *pw twice. The second destruction is responsible for the undefined behavior.

There are at least two lessons regarding std::shared_ptr use here. First, try to avoid passing raw pointers to a std::shared_ptr constructor. The usual alternative is to use std::make_shared (see Item 21), but in the example above, we’re using custom deleters, and that’s not possible with std::make_shared. Second, if you must pass a raw pointer to a std::shared_ptr constructor, pass the result of new directly instead of going through a raw pointer variable. If the first part of the code above were rewritten like this,

std::shared_ptr<Widget> spw1(new Widget,    // direct use of new
                             loggingDel);

it’d be a lot less tempting to create a second std::shared_ptr from the same raw pointer. Instead, the author of the code creating spw2 would naturally use spw1 as an initialization argument (i.e., would call the std::shared_ptr copy constructor), and that would pose no problem whatsoever:

std::shared_ptr<Widget> spw2(spw1);     // spw2 uses same
                                        // control block as spw1

An especially surprising way that using raw pointer variables as std::shared_ptr constructor arguments can lead to multiple control blocks involves the this pointer. Suppose our program uses std::shared_ptrs to manage Widget objects, and we have a data structure that keeps track of Widgets that have been processed:

std::vector<std::shared_ptr<Widget>> processedWidgets;

Further suppose that Widget has a member function that does the processing:

class Widget {
public:
  …
  void process();
  …
};

Here’s a reasonable-looking approach for Widget::process:

void Widget::process()
{
  …                                       // process the Widget

  processedWidgets.emplace_back(this);    // add it to list of
}                                         // processed Widgets;
                                          // this is wrong!

The comment about this being wrong says it all—or at least most of it. (The part that’s wrong is the passing of this, not the use of emplace_back. If you’re not familiar with emplace_back, see Item 42.) This code will compile, but it’s passing a raw pointer (this) to a container of std::shared_ptrs. The std::shared_ptr thus constructed will create a new control block for the pointed-to Widget (*this). That doesn’t sound harmful until you realize that if there are std::shared_ptrs outside the member function that already point to that Widget, it’s game, set, and match for undefined behavior.

The std::shared_ptr API includes a facility for just this kind of situation. It has probably the oddest of all names in the Standard C++ Library: std::enable_shared_from_this. That’s a template for a base class you inherit from if you want a class managed by std::shared_ptrs to be able to safely create a std::shared_ptr from a this pointer. In our example, Widget would inherit from std::enable_shared_from_this as follows:

class Widget: public std::enable_shared_from_this<Widget> {
public:
  …
  void process();
  …
};

As I said, std::enable_shared_from_this is a base class template. Its type parameter is always the name of the class being derived, so Widget inherits from std::enable_shared_from_this<Widget>. If the idea of a derived class inheriting from a base class templatized on the derived class makes your head hurt, try not to think about it. The code is completely legal, and the design pattern behind it is so well established, it has a standard name, albeit one that’s almost as odd as std::enable_shared_from_this. The name is The Curiously Recurring Template Pattern (CRTP). If you’d like to learn more about it, unleash your search engine, because here we need to get back to std::enable_shared_from_this.

std::enable_shared_from_this defines a member function that creates a std::shared_ptr to the current object, but it does it without duplicating control blocks. The member function is shared_from_this, and you use it in member functions whenever you want a std::shared_ptr that points to the same object as the this pointer. Here’s a safe implementation of Widget::process:

void Widget::process()
{
  // as before, process the Widget
  …

  // add std::shared_ptr to current object to processedWidgets
  processedWidgets.emplace_back(shared_from_this());
}

Internally, shared_from_this looks up the control block for the current object, and it creates a new std::shared_ptr that refers to that control block. The design relies on the current object having an associated control block. For that to be the case, there must be an existing std::shared_ptr (e.g., one outside the member function calling shared_from_this) that points to the current object. If no such std::shared_ptr exists (i.e., if the current object has no associated control block), behavior is undefined, although shared_from_this typically throws an exception.

To prevent clients from calling member functions that invoke shared_from_this before a std::shared_ptr points to the object, classes inheriting from std::enable_shared_from_this often declare their constructors private and have clients create objects by calling factory functions that return std::shared_ptrs. Widget, for example, could look like this:

class Widget: public std::enable_shared_from_this<Widget> {
public:
  // factory function that perfect-forwards args
  // to a private ctor
  template<typename... Ts>
  static std::shared_ptr<Widget> create(Ts&&... params);

  …
  void process();             // as before
  …

private:
  …                           // ctors
};

By now, you may only dimly recall that our discussion of control blocks was motivated by a desire to understand the costs associated with std::shared_ptrs. Now that we understand how to avoid creating too many control blocks, let’s return to the original topic.

A control block is typically only a few words in size, although custom deleters and allocators may make it larger. The usual control block implementation is more sophisticated than you might expect. It makes use of inheritance, and there’s even a virtual function. (It’s used to ensure that the pointed-to object is properly destroyed.) That means that using std::shared_ptrs also incurs the cost of the machinery for the virtual function used by the control block.

Having read about dynamically allocated control blocks, arbitrarily large deleters and allocators, virtual function machinery, and atomic reference count manipulations, your enthusiasm for std::shared_ptrs may have waned somewhat. That’s fine. They’re not the best solution to every resource management problem. But for the functionality they provide, std::shared_ptrs exact a very reasonable cost. Under typical conditions, where the default deleter and default allocator are used and where the std::shared_ptr is created by std::make_shared, the control block is only about three words in size, and its allocation is essentially free. (It’s incorporated into the memory allocation for the object being pointed to. For details, see Item 21.) Dereferencing a std::shared_ptr is no more expensive than dereferencing a raw pointer. Performing an operation requiring a reference count manipulation (e.g., copy construction or copy assignment, destruction) entails one or two atomic operations, but these operations typically map to individual machine instructions, so although they may be expensive compared to non-atomic instructions, they’re still just single instructions. The virtual function machinery in the control block is generally used only once per object managed by std::shared_ptrs: when the object is destroyed.

In exchange for these rather modest costs, you get automatic lifetime management of dynamically allocated resources. Most of the time, using std::shared_ptr is vastly preferable to trying to manage the lifetime of an object with shared ownership by hand. If you find yourself doubting whether you can afford use of std::shared_ptr, reconsider whether you really need shared ownership. If exclusive ownership will do or even may do, std::unique_ptr is a better choice. Its performance profile is close to that for raw pointers, and “upgrading” from std::unique_ptr to std::shared_ptr is easy, because a std::shared_ptr can be created from a std::unique_ptr.

The reverse is not true. Once you’ve turned lifetime management of a resource over to a std::shared_ptr, there’s no changing your mind. Even if the reference count is one, you can’t reclaim ownership of the resource in order to, say, have a std::unique_ptr manage it. The ownership contract between a resource and the std::shared_ptrs that point to it is of the ’til-death-do-us-part variety. No divorce, no annulment, no dispensations.

Something else std::shared_ptrs can’t do is work with arrays. In yet another difference from std::unique_ptr, std::shared_ptr has an API that’s designed only for pointers to single objects. There’s no std::shared_ptr<T[]>. From time to time, “clever” programmers stumble on the idea of using a std::shared_ptr<T> to point to an array, specifying a custom deleter to perform an array delete (i.e., delete []). This can be made to compile, but it’s a horrible idea. For one thing, std::shared_ptr offers no operator[], so indexing into the array requires awkward expressions based on pointer arithmetic. For another, std::shared_ptr supports derived-to-base pointer conversions that make sense for single objects, but that open holes in the type system when applied to arrays. (For this reason, the std::unique_ptr<T[]> API prohibits such conversions.) Most importantly, given the variety of C++11 alternatives to built-in arrays (e.g., std::array, std::vector, std::string), declaring a smart pointer to a dumb array is almost always a sign of bad design.
Things to Remember

    std::shared_ptrs offer convenience approaching that of garbage collection for the shared lifetime management of arbitrary resources.

    Compared to std::unique_ptr, std::shared_ptr objects are typically twice as big, incur overhead for control blocks, and require atomic reference count manipulations.

    Default resource destruction is via delete, but custom deleters are supported. The type of the deleter has no effect on the type of the std::shared_ptr.

    Avoid creating std::shared_ptrs from variables of raw pointer type.

				35.1.2.1.13  Use std::weak_ptr for std::shared_ptr-like pointers that can dangle.

Paradoxically, it can be convenient to have a smart pointer that acts like a std::shared_ptr (see Item 19), but that doesn’t participate in the shared ownership of the pointed-to resource. In other words, a pointer like std::shared_ptr that doesn’t affect an object’s reference count. This kind of smart pointer has to contend with a problem unknown to std::shared_ptrs: the possibility that what it points to has been destroyed. A truly smart pointer would deal with this problem by tracking when it dangles, i.e., when the object it is supposed to point to no longer exists. That’s precisely the kind of smart pointer std::weak_ptr is. 

You may be wondering how a std::weak_ptr could be useful. You’ll probably wonder even more when you examine the std::weak_ptr API. It looks anything but smart. std::weak_ptrs can’t be dereferenced, nor can they be tested for nullness. That’s because std::weak_ptr isn’t a standalone smart pointer. It’s an augmentation of std::shared_ptr.

The relationship begins at birth. std::weak_ptrs are typically created from std::shared_ptrs. They point to the same place as the std::shared_ptrs initializing them, but they don’t affect the reference count of the object they point to:

auto spw =                       // after spw is constructed,
  std::make_shared<Widget>();    // the pointed-to Widget's
                                 // ref count (RC) is 1. (See
                                 // Item 21 for info on
                                 // std::make_shared.)
…

std::weak_ptr<Widget> wpw(spw);  // wpw points to same Widget
                                 // as spw. RC remains 1
…

spw = nullptr;                   // RC goes to 0, and the
                                 // Widget is destroyed.
                                 // wpw now dangles

std::weak_ptrs that dangle are said to have expired. You can test for this directly,

if (wpw.expired()) …             // if wpw doesn't point
                                 // to an object…

but often what you desire is a check to see if a std::weak_ptr has expired and, if it hasn’t (i.e., if it’s not dangling), to access the object it points to. This is easier desired than done. Because std::weak_ptrs lack dereferencing operations, there’s no way to write the code. Even if there were, separating the check and the dereference would introduce a race condition: between the call to expired and the dereferencing action, another thread might reassign or destroy the last std::shared_ptr pointing to the object, thus causing that object to be destroyed. In that case, your dereference would yield undefined behavior.

What you need is an atomic operation that checks to see if the std::weak_ptr has expired and, if not, gives you access to the object it points to. This is done by creating a std::shared_ptr from the std::weak_ptr. The operation comes in two forms, depending on what you’d like to have happen if the std::weak_ptr has expired when you try to create a std::shared_ptr from it. One form is std::weak_ptr::lock, which returns a std::shared_ptr. The std::shared_ptr is null if the std::weak_ptr has expired:

std::shared_ptr<Widget> spw1 = wpw.lock();  // if wpw's expired,
                                            // spw1 is null

auto spw2 = wpw.lock();                     // same as above,
                                            // but uses auto

The other form is the std::shared_ptr constructor taking a std::weak_ptr as an argument. In this case, if the std::weak_ptr has expired, an exception is thrown:

std::shared_ptr<Widget> spw3(wpw);    // if wpw's expired,
                                      // throw std::bad_weak_ptr

But you’re probably still wondering about how std::weak_ptrs can be useful. Consider a factory function that produces smart pointers to read-only objects based on a unique ID. In accord with Item 18’s advice regarding factory function return types, it returns a std::unique_ptr:

std::unique_ptr<const Widget> loadWidget(WidgetID id);

If loadWidget is an expensive call (e.g., because it performs file or database I/O) and it’s common for IDs to be used repeatedly, a reasonable optimization would be to write a function that does what loadWidget does, but also caches its results. Clogging the cache with every Widget that has ever been requested can lead to performance problems of its own, however, so another reasonable optimization would be to destroy cached Widgets when they’re no longer in use.

For this caching factory function, a std::unique_ptr return type is not a good fit. Callers should certainly receive smart pointers to cached objects, and callers should certainly determine the lifetime of those objects, but the cache needs a pointer to the objects, too. The cache’s pointers need to be able to detect when they dangle, because when factory clients are finished using an object returned by the factory, that object will be destroyed, and the corresponding cache entry will dangle. The cached pointers should therefore be std::weak_ptrs—pointers that can detect when they dangle. That means that the factory’s return type should be a std::shared_ptr, because std::weak_ptrs can detect when they dangle only when an object’s lifetime is managed by std::shared_ptrs.

Here’s a quick-and-dirty implementation of a caching version of loadWidget:

std::shared_ptr<const Widget> fastLoadWidget(WidgetID id)
{
  static std::unordered_map<WidgetID,
                            std::weak_ptr<const Widget>> cache;

  auto objPtr = cache[id].lock();   // objPtr is std::shared_ptr
                                    // to cached object (or null
                                    // if object's not in cache)

  if (!objPtr) {                    // if not in cache,
    objPtr = loadWidget(id);        // load it
    cache[id] = objPtr;             // cache it
  }
  return objPtr;
}

This implementation employs one of C++11’s hash table containers (std::unordered_map), though it doesn’t show the WidgetID hashing and equality-comparison functions that would also have to be present.

The implementation of fastLoadWidget ignores the fact that the cache may accumulate expired std::weak_ptrs corresponding to Widgets that are no longer in use (and have therefore been destroyed). The implementation can be refined, but rather than spend time on an issue that lends no additional insight into std::weak_ptrs, let’s consider a second use case: the Observer design pattern. The primary components of this pattern are subjects (objects whose state may change) and observers (objects to be notified when state changes occur). In most implementations, each subject contains a data member holding pointers to its observers. That makes it easy for subjects to issue state change notifications. Subjects have no interest in controlling the lifetime of their observers (i.e., when they’re destroyed), but they have a great interest in making sure that if an observer gets destroyed, subjects don’t try to subsequently access it. A reasonable design is for each subject to hold a container of std::weak_ptrs to its observers, thus making it possible for the subject to determine whether a pointer dangles before using it.

As a final example of std::weak_ptr’s utility, consider a data structure with objects A, B, and C in it, where A and C share ownership of B and therefore hold std::shared_ptrs to it:
Image

Suppose it’d be useful to also have a pointer from B back to A. What kind of pointer should this be?
Image

There are three choices:

    A raw pointer. With this approach, if A is destroyed, but C continues to point to B, B will contain a pointer to A that will dangle. B won’t be able to detect that, so B may inadvertently dereference the dangling pointer. That would yield undefined behavior.

    A std::shared_ptr. In this design, A and B contain std::shared_ptrs to each other. The resulting std::shared_ptr cycle (A points to B and B points to A) will prevent both A and B from being destroyed. Even if A and B are unreachable from other program data structures (e.g., because C no longer points to B), each will have a reference count of one. If that happens, A and B will have been leaked, for all practical purposes: it will be impossible for the program to access them, yet their resources will never be reclaimed.

    A std::weak_ptr. This avoids both problems above. If A is destroyed, B’s pointer back to it will dangle, but B will be able to detect that. Furthermore, though A and B will point to one another, B’s pointer won’t affect A’s reference count, hence can’t keep A from being destroyed when std::shared_ptrs no longer point to it.

Using std::weak_ptr is clearly the best of these choices. However, it’s worth noting that the need to employ std::weak_ptrs to break prospective cycles of std::shared_ptrs is not terribly common. In strictly hierarchal data structures such as trees, child nodes are typically owned only by their parents. When a parent node is destroyed, its child nodes should be destroyed, too. Links from parents to children are thus generally best represented by std::unique_ptrs. Back-links from children to parents can be safely implemented as raw pointers, because a child node should never have a lifetime longer than its parent. There’s thus no risk of a child node dereferencing a dangling parent pointer.

Of course, not all pointer-based data structures are strictly hierarchical, and when that’s the case, as well as in situations such as caching and the implementation of lists of observers, it’s nice to know that std::weak_ptr stands at the ready.

From an efficiency perspective, the std::weak_ptr story is essentially the same as that for std::shared_ptr. std::weak_ptr objects are the same size as std::shared_ptr objects, they make use of the same control blocks as std::shared_ptrs (see Item 19), and operations such as construction, destruction, and assignment involve atomic reference count manipulations. That probably surprises you, because I wrote at the beginning of this Item that std::weak_ptrs don’t participate in reference counting. Except that’s not quite what I wrote. What I wrote was that std::weak_ptrs don’t participate in the shared ownership of objects and hence don’t affect the pointed-to object’s reference count. There’s actually a second reference count in the control block, and it’s this second reference count that std::weak_ptrs manipulate. For details, continue on to Item 21.
Things to Remember

    Use std::weak_ptr for std::shared_ptr-like pointers that can dangle.

    Potential use cases for std::weak_ptr include caching, observer lists, and the prevention of std::shared_ptr cycles.

				35.1.2.1.14  Prefer std::make_unique and std::make_shared to direct use of new.

Let’s begin by leveling the playing field for std::make_unique and std::make_shared. std::make_shared is part of C++11, but, sadly, std::make_unique isn’t. It joined the Standard Library as of C++14. If you’re using C++11, never fear, because a basic version of std::make_unique is easy to write yourself. Here, look:

template<typename T, typename... Ts>
std::unique_ptr<T> make_unique(Ts&&... params)
{
  return std::unique_ptr<T>(new T(std::forward<Ts>(params)...));
}

As you can see, make_unique just perfect-forwards its parameters to the constructor of the object being created, constructs a std::unique_ptr from the raw pointer new produces, and returns the std::unique_ptr so created. This form of the function doesn’t support arrays or custom deleters (see Item 18), but it demonstrates that with only a little effort, you can create make_unique if you need to.3 Just remember not to put your version in namespace std, because you won’t want it to clash with a vendor-provided version when you upgrade to a C++14 Standard Library implementation.

std::make_unique and std::make_shared are two of the three make functions: functions that take an arbitrary set of arguments, perfect-forward them to the constructor for a dynamically allocated object, and return a smart pointer to that object. The third make function is std::allocate_shared. It acts just like std::make_shared, except its first argument is an allocator object to be used for the dynamic memory allocation.

Even the most trivial comparison of smart pointer creation using and not using a make function reveals the first reason why using such functions is preferable. Consider:

auto upw1(std::make_unique<Widget>());      // with make func

std::unique_ptr<Widget> upw2(new Widget);   // without make func


auto spw1(std::make_shared<Widget>());      // with make func

std::shared_ptr<Widget> spw2(new Widget);   // without make func

I’ve highlighted the essential difference: the versions using new repeat the type being created, but the make functions don’t. Repeating types runs afoul of a key tenet of software engineering: code duplication should be avoided. Duplication in source code increases compilation times, can lead to bloated object code, and generally renders a code base more difficult to work with. It often evolves into inconsistent code, and inconsistency in a code base often leads to bugs. Besides, typing something twice takes more effort than typing it once, and who’s not a fan of reducing their typing burden?

The second reason to prefer make functions has to do with exception safety. Suppose we have a function to process a Widget in accord with some priority:

void processWidget(std::shared_ptr<Widget> spw, int priority);

Passing the std::shared_ptr by value may look suspicious, but Item 41 explains that if processWidget always makes a copy of the std::shared_ptr (e.g., by storing it in a data structure tracking Widgets that have been processed), this can be a reasonable design choice.

Now suppose we have a function to compute the relevant priority,

int computePriority();

and we use that in a call to processWidget that uses new instead of std::make_shared:

processWidget(std::shared_ptr<Widget>(new Widget),  // potential
              computePriority());                   // resource
                                                    // leak!

As the comment indicates, this code could leak the Widget conjured up by new. But how? Both the calling code and the called function are using std::shared_ptrs, and std::shared_ptrs are designed to prevent resource leaks. They automatically destroy what they point to when the last std::shared_ptr pointing there goes away. If everybody is using std::shared_ptrs everywhere, how can this code leak?

The answer has to do with compilers’ translation of source code into object code. At runtime, the arguments for a function must be evaluated before the function can be invoked, so in the call to processWidget, the following things must occur before processWidget can begin execution:

    The expression “new Widget” must be evaluated, i.e., a Widget must be created on the heap.

    The constructor for the std::shared_ptr<Widget> responsible for managing the pointer produced by new must be executed.

    computePriority must run.

Compilers are not required to generate code that executes them in this order. “new Widget” must be executed before the std::shared_ptr constructor may be called, because the result of that new is used as an argument to that constructor, but computePriority may be executed before those calls, after them, or, crucially, between them. That is, compilers may emit code to execute the operations in this order:

    Perform “new Widget”.

    Execute computePriority.

    Run std::shared_ptr constructor.

If such code is generated and, at runtime, computePriority produces an exception, the dynamically allocated Widget from Step 1 will be leaked, because it will never be stored in the std::shared_ptr that’s supposed to start managing it in Step 3.

Using std::make_shared avoids this problem. Calling code would look like this:

processWidget(std::make_shared<Widget>(),   // no potential
              computePriority());           // resource leak

At runtime, either std::make_shared or computePriority will be called first. If it’s std::make_shared, the raw pointer to the dynamically allocated Widget is safely stored in the returned std::shared_ptr before computePriority is called. If computePriority then yields an exception, the std::shared_ptr destructor will see to it that the Widget it owns is destroyed. And if computePriority is called first and yields an exception, std::make_shared will not be invoked, and there will hence be no dynamically allocated Widget to worry about.

If we replace std::shared_ptr and std::make_shared with std::unique_ptr and std::make_unique, exactly the same reasoning applies. Using std::make_unique instead of new is thus just as important in writing exception-safe code as using std::make_shared.

A special feature of std::make_shared (compared to direct use of new) is improved efficiency. Using std::make_shared allows compilers to generate smaller, faster code that employs leaner data structures. Consider the following direct use of new:

std::shared_ptr<Widget> spw(new Widget);

It’s obvious that this code entails a memory allocation, but it actually performs two. Item 19 explains that every std::shared_ptr points to a control block containing, among other things, the reference count for the pointed-to object. Memory for this control block is allocated in the std::shared_ptr constructor. Direct use of new, then, requires one memory allocation for the Widget and a second allocation for the control block.

If std::make_shared is used instead,

auto spw = std::make_shared<Widget>();

one allocation suffices. That’s because std::make_shared allocates a single chunk of memory to hold both the Widget object and the control block. This optimization reduces the static size of the program, because the code contains only one memory allocation call, and it increases the speed of the executable code, because memory is allocated only once. Furthermore, using std::make_shared obviates the need for some of the bookkeeping information in the control block, potentially reducing the total memory footprint for the program.

The efficiency analysis for std::make_shared is equally applicable to std::allocate_shared, so the performance advantages of std::make_shared extend to that function, as well.

The arguments for preferring make functions over direct use of new are strong ones. Despite their software engineering, exception safety, and efficiency advantages, however, this Item’s guidance is to prefer the make functions, not to rely on them exclusively. That’s because there are circumstances where they can’t or shouldn’t be used.

For example, none of the make functions permit the specification of custom deleters (see Items 18 and 19), but both std::unique_ptr and std::shared_ptr have constructors that do. Given a custom deleter for a Widget,

auto widgetDeleter = [](Widget* pw) { … };

creating a smart pointer using it is straightforward using new:

std::unique_ptr<Widget, decltype(widgetDeleter)>
  upw(new Widget, widgetDeleter);

std::shared_ptr<Widget> spw(new Widget, widgetDeleter);

There’s no way to do the same thing with a make function.

A second limitation of make functions stems from a syntactic detail of their implementations. Item 7 explains that when creating an object whose type overloads constructors both with and without std::initializer_list parameters, creating the object using braces prefers the std::initializer_list constructor, while creating the object using parentheses calls the non-std::initializer_list constructor. The make functions perfect-forward their parameters to an object’s constructor, but do they do so using parentheses or using braces? For some types, the answer to this question makes a big difference. For example, in these calls,

auto upv = std::make_unique<std::vector<int>>(10, 20);

auto spv = std::make_shared<std::vector<int>>(10, 20);

do the resulting smart pointers point to std::vectors with 10 elements, each of value 20, or to std::vectors with two elements, one with value 10 and the other with value 20? Or is the result indeterminate?

The good news is that it’s not indeterminate: both calls create std::vectors of size 10 with all values set to 20. That means that within the make functions, the perfect forwarding code uses parentheses, not braces. The bad news is that if you want to construct your pointed-to object using a braced initializer, you must use new directly. Using a make function would require the ability to perfect-forward a braced initializer, but, as Item 30 explains, braced initializers can’t be perfect-forwarded. However, Item 30 also describes a workaround: use auto type deduction to create a std::initializer_list object from a braced initializer (see Item 2), then pass the auto-created object through the make function:

// create std::initializer_list
auto initList = { 10, 20 };

// create std::vector using std::initializer_list ctor
auto spv = std::make_shared<std::vector<int>>(initList);

For std::unique_ptr, these two scenarios (custom deleters and braced initializers) are the only ones where its make functions are problematic. For std::shared_ptr and its make functions, there are two more. Both are edge cases, but some developers live on the edge, and you may be one of them.

Some classes define their own versions of operator new and operator delete. The presence of these functions implies that the global memory allocation and deallocation routines for objects of these types are inappropriate. Often, class-specific routines are designed only to allocate and deallocate chunks of memory of precisely the size of objects of the class, e.g., operator new and operator delete for class Widget are often designed only to handle allocation and deallocation of chunks of memory of exactly size sizeof(Widget). Such routines are a poor fit for std::shared_ptr’s support for custom allocation (via std::allocate_shared) and deallocation (via custom deleters), because the amount of memory that std::allocate_shared requests isn’t the size of the dynamically allocated object, it’s the size of that object plus the size of a control block. Consequently, using make functions to create objects of types with class-specific versions of operator new and operator delete is typically a poor idea.

The size and speed advantages of std::make_shared vis-à-vis direct use of new stem from std::shared_ptr’s control block being placed in the same chunk of memory as the managed object. When that object’s reference count goes to zero, the object is destroyed (i.e., its destructor is called). However, the memory it occupies can’t be released until the control block has also been destroyed, because the same chunk of dynamically allocated memory contains both.

As I noted, the control block contains bookkeeping information beyond just the reference count itself. The reference count tracks how many std::shared_ptrs refer to the control block, but the control block contains a second reference count, one that tallies how many std::weak_ptrs refer to the control block. This second reference count is known as the weak count.4 When a std::weak_ptr checks to see if it has expired (see Item 19), it does so by examining the reference count (not the weak count) in the control block that it refers to. If the reference count is zero (i.e., if the pointed-to object has no std::shared_ptrs referring to it and has thus been destroyed), the std::weak_ptr has expired. Otherwise, it hasn’t.

As long as std::weak_ptrs refer to a control block (i.e., the weak count is greater than zero), that control block must continue to exist. And as long as a control block exists, the memory containing it must remain allocated. The memory allocated by a std::shared_ptr make function, then, can’t be deallocated until the last std::shared_ptr and the last std::weak_ptr referring to it have been destroyed.

If the object type is quite large and the time between destruction of the last std::shared_ptr and the last std::weak_ptr is significant, a lag can occur between when an object is destroyed and when the memory it occupied is freed:

class ReallyBigType { … };

auto pBigObj =                          // create very large
  std::make_shared<ReallyBigType>();    // object via
                                        // std::make_shared

…            // create std::shared_ptrs and std::weak_ptrs to
             // large object, use them to work with it

…            // final std::shared_ptr to object destroyed here,
             // but std::weak_ptrs to it remain

…            // during this period, memory formerly occupied
             // by large object remains allocated

…            // final std::weak_ptr to object destroyed here;
             // memory for control block and object is released

With a direct use of new, the memory for the ReallyBigType object can be released as soon as the last std::shared_ptr to it is destroyed:

class ReallyBigType { … };              // as before

std::shared_ptr<ReallyBigType> pBigObj(new ReallyBigType);
                                        // create very large
                                        // object via new

…            // as before, create std::shared_ptrs and
             // std::weak_ptrs to object, use them with it

…            // final std::shared_ptr to object destroyed here,
             // but std::weak_ptrs to it remain;
             // memory for object is deallocated

…            // during this period, only memory for the
             // control block remains allocated

…            // final std::weak_ptr to object destroyed here;
             // memory for control block is released

Should you find yourself in a situation where use of std::make_shared is impossible or inappropriate, you’ll want to guard yourself against the kind of exception-safety problems we saw earlier. The best way to do that is to make sure that when you use new directly, you immediately pass the result to a smart pointer constructor in a statement that does nothing else. This prevents compilers from generating code that could emit an exception between the use of new and invocation of the constructor for the smart pointer that will manage the newed object.

As an example, consider a minor revision to the exception-unsafe call to the processWidget function we examined earlier. This time, we’ll specify a custom deleter:

void processWidget(std::shared_ptr<Widget> spw,  // as before
                   int priority);

void cusDel(Widget *ptr);                        // custom
                                                 // deleter

Here’s the exception-unsafe call:

processWidget(                                   // as before,
  std::shared_ptr<Widget>(new Widget, cusDel),   // potential
  computePriority()                              // resource
);                                               // leak!

Recall: if computePriority is called after “new Widget” but before the std::shared_ptr constructor, and if computePriority yields an exception, the dynamically allocated Widget will be leaked.

Here the use of a custom deleter precludes use of std::make_shared, so the way to avoid the problem is to put the allocation of the Widget and the construction of the std::shared_ptr into their own statement, then call processWidget with the resulting std::shared_ptr. Here’s the essence of the technique, though, as we’ll see in a moment, we can tweak it to improve its performance:

std::shared_ptr<Widget> spw(new Widget, cusDel);

processWidget(spw, computePriority());     // correct, but not
                                           // optimal; see below

This works, because a std::shared_ptr assumes ownership of the raw pointer passed to its constructor, even if that constructor yields an exception. In this example, if spw’s constructor throws an exception (e.g., due to an inability to dynamically allocate memory for a control block), it’s still guaranteed that cusDel will be invoked on the pointer resulting from “new Widget”.

The minor performance hitch is that in the exception-unsafe call, we’re passing an rvalue to processWidget,

processWidget(
  std::shared_ptr<Widget>(new Widget, cusDel),  // arg is rvalue
  computePriority()
);

but in the exception-safe call, we’re passing an lvalue:

processWidget(spw, computePriority());          // arg is lvalue

Because processWidget’s std::shared_ptr parameter is passed by value, construction from an rvalue entails only a move, while construction from an lvalue requires a copy. For std::shared_ptr, the difference can be significant, because copying a std::shared_ptr requires an atomic increment of its reference count, while moving a std::shared_ptr requires no reference count manipulation at all. For the exception-safe code to achieve the level of performance of the exception-unsafe code, we need to apply std::move to spw to turn it into an rvalue (see Item 23):

processWidget(std::move(spw),            // both efficient and
              computePriority());        // exception safe

That’s interesting and worth knowing, but it’s also typically irrelevant, because you’ll rarely have a reason not to use a make function. And unless you have a compelling reason for doing otherwise, using a make function is what you should do.
Things to Remember

    Compared to direct use of new, make functions eliminate source code duplication, improve exception safety, and, for std::make_shared and std::allocate_shared, generate code that’s smaller and faster.

    Situations where use of make functions is inappropriate include the need to specify custom deleters and a desire to pass braced initializers.

    For std::shared_ptrs, additional situations where make functions may be ill-advised include (1) classes with custom memory management and (2) systems with memory concerns, very large objects, and std::weak_ptrs that outlive the corresponding std::shared_ptrs.

				35.1.2.1.15  When using the Pimpl Idiom, define special member functions in the implementation file.

If you’ve ever had to combat excessive build times, you’re familiar with the Pimpl (“pointer to implementation”) Idiom. That’s the technique whereby you replace the data members of a class with a pointer to an implementation class (or struct), put the data members that used to be in the primary class into the implementation class, and access those data members indirectly through the pointer. For example, suppose Widget looks like  this:

class Widget {                     // in header "widget.h"
public:
  Widget();
  …
private:
  std::string name;
  std::vector<double> data;
  Gadget g1, g2, g3;               // Gadget is some user-
};                                 // defined type

Because Widget’s data members are of types std::string, std::vector, and Gadget, headers for those types must be present for Widget to compile, and that means that Widget clients must #include <string>, <vector>, and gadget.h. Those headers increase the compilation time for Widget clients, plus they make those clients dependent on the contents of the headers. If a header’s content changes, Widget clients must recompile. The standard headers <string> and <vector> don’t change very often, but it could be that gadget.h is subject to frequent revision.

Applying the Pimpl Idiom in C++98 could have Widget replace its data members with a raw pointer to a struct that has been declared, but not defined:

class Widget {                 // still in header "widget.h"
public:
  Widget();
  ~Widget();                   // dtor is needed—see below
  …

private:
  struct Impl;                 // declare implementation struct
  Impl *pImpl;                 // and pointer to it
};

Because Widget no longer mentions the types std::string, std::vector, and Gadget, Widget clients no longer need to #include the headers for these types. That speeds compilation, and it also means that if something in these headers changes, Widget clients are unaffected.

A type that has been declared, but not defined, is known as an incomplete type. Widget::Impl is such a type. There are very few things you can do with an incomplete type, but declaring a pointer to it is one of them. The Pimpl Idiom takes advantage of that.

Part 1 of the Pimpl Idiom is the declaration of a data member that’s a pointer to an incomplete type. Part 2 is the dynamic allocation and deallocation of the object that holds the data members that used to be in the original class. The allocation and deallocation code goes in the implementation file, e.g., for Widget, in widget.cpp:

#include "widget.h"            // in impl. file "widget.cpp"
#include "gadget.h"
#include <string>
#include <vector>

struct Widget::Impl {          // definition of Widget::Impl
  std::string name;            // with data members formerly
  std::vector<double> data;    // in Widget
  Gadget g1, g2, g3;
};

Widget::Widget()               // allocate data members for
: pImpl(new Impl)              // this Widget object
{}

Widget::~Widget()              // destroy data members for
{ delete pImpl; }              // this object

Here I’m showing #include directives to make clear that the overall dependencies on the headers for std::string, std::vector, and Gadget continue to exist. However, these dependencies have been moved from widget.h (which is visible to and used by Widget clients) to widget.cpp (which is visible to and used only by the Widget implementer). I’ve also highlighted the code that dynamically allocates and deallocates the Impl object. The need to deallocate this object when a Widget is destroyed is what necessitates the Widget destructor.

But I’ve shown you C++98 code, and that reeks of a bygone millennium. It uses raw pointers and raw new and raw delete and it’s all just so…raw. This chapter is built on the idea that smart pointers are preferable to raw pointers, and if what we want is to dynamically allocate a Widget::Impl object inside the Widget constructor and have it destroyed at the same time the Widget is, std::unique_ptr (see Item 18) is precisely the tool we need. Replacing the raw pImpl pointer with a std::unique_ptr yields this code for the header file,

class Widget {                      // in "widget.h"
public:
  Widget();
  …

private:
  struct Impl; 
  std::unique_ptr<Impl> pImpl;      // use smart pointer
};                                  // instead of raw pointer

and this for the implementation file:

#include "widget.h"                 // in "widget.cpp"
#include "gadget.h"
#include <string>
#include <vector>

struct Widget::Impl {               // as before
  std::string name;
  std::vector<double> data;
  Gadget g1, g2, g3;
};

Widget::Widget()                    // per Item 21, create
: pImpl(std::make_unique<Impl>())   // std::unique_ptr
{}                                  // via std::make_unique

You’ll note that the Widget destructor is no longer present. That’s because we have no code to put into it. std::unique_ptr automatically deletes what it points to when it (the std::unique_ptr) is destroyed, so we need not delete anything ourselves. That’s one of the attractions of smart pointers: they eliminate the need for us to sully our hands with manual resource release.

This code compiles, but, alas, the most trivial client use doesn’t:

#include "widget.h"

Widget w;                           // error!

The error message you receive depends on the compiler you’re using, but the text generally mentions something about applying sizeof or delete to an incomplete type. Those operations aren’t among the things you can do with such types.

This apparent failure of the Pimpl Idiom using std::unique_ptrs is alarming, because (1) std::unique_ptr is advertised as supporting incomplete types, and (2) the Pimpl Idiom is one of std::unique_ptrs most common use cases. Fortunately, getting the code to work is easy. All that’s required is a basic understanding of the cause of the problem.

The issue arises due to the code that’s generated when w is destroyed (e.g., goes out of scope). At that point, its destructor is called. In the class definition using std::unique_ptr, we didn’t declare a destructor, because we didn’t have any code to put into it. In accord with the usual rules for compiler-generated special member functions (see Item 17), the compiler generates a destructor for us. Within that destructor, the compiler inserts code to call the destructor for Widget’s data member pImpl. pImpl is a std::unique_ptr<Widget::Impl>, i.e., a std::unique_ptr using the default deleter. The default deleter is a function that uses delete on the raw pointer inside the std::unique_ptr. Prior to using delete, however, implementations typically have the default deleter employ C++11’s static_assert to ensure that the raw pointer doesn’t point to an incomplete type. When the compiler generates code for the destruction of the Widget w, then, it generally encounters a static_assert that fails, and that’s usually what leads to the error message. This message is associated with the point where w is destroyed, because Widget’s destructor, like all compiler-generated special member functions, is implicitly inline. The message itself often refers to the line where w is created, because it’s the source code explicitly creating the object that leads to its later implicit destruction.

To fix the problem, you just need to make sure that at the point where the code to destroy the std::unique_ptr<Widget::Impl> is generated, Widget::Impl is a complete type. The type becomes complete when its definition has been seen, and Widget::Impl is defined inside widget.cpp. The key to successful compilation, then, is to have the compiler see the body of Widget’s destructor (i.e., the place where the compiler will generate code to destroy the std::unique_ptr data member) only inside widget.cpp after Widget::Impl has been defined.

Arranging for that is simple. Declare Widget’s destructor in widget.h, but don’t define it there:

class Widget {                     // as before, in "widget.h"
public:
  Widget();
  ~Widget();                       // declaration only
  …

private:                           // as before
  struct Impl;
  std::unique_ptr<Impl> pImpl;
};

Define it in widget.cpp after Widget::Impl has been defined:

#include "widget.h"                // as before, in "widget.cpp"
#include "gadget.h"
#include <string>
#include <vector>

struct Widget::Impl {              // as before, definition of
  std::string name;                // Widget::Impl
  std::vector<double> data;
  Gadget g1, g2, g3;
};

Widget::Widget()                   // as before
: pImpl(std::make_unique<Impl>())
{}

Widget::~Widget()                  // ~Widget definition
{}

This works well, and it requires the least typing, but if you want to emphasize that the compiler-generated destructor would do the right thing—that the only reason you declared it was to cause its definition to be generated in Widget’s implementation file, you can define the destructor body with “= default”:

Widget::~Widget() = default;       // same effect as above

Classes using the Pimpl Idiom are natural candidates for move support, because compiler-generated move operations do exactly what’s desired: perform a move on the underlying std::unique_ptr. As Item 17 explains, the declaration of a destructor in Widget prevents compilers from generating the move operations, so if you want move support, you must declare the functions yourself. Given that the compiler-generated versions would behave correctly, you’re likely to be tempted to implement them as follows:

class Widget {                                 // still in
public:                                        // "widget.h"
  Widget();
  ~Widget();

  Widget(Widget&& rhs) = default;              // right idea,
  Widget& operator=(Widget&& rhs) = default;   // wrong code!
 
  …

private:                                       // as before
  struct Impl;
  std::unique_ptr<Impl> pImpl;
};

This approach leads to the same kind of problem as declaring the class without a destructor, and for the same fundamental reason. The compiler-generated move assignment operator needs to destroy the object pointed to by pImpl before reassigning it, but in the Widget header file, pImpl points to an incomplete type. The situation is different for the move constructor. The problem there is that compilers typically generate code to destroy pImpl in the event that an exception arises inside the move constructor, and destroying pImpl requires that Impl be complete.

Because the problem is the same as before, so is the fix—move the definition of the move operations into the implementation file:

class Widget {                       // still in "widget.h"
public:
  Widget();
  ~Widget();

  Widget(Widget&& rhs);              // declarations
  Widget& operator=(Widget&& rhs);   // only

  …

private:                             // as before
  struct Impl;
  std::unique_ptr<Impl> pImpl;
};

#include <string>                    // as before,
…                                    // in "widget.cpp"

struct Widget::Impl { … };           // as before

Widget::Widget()                     // as before
: pImpl(std::make_unique<Impl>())
{}

Widget::~Widget() = default;         // as before

Widget::Widget(Widget&& rhs) = default;              // defini-
Widget& Widget::operator=(Widget&& rhs) = default;   // tions

The Pimpl Idiom is a way to reduce compilation dependencies between a class’s implementation and the class’s clients, but, conceptually, use of the idiom doesn’t change what the class represents. The original Widget class contained std::string, std::vector, and Gadget data members, and, assuming that Gadgets, like std::strings and std::vectors, can be copied, it would make sense for Widget to support the copy operations. We have to write these functions ourselves, because (1) compilers won’t generate copy operations for classes with move-only types like std::unique_ptr and (2) even if they did, the generated functions would copy only the std::unique_ptr (i.e., perform a shallow copy), and we want to copy what the pointer points to (i.e., perform a deep copy).

In a ritual that is by now familiar, we declare the functions in the header file and implement them in the implementation file:

class Widget {                         // still in "widget.h"
public:
  …                                    // other funcs, as before

  Widget(const Widget& rhs);              // declarations
  Widget& operator=(const Widget& rhs);   // only

private:                                  // as before
  struct Impl;
  std::unique_ptr<Impl> pImpl;
};


#include "widget.h"                  // as before,
…                                    // in "widget.cpp"

struct Widget::Impl { … };           // as before

Widget::~Widget() = default;         // other funcs, as before

Widget::Widget(const Widget& rhs)              // copy ctor
: pImpl(nullptr)
{ if (rhs.pImpl) pImpl = std::make_unique<Impl>(*rhs.pImpl); }

Widget& Widget::operator=(const Widget& rhs)   // copy operator=
{
  if (!rhs.pImpl) pImpl.reset();
  else if (!pImpl) pImpl = std::make_unique<Impl>(*rhs.pImpl);
  else *pImpl = *rhs.pImpl;

  return *this;
}

The implementations are straightforward, though we must handle cases where the parameter rhs or, in the case of the copy assignment operator, *this has been moved from and thus contains a null pImpl pointer. In general, we take advantage of the fact that compilers will create the copy operations for Impl, and these operations will copy each field automatically. We thus implement Widget’s copy operations by calling Widget::Impl’s compiler-generated copy operations. In both functions, note that we still follow the advice of Item 21 to prefer use of std::make_unique over direct use of new.

For purposes of implementing the Pimpl Idiom, std::unique_ptr is the smart pointer to use, because the pImpl pointer inside an object (e.g., inside a Widget) has exclusive ownership of the corresponding implementation object (e.g., the Widget::Impl object). Still, it’s interesting to note that if we were to use std::shared_ptr instead of std::unique_ptr for pImpl (i.e., if the values in an Impl struct could be shared by multiple Widgets), we’d find that the advice of this Item no longer applied. There’d be no need to declare a destructor in Widget, and without a user-declared destructor, compilers would happily generate the move operations, which would do exactly what we’d want them to. That is, given this code in widget.h,

class Widget {                     // in "widget.h"
public:
  Widget();
  …                                // no declarations for dtor
                                   // or move operations
private:
  struct Impl; 
  std::shared_ptr<Impl> pImpl;     // std::shared_ptr
};                                 // instead of std::unique_ptr

and this client code that #includes widget.h,

Widget w1;

auto w2(std::move(w1));            // move-construct w2

w1 = std::move(w2);                // move-assign w1

everything would compile and run as we’d hope: w1 would be default constructed, its value would be moved into w2, that value would be moved back into w1, and then both w1 and w2 would be destroyed (thus causing the pointed-to Widget::Impl object to be destroyed).

The difference in behavior between std::unique_ptr and std::shared_ptr for pImpl pointers stems from the differing ways these smart pointers support custom deleters. For std::unique_ptr, the type of the deleter is part of the type of the smart pointer, and this makes it possible for compilers to generate smaller runtime data structures and faster runtime code. A consequence of this greater efficiency is that pointed-to types must be complete when compiler-generated special functions (e.g., destructors or move operations) are used. For std::shared_ptr, the type of the deleter is not part of the type of the smart pointer. This necessitates larger runtime data structures and somewhat slower code, but pointed-to types need not be complete when compiler-generated special functions are employed.

For the Pimpl Idiom, there’s not really a trade-off between the characteristics of std::unique_ptr and std::shared_ptr, because the relationship between classes like Widget and classes like Widget::Impl is exclusive ownership, and that makes std::unique_ptr the proper tool for the job. Nevertheless, it’s worth knowing that in other situations—situations where shared ownership exists (and std::shared_ptr is hence a fitting design choice), there’s no need to jump through the function-definition hoops that use of std::unique_ptr entails.
Things to Remember

    The Pimpl Idiom decreases build times by reducing compilation dependencies between class clients and class implementations.

    For std::unique_ptr pImpl pointers, declare special member functions in the class header, but implement them in the implementation file. Do this even if the default function implementations are acceptable.

    The above advice applies to std::unique_ptr, but not to std::shared_ptr.

1 There are a few exceptions to this rule. Most stem from abnormal program termination. If an exception propagates out of a thread’s primary function (e.g., main, for the program’s initial thread) or if a noexcept specification is violated (see Item 14), local objects may not be destroyed, and if std::abort or an exit function (i.e., std::_Exit, std::exit, or std::quick_exit) is called, they definitely won’t be.

2 This implementation is not required by the Standard, but every Standard Library implementation I’m familiar with employs it.

3 To create a full-featured make_unique with the smallest effort possible, search for the standardization document that gave rise to it, then copy the implementation you’ll find there. The document you want is N3656 by Stephan T. Lavavej, dated 2013-04-18.

4 In practice, the value of the weak count isn’t always equal to the number of std::weak_ptrs referring to the control block, because library implementers have found ways to slip additional information into the weak count that facilitate better code generation. For purposes of this Item, we’ll ignore this and assume that the weak count’s value is the number of std::weak_ptrs referring to the control block.

				35.1.2.1.16  Rvalue References, Move Semantics, and Perfect Forwarding

When you first learn about them, move semantics and perfect forwarding seem pretty straightforward:

    Move semantics makes it possible for compilers to replace expensive copying operations with less expensive moves. In the same way that copy constructors and copy assignment operators give you control over what it means to copy objects, move constructors and move assignment operators offer control over the semantics of moving. Move semantics also enables the creation of move-only types, such as std::unique_ptr, std::future, and std::thread.

    Perfect forwarding makes it possible to write function templates that take arbitrary arguments and forward them to other functions such that the target functions receive exactly the same arguments as were passed to the forwarding functions.

Rvalue references are the glue that ties these two rather disparate features together. They’re the underlying language mechanism that makes both move semantics and perfect forwarding possible.

The more experience you have with these features, the more you realize that your initial impression was based on only the metaphorical tip of the proverbial iceberg. The world of move semantics, perfect forwarding, and rvalue references is more nuanced than it appears. std::move doesn’t move anything, for example, and perfect forwarding is imperfect. Move operations aren’t always cheaper than copying; when they are, they’re not always as cheap as you’d expect; and they’re not always called in a context where moving is valid. The construct “type&&” doesn’t always represent an rvalue reference.

No matter how far you dig into these features, it can seem that there’s always more to uncover. Fortunately, there is a limit to their depths. This chapter will take you to the bedrock. Once you arrive, this part of C++11 will make a lot more sense. You’ll know the usage conventions for std::move and std::forward, for example. You’ll be comfortable with the ambiguous nature of “type&&”. You’ll understand the reasons for the surprisingly varied behavioral profiles of move operations. All those pieces will fall into place. At that point, you’ll be back where you started, because move semantics, perfect forwarding, and rvalue references will once again seem pretty straightforward. But this time, they’ll stay that way.

In the Items in this chapter, it’s especially important to bear in mind that a parameter is always an lvalue, even if its type is an rvalue reference. That is, given

void f(Widget&& w);

the parameter w is an lvalue, even though its type is rvalue-reference-to-Widget. (If this surprises you, please review the overview of lvalues and rvalues that begins here.)

					35.1.2.1.16.1  Understand std::move and std::forward.

It’s useful to approach std::move and std::forward in terms of what they don’t do. std::move doesn’t move anything. std::forward doesn’t forward anything. At runtime, neither does anything at all. They generate no executable code. Not a single byte.

std::move and std::forward are merely functions (actually function templates) that perform casts. std::move unconditionally casts its argument to an rvalue, while std::forward performs this cast only if a particular condition is fulfilled. That’s it. The explanation leads to a new set of questions, but, fundamentally, that’s the complete story.

To make the story more concrete, here’s a sample implementation of std::move in C++11. It’s not fully conforming to the details of the Standard, but it’s very close.

template<typename T>                       // in namespace std
typename remove_reference<T>::type&&
move(T&& param)
{
  using ReturnType =                       // alias declaration;
    typename remove_reference<T>::type&&;  // see Item 9

  return static_cast<ReturnType>(param);
}

I’ve highlighted two parts of the code for you. One is the name of the function, because the return type specification is rather noisy, and I don’t want you to lose your bearings in the din. The other is the cast that comprises the essence of the function. As you can see, std::move takes a reference to an object (a universal reference, to be precise—see Item 24) and it returns a reference to the same object.

The “&&” part of the function’s return type implies that std::move returns an rvalue reference, but, as Item 28 explains, if the type T happens to be an lvalue reference, T&& would become an lvalue reference. To prevent this from happening, the type trait (see Item 9) std::remove_reference is applied to T, thus ensuring that “&&” is applied to a type that isn’t a reference. That guarantees that std::move truly returns an rvalue reference, and that’s important, because rvalue references returned from functions are rvalues. Thus, std::move casts its argument to an rvalue, and that’s all it does.

As an aside, std::move can be implemented with less fuss in C++14. Thanks to function return type deduction (see Item 3) and to the Standard Library’s alias template std::remove_reference_t (see Item 9), std::move can be written this way:

template<typename T>                          // C++14; still in
decltype(auto) move(T&& param)                // namespace std
{
  using ReturnType = remove_reference_t<T>&&;
  return static_cast<ReturnType>(param);
}

Easier on the eyes, no?

Because std::move does nothing but cast its argument to an rvalue, there have been suggestions that a better name for it might have been something like rvalue_cast. Be that as it may, the name we have is std::move, so it’s important to remember what std::move does and doesn’t do. It does cast. It doesn’t move.

Of course, rvalues are candidates for moving, so applying std::move to an object tells the compiler that the object is eligible to be moved from. That’s why std::move has the name it does: to make it easy to designate objects that may be moved from.

In truth, rvalues are only usually candidates for moving. Suppose you’re writing a class representing annotations. The class’s constructor takes a std::string parameter comprising the annotation, and it copies the parameter to a data member. Flush with the information in Item 41, you declare a by-value parameter:

class Annotation {
public:
  explicit Annotation(std::string text);  // param to be copied,
  …                                       // so per Item 41,
};                                        // pass by value

But Annotation’s constructor needs only to read text’s value. It doesn’t need to modify it. In accord with the time-honored tradition of using const whenever possible, you revise your declaration such that text is const:

class Annotation {
public:
  explicit Annotation(const std::string text);
  …
};

To avoid paying for a copy operation when copying text into a data member, you remain true to the advice of Item 41 and apply std::move to text, thus producing an rvalue:

class Annotation {
public:
  explicit Annotation(const std::string text)
  : value(std::move(text))  // "move" text into value; this code
  { … }                     // doesn't do what it seems to!
  
  …

private:
  std::string value;
};

This code compiles. This code links. This code runs. This code sets the data member value to the content of text. The only thing separating this code from a perfect realization of your vision is that text is not moved into value, it’s copied. Sure, text is cast to an rvalue by std::move, but text is declared to be a const std::string, so before the cast, text is an lvalue const std::string, and the result of the cast is an rvalue const std::string, but throughout it all, the constness remains.

Consider the effect that has when compilers have to determine which std::string constructor to call. There are two possibilities:

class string {            // std::string is actually a 
public:                   // typedef for std::basic_string<char>
  …
  string(const string& rhs);    // copy ctor
  string(string&& rhs);         // move ctor
  …
};

In the Annotation constructor’s member initialization list, the result of std::move(text) is an rvalue of type const std::string. That rvalue can’t be passed to std::string’s move constructor, because the move constructor takes an rvalue reference to a non-const std::string. The rvalue can, however, be passed to the copy constructor, because an lvalue-reference-to-const is permitted to bind to a const rvalue. The member initialization therefore invokes the copy constructor in std::string, even though text has been cast to an rvalue! Such behavior is essential to maintaining const-correctness. Moving a value out of an object generally modifies the object, so the language should not permit const objects to be passed to functions (such as move constructors) that could modify them.

There are two lessons to be drawn from this example. First, don’t declare objects const if you want to be able to move from them. Move requests on const objects are silently transformed into copy operations. Second, std::move not only doesn’t actually move anything, it doesn’t even guarantee that the object it’s casting will be eligible to be moved. The only thing you know for sure about the result of applying std::move to an object is that it’s an rvalue.

The story for std::forward is similar to that for std::move, but whereas std::move unconditionally casts its argument to an rvalue, std::forward does it only under certain conditions. std::forward is a conditional cast. To understand when it casts and when it doesn’t, recall how std::forward is typically used. The most common scenario is a function template taking a universal reference parameter that is to be passed to another function:

void process(const Widget& lvalArg);     // process lvalues
void process(Widget&& rvalArg);          // process rvalues

template<typename T>                     // template that passes
void logAndProcess(T&& param)            // param to process
{
  auto now =                             // get current time
    std::chrono::system_clock::now();

  makeLogEntry("Calling 'process'", now);
  process(std::forward<T>(param));
}

Consider two calls to logAndProcess, one with an lvalue, the other with an rvalue:

Widget w;

logAndProcess(w);                  // call with lvalue
logAndProcess(std::move(w));       // call with rvalue

Inside logAndProcess, the parameter param is passed to the function process. process is overloaded for lvalues and rvalues. When we call logAndProcess with an lvalue, we naturally expect that lvalue to be forwarded to process as an lvalue, and when we call logAndProcess with an rvalue, we expect the rvalue overload of process to be invoked.

But param, like all function parameters, is an lvalue. Every call to process inside logAndProcess will thus want to invoke the lvalue overload for process. To prevent this, we need a mechanism for param to be cast to an rvalue if and only if the argument with which param was initialized—the argument passed to logAndProcess—was an rvalue. This is precisely what std::forward does. That’s why std::forward is a conditional cast: it casts to an rvalue only if its argument was initialized with an rvalue.

You may wonder how std::forward can know whether its argument was initialized with an rvalue. In the code above, for example, how can std::forward tell whether param was initialized with an lvalue or an rvalue? The brief answer is that that information is encoded in logAndProcess’s template parameter T. That parameter is passed to std::forward, which recovers the encoded information. For details on exactly how that works, consult Item 28.

Given that both std::move and std::forward boil down to casts, the only difference being that std::move always casts, while std::forward only sometimes does, you might ask whether we can dispense with std::move and just use std::forward everywhere. From a purely technical perspective, the answer is yes: std::forward can do it all. std::move isn’t necessary. Of course, neither function is really necessary, because we could write casts everywhere, but I hope we agree that that would be, well, yucky.

std::move’s attractions are convenience, reduced likelihood of error, and greater clarity. Consider a class where we want to track how many times the move constructor is called. A static counter that’s incremented during move construction is all we need. Assuming the only non-static data in the class is a std::string, here’s the conventional way (i.e., using std::move) to implement the move constructor:

class Widget {
public:
  Widget(Widget&& rhs)
  : s(std::move(rhs.s))
  { ++moveCtorCalls; }

  …

private:
  static std::size_t moveCtorCalls;
  std::string s;
};

To implement the same behavior with std::forward, the code would look like this:

class Widget {
public:
  Widget(Widget&& rhs)                      // unconventional,
  : s(std::forward<std::string>(rhs.s))     // undesirable
  { ++moveCtorCalls; }                      // implementation

  …

};

Note first that std::move requires only a function argument (rhs.s), while std::forward requires both a function argument (rhs.s) and a template type argument (std::string). Then note that the type we pass to std::forward should be a non-reference, because that’s the convention for encoding that the argument being passed is an rvalue (see Item 28). Together, this means that std::move requires less typing than std::forward, and it spares us the trouble of passing a type argument that encodes that the argument we’re passing is an rvalue. It also eliminates the possibility of our passing an incorrect type (e.g., std::string&, which would result in the data member s being copy constructed instead of move constructed).

More importantly, the use of std::move conveys an unconditional cast to an rvalue, while the use of std::forward indicates a cast to an rvalue only for references to which rvalues have been bound. Those are two very different actions. The first one typically sets up a move, while the second one just passes—forwards—an object to another function in a way that retains its original lvalueness or rvalueness. Because these actions are so different, it’s good that we have two different functions (and function names) to distinguish them.
Things to Remember

    std::move performs an unconditional cast to an rvalue. In and of itself, it doesn’t move anything.

    std::forward casts its argument to an rvalue only if that argument is bound to an rvalue.

    Neither std::move nor std::forward do anything at runtime.


					35.1.2.1.16.2  
					35.1.2.1.16.3  
					35.1.2.1.16.4  
					35.1.2.1.16.5  
					35.1.2.1.16.6  
					35.1.2.1.16.7  


				35.1.2.1.17  
				35.1.2.1.18  
				35.1.2.1.19  
				35.1.2.1.20  
				35.1.2.1.21  
				35.1.2.1.22  
				35.1.2.1.23  
				35.1.2.1.24  
				35.1.2.1.25  
				35.1.2.1.26  
				35.1.2.1.27  
				35.1.2.1.28  
				35.1.2.1.29  
				35.1.2.1.30  
				35.1.2.1.31  
			35.1.2.2




		35.1.3
	35.2

36. Youtube course https://www.youtube.com/watch?v=8jLOx1hD3_o&t=25s , c++ with visual Studio code

    36.1 getting started 
a. in vscode extensions (shift+cmd+x), search c++ by Microsoft and Installing
b. setup compiler. verify you have g++ and clang++ installed (clang comes w/ xcode) then terminal, configure tasks, choose g++ (later repeat for clang++)
tasks.json will open up w/ defaults 
see:
[i500695@WYLQRXL9LQ:2022-07-03 18:31:43:~/work/code/CPP/tutorial:]2036$ ls -a .vscode/
./		../		launch.json	tasks*		tasks.dSYM/	tasks.json

change label, add -std= and modify what to compile (all .cpp) and target (main)
{
			"type": "cppbuild",
			"label": "Apple clang version 13.1.6",
			"command": "/usr/bin/clang++",
			"args": [
				"-fdiagnostics-color=always",
				"-g",
				"-std=c++20",
				"${workspaceFolder}//*.cpp",
				"-o",
				"${fileDirname}/main"
			],
			"options": {
				"cwd": "${fileDirname}"
			},
			"problemMatcher": [
				"$gcc"
			],
			"group": "build",
			"detail": "compiler: /usr/bin/clang++"
		}
c. to configure extension do cmd+p (command pallette) search extension c/c++ click settings (wheel) 

d. online compilers 
https://wandbox.org/

e. all the configuration for c++-20 is saved here, /Users/i500695/work/code/CPP/c++20vscodetemplate
This folder is a template for new projects 
actual configuration in: .vscode/tasks.json 

    36.2 C++ basics

        36.2.1 iostream and main
iostream for input/output 
main - entry point to program

        36.2.2 comments
//online
//
/*
multi 
line
  */
        36.2.3 Errors and warnings


            36.2.3.1 Compilation time errors
fail Compilation
            36.2.3.2 runtime errors
Compilation works but unexpected behavior and/or crashes

            36.2.3.3 warnings

            36.2.3.4
        36.2.4 statements and functions
a statement is a basic unit of execution 
ends with a ;
a c++ program is a set of statements
statements are executed in order top to buttom

a function is a block of code that takes arguments and returns something 
a function must be defined before its called  

        36.2.5 IO
abstraction of OS output/input/error file-descriptors (0,1,2). so cout/cin/cerr (also clog prints logs to console)

        36.2.6 execution and memory model
see note: c++ execution and memory model 

        36.2.7 core language vs Standard library vs STL 
- core language , c++ language itself
- Standard library, iostream, string, and more libraries 
- STL, part of the Standard-library. It's a subset that uses templates and provides collections, iterators and algorithms 

        36.2.8 Variable types 
int, short, long int for integers (32,8 and 64 bits signed. there's also unsigned version)
double, float (32/64 bit precision floating-point numbers)
char, characters (8 bit)
void, no type 
auto, auto deduce type 

number systems:
- binary 
- octal
- hexadecimal
void numberSystemsFourteen(){
    int n1 = 14; //decimal
    int n2 = 016; //octal
    int n3 = 0x0e; //hexadecimal
    int n4 = 0b00001110; //c++-14 binary
    cout<<"14 as decimal "<<n1<<endl;
    cout<<"14 as octal "<<n2<<endl;
    cout<<"14 as hexadecimal "<<n3<<endl;
    cout<<"14 as binary "<<n4<<endl;
}

- Braces initialization 
void bracedInit() {
    int garbageVal;
    int initToZero{};
    int initToTen{10};
    int initFromExpression{initToTen+initToZero};
    // wontCompileBCInitFromUndeclared{foo+bar};
    // int initWithNarrowingConversion{3.2}; //  warning: implicit conversion from 'double' to 'int' changes value from 3.2 to 3 [-Wliteral-conversion]
}

- functional initialization, () less advisable as it implicitly casts 
e.g.
    // int initWithNarrowingConversion(3.2); //  will silently cast to 2

- assignment initialization 
e.g.
int var = 3;

- memory size 
  sizeof(int)
  sizeof(myvar)
  

            36.2.8.1 Floating
Uses IEEE_754 number system  

use f suffix for float number, L for long double
void floatingPoint() {
    float n1{1.101f};
    double n2{1.1012354};
    long double n3{1.101234234234234234234234234234234234234234234234234234234234234234234234L};
    cout<<"sizeof float "<<sizeof(float)<<endl;
    cout<<"sizeof double "<<sizeof(double)<<endl;
    cout<<"sizeof long double "<<sizeof(long double)<<endl;
}

run:
sizeof float 4
sizeof double 8
sizeof long double 8

            36.2.8.2 Booleans
true/false values 
take 1 byte in memory (although 1 bit is enough)

            36.2.8.3 characters and strings 
characters are encoded using ASCII 
char A = 65; 
int Avalue = static_cast<int>(A);

code:
           void asciiEncoding(){
    char a = 'a';
    char b{'b'};
    char A = 65;
    cout<<"char a "<<a<<", A "<<A<<", values: a="<<static_cast<int>(a)<<", A="<<static_cast<int>(A)<<endl;
} 
            36.2.8.4 auto
compiler deduction for types 

            36.2.8.5
        36.2.9 assignments 

int num{9};
num=10;

        36.2.10 Operations 
+-*/% etc
they have precedence, to make explicit use () 

++, -- increment/decrement
can be done post or prior 
x++ (use x then increment)
++x (increment then use x )

Compound operators 
+=, /=, -= etc 
x+=5, x is incremented by 5 and result is assigned to x
        36.2.11 comparisons operators
==, >=, >, < != etc 

&& and
|| or 
! not 
^ xor 


        36.2.12 output formatting 
all are std: namespace
endl (like /n) newline
flush (flush write buffer to output device)

setw set width
right, left - justify right left
setfill - set a fill character (defaults to space)
example:
auto column_width = 20;
std::cout<<std::right;
std::cout<<set::setw(column_width)<<"name"<<set::setw(column_width)<<"age"<<std::endl;
std::cout<<set::setw(column_width)<<"yosi"<<set::setw(column_width)<<"46"<<std::endl;


        36.2.13
    36.3

    36.3
37.

